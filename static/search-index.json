[
  {
    "url": "Cheat_Sheets/ansi_color_codes.html",
    "content": "---\nid: ansi_color_codes\naliases: []\ntags: []\ndescription: A list of all colors in ansi\ntitle: Ansi Colors\n---\n\n# Regular Colors\n\n| Value    | Color  |\n| -------- | ------ |\n| \\e[0;30m | Black  |\n| \\e[0;31m | Red    |\n| \\e[0;32m | Green  |\n| \\e[0;33m | Yellow |\n| \\e[0;34m | Blue   |\n| \\e[0;35m | Purple |\n| \\e[0;36m | Cyan   |\n| \\e[0;37m | White  |\n\n# Bold\n\n| Value    | Color  |\n| -------- | ------ |\n| \\e[1;30m | Black  |\n| \\e[1;31m | Red    |\n| \\e[1;32m | Green  |\n| \\e[1;33m | Yellow |\n| \\e[1;34m | Blue   |\n| \\e[1;35m | Purple |\n| \\e[1;36m | Cyan   |\n| \\e[1;37m | White  |\n\n# Underline\n\n| Value    | Color  |\n| -------- | ------ |\n| \\e[4;30m | Black  |\n| \\e[4;31m | Red    |\n| \\e[4;32m | Green  |\n| \\e[4;33m | Yellow |\n| \\e[4;34m | Blue   |\n| \\e[4;35m | Purple |\n| \\e[4;36m | Cyan   |\n| \\e[4;37m | White  |\n\n# Background\n\n| Value  | Color  |\n| ------ | ------ |\n| \\e[40m | Black  |\n| \\e[41m | Red    |\n| \\e[42m | Green  |\n| \\e[43m | Yellow |\n| \\e[44m | Blue   |\n| \\e[45m | Purple |\n| \\e[46m | Cyan   |\n| \\e[47m | White  |\n\n# High Intensty\n\n| Value    | Color  |\n| -------- | ------ |\n| \\e[0;90m | Black  |\n| \\e[0;91m | Red    |\n| \\e[0;92m | Green  |\n| \\e[0;93m | Yellow |\n| \\e[0;94m | Blue   |\n| \\e[0;95m | Purple |\n| \\e[0;96m | Cyan   |\n| \\e[0;97m | White  |\n\n# Bold High Intensty\n\n| Value    | Color  |\n| -------- | ------ |\n| \\e[1;90m | Black  |\n| \\e[1;91m | Red    |\n| \\e[1;92m | Green  |\n| \\e[1;93m | Yellow |\n| \\e[1;94m | Blue   |\n| \\e[1;95m | Purple |\n| \\e[1;96m | Cyan   |\n| \\e[1;97m | White  |\n\n# High Intensty backgrounds\n\n| Value     | Color  |\n| --------- | ------ |\n| \\e[0;100m | Black  |\n| \\e[0;101m | Red    |\n| \\e[0;102m | Green  |\n| \\e[0;103m | Yellow |\n| \\e[0;104m | Blue   |\n| \\e[0;105m | Purple |\n| \\e[0;106m | Cyan   |\n| \\e[0;107m | White  |\n\n# Reset\n\n| Value | Color  |\n| ----- | ------ |\n| \\e[0m | Reset  |\n\n\n"
  },
  {
    "url": "Cheat_Sheets/Git.html",
    "content": "---\nid: Git\naliases: []\ntags: []\ndescription: A cheatsheet for most used git commands\ntitle: Git\n---\n\n### Create ssh key and link it to github\n| command | Description |\n| ---- | ---- |\n| ssh-keygen -t ed25519 -C \"your_email@example.com\" | You can also specify a different key type by replacing rsa with ed25519 or ecdsa if you prefer. |\n|  |  |\n- Now go to the location where the saved  ssh key is. by default at ~/.ssh/.it'll be named id_ed25519.pub. Depending upon the type of key it may be difficult.\n- Copy it and go to your Github.\n- Go to settings/SSH and GPG keys. Click on new ssh key and paste it.\n\nRun\n~~~\n$ git config --global user.email \"you@example.com\"\n$ git config --global user.name \"Your Name\"\n~~~\n\nto set your account's default identity.\nOmit `--global` to set the identity only in this repository.\n\n### **Git Commands**\n\n| Command | Decription |\n| --------------------------------------------------------------------- | --------------------------------- |\n| `git init`                                                            | Initialize a local Git repository |\n| `git clone ssh://git@github.com/[username]/[repository-name].git`     | Create a local copy of a remote repository |\n| `git status`                                                          | Check status |\n| `git add [file-name.txt]`                                             | Add a file to the staging area |\n| `git add -A`                                                          | Add all new and changed files to the staging area |\n| `git commit -m \"[commit message]\"`                                    | Commit changes |\n| `git rm -r [file-name.txt]`                                           | Remove a file (or folder) |\n| `git branch`                                                          | List branches (the asterisk denotes the current branch) |\n| `git branch -a`                                                       | List all branches (local and remote) |\n| `git branch [branch name]`                                            | Create a new branch |\n| `git branch -d [branch name]`                                         | Delete a branch |\n| `git push origin --delete [branch name]`                              | Delete a remote branch |\n| `git checkout -b [branch name]`                                       | Create a new branch and switch to it |\n| `git checkout -b [branch name] origin/[branch name]`                  | Clone a remote branch and switch to it |\n| `git branch -m [old branch name] [new branch name]`                   | Rename a local branch |\n| `git checkout [branch name]`                                          | Switch to a branch |\n| `git checkout -`                                                      | Switch to the branch last checked out |\n| `git checkout -- [file-name.txt]`                                     | Discard changes to a file |\n| `git merge [branch name]`                                             | Merge a branch into the active branch |\n| `git merge [source branch] [target branch]`                           | Merge a branch into a target branch |\n| `git stash`                                                           | Stash changes in a dirty working directory |\n| `git stash clear`                                                     | Remove all stashed entries |\n| `git push origin [branch name]`                                       | Push a branch to your remote repository |\n| `git push -u origin [branch name]`                                    | Push changes to remote repository (and remember the branch) |\n| `git push`                                                            | Push changes to remote repository (remembered branch) |\n| `git push origin --delete [branch name]`                               | Delete a remote branch |\n| `git pull`                                                            | Update local repository to the newest commit |\n| `git pull origin [branch name]`                                       | Pull changes from remote repository |\n| `git remote add origin ssh://git@github.com/[username]/[repository-name].git` | Add a remote repository |\n| `git remote set-url origin ssh://git@github.com/[username]/[repository-name].git` | Set a repository's origin branch to SSH |\n| `git log`                                                             | View changes |\n| `git log --summary`                                                   | View changes (detailed) |\n| `git log --oneline`                                                   | View changes (briefly) |\n| `git diff [source branch] [target branch]`                            | Preview changes before merging |\n\n### *gh repo commands*\n`gh repo create [<name>] [flags]`\n\n| command | Decription |\n| ----------------------------------| ----------------------------------------------|\n| `--add-readme`                    | Add a README file to the new repository        |\n| `-c, --clone`                     | Clone the new repository to the current directory |\n| `-d, --description <string>`      | Description of the repository                  |\n| `--disable-issues`                | Disable issues in the new repository          |\n| `--disable-wiki`                  | Disable wiki in the new repository            |\n| `-g, --gitignore <string>`        | Specify a gitignore template for the repository |\n| `-h, --homepage <URL>`            | Repository home page URL                      |\n| `--include-all-branches`          | Include all branches from template repository |\n| `--internal`                      | Make the new repository internal              |\n| `-l, --license <string>`          | Specify an Open Source License for the repository |\n| `--private`                       | Make the new repository private               |\n| `--public`                        | Make the new repository public                |\n| `--push`                          | Push local commits to the new repository      |\n| `-r, --remote <string>`           | Specify remote name for the new repository    |\n| `-s, --source <string>`           | Specify path to local repository to use as source |\n| `-t, --team <name>`               | The name of the organization team to be granted access |\n| `-p, --template <repository>`     | Make the new repository based on a template repository |\n\nChanges made:\n1. Aligned the table headers and content properly using consistent spacing\n2. Added proper separators (`|`) between columns\n3. Fixed the alignment of flags and their descriptions\n4. Added a blank description for the main command to maintain table structure\n5. Ensured consistent formatting of flags (with proper spacing around dashes)\n\nExamples\n\n- create a repository interactively\n`gh repo create`\n\n- create a new remote repository and clone it locally\n`gh repo create my-project --public --clone`\n\n- create a remote repository from the current directory\n`gh repo create my-project --private --source=. --remote=upstream`\n\nMore Commands: \n[git-docs](https://git-scm.com/docs/git)\n[gh repo](https://cli.github.com/manual/gh_repo)\n"
  },
  {
    "url": "Cheat_Sheets/ssh_android_to_pc.html",
    "content": "---\nid: ssh_android_to_pc\naliases: []\ntags: []\ndescription: step to ssh into termux\ntitle: ssh_android_to_pc\n---\n\n1. Install Termux in android using F-droid\n2. Upgrade softwares.\n```\n$ pkg update\n$ pkg upgrade\n```\n3. install openssh\n```\n$ pkg install openssh\n```\n4. setup a password\n```\n$ passwd\n```\n5. Start an ssh server\n```\n$ sshd  // start an ssh server\n$ ifconfig // know your phone inet ip\n```\n6. In your pc/laptop. \n```\n$ ssh <ipaddress of your phone> -p 8022\n```\n7. Congrats. you have ssh'd into your phone.\n8. When done with it\n```\n$ pkill sshd\n```\n\n\n### Troubleshooting\n- Waiting too long - try to ping that ip, Recheck the ip address, reboot your phone.\n\n"
  },
  {
    "url": "Courses/Boot_Dev/HTTP.html",
    "content": "---\nid: HTTP\naliases: []\ntags: []\n---\n\nHTTP (Hypertext Transfer Protocol) is a language for computer to communicate with each other on web. At heart HTTP sits above TCP and is therefore a request-response model.\n\nThe \"requesting\" computer, also known as \"client\", asks another computer for some information. That computer, \"the server\" send back a response with the information that the client asked for.\n\n## HTTP Urls\nA URL(uniform resource locator), is essentially the address of the server on the internet.\n``` \nhttp://example.com \n```\nthe ==http://== at the starting tells us about the Protocol by which the data is being transferred.\n\n## JS fetch api\nIn JS we use its fetch api to do http requests.\n``` Javascript\nconst response = await fetch(url, settings)\nconst responseData = await response.json()\n```\n\n- ==response== is the data we receive from the server.\n- ==url== is the endpoint from where we are fetching the data.\n- ==settings== is an object containing some request-specific setting.\n- ==await== is a JS keyword for telling it to wait till the response arrives.\n- ==response.json()== converts the response data from server into json.\n\n## Web Client\nA Web client is a computer that sends the request of data to a server. It can be any computer like a phone, pc, game console, fridge or even a server(a server sending req to another server is a client as its just a name assigned to a computer that requests stuff).\n\nA web client is the front-end. \n\n## Web Server\nA server is a computer that serves data to a client upon requesting to a web client.\n\nThe server has a port to listen the request from the client and do some computation and send the appropriate response to the client.\n\nWhile the Web client is the front-end, the Web server is the back-end.\n\n## Web Addresses\nIn real world, like we use house addresses to navigate to someones house. Similarly we have IP (internet Protocol) that is kind of the address of a computer.\n\nAn IP address is a numerical label that servers two putpose:\n1. Location Addressing\n2. Network identification\n\n### Domain names and ip addresses\nEach device connected to the internet has a unique IP address. The router refer to this IP address to send and receive requests.\n\n### DNS \nWhen we browse the internet and go a website like ==google.com== before sending the fetch request, the url gets converted to a specific IP address that is stored in the DNS (it has convertion table for website to their IP addresses). \n\nIn JS we can use its inbuilt URL to get hostname of an address\n```Javascript\nconst urlObj = new URL('https://boot.dev/learn/learn-python')\nconst urlObj.hostname // boot.dev\n```\n\n[**DNS**](https://en.wikipedia.org/wiki/Domain_Name_System) or \"Domain Name System\", is like a phonebook of all the hostnames mapped to their IP address. DNS \"resolves\" these domain names to find the associated \"IP Address\" so the web clients can load the resources for the specific address.\n\nWhen we make a request to a specific domain name like ==example.com==.\nThere are 4 DNS servers involved - \n- DNS recursor - It receives request from the client and makes additional requests to satisfy clients DNS query.\n- Root nameserver - It serves as a reference to other more specific location.\n- TDL nameserver - It extract the top level domain(.com, .gov, .jp, .tv, etc).\n- Authoritative nameserver - In it the specific name is looked up and the IP address will then be returned to DNS server that made the initial request. It is the server that contains the DNS resource records.\n\n### Sub Domains\nIt's the prefix that is added to domain name allowing a domain to route network traffic to some other server where the data is stored.\nExample- \n==www.netflix.com== is the domain name where we can watch netflix show.\n==www.jobs.netflix.com== is the domain name of the site where we can see latest job posting available at netflix. Here ==jobs== is the sub-domain.\n\n## URI\nA URI, Uniform resource identifier, is a unique character sequence that identifies a resource that is (almost always) access by the internet.\nURI are of two types:\n- URL\n- URN\n\n[URI](https://storage.googleapis.com/qvault-webapp-dynamic-assets/course_assets/dcBoy2F.png)\n\n### Parts of a URL\nThere are 8 main parts of a url though not always all 8 are present.\n[part of URL](https://storage.googleapis.com/qvault-webapp-dynamic-assets/course_assets/7obhZ2w.png)\n\n#### The Protocols\nThe 'protocols' or the 'scheme' is the first component of the url. It's purpose is to define the rules by which the data being communicated is displayed, encoded and formatted.\n\nSome example of different protocols\n- HTTP - Hypertext Transfer Protocol\n- FTP - File Transfer Protocol\n- SMTP - Secure Mail Transfer Protocol\n- HTTPS - Hypertext Transfer Protocol Secure\n\n#### Ports\nThe Port in the URL is a virtual hub to which the data is transmitted to. The ports are handled by the operating system. There are 2^16 (0 -> 65535) ports. \nWhen you connect to a computer on network, you are connected to a specific port on that computer. If not specifically mentioned in the URL, then the system uses default ports assigned (==$ cat /etc/services== on any unix system). For HTTP - 80, HTTPS - 443. When you aren't using default port, you have to specify in the URL like developers generally use port ==8080== as a testing port that is HTTP-ALT. \n\n#### URL paths\nIn early days of internet and even today, many web servers hosted raw file over the internet and to access different pages we would just change the path just like we do on out computers. \n\nLike if i host my ==docs== directory. it would search index.html in /docs. We can see other files in the docs folder by just appending the path like i have another page that inside ==http== directory inside of ==docs==. We would just append /docs/http. The server will host index.html inside http directory.\n\nMost modern web servers don't use simple mapping of ==URL PATH -> file path==. Since URL is just a string so we can just map it to anything. So generally we just use them like flags and show the data depending upon that.\n\n#### Query Parameters\nQuery parameters are often used to change page's contents or market analysis. like ==https://google.com/search?q=hello== will search hello for you.\n\n## Async\nAsynchronous code allow the execution of the code and not have to wait for that async operation to finish. Like in a website, when we fetch data it may take more time if we are hitting many different service. We don't the website to be unusable for that long. So we do fetch operation asynchronously and let the server send data and fill the data on the site afterwards the page has rendered.\n\n#### Promises in JS\nThe ==Promise Object== in JS represent eventual fulfilment or rejection of our promise. While the promise is being fulfilled or rejected other part of code will execute.\n``` Javascript\nconst promise = new Promise((resolve, reject) => {\n  setTimeout(() => {\n    if (getRandomBool()) {\n      resolve(\"resolved!\")\n    } else {\n      reject(\"rejected!\")\n    }\n  }, 1000)\n})\n\nfunction getRandomBool(){\n  return Math.random() < .5\n}\n```\n\nwhile the ==await== keyword can be used place ==.then()== to resolve a promise, the ==async== keyword is used in place of ==new Promise== to create a new promise.\n\n## Headers\nAn HTTP header allows the client and server to pass additional information with each request or response. They are just key-value pair that pass additional metadata like type of content needed, operating system, the type of client, etc.\n\n## HTTP Methods\nHTTP defines a set of methods that we can use everytime while we make a request to the server to make it a do a specific thing.\n\nMost backend developers write their server code that the methods correspond with \"CRUD\" actions.\nC - Create\nR - Read\nU - Update\nD - Delete\n\nDue to this the 3 most common HTTP methods are:\nPOST - Create\nGET - Read\nPUT - Update\nDELETE - Delete\n\n### GET\nIt is used to \"get\" or fetch some data from the server. GET requests are safe methods as they dont alter the state of the server.\n\n``` Javascript\nawait fetch(url, {\n  method: 'GET',\n  mode: 'cors',\n  headers: {\n    'sec-ch-ua-platform': 'macOS'\n  }\n})\n\n```\n\n### POST\nIt is used to \"Post\" or send or create data to the server. It is an unsafe method as it alters the state of the server.\n\n```Javascript\nawait fetch(url, {\n  method: 'POST',\n  mode: 'cors',\n  headers: {\n    'Content-Type': 'application/json'\n  },\n  body: JSON.stringify(data)\n})\n```\n\n### PUT\nIt creates a new resource or updates the resources properties.\n\n```Javascript\nawait fetch(url, {\n   method: 'PUT',\n   mode: 'cors',\n   headers: {\n   'Content-Type': 'application/json'\n   },\n   body: JSON.stringify(data)\n})\n```\n\n#### POST VS PUT \nThe main difference between POST and PUT is that PUT is [idempotent](https://developer.mozilla.org/en-US/docs/Glossary/Idempotent) - it doesn't have side effects if we send the same PUT requests repeatedly.\nOn the other hand POST is not idempotent as sending repeat POST requests can create copies of the same data.\n\n### DELETE\nIt deletes the specified resource.\n\n```Javascript\n// This deletes the location with ID: 52fdfc07-2182-454f-963f-5f0f9a621d72\nconst url = 'https://api.boot.dev/v1/courses_rest_api/learn-http/locations/52fdfc07-2182-454f-963f-5f0f9a621d72'\n\nawait fetch(url, {\n  method: 'DELETE',\n  mode: 'cors'\n})\n```\n### PATCH\nPatch is intended to partially modify a resource. \n\nMany servers even if they support partial updates will still use PUT instead of PUT as PUT is generally more known than PATCH.\n### HTTP status code\n- ==100-199==: informational responses\n- ==200-299==: Successful responses\n- ==300-399==: Redirection message.\n- ==400-499==: Client Error\n- ==500-599==: Server Error\n\nSome common status codes\n- 200 - OK\n- 201 - Created. Successful POST.\n- 301 - Moved Permanently\n- 400 - Bad request\n- 401 - Unauthorized\n- 404 - Not found\n- 500 - Internal Server Error\n\n#### [Website to look up status codes](https://github.com/httpcats/http.cat)\n\n## REST API\n[Representational State Transfer or REST](https://developer.mozilla.org/en-US/docs/Glossary/REST) follow a loose set of rules that make it easy to build reliable and predictable web API's. REST is conventions how HTTP should be used.\n\n**Seperate and Agnostic** - In it resources are transferred via well-recognized, language-agnostic client/server interactions. A RESTful style means that implementaton of both client/server can be done independently as long as some standards are established.\n**Stateless** - The server doesnt need to know the state of the client, nor does the client need to care what state the server is in. Statelessness in REST is enforced by interacting with resources instead of command.\n\n```\nhttps://api.github.com/repos/OWNER/REPO - to get info about the repo\nhttps://api.github.com/repos/OWNER/REPO/commits - to get total commits of a repo\n```\n\n## HTTPS - HTTP Secure\nExtension of HTTP. It uses [Transport Layer Security](https://en.wikipedia.org/wiki/Transport_Layer_Security) (TLS) or Secure Sockets Layer(SSL) to encrypt data for secure communication over networks.\n\n**How it Works(On a really higher level)**:\n- Client sends a request to the server.\n- Server sends a public key to the client key and keeps the private key. The public key can only encrypt and private key and only decrypt.\n- Client and server negotiate a symmetric key(can both encrypt and decrypt) as the server response should be encrypted too.\n- Client sends encrypted HTTP request.\n- Server decrypts it and process it.\n- Server sends encrypted response to the client.\n- Client decrypts the response.\n\n"
  },
  {
    "url": "Courses/CSES/Complete_Search.html",
    "content": "---\nid: Complete Search\naliases: []\ntags: []\ntitle: Complete Search\n---\n\nthe idea of complete search is to generate all the possible solution to the problem using brute force and then select the best solution or count the number of solutions, depending on the problem.\n\nits fine if the input is small but would give tle or mle if the input is large.\n\n## Generating subsets\n\n### Using recursive backtracking\n```cpp\nvector<int> subset;\nint n = 3;\n\nvoid search(int k) {\n    if(k == n ) {\n        cout << \"{ \";\n        for (int num : subset) cout << num << \" \";\n        cout << \"}\" << endl;\n    } else {\n        subset.push_back(k);\n        search(k + 1);\n        subset.pop_back();\n        search(k + 1);\n    }\n}\nint main() {\n    search(0); // Start with the first element (index 0)\n    return 0;\n}\n```\n\n### Using bitset\n```cpp\nvector<vector<int>> genSet(vector<int>& nums) {\n    int n = nums.size();\n    int totalSubsets = 1 << n;\n    vector<vector<int>> subsets;\n    for(int b = 0; b < totalSubsets; b++) {\n        vector<int> subset;\n        for(int i = 0; i < n;i++) {\n            if (b & (1 << i)) subset.push_back(nums[i]); // Push nums[i] instead of i\n        }\n        subsets.push_back(subset);\n    }\n    return subsets;\n}\n\n000 -> {}      // Empty subset\n001 -> {1}     // 1st element included\n010 -> {2}     // 2nd element included\n011 -> {1,2}   // 1st and 2nd elements included\n100 -> {3}     // 3rd element included\n101 -> {1,3}   // 1st and 3rd elements included\n110 -> {2,3}   // 2nd and 3rd elements included\n111 -> {1,2,3} // All elements included\n\n```\n\n## Generating Permutations\n### Using `next_permutation`\nc++ std library contains a function `next_permutation` that can be used for this\n```cpp\nvector<int> perm = {1, 2, 3};\ndo {\n    // process\n} while(next_permutation(perm.begin(), perm.end()));\n```\n\n### Using recursive backtracking\n```cpp\nvoid backtrack(vector<int>& nums, int start, vector<vector<int>>& result) {\n    if (start == nums.size()) {\n        result.push_back(nums); // Store a valid permutation\n        return;\n    }\n    \n    for (int i = start; i < nums.size(); i++) {\n        swap(nums[start], nums[i]);       // Swap current element with the start\n        backtrack(nums, start + 1, result); // Recur for next index\n        swap(nums[start], nums[i]);       // Backtrack (undo swap)\n    }\n}\n\nvector<vector<int>> generatePermutations(vector<int>& nums) {\n    vector<vector<int>> result;\n    backtrack(nums, 0, result);\n    return result;\n}\n```\n\n\n"
  },
  {
    "url": "Courses/CSES/Data_Structures.html",
    "content": "---\nid: Data Structures\naliases: []\ntags: []\ntitle: Data Structures\n---\n\n## Dynamic Arrays\nAn array whose size can be changed automatically during runtime.\n```cpp\nvector<int> vec;\nvec.push_back(5);\nvec.push_back(7);\nvec.push_back(9);\nvec.push_back(11);\n\ncout << vec[0] << endl;\ncout << vec[1] << endl;\n\n// normal for loop\nfor(int i = 0; i < vec.size(); i++) {\n    cout << vec[i] << endl;\n}\n\n//range based loop\nfor(const int& i : vec) {\n    cout << i << endl;\n}\n\n\ncout << vec.back() << endl; // 11\nvec.pop_back();\ncout << vec.back() << endl; // 9\n\n//size 10, initial value = 0\nvector<int> vec(10);\n\n//size 10, initial value = 5\nvector<int> vec(10, 5);\n```\n\n## Strings\nA dynamic arrays like vector but only contains chars.\n\n```cpp\nstring a = \"abcde\";\nstring b = a + a;\ncout << b << endl; // abcdeabcde\nb[0] = 'd';\ncout << b << endl; // dbcdeabcde\nstring c = substr(3, 4);\ncout << c << endl; // deab\n```\n\n## Set\nMaintains a collection of elements just like vector but has no duplicates.\n\nC++ has two set implementations: \n- `set` - based on a binary tree and its operations work in O(logN) time.\n- `unordered_set` - uses hashing and its operation take O(1) on average.\n\n```cpp\nset<int> s;\ns.insert(3);\ns.insert(2);\ns.insert(5);\n\ncout << s.count(3) << endl; // 1\ncout << s.count(4) << endl; // 0\n\ns.erase(3);\ns.insert(4);\ncout << s.count(3) << endl; // 0\ncout << s.count(4) << endl; // 1\n```\n\na set can be used like a vector but cant use the indexes to get the values.\n\n```cpp\nset<int> s = {2, 5, 6, 8};\ncout << s.size() << endl; // 4\n\nfor(const int& i : s) {\n    cout << i << endl;\n}\n```\n\nc++ also contains `multiset` and `unordered_multiset` that otherwise work like `set` and `unordered_set` but they can contain multiple instances of an element.\n\n```cpp\nmultiset<int> m;\nm.insert(5);\nm.insert(5);\nm.insert(5);\ncout << m.count(5) << endl; // 5\n\nm.erase(5);\ncout << m.count(5) << endl; // 0\n\n//if want to remove only one instance \ns.erase(s.find(5));\ncout << m.count(5) << endl; // 2\n```\n\n## Map\nA generalized array of key-value pairs. The structure map is based on balanced binary tree and accessing element takes O(logN) time, while the `unordered_map` uses hashing and accessing elements take O(1) time.\n\n```cpp\nmap<string, int> m;\nm['monkey'] = 4;\nm['banana'] = 3;\nm['harpsichord'] = 9;\ncout << m['banana'] << endl; // 3\n\nfor(const auto& i: m) {\n    cout << i.first << \" \" << i.second << endl;\n}\n```\n\nif the `key-value` pair are not present in the map but they are requested, the `key-value` pair is put into the map with value = 0;\n```cpp\ncout << m['hi'] << endl;\n```\n\nTo check if a key exists in a map: \n```cpp\nif(m.count(\"hi\")) {\n    // key exists\n}\n```\n\n## Bitset\nAn array whose value is either 0 or 1.\n```cpp\nbitset<10> s;\n\ns[1] = 1;\ns[3] = 1;\ns[4] = 1;\n\ncout << s[4] << endl; // 1\ncout << s[5] << endl; // 0\n\nbitset<10> s(string(\"0010011010\"));\ncout << s[4] << endl; // 1\ncout << s[5] << endl; // 0\n```\n\nthey are good cause we can to bitwise operations on them.\n\n```cpp\nbitset<10> a(string(\"0010110110\"))\nbitset<10> b(string(\"1011011000\"))\n\ncout << (a & b) << endl;\ncout << (a | b) << endl;\ncout << (a ^ b) << endl;\n```\n\n## Deque\nA queue like data structure where we can insert and pop from both ends.\n\n```cpp\ndeque<int> d;\nd.push_back(5);\nd.push_back(2);\nd.push_front(3);\n\nd.pop_back();\nd.pop_front();\n```\n\ndeque is slower than a vector but still pushing and popping are O(1) operations.\n\n## Stack\nA LIFO data structure that has two O(1) operations: pushing on top of stack and popping of the stack.\n\n```cpp\nstack<int> s;\ns.push(3);\ns.push(2);\ns.push(5);\n\ncout << s.top() << endl;\ns.pop();\ncout << s.top() << endl;\n```\n\n## Queue\nA FIFO based data structure which also has two O(1) operations: pushing at end of queue and popping from front of queue.\n\n```cpp\nqueue<int> q;\nq.push(3);\nq.push(2);\nq.push(5);\n\ncout << q.front() << endl; // 3\nq.pop();\ncout << q.front() << endl; // 2\n```\n\n## Priority queue\nA heap based data structure.\n```cpp\npriority_queue<int> q; // max heap\nq.push(3);\nq.push(5);\nq.push(7);\nq.push(2);\n\ncout << q.top() << endl; // 7\nq.pop();\nq.push(6);\ncout << q.top() << endl; // 6\n\npriority_queue<int, vector<int> , greater<int>> q; // min heap\n```\n\n## Policy based data structures\ng++ also contains some data structures that are not part of c++ std library.\n```cpp\n#include <ext/pb_ds/assoc_container.hpp>\nusing namespace __gnu_pbds;\n\ntypedef tree<int,null_type,less<int>,rb_tree_tag,tree_order_statistics_node_update> indexed_set;\nindexed_set s;\ns.insert(2);\ns.insert(3);\ns.insert(7);\ns.insert(9);\n\nauto x = s.find_by_order(2);\ncout << *x << \"\\n\"; // 7\ncout << s.order_of_key(7) << \"\\n\"; // 2\n```\n\nIf the element does not appear in the set, we get the position that the element would have in the set\n```cpp\ncout << s.order_of_key(6) << \"\\n\"; // 2\ncout << s.order_of_key(8) << \"\\n\"; // 3\n```\n\nboth work in logarithmic time.\n\n"
  },
  {
    "url": "Courses/Data_Structures_and_algorithms/backtracking.html",
    "content": "---\nid: backtracking\naliases: []\ntags: []\ntitle: backtracking\n---\n\n**Backtracking** is a systematic way to iterate through all the possible configurations of a search space. These configurations may represent all possible arrangements of objects(permutations) or all possible ways to building a collection of them(subsets).\n"
  },
  {
    "url": "Courses/Data_Structures_and_algorithms/linear_data_structure.html",
    "content": "---\nid: linear_data_structure\naliases: []\ntags: []\ntitle: linear_data_structure\n---\n\n## Linear Data Structures\n\n### Arrays\nAn arrays is linear data structure that stores elements in a contiguous space in memory. Each element in an array is identified by an index, allowing constant-time access to elements using their index.\n\nThis constant time access of element is possible due to the elements being stored in a contiguous manner. We can use pointer arithematic to find the element we wanna use with the index.\n\n```c\nint arr[10] = {1, 2, 3, 4, 5, 6, 7, 8, 9, 10};\n```\nFor example when we do `arr[5]` we are saying to give the value stored at `address of arr + (index * size of the data type) = &arr + (5 * sizeof(int))`. Due to this the complexity of getting an element of an arrays is constant.\n\n#### Properties\n- **Fixed Size** - The size of a static arrays is fixed i.e. if we have declared a static arrays of size `10`, we cannot increase the size of array and accessing the `11th element` should give an `out-of-bound` error.\n- **Contiguous memory** - Elements are stored sequentially in memory leading to constant time for finding and updating elements.\n\n#### Types of arrays\n- 1D arrays - A simple list of elements stored in a single row.\n```c\nint arr[5] = {1, 2, 3, 4, 5};\n```\n\n- 2D arrays - A matrix like data structures useful for tabular data.\n```c\nint matrix[3][3] = {\n    {1, 2, 3},\n    {4, 5, 6},\n    {7, 8, 9}\n};\n```\n\n- nD arrays - An array that has more than two dimensions.\n```c\nint arr[2][2][2];\n```\n\n## Dynamic Arrays\nA dynamic arrays is just like static arrays but they are resizable. A dynamic array maintain an underlying fixed-size arrays but doubles(depends on implementation) when it reaches capacity. \n\nDynamic arrays are heap allocated arrays that are made of three components: \n- Pointer(`&ptr`) - A pointer to a heap allocated contiguous memory block that stores the elements\n- Length(`len`) - The current number of elements stored in the array.\n- Capacity (`cap`) - The total number of elements that can be stored in the allocated memory block until reallocation is needed.\n\nSimilar to arrays, dynamic arrays can be of any dimensions.\n\nSome example of dynamic arrays are `std::vector<T> - cpp` , `Vec<T> rust` , `list - py`, etc \n\n### Some complexities\n- Peek index - O(1)\n- Update an index - O(1)\n- insert at location - beginning - O(n), middle - O(n), end - O(1) amortized\n- Resize - O(n)\n\n\n## Linked Lists\nLinked lists are linear data structures that store data in nodes that point to one another, rather than in contiguous memory locations like arrays.\n\nThe nodes of a linked list are heap allocated and are made up of two components depending upon type of linked lists -\n- **Data** - The data that must be stored\n- **Next** - The pointer to next node.\n\n![linked-lists](https://www.freecodecamp.org/news/content/images/2023/05/7.png)\n\nThe first node of the linked list is called `head` and the last one is called `tail`.\n\n### Types of linked lists\nThere are various types of linked lists:\n- Singly linked lists: In this type of linked list, the data is stored in the node and the node points to the next node.\n- Doubly linked lists: In this type of linked lists, the node contains a pointer to both its previous and next node.\n- Circular linked lists: In this type of linked lists, the last node points to the first node of the linked list.\n- Doubly Circular linked lists: In this type of lists, the node pointer contains the address of previous and next node. The last node also points to the first node and the first node points to last node.\n\n// NOTE PUT SOME COMPLEXITIES HERE.\n\n## Stack\nA Stack is a linear data structure that follows the LIFO principle i.e. the last element pushed onto the stack is the first one to pop.\n\nYou can imagine a stack as a stack of objects in real life. If we have to put something on that stack we put it on the top and if we have to remove it, we remove the top one from the stack thus following the LIFO principle.\n\n### Key Operation \n- Push - Pushing an element at top - O(1)\n- Pop - Popping an element from the top - O(1)\n- Peek - Peeking an element from the top - O(1)\n- IsEmpty - Checking if the stack is empty - O(1)\n- Size - Returning the size of stack - O(1)\n\n\n\n"
  },
  {
    "url": "Courses/Data_Structures_and_algorithms/tree.html",
    "content": "---\nid: tree\naliases: []\ntags: []\ntitle: tree\n---\n\nA **tree** is a frequently used data structure to simulate a hierarchical tree structure. Each node of the tree will have a root value and a list of references to other nodes which are called child nodes. From a graph view, a tree is defined as a directed acyclic graph which has N nodes and N - 1 edges.\n\nA **Binary Tree** is one of the most used type of tree structure. It is a tree structure in which each node has at most two child nodes.\n\n## Traverse a Tree\n\n### Pre-order Traversal\nIt is one of ways to traverse a binary tree. The order for visiting the nodes are - \n- Visit the root\n- traverse the left subtree recursively\n- traverse the right subtree recursively\n\n```mathematica\n        A\n       / \\\n      B   C\n     / \\   \\\n    D   E   F\n```\n\nthe pre order traversal of this tree would be \n\n```mathematica\nA → B → D → E → C → F\n```\n\n```cpp\n/**\n * Definition for a binary tree node.\n * struct TreeNode {\n *     int val;\n *     TreeNode *left;\n *     TreeNode *right;\n *     TreeNode() : val(0), left(nullptr), right(nullptr) {}\n *     TreeNode(int x) : val(x), left(nullptr), right(nullptr) {}\n *     TreeNode(int x, TreeNode *left, TreeNode *right) : val(x), left(left), right(right) {}\n * };\n */\nclass Solution {\npublic:  \n    vector<int> preorderTraversal(TreeNode* root) {\n        vector<int> res;\n        stack<TreeNode*> st;\n        if(!root) return res;\n        st.push(root);\n\n        while(!st.empty()) {\n            TreeNode* curr = st.top();\n            st.pop();\n            res.push_back(res);\n            \n            if(curr->left) st.push(curr->left);\n            if(curr->right) st.push(curr->right);\n        }\n    }\n};\n```\n\n### In-Order traversal\nThe order for visiting the nodes are -\n- traverse the left subtree recursively\n- Visit the root\n- traverse the right subtree recursively\n\n```mathematica\n        A\n       / \\\n      B   C\n     / \\   \\\n    D   E   F\n```\n\nthe pre order traversal of this tree would be \n\n```mathematica\nD → B → E → A → C → F\n```\n\n```cpp\n/**\n * Definition for a binary tree node.\n * struct TreeNode {\n *     int val;\n *     TreeNode *left;\n *     TreeNode *right;\n *     TreeNode() : val(0), left(nullptr), right(nullptr) {}\n *     TreeNode(int x) : val(x), left(nullptr), right(nullptr) {}\n *     TreeNode(int x, TreeNode *left, TreeNode *right) : val(x), left(left), right(right) {}\n * };\n */\nclass Solution {\npublic:  \n    vector<int> inorderTraversal(TreeNode* root) {\n        vector<int> res;\n        if(!root) return res;\n        stack<TreeNode* > st;\n        TreeNode* curr = root;\n        \n        while(curr != nullptr || !st.empty()) {\n            while(curr != nullptr) {\n                st.push(curr);\n                curr = curr->left;\n            }\n            curr = st.top();\n            st.pop();\n            res.push_back(curr->val);\n\n            curr = curr->right;\n        }\n        return res;\n    }\n};\n```\n\n### Post-Order traversal\nThe order for visiting the nodes are -\n- traverse the left subtree recursively\n- traverse the right subtree recursively\n- Visit the root\n\n```mathematica\n        A\n       / \\\n      B   C\n     / \\   \\\n    D   E   F\n```\n\nthe post order traversal of this tree would be \n\n```mathematica\nD → E → B → F → C → A\n```\n"
  },
  {
    "url": "Courses/Languages/Go/go.html",
    "content": "---\nid: Go\naliases: []\ntags: []\n---\n\n## Hello World\n\n```go\npackage main\nimport \"fmt\"\nfunc main() {\n\tfmt.Println(\"hello world\")\n}\n```\n## Basic Data types\n```go\nbool\n\nstring\n\nint  int8  int16  int32  int64\nuint uint8 uint16 uint32 uint64 uintptr\n\nbyte // alias for uint8\n\nrune // alias for int32\n     // represents a Unicode code point\n\nfloat32 float64\n\ncomplex64 complex128\n```\n\n## Declaring a varible\n```go\nvar message string = \"Hello\" // specifically assigning message as string and it is a variable.\nmessage := \"hello\" // letting the compiler choose type of message according to whats on the right.\n\nmileage, company := 8029, \"Toyota\"\n// the above is similar to\nmileage := 8029\ncompany := \"Toyota\"\n\n```\n\n## Type conversion\n```go\ntemperatureFloat := 88.26\ntemperatureInt := int64(temperatureFloat)\n\n```\n\n## Conditional\n```go\nif height > 6 {\n    fmt.Println(\"You are super tall!\")\n} else if height > 4 {\n    fmt.Println(\"You are tall enough!\")\n} else {\n    fmt.Println(\"You are not tall enough!\")\n}\n```\n\n```go\nif INITIAL_STATEMENT; CONDITION {\n}\n\nif length := getLength(email); length < 1 {\n    fmt.Println(\"Email is invalid\")\n}\n\n```\n## Functions\n\n```go\nfunc sub(x int, y int) int {\n  return x-y\n}\n```\n\nIgnoring return values\n\n```go\nfunc getPoint() (x int, y int) {\n  return 3, 4\n}\n\n// ignore y value\nx, _ := getPoint()\n```\n\n### Variadic functions\nMany functions, especially those in std library, can take an abitrary number of final arguments. This is accomplished by using \"...\" syntax in function signature.\n\n```go\nfunc concat(strs ...string) string {\n    final := \"\"\n    // strs is just a slice of strings\n    for i := 0; i < len(strs); i++ {\n        final += strs[i]\n    }\n    return final\n}\n\nfunc main() {\n    final := concat(\"Hello \", \"there \", \"friend!\")\n    fmt.Println(final)\n    // Output: Hello there friend!\n}\n```\n\n==fmt.Println== and ==fmt.Sprintf== both are variadic function as we can pass as many arguments in them as we want.\n\n## Structs\n```go\ntype car struct {\n  make string\n  model string\n  doors int\n  mileage int\n  frontWheel wheel\n  backWheel wheel\n}\n\ntype wheel struct {\n  radius int\n  material string\n}\n\nmyCar := car{}\nmyCar.frontWheel.radius = 5 // Use dot operator to access fields of a struct\n```\n### Struct Methods\n```go\ntype rect struct {\n  width int\n  height int\n}\n\n// area has a receiver of (r rect)\n// rect is the struct\n// r is the placeholder\nfunc (r rect) area() int {\n  return r.width * r.height\n}\n\nvar r = rect{\n  width: 5,\n  height: 10,\n}\n\nfmt.Println(r.area())\n// prints 50\n```\n\n## Interfaces\n[Interface](https://go.dev/tour/methods/9)  is defined as a set of method signatures.\n\n```go\ntype shape interface {\n  area() float64\n  perimeter() float64\n}\n\ntype rect struct {\n    width, height float64\n}\nfunc (r rect) area() float64 {\n    return r.width * r.height\n}\nfunc (r rect) perimeter() float64 {\n    return 2*r.width + 2*r.height\n}\n\ntype circle struct {\n    radius float64\n}\nfunc (c circle) area() float64 {\n    return math.Pi * c.radius * c.radius\n}\nfunc (c circle) perimeter() float64 {\n    return 2 * math.Pi * c.radius\n}\n```\n\nName your interface for better understanding==\n```go\ntype Copier interface {\n  Copy(string, string) int\n}\ntype Copier interface { // This is easier to understand than the above one.\n  Copy(sourceFile string, destinationFile string) (bytesCopied int)\n}\n```\n### Type Assertions\nA type assertion provides access to an interface value underlying concrete value.\n\n```go\nt := i.(T) // This statement asserts that the interface value i holds the concrete type T and assigns the underlying T value to the variable t.\n```\n\nIf ==i== doesn't hold a ==T==, the statement will trigger a panic.\n\nTo test where an interface value holds a specific type, a type assertion can return two values. ==Value== and ==Bool== that tells if the assertion succeeded.\n```go\nt, ok := i.(T)\n```\n\nIf i holds a T, then t will be the underlying value and ==ok== will be true and thus we can explicitly give an error out.\n\n### Type switches\nA [type switch](https://go.dev/tour/methods/16) is a construct that permits several type assertion in series.\n\n```go\nswitch v := i.(type) {\ncase T:\n    // here v has type T\ncase S:\n    // here v has type S\ndefault:\n    // no match; here v has the same type as i\n}\n```\n\nSome things to remember:\n- Keep interface small and concise.\n- Interfaces should have no knowledge of satisfying types.\n- Interfaces are not classes.\n\n## Error\nWhen something goes wrong inside a function, it should return a error value as it's last param. The programmer can thus check it by comparing it to ==nil== if the error occurred.\n\n```go\n// Atoi converts a stringified number to an integer\ni, err := strconv.Atoi(\"42b\")\nif err != nil {\n    fmt.Println(\"couldn't convert:\", err)\n    // because \"42b\" isn't a valid integer, we print:\n    // couldn't convert: strconv.Atoi: parsing \"42b\": invalid syntax\n    // Note:\n    // 'parsing \"42b\": invalid syntax' is returned by the .Error() method\n    return\n}\n// if we get here, then\n// i was converted successfully\n```\n\n### Error interface\nBecause errors are interfaces, you can build your own custom types that implement the error interface.\n```go\ntype userError struct {\n    name string\n}\n\nfunc (e userError) Error() string {\n    return fmt.Sprintf(\"%v has a problem with their account\", e.name)\n}\n```\n```c\nfunc sendSMS(msg, userName string) error {\n    if !canSendToUser(userName) {\n        return userError{name: userName}\n    }\n    ...\n}\n```\n\n### Error Package\nThe Go standard library has a [==\"errors\"==](https://pkg.go.dev/errors) package.\n\n## Loops\n```go\nfor INITIAL; CONDITION; AFTER{ // C-style loops without the parenthesis.\n  // do something\n}\n```\ngo doesn't have any while loop\n\nIt's just:\n```go\nfor CONDITION {\n  // do some stuff while CONDITION is true\n}\n```\n## Arrays\nSame as C-arrays with type at the end instead of the start.\n```go\nvar myInts [10]int\nprimes := [6]int{2, 3, 5, 7, 11, 13}\n```\n\n### Slices\nDynamically allocated array. Empty slice is nil.\nSlices always have an underlying array, though it isn't always specified explicitly.  To explicitly create a slice over an array, we do this:\n```go\nprimes := [6]int{2, 3, 5, 7, 11, 13}\nmySlice := primes[1:4]\n// mySlice = {3, 5, 7}\n\n// arrayname[lowIndex:highIndex]\n// arrayname[lowIndex:]\n// arrayname[:highIndex]\n// arrayname[:]\n\n// lower index is inclusive but the high index is exclusive.\n```\n\n### Make\nMost of the time since we don't need to think about the underlying array of the slice. We can create a new slice using the [make](https://pkg.go.dev/builtin#make) function\n```go\n// func make([]T, len, cap) []T\nmySlice := make([]int, 5, 10)\n\n// the capacity argument is usually omitted and defaults to the length\nmySlice := make([]int, 5)\n```\n\n### Spread Operator\nThe spread(...) operator allows us to pass a slice into a variadic function.\n\n```go\nfunc printStrings(strings ...string) {\n\tfor i := 0; i < len(strings); i++ {\n\t\tfmt.Println(strings[i])\n\t}\n}\n\nfunc main() {\n    names := []string{\"bob\", \"sue\", \"alice\"}\n    printStrings(names...)\n}\n```\n\n### Append\n```go\nfunc append(slice []Type, elems ...Type) []Type\n```\nYou should append things to the same slice.\n```go\nmySlice := []int{1, 2, 3}\nmySlice = append(mySlice, 4)\n```\n### Slices of slices - 2D matrix\n```go\nrows := [][]int{}\n```\n\n### Range based loop\nGo provides syntactic sugar to iterate easily over elements of slice.\n```go\nfor INDEX, ELEMENT := range SLICE {\n}\n```\n```c\nfruits := []string{\"apple\", \"banana\", \"grape\"}\nfor i, fruit := range fruits {\n    fmt.Println(i, fruit)\n}\n// 0 apple\n// 1 banana\n// 2 grape\n```\n\n## Maps\nMaps are like pythons dicts, javascript's objects. In other sense key-value pairs. Hash map.\nEmpty map is equal to ==nil==.\n\n```go\nages := make(map[string]int)\nages[\"John\"] = 37\nages[\"Mary\"] = 24\nages[\"Mary\"] = 21 // overwrites 24\n```\n\n```go\nages = map[string]int{\n  \"John\": 37,\n  \"Mary\": 21,\n}\n```\n\n### Insert an element\n> m[key] = elem\n\n### Get an element\n> elem = m[key]\n\n### Delete an element\n> delete(m, key)\n\n### Check if key exists\n> elem, ok := m[key]\n\n### Nested maps\n```go\nmap[string]map[string]int\nmap[rune]map[string]int\nmap[int]map[string]map[string]int\n```\n\n## Advanced Functions\n### Currying\nCurryied function are those function with more than one argument that can wait for an argument unlike normal function that require all arguments before calling.\n\nIt allows a function with multiple arguments to be transformed into a sequence of functions, each taking a single argument.\n\nAlthough proper currying is not possible in go we can simulate it.\n```haskell\nadd x = /y -> x + y   currying function in haskell. add function wait for y and then proceed to give x + y.\n```\nTo understand currying properly. refer to [[Currying.md]]\n```go\nfunc main() {\n  squareFunc := selfMath(multiply)\n  doubleFunc := selfMath(add)\n\n  fmt.Println(squareFunc(5))\n  // prints 25\n\n  fmt.Println(doubleFunc(5))\n  // prints 10\n}\n\nfunc multiply(x, y int) int {\n  return x * y\n}\n\nfunc add(x, y int) int {\n  return x + y\n}\n\nfunc selfMath(mathFunc func(int, int) int) func (int) int {\n  return func(x int) int {\n    return mathFunc(x, x)\n  }\n}\n```\n### Defer\nThe ==defer== keyword allows a function to be executed automatically just before its enclosing function returns. \n\nUsually its for cleanup like closing files, releasing resources, etc when a function is finished executing.\n\n```go\nfunc main() {\n    fmt.Println(\"Opening file...\")\n    file, err := os.Open(\"example.txt\")\n    if err != nil {\n        fmt.Println(\"Error opening file:\", err)\n        return\n    }\n    defer file.Close() // Ensure the file is closed when main exits\n\n    fmt.Println(\"Reading file...\")\n    // Assume some file reading operations here\n\n    fmt.Println(\"File reading completed.\")\n}\n```\n\n### Closures\nA closure is a function value that references variables from outside its body. The function may access and modify the variables within its scope even after the outer function has finished executing.\n```go\nfunc concatter() func(string) string {\n\tdoc := \"\"\n\treturn func(word string) string {\n\t\tdoc += word + \" \"\n\t\treturn doc\n\t}\n}\n\nfunc main() {\n\tharryPotterAggregator := concatter()\n\tharryPotterAggregator(\"Mr.\")\n\tharryPotterAggregator(\"and\")\n\tharryPotterAggregator(\"Mrs.\")\n\tharryPotterAggregator(\"Dursley\")\n\tharryPotterAggregator(\"of\")\n\tharryPotterAggregator(\"number\")\n\tharryPotterAggregator(\"four,\")\n\tharryPotterAggregator(\"Privet\")\n\n\tfmt.Println(harryPotterAggregator(\"Drive\"))\n\t// Mr. and Mrs. Dursley of number four, Privet Drive\n}\n```\n\n### Anonymous Functions\nAnonymous function are those function that have no name.\nThey are useful when defining a function that will only return once or while defining a quick closure.\n\n```go\n// doMath accepts a function that converts one int into another\n// and a slice of ints. It returns a slice of ints that have been\n// converted by the passed in function.\nfunc doMath(f func(int) int, nums []int) []int {\n\tvar results []int\n\tfor _, n := range nums {\n\t\tresults = append(results, f(n))\n\t}\n\treturn results\n}\n\nfunc main() {\n\tnums := []int{1, 2, 3, 4, 5}\n\t\n    // Here we define an anonymous function that doubles an int\n    // and pass it to doMath\n\tallNumsDoubled := doMath(func(x int) int {\n\t    return x + x\n\t}, nums)\n\t\n\tfmt.Println(allNumsDoubled)\n    // prints:\n    // [2 4 6 8 10]\n}\n\n```\n## Pointers \nPoints to a memory address.\n\n```go\nvar p *int\nmyString := \"hello\"\nmyStringPtr := &myString\n```\n**Go has no pointer arithmetic**\n\n## Local Development\n\n### Packages\nEvery Go program is made up of packages.\nA package named main has an entrypoint at the ==main()== function. A main package is being compiled into an executable programming.\n\nWhen naming a Go package, it's name is generally same as the name of the file. If i wanted to make a go package to create a random number. I can write ==package rnd== but it's preferred to write ==package rand==.\n\nA directory of a go code must have **at most** one package. All the ==.go== file in a single directory must belong to one package.\n\n### Modules\nA file name ==go.mod== at root of the project declares the module. It contains:\n- Module Path -  It not only servers as an import path prefix for package within but also where the go command should look to download it. Like ==require github.com/google/examplepackage v1.3.0==\n- The version of Go.\n- Any dependencies we use.\n\n```go\nmodule github.com/wagslane/hellogo\n\ngo 1.22.1\n\n// replace github.com/wagslane/mystrings v0.0.0 => ../mystrings       // we write this to tell this module is at ../mustrings locally. This should be avoided. Just publish your code to a remote location. That's just how go creaters thought of handling packages and i think its better than npm at it.\n\nrequire (\n\tgithub.com/wagslane/mystrings v0.0.0\n)\n```\n\n## Channels\n### Concurrency\nypically, our code is executed one line at a time, one after the other. This is called sequential execution or synchronous execution.\nIf the computer we're running our code on has multiple cores, we can even execute multiple tasks at exactly the same time. If we're running on a single core, a single core executes code at almost the same time by switching between tasks very quickly. Either way, the code we write looks the same in Go and takes advantage of whatever resources are available.\n\nIn go We just use the ==go== keyword before an operation to make it concurrent. The ==go== keyword spawns a new [goroutine](https://gobyexample.com/goroutines) when calling a functions\n\n### Channels \nChannels are typed, thread-safe queue. Channels allow different goroutines to communicate with each other.\n\n```go\nch := make(chan int) // make a channel.\nch <- 69 // send data to channel using the send operator.\nv := <-ch // receive data from ch channel.\n```\n\nThis reads and removes value from channel ch and saves it to v.\n\nA [deadlock](https://yourbasic.org/golang/detect-deadlock/#:~:text=yourbasic.org%2Fgolang,look%20at%20this%20simple%20example.) is when a group of goroutines are all blocking so none of them can operate.This is a common bug that you need to watch out for in concurrent programming.\n\nEmpty structs are often used a ==tokens== in Go programs. In this context, a token is a unary value. We don't care what is passed through, we care if it is passed or not.\n\nWe can block and wait until something is sent on channel using \n```go\n<-ch // this will block until it pops a single item off the channel, then continue, discarding an item.\n```\n\n### Buffered Channels\nChannels can optionally be buffered.\nWe can provide a buffer length as the second argument to ==make()== to create a buffered channel.\n```go\nch := make(chan int, 100)\n```\n\nA buffered channel only allows us to send data and only block channels when the buffer is full and receiving block only when the buffer is empty.\n\n### Closing Channels\nChannels can be explicitly closed by a sender:\n```go\nch := make(chan int)\n\n// do some stuff with the channel\n\nclose(ch)\n```\n\nWe can check if a channel is closed \n```go\nv, ok := <-ch\n```\n\n### Range\nChannels can be ranged over. In this the channel will receive the value over the channel (blocking at each iteration if nothing new is there) and will exit only when the channel is closed.\n\n```go\nfor item := range ch {\n    // item is the next value received from the channel\n}\n```\n\n### Select\nSometimes we have a single goroutine and we want to process the data in the order it comes in.\n\nA ==select== statement is used to listen to multiple channels at the same time.\n\n```go\nselect {\ncase i, ok := <- chInts:\n    fmt.Println(i)\ncase s, ok := <- chStrings:\n    fmt.Println(s)\ndefault: \n    // receiving from ch would block\n    // so do something else\n}\n```\nThe ==default== case in a ==select== statement executes immediately if no other channel has a value ready.A default case stops the ==select== statement from blocking.\n\n### Tickers\n- [time.Tick()](https://golang.org/pkg/time/#Tick) returns a channel that sends a value on a given interval.\n- [time.After()](https://golang.org/pkg/time/#After) sends a value once after the duration has passed.\n- [time.Sleep()](https://golang.org/pkg/time/#Sleep) blocks the current goroutine for specific amount of time.\n\n### Read only channels\nA channel can be marked as read-only by casting it from a ==chan== to a ==<-chan== type.\n```go\nfunc main() {\n    ch := make(chan int)\n    readCh(ch)\n}\n\nfunc readCh(ch <-chan int) {\n    // ch can only be read from\n    // in this function\n}\n```\n\n### Write only channels\nWe can similarly make then write only by shifting the arrow.\n```go\nfunc writeCh(ch chan<- int) {\n    // ch can only be written to\n    // in this function\n}\n```\n\n### Extra Stuff\n#### A send to a nil channel blocks forever\n```go\nvar c chan string // c is nil\nc <- \"let's get started\" // blocks\n```\n\n#### A receive from a nil channel blocks forever\n```go\nvar c chan string // c is nil\nfmt.Println(<-c) // blocks\n```\n\n#### A send to a closed channel panics\n```go\nvar c = make(chan int, 100)\nclose(c)\nc <- 1 // panic: send on closed channel\n```\n\n#### A receive from a closed channel returns the zero value immediately\n```go\nvar c = make(chan int, 100)\nclose(c)\nfmt.Println(<-c) // 0\n```\n\n## Mutexes - \nMutually excludes different threads from accessing the same data at the same time.\nMutexes allow us to lock access to data to control the access of data by goroutines.\n\nGo std library provides a built-in implementation of a mutex with the sync.Mutex type and its two methods\n- [Lock()](https://golang.org/pkg/sync/#Mutex.Lock)\n- [Unlock()](https://golang.org/pkg/sync/#Mutex.Unlock)\n\n```go\nfunc protected(){\n    mu.Lock() // \n    defer mu.Unlock() // use defer to ensure that we never forget to unlock.\n    // the rest of the function is protected\n    // any other calls to `mu.Lock()` will block\n}\n```\n\n### Maps are not thread-safe.\nMap are not safe for concurrent use. If you have multiple go routines accessing the same map, at least one of them is writing to the map. We must lock the map with a mutex.\n\n### RW Mutex\nThe standard library also exposes a [sync.RWMutex](https://golang.org/pkg/sync/#RWMutex) and it has these methods :\n- [RLock()](https://golang.org/pkg/sync/#RWMutex.RLock)\n- [RUnlock()](https://golang.org/pkg/sync/#RWMutex.RUnlock)\n\nIt can help with performance if we have ==read intensive== task\n\nMaps are cool with concurrent reads as we are not mutating data so more than one goroutines can read a map at the same time.\n\n## Generics\nAs go doesn't have classes so it was impossible to reuse code that does the same thing.\n\nAs of Go v1.18, support for [generics](https://blog.boot.dev/golang/how-to-use-golangs-generics/) was released.\n\n### Type parameters\nPut simply, generics allow us to use variables to refer to specific types.\n```go\nfunc splitAnySlice[T any](s []T) ([]T, []T) {\n    mid := len(s)/2\n    return s[:mid], s[mid:]\n}\n```\n\n### Constraints\nConstraints are just interfaces that allow us to write generics that only operate within the constraints of a given interface type.\n```go\ntype stringer interface {\n    String() string\n}\n\nfunc concat[T stringer](vals []T) string {\n    result := \"\"\n    for _, val := range vals {\n        // this is where the .String() method\n        // is used. That's why we need a more specific\n        // constraint instead of the any constraint\n        result += val.String()\n    }\n    return result\n}\n```\n\n### Interface type lists\nWe can now simply list a bunch of types to get a new interface/constraint.\n\n```go\n// Ordered is a type constraint that matches any ordered type.\n// An ordered type is one that supports the <, <=, >, and >= operators.\ntype Ordered interface {\n    ~int | ~int8 | ~int16 | ~int32 | ~int64 |\n        ~uint | ~uint8 | ~uint16 | ~uint32 | ~uint64 | ~uintptr |\n        ~float32 | ~float64 |\n        ~string\n}\n```\n\n### Generic type naming\n```go\nfunc splitAnySlice[T any](s []T) ([]T, []T) {\n    mid := len(s)/2\n    return s[:mid], s[mid:]\n}\n```\n==T== is just a variable name and can be anything. ==T== has just become a convention like ==i== for for loops.\n\n```go\nfunc splitAnySlice[MyAnyType any](s []MyAnyType) ([]MyAnyType, []MyAnyType) {\n    mid := len(s)/2\n    return s[:mid], s[mid:]\n}\n```\n"
  },
  {
    "url": "Courses/Languages/Java/Containers.html",
    "content": "---\nid: Containers\naliases: []\ntags: []\ntitle: Containers\n---\n\n## Arrays\nAn **array** in Java is a container that holds multiple values of the **same data type** in a **fixed-size, contiguous memory location**. \n\n```java\nint[] numbers = new int[5]; // Creates an array of size 5 with default values (0)\nint[] nums = {10, 20, 30, 40, 50}; // Declares and initializes an array\n\nnumbers[0] = 100;\nnumbers[1] = 200;\nnumbers[2] = 300;\n\nSystem.out.println(numbers[0]); // Output: 100\nSystem.out.println(numbers[2]); // Output: 300\n\nSystem.out.println(numbers.length); // Output: 3\n\nfor (int i = 0; i < numbers.length; i++) {\n    System.out.println(numbers[i]);\n}\n\nfor (int num : numbers) {\n    System.out.println(num);\n}\n\n// multi dimensional array\nint[][] matrix = {\n    {1, 2, 3},\n    {4, 5, 6},\n    {7, 8, 9}\n};\n\nSystem.out.println(matrix[0][1]); // Output: 2\n\nfor (int i = 0; i < matrix.length; i++) {\n    for (int j = 0; j < matrix[i].length; j++) {\n        System.out.print(matrix[i][j] + \" \");\n    }\n    System.out.println();\n}\n\nArrays.sort(numbers);\nSystem.out.println(Arrays.toString(numbers));\n```\n\n## **Default Values in Arrays**\nWhen an array is created with `new`, elements get default values:\n\n| Data Type  | Default Value |\n|------------|--------------|\n| `int[]`    | `0` |\n| `double[]` | `0.0` |\n| `char[]`   | `'\\u0000'` (null character) |\n| `boolean[]` | `false` |\n| `String[]` | `null` |\n\n---\n\n## **Arraylists**\n`ArrayList` is a **resizable array** implementation in Java, part of the `java.util` package. Unlike arrays, `ArrayList` can grow or shrink dynamically.\n\n```java\nArrayList<Type> listName = new ArrayList<>();\n```\n```java\nimport java.util.ArrayList;\n\npublic class Main {\n    public static void main(String[] args) {\n        ArrayList<String> names = new ArrayList<>(); // Creates an empty ArrayList\n        names.add(\"Alice\");\n        names.add(\"Bob\");\n        names.add(\"Charlie\");\n        System.out.println(names); // Output: [Alice, Bob, Charlie]\n\n        System.out.println(names.get(1)); // Output: Bob\n\n        names.set(1, \"David\");\n        System.out.println(names); // Output: [Alice, David, Charlie]\n        names.remove(0); // Removes \"Alice\"\n        System.out.println(names.size()); // Output: 2\n\n        for (int i = 0; i < names.size(); i++) {\n            System.out.println(names.get(i));\n        }\n\n        // range base loop\n        for (String name : names) {\n            System.out.println(name);\n        }\n\n        //using forEach\n        names.forEach(System.out::println);\n\n        System.out.println(names.contains(\"Bob\")); // Output: false\n        Collections.sort(names) // sorting\n\n        names.clear();\n        System.out.println(names); // Output: []\n    }\n}\n```\n## **ArrayList vs. Arrays**\n| Feature      | Array | ArrayList |\n|-------------|-------|-----------|\n| Size        | Fixed | Dynamic (Resizable) |\n| Performance | Faster | Slightly slower (due to resizing) |\n| Type        | Can store primitives | Stores only objects (Wrapper classes for primitives) |\n| Flexibility | Low | High (Built-in methods) |\n\n"
  },
  {
    "url": "Courses/Languages/Java/Data_Types.html",
    "content": "---\nid: Data Types\naliases: []\ntags: []\ntitle: Data Types\n---\n\n## Data types\nJava has eight primitive data types:\n### byte\n- size - 1 byte (8 bits)\n- stores whole number from -128 to 127\n```java\nbyte smallNumber = 100;\n```\n### short\n- size - 2 bytes (16 bits)\n- stores value from - 32,768 to 32,767\n```java\nshort mediumNumber = 30000;\n```\n### int\n- size - 4 bytes (32 bits)\n- stores values from --2,147,483,648 to 2,147,483,647\n```java\nint number = 100000;\n```\n### long\n- size - 8 bytes (64 bits)\n- stores values from -2^63 to 2^63 - 1\n```java\nlong bigNumber = 9223372036854775807L; // Add 'L' at the end\n```\n### float\n- size - 4 bytes (32 bits)\n- stores decimal values with ~7 decimal precision\n```java\nfloat decimalNumber = 3.14f; // Add 'f' at the end\n```\n### double\n- size - 8 bytes (64 bits)\n- stores decimal values with ~15 decimal precision\n```java\ndouble preciseNumber = 3.14159265358979;\n```\n### char\n- size - 2 bytes (16 bits)\n- stores a single unicode character.\n```java\nchar letter = 'A';\n```\n### boolean\n- size - 1 bit\n```java\nboolean yes = true;\n```\n\n### default values\n| Data Type | Default Value |\n|-----------|--------------|\n| byte      | 0 |\n| short     | 0 |\n| int       | 0 |\n| long      | 0L |\n| float     | 0.0f |\n| double    | 0.0d |\n| char      | '\\u0000' (null character) |\n| boolean   | false |\n\n## Variables\nA **variable** is a named storage location in memory. It has:\n1. **Data type** (primitive or reference type)\n2. **Name** (identifier)\n3. **Value** (stored data)\n```java\nint age = 20;        // Declaration + Initialization\ndouble price;        // Declaration only\nprice = 99.99;       // Assigning a value later\n```\n\n### **Variable Naming Rules**\n- Can contain **letters, digits, underscores (_) and dollar signs ($)**\n- **Cannot** start with a number\n- **Cannot** use reserved keywords (e.g., `int`, `class`)\n- Java follows **camelCase** naming convention:\n```java\n  int studentAge = 25;\n```\n"
  },
  {
    "url": "Courses/Languages/Java/Expression_Statements.html",
    "content": "---\nid: Expression Statements\naliases: []\ntags: []\ntitle: Expression Statements\n---\n\n### **Expressions**\nAn **expression** is a combination of variables, literals, operators, and method calls that evaluates to a single value. It represents a computation and always produces a result of a specific data type (e.g., `int`, `boolean`, `String`).\n\n#### Key Characteristics:\n- Must evaluate to a value.\n- Can be part of a larger expression or statement.\n- Can include operators (e.g., `+`, `-`, `==`) and operands (e.g., variables, constants).\n- Example: `5 + 3` evaluates to `8`.\n\n```java\npublic class Main {\n    public static void main(String[] args) {\n        int a = 10, b = 5;\n        System.out.println(a + b);          // 15 (arithmetic)\n        System.out.println(a > b);          // true (relational)\n        System.out.println(a > 0 && b < 10); // true (logical)\n        System.out.println(Math.max(a, b)); // 10 (method call)\n        int c = a + b;                      // c = 15 (assignment expression)\n    }\n}\n```\n- **Note**: Parentheses `()` can be used to control the order of evaluation in complex expressions.\n\n---\n\n### **Statements**\nA **statement** is a complete unit of execution in Java that performs an action. Unlike expressions, statements don’t necessarily produce a value—they instruct the program to *do something* (e.g., assign a value, control flow, or call a method).\n\n#### Key Characteristics:\n- Ends with a semicolon (`;`) in most cases (except block statements).\n- Can contain expressions.\n- Represents an actionable command.\n\n#### Types of Statements:\n1. **Expression Statements**:\n   - An expression followed by a semicolon becomes a statement.\n   - Example: `x = 5;` (assigns `5` to `x`).\n   - Example: `System.out.println(\"Hello\");` (calls a method).\n2. **Declaration Statements**:\n   - Declare variables and optionally initialize them.\n   - Example: `int x;` or `int x = 10;`.\n3. **Control Flow Statements**:\n   - Alter the execution path of a program.\n   - **Types**:\n     - **Conditional**: `if`, `if-else`, `switch`.\n     - **Looping**: `for`, `while`, `do-while`.\n     - **Branching**: `break`, `continue`, `return`.\n   - Example: `if (x > 0) System.out.println(\"Positive\");`.\n4. **Block Statements**:\n   - Group multiple statements within curly braces `{}`.\n   - Example:\n```java\n{\n    int x = 5;\n    System.out.println(x);\n}\n```\n5. **Empty Statement**:\n   - A standalone semicolon (`;`) that does nothing.\n   - Example: `for (int i = 0; i < 5; i++);` (loop does nothing).\n\n#### Examples:\n```java\npublic class Main {\n    public static void main(String[] args) {\n        // Expression Statement\n        int x = 10;                     // Assignment\n        System.out.println(x);          // Method call\n\n        // Declaration Statement\n        double y = 5.5;\n\n        // Control Flow Statement\n        if (x > 0) {\n            System.out.println(\"x is positive\"); // Block statement\n        }\n\n        // Loop Statement\n        for (int i = 0; i < 3; i++) {\n            System.out.println(i);\n        }\n    }\n}\n```\n- **Output**:\n```\n10\nx is positive\n0\n1\n2\n```\n\n---\n\n### Key Differences Between Expressions and Statements\n| **Aspect**           | **Expression**                     | **Statement**                     |\n|----------------------|------------------------------------|-----------------------------------|\n| **Purpose**          | Evaluates to a value              | Performs an action                |\n| **Result**           | Always produces a value           | May or may not produce a value    |\n| **Examples**         | `5 + 3`, `x > y`, `Math.sqrt(4)` | `x = 5;`, `if (x > 0) { ... }`   |\n| **Semicolon**        | Not required unless part of a statement | Usually ends with `;` (except blocks) |\n| **Composition**      | Can be part of a statement        | Can contain expressions           |\n\n---\n"
  },
  {
    "url": "Courses/Languages/Java/Garbage_Collection.html",
    "content": "---\nid: Garbage Collection\naliases: []\ntags: []\ntitle: Garbage Collection\n---\n\n### What is Garbage Collection?\nGarbage collection (GC) is an automatic memory management feature in many programming languages. It’s the process of identifying and freeing up memory that’s no longer in use by a program—essentially cleaning up “garbage” objects so that memory can be reused. This saves developers from manually allocating and deallocating memory (like in C or C++).\n\nIn short: GC finds objects you’re done with and reclaims their memory for you.\n\n### Why Do We Need It?\nWhen you create objects (e.g., with `new` in Java), they take up space in the **heap**—a region of memory for dynamic allocation. If you stop using an object (say, by losing all references to it), that memory doesn’t free itself automatically. Without garbage collection:\n- You’d have to manually deallocate memory (error-prone and tedious).\n- Unused objects would pile up, leading to **memory leaks**—where memory is occupied but inaccessible, eventually crashing your program.\n\nGC automates this cleanup, making coding easier and safer.\n\n### How Does Garbage Collection Work?\nGarbage collection typically involves two main steps:\n1. **Identifying garbage**: Finding objects that are no longer reachable.\n2. **Reclaiming memory**: Freeing up the space those objects occupied.\n\n#### Key Concept: Reachability\nAn object is “reachable” if there’s a way to get to it from a **root**—a starting point like:\n- Local variables on the stack (e.g., in a method).\n- Static variables in a class.\n- References held by active threads.\n\nIf an object can’t be reached from any root through a chain of references, it’s **unreachable** and considered garbage.\n\n```java\npublic class Example {\n    public static void main(String[] args) {\n        Object obj = new Object();  // obj references a new object\n        obj = null;                // No references to the object remain\n        // At this point, the object is unreachable and eligible for GC\n    }\n}\n```\n- Initially, `obj` points to an object in the heap.\n- After `obj = null`, no references point to that object—it’s garbage.\n\n#### The Process (Simplified)\n1. **Mark**: The garbage collector scans the heap, starting from roots, and marks all reachable objects.\n2. **Sweep**: It then sweeps through the heap and reclaims memory from unmarked (unreachable) objects.\n3. **Compact (optional)**: Some GCs move remaining objects to reduce fragmentation, making future allocations more efficient.\n\n\n### Garbage Collection in Java\nJava’s garbage collector is built into the Java Virtual Machine (JVM) and runs automatically. Here’s how it plays out:\n\n#### The Heap\n- Java’s heap is divided into regions:\n  - **Young Generation**: New objects go here (split into Eden and Survivor spaces).\n  - **Old Generation**: Long-lived objects get promoted here.\n  - **Metaspace**: Class metadata (not technically garbage-collected in the same way).\n- GC is generational: it assumes most objects die young (short-lived) and optimizes for that.\n\n#### Types of GC in Java\n- **Minor GC**: Cleans the Young Generation (fast, frequent).\n- **Major GC**: Cleans the Old Generation (slower, less frequent).\n- **Full GC**: Cleans the entire heap (slowest, rare).\n\n#### When Does GC Run?\n- The JVM decides, based on heap usage or memory pressure.\n- You can’t force GC directly, but `System.gc()` suggests it (not guaranteed).\n\n### How Does It Know What’s Garbage?\nJava uses a **reference counting** idea conceptually, but modern GCs rely on **tracing**:\n- **Reference Counting**: Each object tracks how many references point to it (used in Python, not Java). If it hits zero, it’s garbage. Problem: Can’t detect cycles (e.g., A points to B, B points to A, but no one else points to them).\n- **Tracing**: Java’s approach. Starts from roots and follows all references. Anything not visited is garbage, even in cycles.\n\n#### Cycle Example\n```java\npublic class Node {\n    Node next;\n\n    public static void main(String[] args) {\n        Node a = new Node();\n        Node b = new Node();\n        a.next = b;\n        b.next = a;  // Circular reference\n        a = null;\n        b = null;  // Both are unreachable despite the cycle\n        // GC will still collect them\n    }\n}\n```\n- Even though `a` and `b` reference each other, no root points to them—GC reclaims them.\n\n---\n\n### Advantages of Garbage Collection\n1. **No manual memory management**: No `malloc`/`free` like in C.\n2. **Prevents leaks**: Automatically cleans up unused objects.\n3. **Safer**: Avoids dangling pointers or double-free errors.\n\n---\n\n### Disadvantages\n1. **Performance overhead**: GC pauses the program briefly to run (though modern GCs minimize this).\n2. **Unpredictable timing**: You don’t control when it happens.\n3. **Memory usage**: May hold onto memory longer than necessary until GC kicks in.\n\n---\n\n### Controlling GC (Sort Of)\n- **Finalize**: Deprecated in Java 9+, but historically, you could override `finalize()` to run code before an object is collected (unreliable).\n- **Weak References**: Use `WeakReference` for objects you’re okay with GC collecting early.\n- **Tuning**: JVM flags (e.g., `-Xmx`, `-XX:+UseG1GC`) let you adjust heap size or GC algorithm (e.g., G1, CMS).\n\n#### Weak Reference Example\n```java\nimport java.lang.ref.WeakReference;\n\npublic class Main {\n    public static void main(String[] args) {\n        Object obj = new Object();\n        WeakReference<Object> weakRef = new WeakReference<>(obj);\n        obj = null;  // Only weak reference remains\n        System.gc(); // Suggest GC\n        System.out.println(weakRef.get());  // Likely null if GC ran\n    }\n}\n```\n- `weakRef` doesn’t prevent GC; the object can be collected if no strong references exist.\n\n"
  },
  {
    "url": "University/OOP/Module_3/Interfaces.html",
    "content": "---\nid: Interfaces\naliases: []\ntags: []\ntitle: Interfaces\n---\n\n### 1. **Interfaces in Java**\n\nAn **interface** in Java is a blueprint for a class that defines a set of abstract methods (and optionally constants or default methods) that a class must implement. Interfaces are used to achieve **abstraction**, **multiple inheritance**, and **loose coupling** in Java programs.\n\n- **Key Characteristics**:\n  - An interface is implicitly **abstract**; you don’t need to use the `abstract` keyword.\n  - All methods in an interface are implicitly **public** and **abstract** (unless they are `default` or `static` methods, introduced in Java 8).\n  - All fields in an interface are implicitly **public**, **static**, and **final** (i.e., constants).\n  - Interfaces cannot be instantiated directly.\n  - A class can implement multiple interfaces, unlike extending multiple classes.\n\n- **Syntax**:\n  ```java\n  interface InterfaceName {\n      // Constant (public static final)\n      int CONSTANT = 10;\n      // Abstract method (public abstract)\n      void methodName();\n      // Default method (Java 8+)\n      default void defaultMethod() {\n          System.out.println(\"Default implementation\");\n      }\n      // Static method (Java 8+)\n      static void staticMethod() {\n          System.out.println(\"Static method in interface\");\n      }\n  }\n  ```\n\n- **Purpose**:\n  - Define a contract that implementing classes must follow.\n  - Enable polymorphism (e.g., treating different classes uniformly via an interface type).\n  - Support multiple inheritance (a class can implement multiple interfaces).\n\n---\n\n### 2. **Implementing Interfaces**\n\nA class **implements** an interface using the `implements` keyword. By doing so, it agrees to provide concrete implementations for all abstract methods declared in the interface.\n\n- **Syntax**:\n  ```java\n  class ClassName implements InterfaceName {\n      // Provide implementation for abstract methods\n      @Override\n      public void methodName() {\n          // Implementation\n      }\n  }\n  ```\n\n- **Example**:\n  ```java\n  package com.example.myapp;\n  interface Vehicle {\n      void start();\n      void stop();\n      default void honk() {\n          System.out.println(\"Beep beep!\");\n      }\n  }\n  public class Car implements Vehicle {\n      @Override\n      public void start() {\n          System.out.println(\"Car started\");\n      }\n      @Override\n      public void stop() {\n          System.out.println(\"Car stopped\");\n      }\n  }\n  class Test {\n      public static void main(String[] args) {\n          Car car = new Car();\n          car.start(); // Car started\n          car.stop();  // Car stopped\n          car.honk();  // Beep beep!\n      }\n  }\n  ```\n\n- **Key Points**:\n  - A class must implement **all abstract methods** of the interface, or it must be declared `abstract` itself.\n  - If a class implements multiple interfaces, it must provide implementations for all abstract methods in all interfaces.\n  - Example with multiple interfaces:\n    ```java\n    interface Movable {\n        void move();\n    }\n    interface Audible {\n        void makeSound();\n    }\n    class Robot implements Movable, Audible {\n        @Override\n        public void move() {\n            System.out.println(\"Robot moving\");\n        }\n        @Override\n        public void makeSound() {\n            System.out.println(\"Beep boop\");\n        }\n    }\n    ```\n\n- **Rules**:\n  - The implementing class must use the `public` access modifier for interface methods (since interface methods are implicitly `public`).\n  - Use `@Override` to ensure correctness and improve readability.\n  - A class can implement multiple interfaces (e.g., `implements Interface1, Interface2`).\n  - If two interfaces declare methods with the same signature, the class provides a single implementation that satisfies both.\n\n- **Accessing Interface Members**:\n  - Use an instance of the implementing class to call instance methods (abstract or default).\n  - Use the interface name to access static methods or constants (e.g., `InterfaceName.CONSTANT`).\n\n- **Polymorphism with Interfaces**:\n  - An interface type can reference any object of a class that implements it.\n  - Example:\n    ```java\n    Vehicle vehicle = new Car();\n    vehicle.start(); // Calls Car’s start method\n    ```\n\n---\n\n### 3. **Interface vs. Abstract Classes**\n\nBoth **interfaces** and **abstract classes** are used to achieve abstraction in Java, but they serve different purposes and have distinct features. Understanding their differences is critical for exams.\n\n#### **Abstract Classes**\n- An **abstract class** is a class that cannot be instantiated and may contain both abstract (unimplemented) and concrete (implemented) methods.\n- Declared using the `abstract` keyword.\n- Syntax:\n  ```java\n  abstract class AbstractClass {\n      // Abstract method\n      abstract void abstractMethod();\n      // Concrete method\n      void concreteMethod() {\n          System.out.println(\"Concrete implementation\");\n      }\n      // Fields\n      int field;\n  }\n  ```\n\n- **Key Characteristics**:\n  - Can have **instance fields**, **constructors**, and **concrete methods**.\n  - Supports all access modifiers (`public`, `protected`, `private`, etc.).\n  - A class can only **extend one abstract class** (single inheritance).\n  - Can contain both abstract and non-abstract methods.\n\n- **Example**:\n  ```java\n  package com.example.myapp;\n  abstract class Vehicle {\n      int speed;\n      abstract void start();\n      void displaySpeed() {\n          System.out.println(\"Speed: \" + speed);\n      }\n  }\n  class Car extends Vehicle {\n      @Override\n      void start() {\n          System.out.println(\"Car started\");\n          speed = 60;\n      }\n  }\n  ```\n\n#### **Comparison: Interface vs. Abstract Class**\n\n| **Feature**                  | **Interface**                                                                 | **Abstract Class**                                                  |\n|------------------------------|-------------------------------------------------------------------------------|--------------------------------------------------------------------|\n| **Keyword**                  | `interface`                                                                  | `abstract class`                                                   |\n| **Methods**                  | Abstract methods (implicitly `public abstract`), default methods, static methods | Abstract and concrete methods (any access modifier)                 |\n| **Fields**                   | Only constants (`public static final`)                                       | Instance fields, any access modifier                               |\n| **Inheritance**              | A class can implement multiple interfaces                                    | A class can extend only one abstract class                         |\n| **Constructors**             | No constructors                                                              | Can have constructors                                              |\n| **Access Modifiers**         | Methods are implicitly `public`                                              | Methods/fields can have any access modifier (`public`, `private`, etc.) |\n| **Use Case**                 | Defines a contract for unrelated classes; supports multiple inheritance       | Provides a common base with shared code for related classes         |\n| **Instantiation**            | Cannot be instantiated                                                       | Cannot be instantiated                                             |\n| **Java Version Enhancements** | Default/static methods (Java 8+), private methods (Java 9+)                 | No significant changes                                              |\n\n- **Example Combining Both**:\n  ```java\n  package com.example.myapp;\n  interface Drivable {\n      void drive();\n  }\n  abstract class Vehicle {\n      int speed;\n      abstract void start();\n      void displaySpeed() {\n          System.out.println(\"Speed: \" + speed);\n      }\n  }\n  class Car extends Vehicle implements Drivable {\n      @Override\n      void start() {\n          System.out.println(\"Car started\");\n          speed = 60;\n      }\n      @Override\n      public void drive() {\n          System.out.println(\"Car driving\");\n      }\n  }\n  class Test {\n      public static void main(String[] args) {\n          Car car = new Car();\n          car.start();       // Car started\n          car.drive();       // Car driving\n          car.displaySpeed(); // Speed: 60\n      }\n  }\n  ```\n\n- **When to Use**:\n  - **Interface**:\n    - When you want to define a contract that multiple unrelated classes can follow (e.g., `Comparable`, `Runnable`).\n    - When you need multiple inheritance.\n    - Example: `List` interface implemented by `ArrayList`, `LinkedList`.\n  - **Abstract Class**:\n    - When you want to share code (fields, methods) among closely related classes.\n    - When you need non-public methods or instance fields.\n    - Example: `AbstractList` as a base for `ArrayList`.\n\n- **Java 8+ Changes**:\n  - Interfaces can now have `default` and `static` methods, making them more flexible.\n  - Example:\n    ```java\n    interface Example {\n        default void defaultMethod() {\n            System.out.println(\"Default method\");\n        }\n    }\n    ```\n  - This reduces the gap between interfaces and abstract classes, but abstract classes are still better for shared state and complex hierarchies.\n\n---\n\n#### **Practice Program**\n**File 1: `com/example/myapp/Shape.java`**\n```java\npackage com.example.myapp;\npublic interface Shape {\n    double getArea();\n    default void display() {\n        System.out.println(\"Shape with area: \" + getArea());\n    }\n}\n```\n\n**File 2: `com/example/myapp/AbstractShape.java`**\n```java\npackage com.example.myapp;\npublic abstract class AbstractShape {\n    protected String color;\n    public AbstractShape(String color) {\n        this.color = color;\n    }\n    public String getColor() {\n        return color;\n    }\n    public abstract void draw();\n}\n```\n\n**File 3: `com/example/myapp/Circle.java`**\n```java\npackage com.example.myapp;\npublic class Circle extends AbstractShape implements Shape {\n    private double radius;\n    public Circle(String color, double radius) {\n        super(color);\n        this.radius = radius;\n    }\n    @Override\n    public double getArea() {\n        return Math.PI * radius * radius;\n    }\n    @Override\n    public void draw() {\n        System.out.println(\"Drawing a \" + getColor() + \" circle\");\n    }\n}\n```\n\n**File 4: `com/example/myapp/Test.java`**\n```java\npackage com.example.myapp;\npublic class Test {\n    public static void main(String[] args) {\n        Circle circle = new Circle(\"Red\", 5.0);\n        circle.draw();       // Drawing a Red circle\n        circle.display();    // Shape with area: 78.53981633974483\n        System.out.println(\"Color: \" + circle.getColor()); // Color: Red\n    }\n}\n```\n\n**Compile and Run**:\n```bash\njavac com/example/myapp/*.java\njava -cp . com.example.myapp.Test\n```\n"
  },
  {
    "url": "Courses/Languages/Java/intro.html",
    "content": "---\nid: intro\naliases: []\ntags: []\ntitle: intro\n---\n\n- Java was created by James Gosling and his team at Sun Microsystems. It is a high-level, general-purpose, object-oriented programming language.\n- It was intended to let programmers write once and run anywhere meaning that compiled java can run on all platforms without the need to recompile.\n- Java application are typically compiled to bytecode that run on a JVM regardless of the underlying computer architecture.\n- Syntax of java is similar to that of c or c++ but has fewer low level facilities.\n- It is a garbage collected language meaning manual memory allocations are unneeded and garbage collector is responsible for reclaiming space from objects that are not longer in use.\n- Java bytecode is independant of hardware architecture, relying on the JVM to handle platform-specific details.\n- It has a rich standard library.\n"
  },
  {
    "url": "Courses/Languages/Java/JVM.html",
    "content": "---\nid: JVM\naliases: []\ntags: []\ntitle: JVM\n---\n\nThe **Java Virtual Machine** is a critical component of the java ecosystem, enabling java's \"**write once and run anywhere**\" promise. It's an abstract computing machine that provides a runtime environment to run java's bytecode.\n\n- The JVM is a virtual machine that is responsible for running java's bytecode generated by the java compiler (`javac`).\n- It acts as an intermediary between the bytecode and the underlying hardware and platform specific implementation.\n- The JVM is offered for most operating systems thus being able to transcode bytecode to system level operations to run the program. Due to this same written java code can be run on any operating system without recompiling as the hard work is done by the JVM.\n\n## Working of JVM\n1. Compilation - The java compiler(`javac`) converts the `.java` source code into `.class` files containing the platform independent bytecode.\n2. Execution - The JVM loads the bytecode, interprets or compiles it to native machine code, executing it on host's system.\n3. Abstraction - The JVM handles system-specific tasks. eg. memory management, hardware interactions.\n\n## JVM architecture\nThe JVM consists of several components that work together to execute Java programs. These are divided into three main subsystems:\n\n### Class Loader Subsystem\n- loads, links and initialized the `.class` files into the jvm for execution.\n- **process**: \n    - **loading:** \n        - reads the `.class` file from the file system or network and creates a binary representation in memory.\n        - loads the core java libraries and the class for further linking.\n    - **linking:**\n        - Ensures the bytecode is valid and adheres to java's rules.\n        - Allocates memory for static variable and assign default values.\n        - Resolves symbolic references to direct references in memory.\n    - **Initialization**\n        - Executes the static initializers and assign initial value to static vars.\n\n### Runtime Data Areas (Memory Areas)\n- Stores data required during program execution. These areas are shared or thread-specific.\n- **Components** - \n    1. **Method Area**\n        - Stores class-level data, such as the runtime constant pool, field/method data, and bytecode of methods.\n        - Shared across all threads\n    2. **Heap** \n        - Stores all object instances and arrays dynamically allocated during runtime.\n        - Shared across all threads.\n        - Garbage collector is responsible for cleaning the heap memory.\n    3. **Stack**\n        - Stores local variables, method call frames, and intermediate computation results for each thread.\n        - Private to each thread.\n        - Each method call creates a stack frame that contains the data related to that method call such as local vars, reference to runtime constant pool, etc.\n    4. **Register**\n        - Holds the address of the currently executing JVM instruction for each thread.\n        - Private to each thread.\n    5. **Native Method Stack**\n        - Supports execution of native methods (written in C/C++ and called via JNI - Java Native Interface).\n        - Private to each thread\n        - used when Java calls a system-specific function (e.g., file I/O in the OS).\n\n### Execution engine\n- Executes the bytecode by interpreting it or compiling it to native code\n- Language can be interpreted or JIT compiled depending upon the implementation.\n- Garbage collector automatically manages heap memory by reclaiming space from objects no longer being referred.\n- Allows java to call native libraries in C/C++.\n    \n"
  },
  {
    "url": "Courses/Languages/Java/OOP_Concepts.html",
    "content": "---\nid: OOP Concepts\naliases: []\ntags: []\ntitle: OOP Concepts\n---\n\n### Class\nA class is like a blueprint or template for creating objects. It defines the properties (data) and behaviors (functions or methods) that objects created from it will have.\n\n```java\nclass Car {\n    // Attributes (data)\n    String model;\n    int year;\n    double speed;\n\n    // Method (behavior)\n    void accelerate() {\n        speed += 10;\n    }\n}\n```\nHere, `Car` defines what a car *is*—it has a model, a year, and a speed, and it can accelerate. But this class doesn’t do anything on its own yet.\n\n### Object\nAn object is an instance of a class—think of it as the actual cake baked from the recipe. When you create an object, you’re taking the class blueprint and making a real, tangible thing in memory that you can interact with.\n\n```java\nCar myCar = new Car();\nmyCar.model = \"Toyota Camry\";  // Set the model\nmyCar.year = 2020;             // Set the year\nmyCar.speed = 0;               // Set initial speed\nmyCar.accelerate();            // Call the method; speed becomes 10\n```\n- `new Car()` creates a new object (instance) of the `Car` class in memory.\n- `myCar` is a reference variable that points to this object so you can use it.\n\n### Class and Object Fundamentals\n- **Class**: Defines the structure and behavior (static definition).\n- **Object**: A runtime entity with actual data, created from the class.\n- A single class can create multiple objects, each with its own data:\n```java\nCar car1 = new Car();\nCar car2 = new Car();\ncar1.model = \"Honda Civic\";\ncar2.model = \"Ford Mustang\";\n```\nHere, `car1` and `car2` are distinct objects with their own `model` values, but they share the same structure defined by the `Car` class.\n\n### Creating Objects\nCreating an object typically involves:\n1. **Declaration**: Declaring a reference variable (e.g., `Car myCar`).\n2. **Instantiation**: Using `new` to allocate memory for the object (e.g., `new Car()`).\n3. **Initialization**: Optionally setting initial values (e.g., via a constructor).\n\nA constructor is a special method in the class that initializes an object when it’s created. Let’s add one to `Car`:\n```java\nclass Car {\n    String model;\n    int year;\n    double speed;\n\n    // Constructor\n    Car(String m, int y) {\n        model = m;\n        year = y;\n        speed = 0;  // Default speed\n    }\n\n    void accelerate() {\n        speed += 10;\n    }\n}\n\nCar myCar = new Car(\"Tesla Model 3\", 2022);\n```\n\n### Assigning Object Reference Variables\nIn OOP languages like Java, variables of a class type (e.g., `Car myCar`) are *references*, not the objects themselves. They store the memory address of the object. This matters when you assign one reference to another:\n```java\nCar carA = new Car(\"BMW X5\", 2021);\nCar carB = carA;  // carB now points to the same object as carA\ncarB.model = \"Audi Q7\";  // This changes carA’s model too!\n\nCar carC = new Car(\"Audi Q7\", 2021);  // A separate object\n```\n\n### Size of an “Empty Object”?\nAn empty object comes from a class with no fields (instance variables). For example:\n```java\nclass Empty {\n    // No fields, no methods (or just methods, which don’t affect object size)\n}\n```\nWhen you create an object with `Empty obj = new Empty();`, it still takes up some memory. Why? Because the language’s runtime needs to track the object’s existence, identity, and type, even if it holds no data.\n\nIn Java, an object’s size is determined by the Java Virtual Machine (JVM) and includes:\n1. **Object header**: Metadata like the object’s class type and hashcode.\n2. **Alignment**: Memory is padded to align with the system’s word size (e.g., 8 bytes on a 64-bit JVM).\n\nFor an empty object:\n- **Object header**: Typically 12 bytes on a 64-bit JVM (8 bytes for the class pointer, 4 bytes for identity hashcode/mark word).\n- **Padding**: Rounded up to a multiple of 8 bytes.\n\nSo, an empty object in Java is usually **16 bytes** on a 64-bit JVM (12 bytes header + 4 bytes padding). On a 32-bit JVM, it’s often **8 bytes** (smaller header).\n\n### Methods\nA **method** is a block of code inside a class that defines a behavior or action an object (or sometimes the class itself) can perform. It’s like a function tied to the class, often operating on the object’s data (instance variables).\n\n#### Key Features of Methods\n- **Belongs to objects**: Typically, methods work with an object’s instance variables.\n- **Has a return type**: Could return something (e.g., `int`, `String`) or nothing (`void`).\n- **Can take parameters**: Inputs to customize its behavior.\n\n```java\npublic class Dog {\n    String name;\n    int age;\n\n    // Method to make the dog bark\n    public void bark() {\n        System.out.println(name + \" says Woof!\");\n    }\n}\n\nclass Main {\n    public static void main(String[] args) {\n        Dog myDog = new Dog();\n        myDog.name = \"Rex\";\n        myDog.bark();        // Outputs: Rex says Woof!\n    }\n}\n```\n---\n\n### Static Methods\nA **static method** belongs to the *class* itself, not to individual objects. It’s marked with the `static` keyword and can be called without creating an instance of the class.\n\n#### Key Features of Static Methods\n- **No object needed**: Call it using the class name (e.g., `ClassName.method()`).\n- **Can’t access instance variables directly**: Since it’s not tied to an object, it only works with static (class-level) data or parameters passed to it.\n- **Common uses**: Utility functions, helpers, or operations that don’t depend on object state.\n\n```java\npublic class MathUtils {\n    // Static method to add two numbers\n    public static int add(int a, int b) {\n        return a + b;\n    }\n\n    // Static variable\n    public static int counter = 0;\n\n    // Static method using a static variable\n    public static void incrementCounter() {\n        counter++;\n    }\n}\n\nclass Main {\n    public static void main(String[] args) {\n        // Call static method without an object\n        int sum = MathUtils.add(5, 3);  // No need for 'new MathUtils()'\n        System.out.println(\"Sum: \" + sum);  // Outputs: 8\n\n        MathUtils.incrementCounter();\n        System.out.println(\"Counter: \" + MathUtils.counter);  // Outputs: 1\n    }\n}\n```\n---\n\n### Constructors\nA **constructor** is a special method called automatically when an object is created with `new`. It initializes the object’s state (instance variables).\n\n#### Key Features of Constructors\n- **Same name as the class**: No return type (not even `void`).\n- **Runs once per object**: Executes when `new` is called.\n- **Can be public, private, etc.**: Controls how objects are created (public is common).\n\n#### Example\n```java\npublic class Cat {\n    String name;\n    int lives;\n\n    // Constructor\n    public Cat(String name, int lives) {\n        this.name = name;   // 'this' distinguishes instance variable from parameter\n        this.lives = lives;\n    }\n\n    public void meow() {\n        System.out.println(name + \" says Meow!\");\n    }\n}\n\nclass Main {\n    public static void main(String[] args) {\n        Cat myCat = new Cat(\"Whiskers\", 9);  // Constructor runs here\n        myCat.meow();  // Outputs: Whiskers says Meow!\n    }\n}\n```\n---\n\n### Overloading Constructors\n**Constructor overloading** means defining multiple constructors in the same class with different parameter lists. This gives flexibility in how objects can be created.\n\n#### Key Features of Overloading\n- **Same name, different parameters**: Differ by number, type, or order of parameters.\n- **Still called with `new`**: Java picks the right one based on the arguments you provide.\n- **Improves usability**: Lets users instantiate objects in various ways.\n\n```java\npublic class Student {\n    String name;\n    int age;\n    String major;\n\n    // Constructor 1: Full initialization\n    public Student(String name, int age, String major) {\n        this.name = name;\n        this.age = age;\n        this.major = major;\n    }\n\n    // Constructor 2: Name and age only\n    public Student(String name, int age) {\n        this.name = name;\n        this.age = age;\n        this.major = \"Undecided\";  // Default value\n    }\n\n    // Constructor 3: Name only\n    public Student(String name) {\n        this.name = name;\n        this.age = 18;      // Default age\n        this.major = \"Undecided\";\n    }\n\n    public void display() {\n        System.out.println(\"Name: \" + name + \", Age: \" + age + \", Major: \" + major);\n    }\n}\n\nclass Main {\n    public static void main(String[] args) {\n        Student s1 = new Student(\"Alice\", 20, \"Computer Science\");\n        Student s2 = new Student(\"Bob\", 19);\n        Student s3 = new Student(\"Charlie\");\n\n        s1.display();  // Name: Alice, Age: 20, Major: Computer Science\n        s2.display();  // Name: Bob, Age: 19, Major: Undecided\n        s3.display();  // Name: Charlie, Age: 18, Major: Undecided\n    }\n}\n```\n\n- You can call one constructor from another using `this()` to avoid code duplication:\n  ```java\n  public Student(String name) {\n      this(name, 18);  // Calls the (String, int) constructor\n  }\n  ```\n- Overloading applies to regular methods too, not just constructors.\n\n---\n\n### The `this` Keyword\nThe `this` keyword refers to the *current object*—the instance of the class that’s running the code. It’s used to distinguish between instance variables and parameters or to call other constructors/methods within the same class.\n\n#### Key Uses of `this`\n1. **Disambiguate variable names**: When a parameter has the same name as an instance variable.\n2. **Call another constructor**: Chain constructor calls.\n3. **Pass the current object**: Send `this` to another method or object.\n\n```java\npublic class Person {\n    String name;\n    int age;\n\n    // Constructor using 'this' to avoid name clashes\n    public Person(String name, int age) {\n        this.name = name;  // 'this.name' is the instance variable, 'name' is the parameter\n        this.age = age;\n    }\n\n    // Constructor chaining with 'this'\n    public Person(String name) {\n        this(name, 18);  // Calls the (String, int) constructor\n    }\n\n    // Method using 'this' to pass the current object\n    public void introduce(Person other) {\n        System.out.println(\"Hi, I'm \" + this.name + \". Nice to meet you, \" + other.name + \"!\");\n    }\n}\n\nclass Main {\n    public static void main(String[] args) {\n        Person p1 = new Person(\"Alice\", 20);\n        Person p2 = new Person(\"Bob\");\n        p1.introduce(p2);  // Outputs: Hi, I'm Alice. Nice to meet you, Bob!\n    }\n}\n```\n---\n\n### Using Objects as Parameters\nYou can pass objects to methods just like primitive types (e.g., `int`). The method receives a reference to the object and can interact with its data or call its methods.\n\n```java\npublic class Book {\n    String title;\n    int pages;\n\n    public Book(String title, int pages) {\n        this.title = title;\n        this.pages = pages;\n    }\n\n    // Method that takes an object as a parameter\n    public void comparePages(Book otherBook) {\n        if (this.pages > otherBook.pages) {\n            System.out.println(this.title + \" has more pages than \" + otherBook.title);\n        } else {\n            System.out.println(otherBook.title + \" has more pages or equal to \" + this.title);\n        }\n    }\n}\n\nclass Main {\n    public static void main(String[] args) {\n        Book b1 = new Book(\"Java Basics\", 300);\n        Book b2 = new Book(\"Python Guide\", 250);\n        b1.comparePages(b2);  // Outputs: Java Basics has more pages than Python Guide\n    }\n}\n```\n---\n\n### Argument Passing\nIn Java, argument passing follows a simple rule: **everything is passed by value**. But what “value” means depends on the type:\n- **Primitive types** (e.g., `int`, `double`): The actual value is copied.\n- **Objects**: The *reference* (memory address) is copied, not the object itself. This means changes to the object’s fields are visible to the caller, but reassigning the reference isn’t.\n\n```java\npublic class Box {\n    int size;\n\n    public Box(int size) {\n        this.size = size;\n    }\n\n    // Method with primitive parameter\n    public void changePrimitive(int value) {\n        value = 100;  // Changes local copy, not the original\n    }\n\n    // Method with object parameter\n    public void changeObject(Box b) {\n        b.size = 200;  // Changes the object’s field (visible to caller)\n        b = new Box(300);  // Reassigns local reference (not visible to caller)\n    }\n}\n\nclass Main {\n    public static void main(String[] args) {\n        int num = 10;\n        Box myBox = new Box(50);\n\n        myBox.changePrimitive(num);\n        System.out.println(\"Num: \" + num);  // Still 10 (pass-by-value)\n\n        myBox.changeObject(myBox);\n        System.out.println(\"Box size: \" + myBox.size);  // Now 200 (object modified)\n    }\n}\n```\n---\n\n### Returning Objects\nMethods can return objects, allowing you to create or modify an object and send it back to the caller. The return type is the class name (or a superclass/interface).\n\n```java\npublic class Point {\n    int x;\n    int y;\n\n    public Point(int x, int y) {\n        this.x = x;\n        this.y = y;\n    }\n\n    // Method returning a new object\n    public Point move(int dx, int dy) {\n        return new Point(this.x + dx, this.y + dy);\n    }\n\n    public void display() {\n        System.out.println(\"Point: (\" + x + \", \" + y + \")\");\n    }\n}\n\nclass Main {\n    public static void main(String[] args) {\n        Point p1 = new Point(3, 4);\n        Point p2 = p1.move(2, -1);  // Returns a new Point object\n        p1.display();  // Point: (3, 4)\n        p2.display();  // Point: (5, 3)\n    }\n}\n```\n---\n### `finalize()`\n`finalize()` is a method in Java, defined in the `Object` class, that can be overridden by a subclass. It’s called by the garbage collector when it determines that an object is no longer reachable (i.e., there are no references to it) and is about to be reclaimed.\n- It gives an object a last chance to perform cleanup (e.g., releasing resources like file handles or network connections) before it’s destroyed.\n- `protected void finalize() throws Throwable`\n- **How it works**: \n  - The garbage collector (GC) identifies objects that are eligible for collection.\n  - If an object overrides `finalize()`, the GC places it in a queue for finalization.\n  - A separate Finalizer thread runs the `finalize()` method.\n  - After `finalize()` executes, the object can be collected in the next GC cycle.\n- **Key Points**:\n  - It’s not guaranteed to run, as the GC might never reclaim the object, or the program might exit first.\n  - It’s deprecated since Java 9 (2017) and removed in some later versions because it’s unreliable and can cause issues (e.g., delaying garbage collection or resurrecting objects).\n  - Modern practice favors explicit cleanup methods like `close()` with try-with-resources or using `Cleaner` (introduced in Java 9).\n- **Example**:\n  ```java\n  class MyClass {\n      @Override\n      protected void finalize() throws Throwable {\n          System.out.println(\"Object is being finalized\");\n          super.finalize(); // Call the parent’s finalize\n      }\n  }\n\n  public class Test {\n      public static void main(String[] args) {\n          MyClass obj = new MyClass();\n          obj = null; // Make it eligible for GC\n          System.gc(); // Suggest garbage collection (not guaranteed)\n      }\n  }\n  ```\n\n### `final` Keyword\n- **What it is**: `final` is a keyword in Java (and some other languages like C++) that restricts modification, depending on where it’s applied.\n- **Uses and Effects**:\n  1. **Final Variable**:\n     - Makes a variable constant; its value can’t be changed once assigned.\n     - Must be initialized at declaration or in a constructor (for instance fields).\n     - Example:\n       ```java\n       final int MAX_VALUE = 100;\n       MAX_VALUE = 200; // Error: cannot reassign\n       ```\n  2. **Final Method**:\n     - Prevents a method from being overridden in a subclass.\n     - Useful for ensuring a method’s behavior remains consistent.\n     - Example:\n       ```java\n       class Parent {\n           final void display() {\n               System.out.println(\"This is final\");\n           }\n       }\n       class Child extends Parent {\n           void display() { // Error: cannot override\n               System.out.println(\"Override attempt\");\n           }\n       }\n       ```\n  3. **Final Class**:\n     - Prevents a class from being subclassed (no inheritance).\n     - Often used for security or to enforce immutability (e.g., `String` class in Java).\n     - Example:\n       ```java\n       final class MyFinalClass {\n           // Class body\n       }\n       class SubClass extends MyFinalClass { // Error: cannot inherit\n       }\n       ```\n- **Key Points**:\n  - `final` enhances performance slightly (e.g., the compiler can inline final methods), but its main purpose is design clarity and safety.\n  - It’s unrelated to `finalize()` despite the similar name—`final` is about immutability or inheritance, while `finalize()` is about object lifecycle.\n\n### **Inheritance Basics**\nInheritance is a mechanism in OOP where a class (called a *subclass* or *derived class*) inherits properties and behaviors (fields and methods) from another class (called a *superclass* or *base class*). It promotes code reuse and establishes a \"is-a\" relationship between classes.\n\n- **Example**: If `Animal` is a superclass with a method `makeSound()`, a subclass `Dog` can inherit it and use or modify it.\n  ```java\n  class Animal {\n      void makeSound() {\n          System.out.println(\"Some sound\");\n      }\n  }\n\n  class Dog extends Animal {\n      // Inherits makeSound() automatically\n  }\n\n  public class Main {\n      public static void main(String[] args) {\n          Dog dog = new Dog();\n          dog.makeSound(); // Outputs: \"Some sound\"\n      }\n  }\n  ```\n- **Key Points**:\n  - The subclass can add its own fields/methods or modify inherited ones.\n  - Use keywords like `extends` (Java) or `:` (C++) to inherit.\n\n---\n\n### **Access Control**\nAccess control determines how inherited members (fields, methods) are accessible in the subclass or outside it. Common access modifiers include:\n- **Public**: Accessible everywhere.\n- **Protected**: Accessible within the same package and also in subclasses (even if in different packages).\n- **Private**: Accessible only within the same class (not inherited).\n- **Default** (no modifier): Accessible only within the same package.\n\n- **Example**:\n  ```java\n  class Animal {\n      public String name = \"Generic Animal\";\n      protected int age = 5;\n      private String secret = \"Hidden\";\n  }\n\n  class Dog extends Animal {\n      void display() {\n          System.out.println(name);  // Accessible (public)\n          System.out.println(age);   // Accessible (protected)\n          // System.out.println(secret); // Error: private not inherited\n      }\n  }\n  ```\n\n---\n\n### **Multilevel Inheritance**\nThis occurs when a class inherits from a subclass, forming a chain of inheritance (e.g., `A → B → C`).\n- **Example**:\n  ```java\n  class Animal {\n      void eat() {\n          System.out.println(\"Eating...\");\n      }\n  }\n\n  class Mammal extends Animal {\n      void walk() {\n          System.out.println(\"Walking...\");\n      }\n  }\n\n  class Dog extends Mammal {\n      void bark() {\n          System.out.println(\"Barking...\");\n      }\n  }\n\n  public class Main {\n      public static void main(String[] args) {\n          Dog dog = new Dog();\n          dog.eat();  // From Animal\n          dog.walk(); // From Mammal\n          dog.bark(); // From Dog\n      }\n  }\n  ```\n- **Note**: While multilevel inheritance is useful, excessive levels can complicate code maintenance.\n\n---\n\n### **Method Overloading (Polymorphism)**\nMethod overloading is a form of *compile-time polymorphism*, where multiple methods share the same name but differ in parameters (number, type, or order). The compiler decides which method to call based on the arguments.\n\n- **Example**:\n  ```java\n  class Calculator {\n      int add(int a, int b) {\n          return a + b;\n      }\n\n      double add(double a, double b) {\n          return a + b;\n      }\n\n      int add(int a, int b, int c) {\n          return a + b + c;\n      }\n  }\n\n  public class Main {\n      public static void main(String[] args) {\n          Calculator calc = new Calculator();\n          System.out.println(calc.add(2, 3));       // Calls int version\n          System.out.println(calc.add(2.5, 3.5));   // Calls double version\n          System.out.println(calc.add(1, 2, 3));    // Calls three-int version\n      }\n  }\n  ```\n- **Key Points**:\n  - Return type alone doesn’t define overloading; parameter lists must differ.\n  - It’s resolved at compile time.\n\n---\n\n### **Method Overriding (Polymorphism)**\nMethod overriding is a form of *runtime polymorphism*, where a subclass provides a specific implementation of a method already defined in its superclass. The method signature (name, parameters) must match exactly.\n\n- **Rules**:\n  - Must have the same name, return type (or covariant), and parameters.\n  - Access level cannot be more restrictive than the superclass method.\n  - Use `@Override` annotation (in Java) for clarity.\n\n- **Example**:\n  ```java\n  class Animal {\n      void makeSound() {\n          System.out.println(\"Some sound\");\n      }\n  }\n\n  class Dog extends Animal {\n      @Override\n      void makeSound() {\n          System.out.println(\"Woof!\");\n      }\n  }\n\n  public class Main {\n      public static void main(String[] args) {\n          Animal myDog = new Dog(); // Upcasting\n          myDog.makeSound();       // Outputs: \"Woof!\" (runtime decision)\n      }\n  }\n  ```\n- **Key Points**:\n  - It’s resolved at runtime based on the object’s actual type, not the reference type.\n  - Enables dynamic behavior in inheritance hierarchies.\n\n---\n\n### **Abstract Classes**\nAn abstract class is a class that cannot be instantiated directly and is meant to be inherited. It can contain both abstract methods (no implementation) and concrete methods (with implementation).\n\n- **Syntax**:\n  ```java\n  abstract class Animal {\n      abstract void makeSound(); // Abstract method (no body)\n\n      void sleep() {            // Concrete method\n          System.out.println(\"Sleeping...\");\n      }\n  }\n\n  class Dog extends Animal {\n      void makeSound() {        // Must implement abstract method\n          System.out.println(\"Woof!\");\n      }\n  }\n\n  public class Main {\n      public static void main(String[] args) {\n          Dog dog = new Dog();\n          dog.makeSound(); // Outputs: \"Woof!\"\n          dog.sleep();     // Outputs: \"Sleeping...\"\n      }\n  }\n  ```\n- **Key Points**:\n  - Subclasses must implement all abstract methods unless they are also abstract.\n  - Used to define a common interface or template for subclasses.\n  - Contrast with interfaces: Abstract classes can have state (fields) and concrete methods.\n\n---\n"
  },
  {
    "url": "Courses/Languages/Java/Operators.html",
    "content": "---\nid: Operators\naliases: []\ntags: []\ntitle: Operators\n---\n\n### Categories of Java Operators\n1. **Arithmetic Operators**\n2. **Relational Operators**\n3. **Logical Operators**\n4. **Bitwise Operators**\n5. **Assignment Operators**\n6. **Unary Operators**\n7. **Conditional (Ternary) Operator**\n8. **Instanceof Operator**\n9. **Other Operators (e.g., Dot, Cast)**\n\n---\n\n### 1. **Arithmetic Operators**\n- **Purpose**: Perform basic mathematical operations.\n- **Operators**:\n  - `+` : Addition\n  - `-` : Subtraction\n  - `*` : Multiplication\n  - `/` : Division\n  - `%` : Modulus (remainder)\n- **Example**:\n```java\npublic class Main {\n    public static void main(String[] args) {\n        int a = 10, b = 3;\n        System.out.println(\"a + b = \" + (a + b)); // 13\n        System.out.println(\"a - b = \" + (a - b)); // 7\n        System.out.println(\"a * b = \" + (a * b)); // 30\n        System.out.println(\"a / b = \" + (a / b)); // 3 (integer division)\n        System.out.println(\"a % b = \" + (a % b)); // 1 (remainder)\n    }\n}\n```\n- **Note**: `+` can also concatenate strings (e.g., `\"Hello \" + \"World\"` → `\"Hello World\"`).\n\n---\n\n### 2. **Relational Operators**\n- **Purpose**: Compare two operands and return a boolean (`true` or `false`).\n- **Operators**:\n  - `==` : Equal to\n  - `!=` : Not equal to\n  - `>` : Greater than\n  - `<` : Less than\n  - `>=` : Greater than or equal to\n  - `<=` : Less than or equal to\n- **Example**:\n```java\npublic class Main {\n    public static void main(String[] args) {\n        int x = 5, y = 10;\n        System.out.println(\"x == y: \" + (x == y)); // false\n        System.out.println(\"x != y: \" + (x != y)); // true\n        System.out.println(\"x > y: \" + (x > y));   // false\n        System.out.println(\"x < y: \" + (x < y));   // true\n        System.out.println(\"x >= y: \" + (x >= y)); // false\n        System.out.println(\"x <= y: \" + (x <= y)); // true\n    }\n}\n```\n- **Note**: Use `equals()` for object comparison (e.g., `String`), not `==`, which checks reference equality.\n\n---\n\n### 3. **Logical Operators**\n- **Purpose**: Combine boolean expressions.\n- **Operators**:\n  - `&&` : Logical AND (true if both operands are true)\n  - `||` : Logical OR (true if at least one operand is true)\n  - `!` : Logical NOT (inverts the boolean value)\n- **Example**:\n```java\npublic class Main {\n    public static void main(String[] args) {\n        boolean a = true, b = false;\n        System.out.println(\"a && b: \" + (a && b)); // false\n        System.out.println(\"a || b: \" + (a || b)); // true\n        System.out.println(\"!a: \" + (!a));         // false\n    }\n}\n```\n- **Short-Circuiting**: `&&` and `||` evaluate the second operand only if necessary (e.g., `false && expr` skips `expr`).\n\n---\n\n### 4. **Bitwise Operators**\n- **Purpose**: Perform operations on individual bits of integer types.\n- **Operators**:\n  - `&` : Bitwise AND\n  - `|` : Bitwise OR\n  - `^` : Bitwise XOR (exclusive OR)\n  - `~` : Bitwise NOT (complement)\n  - `<<` : Left shift\n  - `>>` : Right shift (signed)\n  - `>>>` : Unsigned right shift\n- **Example**:\n```java\npublic class Main {\n    public static void main(String[] args) {\n        int a = 5;  // Binary: 0101\n        int b = 3;  // Binary: 0011\n        System.out.println(\"a & b: \" + (a & b));  // 1 (0001)\n        System.out.println(\"a | b: \" + (a | b));  // 7 (0111)\n        System.out.println(\"a ^ b: \" + (a ^ b));  // 6 (0110)\n        System.out.println(\"~a: \" + (~a));        // -6 (inverts bits)\n        System.out.println(\"a << 1: \" + (a << 1)); // 10 (1010)\n        System.out.println(\"a >> 1: \" + (a >> 1)); // 2 (0010)\n    }\n}\n```\n- **Use Case**: Low-level programming, flags, or optimization.\n\n---\n\n### 5. **Assignment Operators**\n- **Purpose**: Assign values to variables, often combined with other operations.\n- **Operators**:\n  - `=` : Simple assignment\n  - `+=` : Add and assign\n  - `-=` : Subtract and assign\n  - `*=` : Multiply and assign\n  - `/=` : Divide and assign\n  - `%=` : Modulus and assign\n  - `&=` : Bitwise AND and assign\n  - `|=` : Bitwise OR and assign\n  - `^=` : Bitwise XOR and assign\n  - `<<=` : Left shift and assign\n  - `>>=` : Right shift and assign\n- **Example**:\n```java\npublic class Main {\n    public static void main(String[] args) {\n        int x = 10;\n        x += 5;  // x = x + 5\n        System.out.println(\"x += 5: \" + x); // 15\n        x *= 2;  // x = x * 2\n        System.out.println(\"x *= 2: \" + x); // 30\n    }\n}\n```\n\n---\n\n### 6. **Unary Operators**\n- **Purpose**: Operate on a single operand.\n- **Operators**:\n  - `+` : Unary plus (indicates positive value, rarely used)\n  - `-` : Unary minus (negates value)\n  - `++` : Increment (increases by 1)\n  - `--` : Decrement (decreases by 1)\n  - `!` : Logical NOT (inverts boolean)\n- **Example**:\n```java\npublic class Main {\n    public static void main(String[] args) {\n        int a = 5;\n        System.out.println(\"-a: \" + (-a));   // -5\n        a++;  // a = a + 1\n        System.out.println(\"a++: \" + a);    // 6\n        a--;  // a = a - 1\n        System.out.println(\"a--: \" + a);    // 5\n        boolean b = true;\n        System.out.println(\"!b: \" + (!b));  // false\n    }\n}\n```\n- **Note**: `++a` (pre-increment) vs. `a++` (post-increment) differ in when the value is updated in expressions.\n\n---\n\n### 7. **Conditional (Ternary) Operator**\n- **Purpose**: A shorthand for `if-else` statements.\n- **Syntax**: `condition ? valueIfTrue : valueIfFalse`\n- **Example**:\n```java\npublic class Main {\n    public static void main(String[] args) {\n        int a = 10, b = 20;\n        int max = (a > b) ? a : b;\n        System.out.println(\"Max: \" + max); // 20\n    }\n}\n```\n- **Significance**: Concise way to assign values based on conditions.\n\n---\n\n### 8. **Instanceof Operator**\n- **Purpose**: Tests whether an object is an instance of a specific class or interface.\n- **Syntax**: `object instanceof ClassName`\n- **Example**:\n```java\npublic class Main {\n    public static void main(String[] args) {\n        String str = \"Hello\";\n        System.out.println(\"str instanceof String: \" + (str instanceof String)); // true\n        System.out.println(\"str instanceof Object: \" + (str instanceof Object)); // true\n    }\n}\n```\n- **Use Case**: Useful in polymorphism and type checking.\n\n---\n\n### 9. **Other Operators**\n- **Dot Operator (`.`)**\n  - **Purpose**: Accesses members (fields, methods) of an object or class.\n  - **Example**: `System.out.println()` uses `.` to access `out` and `println`.\n- **Cast Operator**\n  - **Purpose**: Converts one data type to another.\n  - **Example**: \n```java\ndouble d = 5.7;\nint i = (int) d; // Casts double to int\nSystem.out.println(i); // 5\n```\n\n---\n\n### Operator Precedence\nOperators have a hierarchy determining the order of evaluation:\n- Highest: `()`, `[]`, `.`\n- Unary: `++`, `--`, `!`, `~`\n- Arithmetic: `*`, `/`, `%`, then `+`, `-`\n- Relational: `<`, `>`, `<=`, `>=`, then `==`, `!=`\n- Logical: `&&`, then `||`\n- Ternary: `?:`\n- Assignment: `=`, `+=`, etc.\n- **Tip**: Use parentheses `()` to override precedence.\n\n---\n"
  },
  {
    "url": "Courses/Languages/Javascript/javascript.html",
    "content": "---\nid: Javascript\naliases: []\ntags: []\n---\n\nJavascript / Java (same thing) is the language used to make websites by making them dynamic.\n- [Just-in-time-compiled](https://www.howtogeek.com/devops/what-is-just-in-time-jit-compilation/#what-does-jit-compilation-do) - Compiling of program while it's being executed.\n- [Prototype-based](https://developer.mozilla.org/en-US/docs/Glossary/Prototype-based_programming)\n- Single-threaded\n- Dynamic language\n\n```js\nconsole.log(\"Hello World\");\n```\n\nIn JS, you can use a template literal to interpolate dynamic values into a string templates. Kinda like python f-string.\nTemplate literals start with back-ticks. It allows us to interpolate dynamic values into string template.\n```js\nconst v = 5; //declare using const\nlet w = 5; // declare using let\nconsole.log(`v is ${v}`);\n```\n\n### null\nIt's null. Most programming languages have it. null values are 'falsy'\n**Conversion^ - \n- False - boolean\n- 0 - number zero\n- '' = empty string \n\n### undefined poor man's null.\n\n**undefined** means the variable was never assigned a value.\n**null** is just same but we assign it explicitly. It doesn't mean we can't assign undefined.\n\n### Operators and if-else\nNormal operator usage and normal if else and ternary operator like python or c.\n\n### Functions \n```js\nconsole.log(getLabel(3))\n// prints 'awful'\n\nfunction getLabel(numStars) {\n  if (numStars > 7) {\n    return 'great'\n  } else if (numStars > 3) {\n    return 'okay'\n  } else {\n    return 'awful'\n  }\n}\n```\nJS interpreter reads whole first and function definition are globally scoped, then goes back to executing where it is called. In JS it doesn't matter where the function definitions occur. \n\n#### Other ways to define a function\n```js\n//using the function keyworkd\nfunction add(x, y) {\n    return x + y;\n}\nconst add = function(x, y) {\n  return x + y\n}\n\n// Fat arrow function\nconst add = (x, y) => {\n  return x + y\n}\n```\n\n### Arrays\nThese are dynamically allocated arrays. Python list. C++ vectors.\n```js\nconst numbers = [1, 2, 3, 4, 5]\nconst strings = ['banana', 'apple', 'pear']\nconst miscellaneous = [true, 7, 'adamantium']\nnumbers.push(6);\nconsole.log(numbers[0])\n```\n### Loops \n```js\nfor (let i = 0; i < 10; i++) {\n  console.log(i)\n}\n\nlet list = [4, 5, 6];\n// for...in return the keys\nfor (let i in list) {\n  console.log(i); // \"0\", \"1\", \"2\",\n}\n//for...of return the values.\nfor (let i of list) {\n  console.log(i); // 4, 5, 6\n}\n```\n\n### Objects \nJS has a object type. They are variables that can hold more complex information than basic types like String, Number and Boolean.\n```js\nconst apple = {\n  name: 'Apple',\n  radius: 2,\n  color: 'red',\n}\n```\n\n**Syntactic Sugar**\n\n```js\nconst name = 'Apple'\nconst radius = 2\nconst color = 'red'\nconst apple = {\n  name,\n  radius,\n  color,\n}\n\n// Similar to \nconst name = 'Apple'\nconst radius = 2\nconst color = 'red'\nconst apple = {\n  name: name,\n  radius: radius,\n  color: color,\n}\n```\n#### Object Methods\nJavascript Object have methods. Methods are functions that are defined inside an object. They can access and change the properties of the object in question.\n\n```js\nconst person = {\n  firstName: 'Lane',\n  lastName: 'Wagner',\n  getFullName() {\n    return this.firstName + ' ' + this.lastName\n  }\n}\n\nconsole.log(person.getFullName())\n```\n\nMethods can mutate the properties of their object.\n\n```js\nconst tree = {\n  height: 256,\n  color: 'green',\n  cut() {\n    this.height /= 2\n  }\n}\n\ntree.cut()\nconsole.log(tree.height)\n// prints 128\n```\n\n### this\n```js\nconst author = {\n  firstName: 'Lane',\n  lastName: 'Wagner',\n  getName() {\n    return `${this.firstName} ${this.lastName}`\n  }\n}\nconsole.log(author.getName())\n// Prints: Lane Wagner\n```\n\n```js\nconst author = {\n  firstName: 'Lane',\n  lastName: 'Wagner',\n  getName: () => {\n    return `${this.firstName} ${this.lastName}`\n  }\n}\nconsole.log(author.getName())\n// Prints: undefined undefined\n// because the parent scope (the scope outside of the author object)\n// never defined .firstName and .lastName properties\n```\n\nAs we can see when we use the **fat arrow function**  syntax, you sometimes get a different this object. \n\n==this== points to the object on which it is called.\n\nThis is due to property how **fat arrow functions** work. With a fat arrow function ==this== will always refer to the same object that its parent scope would. \n\nEssentially ==this's == value depends on which context it appears - function, class or global. \n\n### Errors\nGonna catch deez errors.\n\nIt's try catch finally. finally is rarely used so we generally use try-catch. \n\n```js\ntry {\n  //code to run\n} catch (err) {\n  //if err occurs log it out\n  console.log(err.message);\n} finally {\n  // It will always run. [OPTIONAL]\n}\n```\n\nThrowing our own error. If we know something bad will happen if the input is of something we know is entered, we can throw an error.\n```js\nthrow new Error('something went wrong');\n```\n\n### Runtime\nA runtime environment is where your program runs. Since JS can run in many places outside browsers so different runtimes are made.\n\n#### Different runtime\n- A Browser\n- Nodejs\n- A web worker within a browser\n- Deno.js\n- Bun and many more.\n\n#### Whats different in all these runtime\n- Performance\n- API - you can use Canvas api to render graphics in browser but can't do those things in node or bun that don't support those.\n- Global object - In browsers, global object is ==window== but in node it's ==global==.\n\n[JS Runtimes](https://www.freecodecamp.org/news/javascript-engine-and-runtime-explained/)\n\n"
  },
  {
    "url": "Courses/Languages/Rust/Async.html",
    "content": "---\nid: Async\naliases: []\ntags: []\ntitle: Async\n---\n\n## Futures and Async Rust\nThe Key elements of asynchronous programming in Rust are futures and Rust's `async` and `await` keywords.\n\nA future is a value that may not be ready now but will become ready at some point in the future. Rust provides a `Future` trait as a building block so that different async operations can be implemented with different data structures but with a common interface.\n\n"
  },
  {
    "url": "Courses/Languages/Rust/Collections.html",
    "content": "---\nid: Collections\naliases: \ntags:\n  - \"#Rust/Collections\"\n  - Rust\n  - Rust/Collections/Vectors\n  - Rust/Collections/HashMap\n  - Rust/Collections/String\ntitle: Collections\n---\n\n## Vectors\nVectors allow you to store more than one value in a single data structure that puts all the values next to each other in memory. Vectors can only store values of the same type. They are similar to vector in C++.\n\n### Create a vector\n```rust\nlet v: Vec<i32> = Vec::new();\n```\nHere we had to define the type cause we haven't put any value in the vector.\n\nGenerally rust compiler will infer the type of data that is stored inside the vector if put an element while defining the vector.\n```rust\n    let v = vec![1, 2, 3];\n```\n### Update a vector\nWe use the push method to push element to the back of the vector\n```rust\n    let mut v = Vec::new();\n\n    v.push(5);\n    v.push(6);\n    v.push(7);\n    v.push(8);\n```\n### Reading elements of a vector\nIn rust we have two way to get the value of a vector at an index - `[]`,`get()`. The vectors in rust at 0 indexed so first element is at index 0.\n\n```rust\n    let v = vec![1, 2, 3, 4, 5];\n\n    let third: &i32 = &v[2];\n    println!(\"The third element is {third}\");\n\n    let third: Option<&i32> = v.get(2);\n    match third {\n        Some(third) => println!(\"The third element is {third}\"),\n        None => println!(\"There is no third element.\"),\n    }\n```\n\n### Iterating over the values in a vector\nTo iterate over elements in a vector we can use for loop to get a mutable or immutable reference of elements in a vector\n```rust\n    let v = vec![1, 2, 3, 4, 5];\n    for i in &b {\n        println!(\"{i}\")\n    }\n\n    let mut v = vec![100, 32, 57];\n    for i in t &mut v {\n        *i += 50;\n    }\n\n```\nVectors (`Vec<T>`) implement the `iter()` method, which returns an iterator over references to the elements in the vector.\n```rust\n    let v = vec![1, 2, 3, 4, 5];\n    for i in v.iter() {\n        println!(\"{i}\")\n    }\n```\n\n### Using an enum to store multiple types\nVectors can only store values that are of the same type. This can be inconvenient; there are definitely use cases for needing to store a list of items of different types\n\n```rust\n    enum SpreadsheetCell {\n        Int(i32),\n        Float(f64),\n        Text(String),\n    }\n\n    let row = vec![\n        SpreadsheetCell::Int(3),\n        SpreadsheetCell::Text(String::from(\"blue\")),\n        SpreadsheetCell::Float(10.12),\n    ];\n```\n\n### Dropping a vector\nVector in rust implement the `Drop` trait i.e. when a vector goes out of scope it would be freed.\n\n```rust\n    {\n        let v = vec![1, 2, 3, 4];\n\n        // do stuff with v\n    } // <- v goes out of scope and is freed here\n```\n\n## String\nRust only has one string type in the core language, which is `str` - string literal.\n\nThe `String` type, which is provided by rust's standard library is a growable, mutable, owned, UTF-8, heap allocated string type.\n\nA `String` is a wrapper around `Vec<u8>` but the `len()` method return the number of bytes not the number of characters. For example the string `\"hola\"` is 4 bytes long(each char is 1-byte in UTF-8) but the string `\"Здравствуйте\"` is 24 bytes long(each cyrillic character is 2 bytes long in UTF-8).\n\nSince `String` is UTF-8 encoded this means that a character can take 1 to 4 bytes to store a char making byte level indexing unreliable. There if we do `&s[0]` this would give us a compilation error.\n\n### Creating a new string\nMany of the same operations available with `Vec<T>` are available with `String` as well because `String` is actually implemented as a wrapper around a vector of bytes with some extra guarantees, restrictions, and capabilities\n```rust\n    let mut s = String::new();\n    let v = String::new(\"hello\")\n```\nThis creates a new, empty string `s` into which we can load data. `v` is a string that is allocated to with initialized string.\n\n### Updating a string\nWe can grow a string using `push_str` method to append a string slice. \n```rust\n    let mut s = String::from(\"foo\");\n    s.push_str(\"bar\");\n```\nthis appends the string literal `\"bar\"` to the string `\"foo\"`. The `push_str` doesn't take ownership of the string literal.\n\nThe `push` method can be used to append a single character.\n```rust\n    let mut s = String::from(\"lo\");\n    s.push('l');\n```\n### Concatenation of string\nIn Rust, the `+` operator is used to concatenate strings\n\nUsing the + Operator:\n- The `+` operator uses the `add` method, which has the signature `fn add(self, s: &str) -> String`.\n- When you use `+`, the first string (`s1`) is moved into the `add` method, meaning it is no longer valid after the operation.\n- The second string (`s2`) is passed as a reference (`&s2`), and Rust automatically coerces `&String` to `&str` using deref coercion.\n- The result is a new String that combines the contents of `s1` and `s2`.\n\n```rust\nlet s1 = String::from(\"Hello, \");\nlet s2 = String::from(\"world!\");\nlet s3 = s1 + &s2; // s1 is moved, s2 remains valid\n```\nIf we need to concatenate multiple strings, the behavior of the + operator gets unwieldy:\n\n```rust\n    let s1 = String::from(\"tic\");\n    let s2 = String::from(\"tac\");\n    let s3 = String::from(\"toe\");\n\n    let s = s1 + \"-\" + &s2 + \"-\" + &s3;\n\n```\nthis can be made easier using the `format!` macro.\n```rust\n    let s = format!(\"{s1}-{s2}-{s3}\"); // all are valid afterwards\n```\n\n### Ways to interpret string\nRust provides three perspectives for working with strings:\n- Bytes: The raw byte representation (e.g., [224, 164, 168, ...] for the Hindi word \"नमस्ते\").\n- Scalar Values (Unicode): The char type, which represents Unicode scalar values (e.g., ['न', 'म', 'स', '्', 'त', 'े'] for \"नमस्ते\").\n- Grapheme Clusters: The closest thing to human-readable \"letters\" (e.g., [\"न\", \"म\", \"स्\", \"ते\"] for \"नमस्ते\").\nEach perspective is useful depending on the context, and Rust allows you to choose the appropriate one.\n\n### Iterating over a string\nThe best way to operate on pieces of strings is to be explicit about whether you want characters or bytes.\n\n```rust\nfor c in \"Зд\".chars() {\n    println!(\"{c}\");\n}\n// З\n// д\n```\n\n```rust\nfor b in \"Зд\".bytes() {\n    println!(\"{b}\");\n}\n\n// 208\n// 151\n// 208\n// 180\n```\n\n## Hash Maps\nThe type `HashMap<K, V>` stores a mapping of keys of type `K` to values of type `V` using a hashing function, which determines how it places these keys and values into memory\n\n### Creating a new map\nOne way to create an empty hash map is to use `new` and to add elements with `insert`.\n```rust\n    use std::collections::HashMap;\n\n    let mut scores = HashMap::new();\n\n    scores.insert(String::from(\"Blue\"), 10);\n    scores.insert(String::from(\"Yellow\"), 50);\n```\n\n### Accessing elements in a hash map\nWe can get a value out of the hash map by providing its key to the `get` method.\n\n```rust\n    use std::collections::HashMap;\n\n    let mut scores = HashMap::new();\n\n    scores.insert(String::from(\"Blue\"), 10);\n    scores.insert(String::from(\"Yellow\"), 50);\n\n    let team_name = String::from(\"Blue\");\n    let score = scores.get(&team_name).copied().unwrap_or(0);\n```\n\n### Iterating over a hash map\n```rust\n    use std::collections::HashMap;\n\n    let mut scores = HashMap::new();\n\n    scores.insert(String::from(\"Blue\"), 10);\n    scores.insert(String::from(\"Yellow\"), 50);\n\n    for (key, value) in &scores {\n        println!(\"{key}: {value}\");\n    }\n```\n\n### Ownership in hash map\nFor types that implement the Copy trait, like `i32`, the values are copied into the hash map. For owned values like `String`, the values will be moved and the hash map will be the owner of those values,\n\n```rust\n    use std::collections::HashMap;\n\n    let field_name = String::from(\"Favorite color\");\n    let field_value = String::from(\"Blue\");\n\n    let mut map = HashMap::new();\n    map.insert(field_name, field_value);\n    // field_name and field_value are invalid at this point, try using them and\n    // see what compiler error you get!\n```\n\n### Overwriting a value\nIf we insert a key and a value into a hash map and then insert that same key with a different value, the value associated with that key will be replaced.\n\n```rust\n    use std::collections::HashMap;\n\n    let mut scores = HashMap::new();\n\n    scores.insert(String::from(\"Blue\"), 10);\n    scores.insert(String::from(\"Blue\"), 25);\n\n    println!(\"{scores:?}\");\n```\n\n### Adding a Key and Value Only If a Key Isn’t Present\nHash maps have a special API for this called entry that takes the key you want to check as a parameter. The return value of the entry method is an enum called Entry that represents a value that might or might not exist.\n\n```rust\n    use std::collections::HashMap;\n\n    let mut scores = HashMap::new();\n    scores.insert(String::from(\"Blue\"), 10);\n\n    scores.entry(String::from(\"Yellow\")).or_insert(50);\n    scores.entry(String::from(\"Blue\")).or_insert(50);\n\n    println!(\"{scores:?}\");\n```\n"
  },
  {
    "url": "Courses/Languages/Rust/Concurrency.html",
    "content": "---\nid: Concurrency\naliases: []\ntags: []\n---\n\n**Concurrent programming**, where different parts of a program execute independently\n\n## Using Threads to run code Simultaneously\nIn an operating system, most programs are run in a process, and the operating system will manage multiple processes. Within a program, you can have different parts being run by threads.\n\nConcurrent programming can help us improve performance but also adds complexity to the code and can lead to bugs such as race conditions, deadlocks, etc.\n\n### Threads\n#### Creating a new thread\nTo create a new thread, we call the `thread::spawn` function and pass it a closure containing the code we want to run in the new thread.\n\n```rust\nuse std::thread;\nuse std::time::Duration;\n\nfn main() {\n    thread::spawn(|| {\n        for i in 1..10 {\n            println!(\"hi number {i} from the spawned thread!\");\n            thread::sleep(Duration::from_millis(1));\n        }\n    });\n\n    for i in 1..5 {\n        println!(\"hi number {i} from the main thread!\");\n        thread::sleep(Duration::from_millis(1));\n    }\n}\n```\n> When the main threads exit, all spawn threads must also exit even if they are not finished.\n\n#### Waiting for all threads to finish\nwe can wait for a spawned thread to not end even if the main thread has finished exiting by using `join` method. The return type of `thread::spawn` is JoinHandle. A JoinHandle is an owned value that, when we call the `join` method on it, it'll wait for the thread to finish.\n```rust\nuse std::thread;\nuse std::time::Duration;\n\nfn main() {\n    let handle = thread::spawn(|| {\n        for i in 1..10 {\n            println!(\"hi number {i} from the spawned thread!\");\n            thread::sleep(Duration::from_millis(1));\n        }\n    });\n\n    for i in 1..5 {\n        println!(\"hi number {i} from the main thread!\");\n        thread::sleep(Duration::from_millis(1));\n    }\n\n    handle.join().unwrap();\n}\n```\n\n#### Using move closures with threads\nthe `move` keyword is used in closures to indicate that the closure should take ownership of the variables it captures from its surrounding environment.\n\n```rust\nuse std::thread;\n\nfn main() {\n    let v = vec![1, 2, 3];\n\n    let handle = thread::spawn(move || {\n        println!(\"Here's a vector: {v:?}\");\n    });\n\n    handle.join().unwrap();\n}\n```\nwe use the `move` keyword to pass the ownership of `v` to the new thread. The vector needs to be moved into the new thread as to make sure that the vector is being modified at one place. Since keeping it in the main thread and passing a reference in the new thread can cause bugs, therefore we transfer the ownership of `v` to the spawned thread.\n\n## Using Message Passing\nOne increasingly popular approach to safe concurrency is message passing, where threads or actors communicate by sending each other messages containing data.\n\nTo accomplish this we use channels. A channel has two halves: a transmitter and receiver.\n\n```rust\nuse std::sync::mpsc;\nuse std::thread;\n\nfn main() {\n    let (tx, rx) = mpsc::channel();\n\n    thread::spawn(move || {\n        let val = String::from(\"hi\");\n        tx.send(val).unwrap();\n    });\n\n    let received = rx.recv().unwrap();\n    println!(\"Got: {received}\");\n}\n```\n\n- we create a new channel using `mpsc::channel` function. `mpsc - multiple producer, single customer`. The mpsc channel returns a tuple, `(tx, rx)` - (transmitter, receiver)\n- The transmitter has a `send` method that takes the value we want to send which returns a `Result<T, E>`.\n- The receiver has two useful methods: `recv` and `try_recv`.\n\n### **`recv` Method**\nThe `recv` method blocks the current thread until a message is received from the channel. If no message is available, the thread will wait indefinitely until a message is sent.\n\n- **Blocking**: The thread is blocked until a message is received.\n- **Result**: Returns a `Result<T, RecvError>`. If a message is received, it returns `Ok(message)`. If the sender is dropped and no more messages will be sent, it returns `Err(RecvError)`.\n\n```rust\nuse std::sync::mpsc;\nuse std::thread;\n\nfn main() {\n    let (tx, rx) = mpsc::channel();\n\n    thread::spawn(move || {\n        let val = String::from(\"Hello\");\n        tx.send(val).unwrap();\n    });\n\n    // Block until a message is received\n    let received = rx.recv().unwrap();\n    println!(\"Got: {}\", received);\n}\n```\n\n### **`try_recv` Method**\nThe `try_recv` method attempts to receive a message from the channel without blocking. If no message is available, it returns immediately with an error instead of waiting.\n\n- **Non-blocking**: The thread is not blocked. If no message is available, it returns immediately.\n- **Result**: Returns a `Result<T, TryRecvError>`. If a message is received, it returns `Ok(message)`. If no message is available, it returns `Err(TryRecvError::Empty)`. If the sender is dropped and no more messages will be sent, it returns `Err(TryRecvError::Disconnected)`.\n\n#### Example:\n```rust\nuse std::sync::mpsc;\nuse std::thread;\nuse std::time::Duration;\n\nfn main() {\n    let (tx, rx) = mpsc::channel();\n\n    thread::spawn(move || {\n        thread::sleep(Duration::from_secs(1)); // Simulate some work\n        let val = String::from(\"Hello\");\n        tx.send(val).unwrap();\n    });\n\n    loop {\n        match rx.try_recv() {\n            Ok(message) => {\n                println!(\"Got: {}\", message);\n                break;\n            }\n            Err(mpsc::TryRecvError::Empty) => {\n                println!(\"No message yet, doing other work...\");\n                thread::sleep(Duration::from_millis(200)); // Simulate other work\n            }\n            Err(mpsc::TryRecvError::Disconnected) => {\n                println!(\"Sender dropped, no more messages.\");\n                break;\n            }\n        }\n    }\n}\n```\n#### **Channels and Ownership:**\n- Channels in Rust (`mpsc`) allow threads to send and receive messages.\n- When you send a value through a channel using `tx.send(val)`, **ownership of the value is transferred** to the receiver.\n- This means you can't use the value after sending it, as it no longer belongs to the sender.\n\n```rust\nuse std::sync::mpsc;\nuse std::thread;\n\nfn main() {\n    let (tx, rx) = mpsc::channel();\n\n    thread::spawn(move || {\n        let val = String::from(\"hi\");\n        tx.send(val).unwrap(); // Ownership of `val` is transferred to the receiver\n        println!(\"val is {val}\"); // Error! `val` is no longer valid here\n    });\n\n    let received = rx.recv().unwrap();\n    println!(\"Got: {received}\");\n}\n```\n\n#### **Sending Multiple Values:**\n- You can send multiple values through a channel, and the receiver can process them one by one.\n```rust\nuse std::sync::mpsc;\nuse std::thread;\nuse std::time::Duration;\n\nfn main() {\n    let (tx, rx) = mpsc::channel();\n\n    thread::spawn(move || {\n        let vals = vec![\n            String::from(\"hi\"),\n            String::from(\"from\"),\n            String::from(\"the\"),\n            String::from(\"thread\"),\n        ];\n\n        for val in vals {\n            tx.send(val).unwrap(); // Send each value\n            thread::sleep(Duration::from_secs(1)); // Pause between sends\n        }\n    });\n\n    for received in rx {\n        println!(\"Got: {received}\"); // Print each received value\n    }\n}\n```\n\n#### **Multiple Producers:**\n- You can have multiple threads sending messages to the same receiver by cloning the transmitter (`tx`).\n```rust\nuse std::sync::mpsc;\nuse std::thread;\nuse std::time::Duration;\n\nfn main() {\n    let (tx, rx) = mpsc::channel();\n    let tx1 = tx.clone(); // Clone the transmitter\n\n    // First thread\n    thread::spawn(move || {\n        let vals = vec![\n            String::from(\"hi\"),\n            String::from(\"from\"),\n            String::from(\"the\"),\n            String::from(\"thread\"),\n        ];\n\n        for val in vals {\n            tx1.send(val).unwrap();\n            thread::sleep(Duration::from_secs(1));\n        }\n    });\n\n    // Second thread\n    thread::spawn(move || {\n        let vals = vec![\n            String::from(\"more\"),\n            String::from(\"messages\"),\n            String::from(\"for\"),\n            String::from(\"you\"),\n        ];\n\n        for val in vals {\n            tx.send(val).unwrap();\n            thread::sleep(Duration::from_secs(1));\n        }\n    });\n\n    for received in rx {\n        println!(\"Got: {received}\");\n    }\n}\n```\n\n## Shared-State Concurrency\nShared memory concurrency is like multiple ownership: multiple threads can access the same memory location at the same time. \n\n### Using mutexes to allow access to data from one thread at a time.\nMutex (mutual exclusion) allows one thread to access some data at any given time. This is done using locks which signals that the thread want to access that data. This can really help in creating race conditions and deadlocks.\n\nIf we have to access a data, we put a lock on it and when you're done with the data that mutex guards, you must unlock it for other threads to use it.\n\n#### API of Mutex<T>\n```rust\nuse std::sync::Mutex;\n\nfn main() {\n    let m = Mutex::new(5);\n\n    {\n        let mut num = m.lock().unwrap();\n        *num = 6;\n    }\n\n    println!(\"m = {m:?}\");\n}\n```\nWe create a `Mutex<T>` with the `new` function. We use the lock method that returns a smart pointer called `MutexGuard`, wrapped in a `LockResult` that we handled with the call to unwrap. The `MutexGuard` implements `Deref` to point to out inner data and `Drop` trait to release the lock automatically when it goes goes out of scope.\n\n### Sharing a `Mutex<T>` Between Multiple Threads using `Arc<T>`\n`Arc<T>` is a reference counter like `Rc<T>` but is atomic in nature ie it's an atomically reference counted type.\n\n```rust\nuse std::sync::{Arc, Mutex};\nuse std::thread;\n\nfn main() {\n    let counter = Arc::new(Mutex::new(0));\n    let mut handles = vec![];\n\n    for _ in 0..10 {\n        let counter = Arc::clone(&counter);\n        let handle = thread::spawn(move || {\n            let mut num = counter.lock().unwrap();\n\n            *num += 1;\n        });\n        handles.push(handle);\n    }\n\n    for handle in handles {\n        handle.join().unwrap();\n    }\n\n    println!(\"Result: {}\", *counter.lock().unwrap());\n}\n```\n\n> `Rc<T>` came with the risk of creating reference cycles, where two `Rc<T>` came with the risk of creating reference cycles which may cause memory leaks. Similarly `Mutex<T>` comes with the risk of creating deadlocks.\n"
  },
  {
    "url": "Courses/Languages/Rust/Enums.html",
    "content": "---\nid: Enums\naliases: \ntags:\n  - \"#Rust/Enums\"\n  - Rust\n  - Rust/Option\ndescription: Enums in rust\ntitle: Enums\n---\n\nEnums in Rust, short for \"enumerations,\" are a powerful feature that allow you to define a type by enumerating its possible variants. Enums are useful for representing data that can be one of several different forms\n\n### Syntax\nAn enum is defined using the enum keyword, followed by the name of the enum and a set of variants enclosed in curly braces {}. Each variant can optionally hold data.\n\n```rust\nenum Direction {\n    North,\n    South,\n    East,\n    West,\n}\n```\nEnums can be useful to represent data in possible forms. For example - As of present the two used standard for IP protocols are IPv4 and IPv6. This can be easily be defined using enums and then matched using rust's `match` operator when needed.\n\n```rust\nenum IpAddrKind {\n    V4,\n    V6,\n}\n```\nYou can create instances of an enum by using one of its variants:\n\n```rust\nlet ipv4 = IpAddrKind::V4;\n```\n### Enums can store data\nEnums can also hold data. Each variant can have different types and amounts of associated data. This makes enums more flexible than simple constants.\n\n```rust\nenum WebEvent {\n    PageLoad,                 // No data\n    KeyPress(char),           // Single character\n    Click { x: i64, y: i64 }, // Named fields\n}\n\nlet load = WebEvent::PageLoad;\nlet press = WebEvent::KeyPress('a');\nlet click = WebEvent::Click { x: 100, y: 200 };\n```\n\n### Some inbuilt enums\nRust standard libraries has defined some enums for being used such as the `Option` enum or the `Result` enum.\n\n#### `Option<T>` enum\n`Option<T>` enum is implemented in Rust to not use `NULL` in as the way to showcase the absense of values as in other languages. Use of `NULL` is considered bad as using a null values as a non-null values can lead to many problems.\n\nDue to this reason, the rust's standard library instead of implementing `NULL` have implemented an `Option<T>` enum. It is used to represent a value that can either be something `(Some)` or nothing `(None)`. This is particularly useful for handling situations where a value might be absent, without resorting to null pointers or other error-prone mechanisms.\n\n```rust\nenum Option<T> {\n    None,\n    Some<T>,\n}\n```\n\n**Why Use Option?**\n  - The Option enum is used to handle cases where a value might not exist. For example:\n  - When looking up a key in a map, the key might not exist.\n  - When parsing user input, the input might be invalid.\n  - When accessing an element in a collection, the index might be out of bounds.\nBy using Option, Rust forces you to explicitly handle both cases (Some and None), which helps prevent runtime errors like null pointer exceptions.\n\n## `match` Control Flow Construct\nRust has an extremely powerful control flow construct called match that allows you to compare a value against a series of patterns and then execute code based on which pattern matches.\n\n```rust\nenum Coin {\n    Penny,\n    Nickel,\n    Dime,\n    Quarter,\n}\n\nfn value_in_cents(coin: Coin) -> u8 {\n    match coin {\n        Coin::Penny => 1,\n        Coin::Nickel => 5,\n        Coin::Dime => 10,\n        Coin::Quarter => 25,\n    }\n}\n```\n### Matching with `Option<T>`\n```\n    fn plus_one(x: Option<i32>) -> Option<i32> {\n        match x {\n            None => None,\n            Some(i) => Some(i + 1),\n        }\n    }\n\n    let five = Some(5);\n    let six = plus_one(five);\n    let none = plus_one(None);\n```\n### Catching all patterns and the _ placeholder\nUsing match construct can be really powerful when have to match one val with other and then execute something.\n\nthe `other` and `_` are catch-all patterns to deal with match's we didnt specifically define.\n\n#### `Other` - Named catch-all\nThis is used when we want to store the value of the expression that didnt match previous expressions.\n```rust\nfn main() {\n    let number = 7;\n\n    match number {\n        1 => println!(\"One\"),\n        2 => println!(\"Two\"),\n        other => println!(\"Number: {}\", other),\n    }\n}\n```\n #### `_` - wild card pattern\nThis is used when we just want to handle the mismatching but dont wanna store the value of amtch express\n\n```rust\nfn main() {\n    let number = 7;\n\n    match number {\n        1 => println!(\"One\"),\n        2 => println!(\"Two\"),\n        _ => println!(\"Other number\"), // `_` catches all other values\n    }\n}\n```\n\n## Control flow with `if let`\n\nThe if let syntax lets you combine if and let into a less verbose way to handle values that match one pattern while ignoring the rest\n```rust\nlet config_max = Some(3u8);\nif let Some(max) = config_max {\n    println!(\"The maximum is configured to be {max}\");\n}\n```\n"
  },
  {
    "url": "Courses/Languages/Rust/Error.html",
    "content": "---\nid: Error\naliases: \ntags:\n  - \"#Rust/Errors\"\n  - Rust\n  - Rust/Result\ntitle: Error\n---\n\n## Error Handling\nRust takes a robust and thoughtful approach to handling errors, recognizing that errors are an inevitable part of software engineering.\n\nRust groups error in two categories - \n- Recoverable - such as `file not found` error. This is recoverable and can be done automatically or reported to user.\n- Non-Recoverable - They are symptoms of bugs, such as trying to access location beyond the end of array.\n\n### Unrecoverable Error\nSometimes bad things may happen and we want a way to just exit and display what bad has happened. For this rust has a `panic!` macro. There are two ways to cause a panic in practice: by taking an action that causes our code to panic (such as accessing an array past the end) or by explicitly calling the `panic!` macro.\n\npanic prints a failure message, unwind and clean up the stack and quit.\n\n```rust\nfn main() {\n    panic!(\"crash and burn\");\n}\n```\n### Recoverable Error\nMost error aren't serious enough to require the program to stop entirely. Sometimes if something fails we can somewhat guess why it may fail and can therefore handle it.\n\nRust implements a `Result<T, E>` enum to handle potential errors.\n```rust\nenum Result<T, E> {\n    Ok(T),\n    Err(E),\n}\n```\nHere `T` represents the type of the value that will be returned in a success case within the `Ok` variant, and `E` represents the type of error that will be returned in a failure case.\n\nFor example while opening a file\n```rust\nuse std::fs::File;\n\nfn main() {\n    let greeting_file_result = File::open(\"hello.txt\");\n\n    let greeting_file = match greeting_file_result {\n        Ok(file) => file,\n        Err(error) => panic!(\"Problem opening the file: {error:?}\"),\n    };\n}\n```\n\nHere we see if opening file succeeds then the its ok. If it fails we panic.\n\nWe can extend this approach to handle different types of errors.\n```rust\nuse std::fs::File;\nuse std::io::ErrorKind;\n\nfn main() {\n    let greeting_file_result = File::open(\"hello.txt\");\n\n    let greeting_file = match greeting_file_result {\n        Ok(file) => file,\n        Err(error) => match error.kind() {\n            ErrorKind::NotFound => match File::create(\"hello.txt\") {\n                Ok(fc) => fc,\n                Err(e) => panic!(\"Problem creating the file: {e:?}\"),\n            },\n            other_error => {\n                panic!(\"Problem opening the file: {other_error:?}\");\n            }\n        },\n    };\n}\n```\nFor example here if the file in not found, we try to create it and then handle the error that may occur while creating the file and if its some other error we then also panic.\n\n### Shortcuts for Panic on Error: unwrap and expect\nUsing match works well enough, but it can be a bit verbose and doesn’t always communicate intent well. The Result enum has some helper methods defined on it to do various, more specific tasks.\n\nThe `unwrap` method is a shortcut method implement just like the `match` expression. If the Result value is the `Ok` variant, unwrap will return the value inside the `Ok`. If the Result is the `Err` variant, unwrap will call the `panic!` macro for us.\n\n```rust\nuse std::fs::File;\n\nfn main() {\n    let greeting_file = File::open(\"hello.txt\").unwrap();\n}\n```\n\nSimilarly, the expect method lets us also choose the panic! error message. Using expect instead of unwrap and providing good error messages can convey your intent and make tracking down the source of a panic easier.\n\n```rust\nuse std::fs::File;\n\nfn main() {\n    let greeting_file = File::open(\"hello.txt\")\n        .expect(\"hello.txt should be included in this project\");\n}\n```\n\n### Propagating errors\nWhen a function’s implementation calls something that might fail, instead of handling the error within the function itself you can return the error to the calling code so that it can decide what to do. This is known as propagating the error and gives more control to the calling code, where there might be more information or logic that dictates how the error should be handled than what you have available in the context of your code.\n\n```rust\nuse std::fs::File;\nuse std::io::{self, Read};\n\nfn read_username_from_file() -> Result<String, io::Error> {\n    let username_file_result = File::open(\"hello.txt\");\n\n    let mut username_file = match username_file_result {\n        Ok(file) => file,\n        Err(e) => return Err(e),\n    };\n\n    let mut username = String::new();\n\n    match username_file.read_to_string(&mut username) {\n        Ok(_) => Ok(username),\n        Err(e) => Err(e),\n    }\n}\n```\n\nIf the code succeeds without any problem the function receive and `Ok` value that hold a `String` - the username. If the function encounter any error, the calling code will receive an `Err` value that hold the instance of `io::Error` that contains info about the problem that happened here.\n\nThe pattern of propagating errors is so common in rust that it provides a `?` operator for this.\n\n```rust\nuse std::fs::File;\nuse std::io::{self, Read};\n\nfn read_username_from_file() -> Result<String, io::Error> {\n    let mut username_file = File::open(\"hello.txt\")?;\n    let mut username = String::new();\n    username_file.read_to_string(&mut username)?;\n    Ok(username)\n}\n```\nThe `?` operator can only be used in functions whose return type is compatible with the value the `?` is used on. This is because the `?` operator is defined to perform an early return of a value out of the function, in the same manner as the match expressions.\n\nThe `?` operator can also used with the `Option<T>` enum. If you have a function that returns an `Option<T>`, the `?` operator can be used to automatically propagate None values. Here's how it works:\n- If the value is Some(value):\n  - The `?` operator unwraps the Some and returns the inner value, allowing the computation to continue.\n- If the value is None:\n  - The `?` operator immediately returns None from the enclosing function, propagating the None upward.\n\n```rust\nfn find_username(id: u32) -> Option<String> {\n    match find_user(id) {\n        Some(user) => Some(user.username),\n        None => None,\n    }\n}\n\nfn find_username(id: u32) -> Option<String> {\n    let user = find_user(id)?;\n    Some(user.username)\n}\n\nfn find_user(id: u32) -> Option<User> {\n    // Simulate a database lookup\n    if id == 1 {\n        Some(User { username: String::from(\"Alice\") })\n    } else {\n        None\n    }\n}\n```\n\n### To Panic or not panic\n#### When to Use panic!:\n- Unrecoverable Errors: Use panic! when an error is unrecoverable, such as when a program enters a \"bad state\" (e.g., invalid values, broken invariants, or unsafe conditions).\n- Examples, Prototypes, and Tests: In examples, prototypes, and tests, panic! (via unwrap or expect) is acceptable for simplicity, as robust error handling can obscure the main point.\n- Logical Guarantees: Use panic! when you have logical guarantees that an error cannot occur (e.g., hardcoded valid values), even if the compiler cannot verify it.\n- Safety and Security: Panic when invalid inputs could lead to unsafe or harmful behavior, such as out-of-bounds memory access.\n\n#### When to Use Result:\n- Recoverable Errors: Use Result for errors that the calling code might recover from, such as parsing malformed data or handling rate limits.\n- Default Choice: Returning Result is the default choice for functions that might fail, as it allows the caller to decide how to handle errors.\n\n#### Guidelines for Error Handling:\n- Bad State: Panic when the program enters a bad state (e.g., invalid inputs, broken invariants) and recovery is not feasible.\n- Expected Failures: Use Result for expected failures, such as user input errors or network issues.\n- Type System: Leverage Rust’s type system (e.g., Option, u32) to enforce valid values at compile time, reducing the need for runtime checks.\n\n#### Custom Types for Validation:\n- Encapsulate Validation: Create custom types (e.g., a Guess type for values between 1 and 100) to enforce validation rules and avoid repetitive checks.\n- Private Fields: Use private fields to ensure values are only set through controlled constructors that enforce validation.\n\n```rust\npub struct Guess {\n    value: i32,\n}\n\nimpl Guess {\n    pub fn new(value: i32) -> Guess {\n        if value < 1 || value > 100 {\n            panic!(\"Guess value must be between 1 and 100, got {value}.\");\n        }\n        Guess { value }\n    }\n\n    pub fn value(&self) -> i32 {\n        self.value\n    }\n}\n```\nThis Guess type ensures values are always within the valid range, panicking if not, and encapsulates the validation logic.\n"
  },
  {
    "url": "Courses/Languages/Rust/Functional.html",
    "content": "---\nid: Functional\naliases: []\ntags:\n  - #Rust/funcional\n  - Rust\ntitle: Functional\n---\n\nRust ❤️  Haskell\n\n## Closures\nClosures are anonymous functions that can capture variables from their surrounding environment and help us define inline functions.\n\nThey don't require us to annotate the types of the parameters or the return value like `fn` functions do. Since they are typically short and are relevant only within a narrow context rather than in any arbitrary scenario, we don't need to explicitly tell the interface we wanna expose the user to as we do in functions.\n\nWe can still add type annotation if we feel like tho.\n```rust\nlet expensive_closure = |num: u32| -> u32 {\n    println!(\"calculating slowly...\");\n    thread::sleep(Duration::from_secs(2));\n    num\n};\n```\n\nSome reference how closures and functions are similar.\n```rust\nfn  add_one_v1   (x: u32) -> u32 { x + 1 }\nlet add_one_v2 = |x: u32| -> u32 { x + 1 };\nlet add_one_v3 = |x|             { x + 1 };\nlet add_one_v4 = |x|               x + 1  ;\n```\n\nThe compiler while compiling assigns the type to the variable and are therefore locked. If we call the closure with a `String` at first, the compiler annotates the type of `String` to the variable in closure and will give an error if the same closure is called with some other data type.\n\n```rust\nlet example_closure = |x| x;\n\nlet s = example_closure(String::from(\"hello\"));\nlet n = example_closure(5); // this will give an error.\n```\n\n### Capturing references and moving ownership\nSimilar to how we pass variables to functions: borrowing immutably, borrowing mutably and taking ownership, the closures will decide which of these to use based on what body of the function does to the captured values.\n\n- Borrowing immutably\n```rust\nfn main() {\n    let list = vec![1, 2, 3];\n    println!(\"Before defining closure: {list:?}\");\n\n    let only_borrows = || println!(\"From closure: {list:?}\");\n\n    println!(\"Before calling closure: {list:?}\");\n    only_borrows();\n    println!(\"After calling closure: {list:?}\");\n}\n```\nhere the closures only borrows the vector for printing, therefore it is passed as immutable references.\n\n- Borrowing mutably\n```rust\nfn main() {\n    let mut list = vec![1, 2, 3];\n    println!(\"Before defining closure: {list:?}\");\n\n    let mut borrows_mutably = || list.push(7);\n\n    borrows_mutably();\n    println!(\"After calling closure: {list:?}\");\n}\n```\nhere the closure takes a mutable reference to the vector cause we push an int into the vector.\n\n- Taking ownership\nWe can give ownership of something to the closure by using the `move` keyword.\n```rust\nuse std::thread;\n\nfn main() {\n    let list = vec![1, 2, 3];\n    println!(\"Before defining closure: {list:?}\");\n\n    thread::spawn(move || println!(\"From thread: {list:?}\"))\n        .join()\n        .unwrap();\n}\n```\nThis is helpful when we have to pass a closure to a new thread to move the data so that it's owned by the new thread.\n\n### Moving captured values out of closure\nA closure body can do any of the following: move a captured value out of the closure, mutate the captured value, neither move nor mutate the value, or capture nothing from the environment to begin with.\n\nThe way a closure captures and handles values from the environment affects which traits the closure implements, and traits are how functions and structs can specify what kinds of closures they can use. Closures will automatically implement one, two, or all three of these Fn traits, in an additive fashion, depending on how the closure’s body handles the values:\n- `FnOnce` applies to closures that can be called once. All closures implement at least this trait, because all closures can be called. A closure that moves captured values out of its body will only implement `FnOnce` and none of the other `Fn` traits, because it can only be called once.\n- `FnMut`  applies to closures that don’t move captured values out of their body, but that might mutate the captured values. These closures can be called more than once.\n- `Fn` applies to closures that don’t move captured values out of their body and that don’t mutate captured values, as well as closures that capture nothing from their environment. These closures can be called more than once without mutating their environment, which is important in cases such as calling a closure multiple times concurrently.\n\n## Iterators\nThe iterator pattern allows you to perform some task on a sequence of items in turn. In Rust, iterators are lazy, meaning they have no effect until you call the methods that consume the iterator to use it up.\n\n```rust\n    let v1 = vec![1, 2, 3];\n\n    let v1_iter = v1.iter();\n\n    for val in v1_iter {\n        println!(\"Got: {val}\");\n    }\n\n```\n\n- The iterator `v1_iter` doesn't do anything until it is consumed by the `for` loop.\n- The `iter()` method returns an iterator that borrows the elements of the vector `(&T)`. If you wanted to take ownership of the elements, you could use `into_iter()` instead of `iter()`.\n- Iterators in Rust are highly flexible and can be combined with various methods like `map`, `filter`, `collect`, etc., to perform complex operations on sequences of data.\n\nFrom a performance point of view, iterators and for loops perform generally the same. `Iterators` is rust are one of the no cost abstractions\n\n### The iterator trait and next method\nAll iterators implement a trait named `Iterator` that is defined in the std library. \n```rust\npub trait Iterator {\n    type Item;\n\n    fn next(&mut self) -> Option<Self::Item>;\n    // methods with default implementations elided\n}\n```\nImplementing the `Iterator` trait requires to define `Item` type and `next` method. The `next` method which returns one item of iterator at a time wrapped in `Some` and, when iteration is over, return `None`.\n\n```rust\n    #[test]\n    fn iterator_demonstration() {\n        let v1 = vec![1, 2, 3];\n\n        let mut v1_iter = v1.iter();\n\n        assert_eq!(v1_iter.next(), Some(&1));\n        assert_eq!(v1_iter.next(), Some(&2));\n        assert_eq!(v1_iter.next(), Some(&3));\n        assert_eq!(v1_iter.next(), None);\n    }\n```\nwe needed to make `v1` mutable cause using the `next` method changes the internal state of the iterator cause it has to keep track of where it is in the sequence. Also when we call the `next` method, we get immutable reference of the value in the vector.\n\n### Methods that consume an iterator.\n- [ ] Methods that call `next` are called **consuming adapters**, because calling them uses up the iterator. For example `sum` method, which takes ownership of the iterator and calculates the sum.\n```rust\n    #[test]\n    fn iterator_sum() {\n        let v1 = vec![1, 2, 3];\n\n        let v1_iter = v1.iter();\n\n        let total: i32 = v1_iter.sum();\n\n        assert_eq!(total, 6);\n    }\n```\n\n### Methods that produce other iterators\n**Iterator adaptors** are methods defined on the `Iterator` trait that don't consume the iterator. Instead they produce the iterators.\n```rust\n    let v1: Vec<i32> = vec![1, 2, 3];\n\n    let v2: Vec<_> = v1.iter().map(|x| x + 1).collect();\n\n    assert_eq!(v2, vec![2, 3, 4]);\n```\nIterator adapter are lazy, and we need to consume the iterator here. Therefore we use the `collect` method which consumes the iterator and collects the resulting values into a collection data type.\n"
  },
  {
    "url": "Courses/Languages/Rust/Generics.html",
    "content": "---\nid: Generics\naliases: \ntags:\n  - \"#Rust/Generics\"\n  - Rust\ntitle: Generics\n---\n\nGenerics in Rust allow you to write flexible, reusable code that can work with any data type. They enable you to define functions, structs, enums, and methods that operate on generic types rather than specific types. This reduces code duplication and increases type safety.\n\n### Generic Functions\nYou can define functions that accept parameters of any type using generics. The generic type is specified in angle brackets `(<T>)`.\n```rust\nfn largest<T: PartialOrd>(list: &[T]) -> &T {\n    let mut largest = &list[0];\n    for item in list {\n        if item > largest {\n            largest = item;\n        }\n    }\n    largest\n}\n```\n- `T` is a placeholder for any type.\n- `PartialOrd` is a trait that ensures the type `T` can be compared (required for the > operator).\n- This function works for any type that implements `PartialOrd`, such as integers, floats, or custom types.\n\n### Generic Structs\nYou can define structs that use generic types for their fields.\n\n```rust\nstruct Point<T> {\n    x: T,\n    y: T,\n}\n\nfn main() {\n    let integer_point = Point { x: 5, y: 10 };\n    let float_point = Point { x: 1.0, y: 4.0 };\n}\n```\n- `Point<T>` can hold values of any type `T`.\n- Both `x` and `y` must be of the same type `T`.\n\nIf we want `x` and `y` to have different types.\n```rust\nstruct Point<T, U> {\n    x: T,\n    y: U,\n}\n\nfn main() {\n    let mixed_point = Point { x: 5, y: 4.0 };\n}\n```\n\n### Generic Enums\nEnums can also use generics. A common example is Rust’s `Option<T>` and `Result<T, E>` enums.\n```rust\nenum Option<T> { // Option<T> can hold a value of type T (Some) or no value (None).\n    Some(T), \n    None,\n}\n\nenum Result<T, E> { // Result<T, E> can hold a success value of type T (Ok) or an error of type E (Err).\n    Ok(T),\n    Err(E),\n}\n```\n\n### Generic Methods\nYou can implement methods for structs or enums using generics.\n\n```rust\nstruct Point<T> {\n    x: T,\n    y: T,\n}\n\nimpl<T> Point<T> {\n    fn x(&self) -> &T {\n        &self.x\n    }\n}\n\nfn main() {\n    let p = Point { x: 5, y: 10 };\n    println!(\"p.x = {}\", p.x());\n}\n```\n\n### Trait Bounds\nTo restrict generics to types that implement specific behavior, you can use trait bounds.\n```rust\nfn largest<T: PartialOrd>(list: &[T]) -> &T {\n    let mut largest = &list[0];\n    for item in list {\n        if item > largest {\n            largest = item;\n        }\n    }\n    largest\n}\n```\n- T: PartialOrd ensures that T implements the PartialOrd trait, allowing comparison.\n\nWe can also use multiple trait bounds with the + syntax:\n```rust\nfn print_and_return<T: PartialOrd + std::fmt::Display>(value: T) -> T {\n    println!(\"Value: {}\", value);\n    value\n}\n```\n\n### Where Clause\n```rust\nfn some_function<T, U>(t: T, u: U) -> i32\nwhere\n    T: std::fmt::Display + Clone,\n    U: Clone + std::fmt::Debug,\n{\n    println!(\"T: {}\", t);\n    println!(\"U: {:?}\", u);\n    42\n}\n```\n\nRust’s generics are zero-cost abstractions. The compiler generates specialized code for each concrete type used with generics, ensuring no runtime overhead.\n\nFor example, if you use `Point<i32>` and `Point<f64>`, the compiler generates two separate versions of the `Point` struct and its methods, optimized for `i32` and `f64`.\n\n"
  },
  {
    "url": "Courses/Languages/Rust/lifetimes.html",
    "content": "---\nid: lifetimes\naliases: \ntags:\n  - \"#Rust/Lifetimes\"\n  - Rust\ntitle: lifetimes\n---\n\nA lifetime is a construct that the Rust compiler uses to track how long references to data are valid. Every reference in Rust has a lifetime, which is the scope for which the reference is valid. Lifetimes are usually inferred by the compiler, but sometimes you need to annotate them explicitly to help the compiler understand your intentions.\n\n### Why Are Lifetimes Important?\nLifetimes ensure that: \n1. **References do not outlive the data they point to**: This prevents dangling references, where a reference points to memory that has already been freed.\n2. **Data races are avoided**: By ensuring that references are valid and that no two mutable references to the same data exist simultaneously, Rust prevents data races at compile time.\n\n### Lifetime Annotations\nLifetime annotations are a way to explicitly specify the relationships between the lifetimes of different references. They are denoted by an apostrophe (`'`) followed by a name, such as `'a`, `'b`, etc.\n\n```rust\n&i32        // a reference\n&'a i32     // a reference with an explicit lifetime\n&'a mut i32 // a mutable reference with an explicit lifetime\n```\n\nHere’s an example of a function with explicit lifetime annotations:\n```rust\nfn longest<'a>(x: &'a str, y: &'a str) -> &'a str {\n    if x.len() > y.len() {\n        x\n    } else {\n        y\n    }\n}\n```\n\n- `'a` is a lifetime parameter.\n- The function `longest` takes two string slices (`&str`) with the same lifetime `'a` and returns a string slice with the same lifetime `'a`.\n- This means that the returned reference will be valid as long as both input references are valid.\n\n### Lifetime Annotations in structs\nSo far, the structs we’ve defined all hold owned types. We can define structs to hold references, but in that case we would need to add a lifetime annotation on every reference in the struct’s definition.\n\n```rust\nstruct ImportantExcerpt<'a> {\n    part: &'a str,\n}\n\nfn main() {\n    let novel = String::from(\"Call me Ishmael. Some years ago...\");\n    let first_sentence = novel.split('.').next().unwrap();\n    let i = ImportantExcerpt {\n        part: first_sentence,\n    };\n}\n```\nThe `ImportantExcerpt` struct has a single field, part, which holds a string slice (a reference). To ensure the reference in part remains valid, the struct uses a lifetime parameter (`'a`) declared in angle brackets (`<'a>`). This means an instance of `ImportantExcerpt` cannot outlive the reference it holds in its part field.\n\n- A `String` named `novel` owns the data.\n- An `ImportantExcerpt` instance is created, referencing the first sentence of novel.\n- Since novel exists before the `ImportantExcerpt` instance and outlives it, the reference in `ImportantExcerpt` is valid throughout its lifetime.\n\n### Lifetime Elision\nIn many cases, Rust can infer lifetimes automatically, so you don’t need to annotate them explicitly. This is known as **lifetime elision**. The compiler follows a set of rules to determine lifetimes in common patterns.\n\n### Lifetime Rules\nThe Rust compiler follows three rules to infer lifetimes when they are not explicitly annotated:\n1. **Each parameter that is a reference gets its own lifetime parameter**. For example, a function with one parameter gets one lifetime, a function with two parameters gets two lifetimes, and so on.\n2. **If there is exactly one input lifetime parameter, that lifetime is assigned to all output lifetime parameters**.\n3. **If there are multiple input lifetime parameters, but one of them is `&self` or `&mut self` (as in method definitions), the lifetime of `self` is assigned to all output lifetime parameters**.\n\n### Lifetime Declarations in impl Blocks\nLifetime names for struct fields must be declared after the `impl` keyword and used after the struct's name because they are part of the struct's type.\n```rust\nimpl<'a> ImportantExcerpt<'a> {\n    fn level(&self) -> i32 {\n        3\n    }\n}\n```\n\n### Static Lifetime\nThe `'static` lifetime is a special lifetime that means the reference is valid for the entire duration of the program. String literals, for example, have a `'static` lifetime because they are stored directly in the program's binary.\n\n```rust\nlet s: &'static str = \"I have a static lifetime.\";\n```\n\n### Generic Type Parameters, Trait Bounds, and Lifetimes Together\n```rust\nuse std::fmt::Display;\n\nfn longest_with_an_announcement<'a, T>(\n    x: &'a str,\n    y: &'a str,\n    ann: T,\n) -> &'a str\nwhere\n    T: Display,\n{\n    println!(\"Announcement! {ann}\");\n    if x.len() > y.len() {\n        x\n    } else {\n        y\n    }\n}\n```\n\nThis is the longest function from Listing 10-21 that returns the longer of two string slices. But now it has an extra parameter named ann of the generic type T, which can be filled in by any type that implements the Display trait as specified by the where clause. This extra parameter will be printed using {}, which is why the Display trait bound is necessary. Because lifetimes are a type of generic, the declarations of the lifetime parameter 'a and the generic type parameter T go in the same list inside the angle brackets after the function name.\n"
  },
  {
    "url": "Courses/Languages/Rust/OOP.html",
    "content": "---\nid: OOP\naliases: []\ntags: []\ntitle: OOP\n---\n\nObject oriented programs are made up of objects. An object packages both data and procedures that operates on that data. The procedures are typically called methods and operations.\n\n### Encapsulation\nWe can use `pub` keyword to decide with modules, types, functions and methods in our code should be public, and by default everything else is private.\n"
  },
  {
    "url": "Courses/Languages/Rust/Ownership.html",
    "content": "---\nid: Ownership\naliases: \ntags:\n  - \"#Rust/Ownership\"\n  - \"#Rust/Scope\"\n  - \"#Rust/Slices\"\n  - \"#Rust/Strings\"\n  - \"#Rust/Borrowing\"\n  - \"#Rust/References\"\n  - Rust\ntitle: Ownership\n---\n\nOwnership is Rust's way of managing memory safety without a garbage collector. It enforces strict rules at compile time to ensure memory safety, prevent data races, and eliminate common bugs like null pointer dereferencing or use-after-free errors.\n### Stack and Heap\nThe stack and heap are two regions of memory used for different purposes in a program. They differ in how memory is allocated, accessed, and managed.\n\n#### Stack - \n- **Structure**: The stack is a LIFO (Last-In, First-Out) data structure. It grows and shrinks automatically as functions are called and return.\n- **Allocation**: Memory is allocated in a contiguous block. Each function call creates a new stack frame, which contains local variables, function parameters, and return addresses.\n- **Speed**: Extremely fast because memory allocation and deallocation are just pointer adjustments.\n- **Size**: Limited in size (typically a few MB per thread).\n- **Lifetime**: Memory is automatically reclaimed when a function returns (its stack frame is popped).\n- **Use Case**: Ideal for small, fixed-size data with predictable lifetimes (e.g., local variables, function arguments).\n\n```rust\nfn main() {\n    let x = 5; // `x` is stored on the stack\n    let y = 10; // `y` is stored on the stack\n    let sum = add(x, y); // Function call creates a new stack frame\n    println!(\"Sum: {}\", sum);\n}\n\nfn add(a: i32, b: i32) -> i32 {\n    a + b // `a` and `b` are stored on the stack\n}\n```\n#### Heap - \n- **Structure**: The heap is a more flexible memory region where data can be allocated and freed in any order.\n- **Allocation**: Memory is allocated dynamically at runtime. You request a block of memory of a specific size, and the memory manager finds a suitable spot.\n- **Speed**: Slower than the stack because it involves finding and managing memory blocks.\n- **Size**: Much larger than the stack (limited by available system memory).\n- **Lifetime**: Memory must be explicitly allocated and deallocated (or managed by a garbage collector or ownership system, as in Rust).\n- **Use Case**: Ideal for data with dynamic size or unpredictable lifetimes (e.g., strings, collections, or large objects).\n\n```rust\nfn main() {\n    let s = String::from(\"hello\"); // `s` is stored on the heap\n    println!(\"{}\", s);\n}\n```\n###  The Three Rules of Ownership\n- **Each value in Rust has a single owner.** - \n\t- At any given time, a piece of data is owned by exactly one variable.\n\t- When the owner goes out of scope, the value is dropped (memory is freed).\n- **There can only be one owner at a time.**\n\t- If you assign a value to another variable or pass it to a function, the ownership is _moved_. The original owner no longer has access to the value.\n- **Ownership can be borrowed, but with strict rules.** - \n\t- Instead of transferring ownership, you can create references to the value. These references can be either:\n\t\t- **Immutable references (`&T`)**: Multiple immutable references are allowed, but no mutable references can exist simultaneously.\n\t\t- **Mutable references (`&mut T`)**: Only one mutable reference is allowed at a time, and no immutable references can coexist.\n\n\n### Variable Scope\nVariable scope refers to the region of code where a variable is valid and can be accessed. It is defined by where the variable is declared and how long it lives in memory.\n\n- Block Scope \n```rust\n{   // s is not valid here, it’s not yet declared \n\tlet s = \"hello\"; // s is valid from this point forward \n\t// do stuff with s \n} \n// this scope is now over, and s is no longer valid\n```\n\n### String Type\n- **String Literals vs. `String` Type**\n    - **String literals**: Immutable, hardcoded text stored in the program's binary.\n    - **`String` type**: Mutable, dynamically allocated on the heap, and can store text of unknown size at compile time (e.g., user input).\n- **Creating a `String`**  \n\t- Use the `String::from` function to create a `String` from a string literal:\n```rust\nlet s = String::from(\"hello\");\n```\n- - **Ownership and Heap Memory**\n    - The `String` type owns its heap-allocated data.\n    - When a `String` goes out of scope, Rust automatically frees the memory (no manual memory management or garbage collection needed)\n\n`String` can be mutated as they are heap allocated and we can append a string literal at the end of it. This isnt possible with string literals as they are hardcoded in programs binary.\n\n```rust\n    let mut s = String::from(\"hello\");\n    s.push_str(\", world!\"); // push_str() appends a literal to a String\n    println!(\"{s}\"); // This will print `hello, world!`\n```\n### Memory Allocation\nThere are two well know and most used ways to allocate data on the heap.\n\n#### Manual Memory Management\n- **How it works**:  \n    Developers explicitly allocate and deallocate memory using functions like `malloc` (in C) or `new`/`delete` (in C++).\n    - **Allocation**: Request memory from the heap using `malloc` or similar functions.\n    - **Deallocation**: Free memory using `free` or similar functions when it’s no longer needed.\n\t\n```c\nint* arr = (int*)malloc(10 * sizeof(int)); // Allocate memory for 10 integers\nif (arr == NULL) {\n    // Handle allocation failure\n}\n// Use the array\nfree(arr); // Free the memory when done\n```\n\n- **Pros**:\n    - Full control over memory allocation and deallocation.\n    - Predictable performance (no garbage collection pauses).\n- **Cons**:\n    - Error-prone: Forgetting to free memory leads to **memory leaks**.\n    - Freeing memory too early leads to **dangling pointers**.\n    - Freeing memory twice leads to **undefined behavior**\n\t\n#### **Garbage Collection (GC)**\n- **How it works**:  \n    The runtime system (e.g., in Java, Python, or Go) automatically tracks memory usage and reclaims memory that is no longer referenced by the program.\n    - **Reference Counting**: Counts references to objects and frees memory when the count drops to zero (used in Python).\n    - **Tracing GC**: Periodically scans the heap to identify unreachable objects (used in Java, Go).\n\t\n```python\ns = \"hello\"  # Memory is allocated automatically\ns = \"world\"  # Old string \"hello\" is garbage collected\n```\n\n- **Pros**:\n    - No manual memory management required.\n    - Prevents memory leaks, dangling pointers, and double-free errors.\n- **Cons**:\n    - Overhead: GC introduces runtime performance costs (e.g., pauses for tracing).\n    - Less control: Developers can’t predict exactly when memory will be freed.\n\n#### Rust’s Approach: Ownership and Borrowing\nRust takes a unique approach that combines the best of both worlds:\n- **No Garbage Collector**: Rust avoids runtime overhead by not using a GC.\n- **No Manual Memory Management**: Rust enforces strict compile-time rules (ownership, borrowing, and lifetimes) to ensure memory safety.\n\n```rust\nfn main() {\n    let x = 5;\n    let y = x;\n}\n```\n\nHere we can guess that `x` is being bound to 5 and the for y we make a copy of `x` and store it in y. This is how it happens for integers, floats, etc cause these are small data types and all can be done on compile time. \n\nFor example the assembly of this may look like this.\n```rust\nmov dword ptr [rsp - 8], 5 \nmov dword ptr [rsp - 4], 5\nret\n```\nThe compiler being an intelligent being know the value of `x` is 5 so it just make two variable with value `5`.\n\nBut in case of data structures such as `String` this isn't possible as we don't know what the size of the `String` needs to be cause the user may append string literal \n\n\n![string_representation](https://doc.rust-lang.org/stable/book/img/trpl04-01.svg)\nAs we can see in this, A string `s1` is made up of three parts - pointer to address on heap, length of string and the total capacity of string. These are stored on the stack. \n\nWhen we assign `s1 = s2` ,  we copy the pointer, the length, and the capacity that are on the stack.\n\n![string_assignment](https://doc.rust-lang.org/stable/book/img/trpl04-02.svg)\n\nNow if we cloned string `s1` and then assigned that to `s2` we would have the following representation: \n![string_clone](https://doc.rust-lang.org/stable/book/img/trpl04-03.svg)\nThere cloning is considered an expensive process as we have to allocate new memory in the heap for the new string. If we don't clone the ownership of the `s1` is transferred to `s2`  not making this an expensive operation due to no heap allocations.\n\nThere its generally not recommended to clone a data as that can be an expensive operation.\n\nThe operation of `s1 = s2` may sound like shallow copy in other languages as we copy the stack data but in Rust we invalidate `s1` , therefore it is called a `move` operation. `s1` was moved into `s2`.\n\n## Scope and Assignment\nIn Rust, when you assign a new value to an existing variable, Rust automatically calls the `drop` function to free the memory of the original value immediately. For example, in the code:\n```rust\nlet mut s = String::from(\"hello\"); \ns = String::from(\"ahoy\"); \nprintln!(\"{s}, world!\");\n```\n\nIn Rust, if you need to create a **deep copy** of heap data (not just the stack data like pointers, length, and capacity), you can use the `clone` method. For example:\n\n```rust\nlet s1 = String::from(\"hello\");\nlet s2 = s1.clone();\nprintln!(\"s1 = {s1}, s2 = {s2}\");\n```\n\n- The `clone` method creates a full copy of the `String`'s heap data, so both `s1` and `s2` are independent and valid.\n- This is different from a move or shallow copy, as `clone` explicitly duplicates the data, allowing both variables to coexist.\n\nIn Rust, certain types, like integers, have a known size at compile time and are stored entirely on the stack. For these types, copying the value is fast and straightforward, so Rust automatically performs a **trivial copy** instead of a move. This means that after assigning one variable to another, both variables remain valid. For example:\n\n```rust\nlet x = 5;\nlet y = x;\nprintln!(\"x = {x}, y = {y}\");\n```\n\nHere, `x` and `y` are both valid because the value `5` is copied, not moved. This behavior is enabled by the **`Copy` trait**, which is automatically implemented for types that can be stored entirely on the stack. Example :\n- All the integer types, such as `u32`.\n- The Boolean type, `bool`, with values `true` and `false`.\n- All the floating-point types, such as `f64`.\n- The character type, `char`.\n- Tuples, if they only contain types that also implement `Copy`. For example, `(i32, i32)` implements `Copy`, but `(i32, String)` does not.\n\n## Ownership and Functions\nIn Rust, passing a value to a function follows the same ownership rules as assigning a value to a variable.\n\n```rust\nfn main() {\n    let s = String::from(\"hello\");  // s comes into scope\n\n    takes_ownership(s);             // s's value moves into the function...\n                                    // ... and so is no longer valid here\n\n    let x = 5;                      // x comes into scope\n\n    makes_copy(x);                  // x would move into the function,\n                                    // but i32 is Copy, so it's okay to still\n                                    // use x afterward\n\n} // Here, x goes out of scope, then s. But because s's value was moved, nothing\n  // special happens.\n\nfn takes_ownership(some_string: String) { // some_string comes into scope\n    println!(\"{some_string}\");\n} // Here, some_string goes out of scope and `drop` is called. The backing\n  // memory is freed.\n\nfn makes_copy(some_integer: i32) { // some_integer comes into scope\n    println!(\"{some_integer}\");\n} // Here, some_integer goes out of scope. Nothing special happens.\n```\n\n### Return values and scopes\n\nReturning a value can transfer ownership cause we are returning the value from the function.\n\n```rust\nfn main() {\n    let s1 = gives_ownership();         // gives_ownership moves its return\n                                        // value into s1\n\n    let s2 = String::from(\"hello\");     // s2 comes into scope\n\n    let s3 = takes_and_gives_back(s2);  // s2 is moved into\n                                        // takes_and_gives_back, which also\n                                        // moves its return value into s3\n} // Here, s3 goes out of scope and is dropped. s2 was moved, so nothing\n  // happens. s1 goes out of scope and is dropped.\n\nfn gives_ownership() -> String {             // gives_ownership will move its\n                                             // return value into the function\n                                             // that calls it\n\n    let some_string = String::from(\"yours\"); // some_string comes into scope\n\n    some_string                              // some_string is returned and\n                                             // moves out to the calling\n                                             // function\n}\n\n// This function takes a String and returns one\nfn takes_and_gives_back(a_string: String) -> String { // a_string comes into\n                                                      // scope\n\n    a_string  // a_string is returned and moves out to the calling function\n}\n```\n\nThis way of giving ownership and taking back ownership of the variable by returning seems tedious therefore we use references to deal with this.\n\n## References and Borrowing\nInstead of returning a tuple from a function to be able to use that variable again we will pass it as a reference to the function.\n\n>  A _reference_ is like a pointer in that it’s an address we can follow to access the data stored at that address; that data is owned by some other variable. Unlike a pointer, a reference is guaranteed to point to a valid value of a particular type for the life of that reference.\n\n```rust\nfn main() {\n    let s1 = String::from(\"hello\");\n    let len = calculate_length(&s1);\n    println!(\"The length of '{s1}' is {len}.\");\n}\n\nfn calculate_length(s: &String) -> usize {\n    s.len()\n}\n```\n\nIn the above example we pass reference of `s1` to `calculate length` , therefore we are able to use it the function without the variable being dropped when function finishes running as the `s1` owner is still the main function.\n\nWe call the action of creating a reference _borrowing_. As in real life, if a person owns something, you can borrow it from them. When you’re done, you have to give it back. You don’t own it.\n\nThere are two types of references:\n- **Immutable Reference (`&T`)** - \n\t- An immutable reference allows you to read the data but not modify it.\n\t- Multiple immutable references to the same data are allowed at the same time.\n- **Mutable Reference (`&mut T`)**\n\t- - A mutable reference allows you to read and modify the data.\n\t- Only one mutable reference to a particular piece of data is allowed at a time (no other references, mutable or immutable, can exist simultaneously).\n\nOnce caveat of mutable references have one big restriction that you cant make more than one mutable references as this can cause data races but we can have as many immutable references as we want.\n\n### Dangling references\nIn languages like C or C++ it's really easy to create dangling pointers. In Rust,  the compiler guarantees that references will never be dangling references: if you have a reference to some data, the compiler will ensure that the data will not go out of scope before the reference to the data does.\n\n```rust\nfn dangle() -> &String { // dangle returns a reference to a String\n\n    let s = String::from(\"hello\"); // s is a new String\n\n    &s // we return a reference to the String, s\n} // Here, s goes out of scope, and is dropped. Its memory goes away.\n  // Danger!\n```\n\n### The Rules of References \nThe rules of references - \n- At any given time, you can have _either_ one mutable reference _or_ any number of immutable references.\n- References must always be valid.\n\n## Slices\n_Slices_ let you reference a contiguous sequence of elements in a [collection](https://doc.rust-lang.org/stable/book/ch08-00-common-collections.html) rather than the whole collection. A slice is a kind of reference, so it does not have ownership.\n\n### String slices\nA _string slice_ is a reference to part of a `String`, and it looks like this:\n```rust\n    let s = String::from(\"hello world\");\n\n    let hello = &s[0..5];\n    let world = &s[6..11];\n```\n\nRather than a reference to the entire `String`, `hello` is a reference to a portion of the `String`, specified in the extra `[0..5]` bit. We create slices using a range within brackets by specifying `[starting_index..ending_index]`, where `starting_index` is the first position in the slice and `ending_index` is one more than the last position in the slice. Internally, the slice data structure stores the starting position and the length of the slice, which corresponds to `ending_index` minus `starting_index`.\n\n![slice_representation](https://doc.rust-lang.org/stable/book/img/trpl04-07.svg)\n> String slice range indices must occur at valid UTF-8 character boundaries. If you attempt to create a string slice in the middle of a multibyte character, your program will exit with an error.\n\n#### String literals as slices\nAs we know that string literals are stored inside the binary\n```rust\nlet s = \"Hello, world!\";\n```\n\nThe type of `s` here is `&str`: it’s a slice pointing to that specific point of the binary. This is also why string literals are immutable; `&str` is an immutable reference.\n\n#### Other parameters\nString slices, as you might imagine, are specific to strings. But there’s a more general slice type too. Consider this array:\n```rust\nlet a = [1, 2, 3, 4, 5];\n```\n\n```rust\nlet a = [1, 2, 3, 4, 5];\nlet slice = &a[1..3];\nassert_eq!(slice, &[2, 3]);\n```\nThis slice has the type `&[i32]`. It works the same way as string slices do, by storing a reference to the first element and a length\n"
  },
  {
    "url": "Courses/Languages/Rust/Packaging.html",
    "content": "---\nid: Packaging\naliases: \ntags:\n  - \"#Rust/Packaging\"\n  - Rust\ntitle: Packaging\n---\n\nA crate is a smallest amount of code that the rust compiler considers at a time. A small hello world program can be considered a crate. Crates can contain modules and the modules may have other files that get compiled with the crate.\n\nA Crate can be of two types:\n- Binary - Programs you can compile to an executable to run. They must have a main function.\n- Library - These crates define functionality to be shared with multiple projects. For example `rand` crate that we import to generate a random number.\n\nA **package** is a bundle of one or more crates that provides a set of functionality. A package contains a `Cargo.toml` file that describes how to build those crates\n\n### Modules Reference\n- **Start from the crate root** - When compiling a crate, the compiler first looks in the crate root file (usually src/lib.rs for a library crate or src/main.rs for a binary crate) for code to compile.\n- **Declaring modules** - Modules are used to organize code into separate namespaces. You declare a module using the mod keyword.\n```rust\nmod garden;\n```\nThis tell the compiler to look for the `garden` module in one of the following places - \n  - inline - inside the same file `mod garden { }`\n  - seperate file such as `src/garden.rs`\n  - inside a subdirectory `src/garden/mod.rs`\n- **Declaring submodules** - In any file other than crate root you can make submodules. For example `mod vegetables` in `garden` modules. The compiler will then look for the module in the following places - \n  - Inline, directly following mod vegetables, within curly brackets instead of the semicolon\n  - In the file src/garden/vegetables.rs\n  - In the file src/garden/vegetables/mod.rs\n- **Paths to code in modules** - To refers to items inside modules we can use the path anywhere inside that crate as long as privacy rules apply.For example, an `Asparagus` struct in the garden vegetables module would be found at `crate::garden::vegetables::Asparagus`\n- **Private vs. public** - Code within a module is private from its parent modules by default. To make a module public, declare it with pub mod instead of mod.\n- **The `use` keyword** - Within a scope we can use the `use` keyword to reduce repetition. For example we can refer `crate::garden::vegetables::Asparagus` as `Asparagus`.\n\n### Paths for referring to an item in module\nTo show Rust where to find an item in a module tree, we use a path in the same way we use a path when navigating a filesystem. To call a function, we need to know its path.\n\nA path can take two forms:\n- An absolute path is the full path starting from a crate root; for code from an external crate, the absolute path begins with the crate name, and for code from the current crate, it starts with the literal crate.\n- A relative path starts from the current module and uses self, super, or an identifier in the current module.\n\n"
  },
  {
    "url": "Courses/Languages/Rust/Rust_Basics.html",
    "content": "---\nid: Rust_Basics\naliases: \ntags:\n  - \"#Rust/Variables\"\n  - \"#Rust/DataTypes\"\n  - \"#Rust/Syntax\"\n  - \"#Rust/Comments\"\n  - \"#Rust/Conditionals\"\n  - \"#Rust/Loops\"\n  - Rust\n---\n\n## Variables and Mutability\n\n### Variables\nIn Rust, you declare a variable using the let keyword. By default, variables in Rust are immutable, meaning once a value is bound to a variable, it cannot be changed.\n\n```Rust\nlet x = 5;\nx = 6; // This will cause a compile-time error\n```\n\n### Mutability\nIf you want a variable to be mutable, you need to explicitly declare it as such using the mut keyword. This allows you to change the value of the variable after it has been initialized.\n\n```rust\nlet mut x = 5;\nx = 6; // This is allowed because x is mutable\n```\nIn this example, x is declared as mutable, so you can change its value from 5 to 6 without any issues.\n\n> **Why Immutability?**\n  Immutability is a key feature in Rust that helps prevent certain kinds of bugs, especially in concurrent programming. When a variable is immutable, you can be sure that its value won't change unexpectedly, which makes reasoning about the code easier and safer.\n\n### Shadowing\nRust also allows variable shadowing, where you can declare a new variable with the same name as a previous variable. The new variable shadows the previous one, and it can have a different type or mutability.\n\n```rust\nlet x = 5;\nlet x = x + 1; // This is allowed, and x is now 6\nlet x = \"hello\"; // This is also allowed, and x is now a string\n```\nShadowing is different from mutability because each let declaration creates a new variable, and the old variable is no longer accessible.\n\n### Constants\nRust also has constants, which are always immutable. Constants are declared using the const keyword and must have a type annotation. They are evaluated at compile time and can be declared in any scope.\n\n```rust\nconst MAX_POINTS: u32 = 100_000;\n```\n\n## Data Types\nRust is a statically typed language, which means that the type of every variable must be known at compile time. Rust provides a rich set of data types that can be broadly categorized into scalar and compound types\n\n- **Scalar types** - Scalar types represent a single value. Rust has four primary scalar types:\n  - Integers - \n    - Integers are whole numbers without a fractional component.\n    - Rust has signed (i) and unsigned (u) integers of various sizes:\n      `i8, i16, i32, i64, i128, isize (signed)`\n      `u8, u16, u32, u64, u128, usize (unsigned)`\n  - Floating point numbers - \n    - Floating-point numbers have a fractional component.\n    - Rust has two floating-point types:\n      `f32 (32-bit, single precision)`\n      `f64 (64-bit, double precision, default)`\n  - Booleans - \n    - Booleans have two possible values: true or false.\n    - The type is `bool`.\n  - Characters - \n    - Characters represent a single Unicode scalar value.\n    - The type is `char`, and it is enclosed in single quotes (').\n    - `char` in Rust is 4 bytes, allowing it to represent more than just ASCII (e.g., emojis, accented letters).\n\n```rust\nlet x: i32 = 42;\nlet y: u64 = 100;\n\nlet x: f32 = 3.14;\nlet y: f64 = 2.71828;\n\nlet is_rust_fun: bool = true;\n\nlet letter: char = 'A';\nlet emoji: char = '😊';\n```\n\n- **Compound Types** - Compound types group multiple values into one type. Rust has two primitive compound types:\n  - Tuples - \n    - Tuples group values of different types into a single compound type.\n    - They have a fixed length: once declared, they cannot grow or shrink in size.\n    - Access elements using dot notation (.0, .1, etc.) or destructuring.\n  - Arrays - \n    - Arrays store multiple values of the same type.\n    - They have a fixed length, and their size is determined at compile time.\n    - Arrays are stored on the stack, making them fast but inflexible.\n\n```rust\nlet tup: (i32, f64, char) = (42, 3.14, 'A');\nlet (x, y, z) = tup; // Destructuring\nprintln!(\"The first value is {}\", tup.0);\n\nlet arr: [i32; 5] = [1, 2, 3, 4, 5];\nprintln!(\"The first element is {}\", arr[0]);\n```\n\n- **Custom Types** - Rust also allows you to define your own custom types using struct, enum, and union.\n  - Structs - \n    - Structs are custom data types that group related data together.\n    - They are similar to classes in other languages but without inheritance.\n  - Enums - \n    - Enums allow you to define a type by enumerating its possible variants.\n    - Each variant can optionally hold data.\n  - Unions - \n    - Unions are similar to structs but share the same memory location for all fields.\n    - They are primarily used for low-level programming and FFI (Foreign Function Interface).\n\n```rust\n//struct \nstruct Person {\n    name: String,\n    age: u8,\n}\n\nlet person = Person {\n    name: String::from(\"Alice\"),\n    age: 30,\n};\n\n// enum\nenum Direction {\n    Up,\n    Down,\n    Left,\n    Right,\n}\n\nlet dir = Direction::Up;\n```\n\n- **Other types**\n  - String- \n    - `String`: A growable, heap-allocated string.\n    - `&str`: A string slice, which is a reference to a part of a string.\n  - Option and Result - \n    - `Option<T>`: Represents an optional value, either Some(T) or None.\n    - `Result<T, E>`: Represents either a success (Ok(T)) or an error (Err(E)).\n  - Slices - \n    - Slices are references to a contiguous sequence of elements in a collection.\n\n```rust\nlet s1: String = String::from(\"Hello\");\nlet s2: &str = \"world\";\n\nlet some_number: Option<i32> = Some(5);\nlet no_number: Option<i32> = None;\n\nlet result: Result<i32, &str> = Ok(42);\nlet error: Result<i32, &str> = Err(\"Something went wrong\");\n\nlet arr = [1, 2, 3, 4, 5];\nlet slice: &[i32] = &arr[1..3]; // [2, 3]\n```\n\n## Functions\nFunctions are a fundamental building block in Rust, and understanding them is key to writing effective Rust code\n\n### Function syntax\nIn Rust, functions are declared using the fn keyword. Here's the basic structure:\n\n```rust\nfn function_name(parameter1: Type1, parameter2: Type2) -> ReturnType {\n    // Function body\n    return value; // Optional return statement\n}\n```\n\n- `fn`: Keyword to define a function.\n- `function_name`: The name of the function (use snake_case by convention).\n- `parameter`: Type: Parameters with their types (Rust is statically typed).\n- `-> ReturnType`: Specifies the return type of the function.\n- `return value`: Optional; the last expression in the function is automatically returned if return is omitted.\n\n```rust\nfn add(x: i32, y: i32) -> i32 {\n    x + y // No semicolon means this is the return value\n}\n\nfn main() {\n    let result = add(3, 5);\n    println!(\"Result: {}\", result); // Output: Result: 8\n}\n```\n\n### Parameters and Arguments\nFunctions can take zero or more parameters and each parameter must have a type annotation.\n```rust\nfn greet(name: &str) {\n    println!(\"Hello, {}!\", name);\n}\n\nfn main() {\n    greet(\"Alice\"); // Output: Hello, Alice!\n}\n```\n### Return Values\n- Functions can return values using the `->` syntax.\n- If the last expression in the function doesn't end with a semicolon, it is automatically returned.\n- You can also use the return keyword explicitly, but it's optional for the last expression.\n\n```rust\nfn is_even(num: i32) -> bool {\n    num % 2 == 0\n}\n\nfn main() {\n    println!(\"Is 4 even? {}\", is_even(4)); // Output: Is 4 even? true\n}\n```\n\n### Expressions and Statements\n- **Expressions**: Evaluate to a value (e.g., `x + y`, `5`, `if condition { ... }`).\n- **Statements**:Perform an action but do not return a value (e.g., `let x = 5;`, `println!()`).\n\n## Comments \n```rust\n// hello, world\n\n// So we’re doing something complicated here, long enough that we need\n// multiple lines of comments to do it! Whew! Hopefully, this comment will\n// explain what’s going on.\n\nfn main() {\n    let lucky_number = 7; // I’m feeling lucky today\n}\n\nfn main() {\n    // I’m feeling lucky today\n    let lucky_number = 7;\n}\n\n/* Multiline comment\nfn main() {\n    // I’m feeling lucky today\n    let lucky_number = 7;\n}\n*/\n\n```\n\n## Control Flow\nControl flow in Rust allows you to dictate the order in which your code executes.\n\n### Conditional Statements\nRust uses `if`, `else if`, and `else` to execute code based on conditions. Unlike some languages, Rust requires the condition to be a boolean value (`true` or `false`).\n\n```rust\nif condition1 {\n    // Code to execute if condition1 is true\n} else if condition2 {\n    // Code to execute if condition2 is true\n} else {\n    // Code to execute if all conditions are false\n}\n```\n\n```rust\nfn main() {\n    let number = 7;\n\n    if number < 5 {\n        println!(\"Condition 1: number is less than 5\");\n    } else if number == 5 {\n        println!(\"Condition 2: number is equal to 5\");\n    } else {\n        println!(\"Condition 3: number is greater than 5\");\n    }\n}\n```\n\n**Using `if` in a `let` statement** \nif is an expression in Rust, so it can be used to assign a value:\n```rust\nfn main() {\n    let condition = true;\n   let number = if condition { 5 } else { 6 }; // gives you the ternary feel\n    println!(\"The value of number is: {}\", number);\n}\n```\n\n### Loops\nRust provides three types of loops: `loop`, `while`, and `for`.\n- **loop** - the `loop` keyword will create an infinite loop.\n```rust\nfn main() {\n    let mut count = 0;\n\n    loop {\n        count += 1;\n        println!(\"Count: {}\", count);\n\n        if count == 3 {\n            break; // Exit the loop\n        }\n    }\n}\n```\n- **while** - The `while` loop runs as long as a condition is true.\n```rust\nfn main() {\n    let mut number = 3;\n\n    while number != 0 {\n        println!(\"{}!\", number);\n        number -= 1;\n    }\n\n    println!(\"LIFTOFF!\");\n}\n```\n\n- **for** - The `for` loop is used to iterate over a collection, such as an array or a range.\n```rust\nfn main() {\n    let arr = [10, 20, 30, 40, 50];\n\n    for element in arr.iter() {\n        println!(\"The value is: {}\", element);\n    }\n\n    // Iterate over a range\n    for number in 1..4 {\n        println!(\"{}!\", number); // Prints 1, 2, 3\n    }\n}\n```\n\n### Pattern Matching\nThe match expression is a powerful control flow construct in Rust. It allows you to compare a value against a series of patterns and execute code based on the matching pattern.\n\n```rust\nmatch value {\n    pattern1 => { /* code */ },\n    pattern2 => { /* code */ },\n    _ => { /* default case */ },\n}\n```\n\n```rust\nfn main() {\n    let number = 3;\n\n    match number {\n        1 => println!(\"One\"),\n        2 => println!(\"Two\"),\n        3 => println!(\"Three\"),\n        _ => println!(\"Something else\"), // Default case\n    }\n}\n```\n\nUsing match with enums \n```rust\nenum Direction {\n    Up,\n    Down,\n    Left,\n    Right,\n}\n\nfn main() {\n    let dir = Direction::Up;\n\n    match dir {\n        Direction::Up => println!(\"Going up!\"),\n        Direction::Down => println!(\"Going down!\"),\n        Direction::Left => println!(\"Going left!\"),\n        Direction::Right => println!(\"Going right!\"),\n    }\n}\n```\n\n### Extra\n- `if let` and `while let` - These constructs are shorthand for match when you only care about one pattern.\n\n```rust\nfn main() {\n    let some_value = Some(5);\n\n    if let Some(x) = some_value {\n        println!(\"x is: {}\", x); // Prints: x is: 5\n    } else {\n        println!(\"No value\");\n    }\n}\n\nfn main() {\n    let mut stack = vec![1, 2, 3];\n\n    while let Some(top) = stack.pop() {\n        println!(\"Popped: {}\", top); // Prints: 3, 2, 1\n    }\n}\n```\n\n- Control Flow with `break` and `continue`\n  - `break`: Exits a loop immediately.\n  - `continue`: Skips the rest of the current iteration and moves to the next iteration.\n\n```rust\nfn main() {\n    let mut count = 0;\n    loop {\n        count += 1;\n        if count == 3 {\n            continue; // Skip the rest of this iteration\n        }\n        println!(\"Count: {}\", count);\n        if count == 5 {\n            break; // Exit the loop\n        }\n    }\n}\n```\n- Nested loops and labels\n  - You can label loops to control which loop break or continue applies to.\n\n```rust\nfn main() {\n    let mut count = 0;\n\n    'outer: loop {\n        'inner: loop {\n            if count >= 5 {\n                break 'outer; // Exit the outer loop\n            }\n            count += 1;\n            println!(\"Count: {}\", count);\n        }\n    }\n}\n```\n"
  },
  {
    "url": "Courses/Languages/Rust/Smart_Pointers.html",
    "content": "---\nid: Smart Pointers\naliases: []\ntags: []\ntitle: Smart Pointers\n---\nA pointer is a general concept for a variable that contains an address in memory. This address refers to, or \"points at\", some other data.\n\nSmart Pointer on the other hand, are data structures that act like a pointer but also have additional metadata and capabilities. `String` and `vec<T>` are also smart pointers. Smart pointers are usually implemented using structs. Unlike ordinary structs, smart pointers implement the `Deref` and `Drop` traits. The `Deref` trait allows an instance of smart pointer struct to behave like reference. The `Drop` trait allows you to customize the code that's run when an instance of the smart pointer goes out of scope.\n\nThe most common smart pointers in std library are - \n- `Box<T>` for allocating values on the heap.\n- `Rc<T>`, a references counting type that enables multiple ownership.\n- `Ref<T>` and `RefMut<T>`, accessed through `RefCell<T>` a type that enforces the borrowing rules at runtime instead of compile time.\n\n## **USING `Box<T>` to point to Data on the heap**\nBoxes allow you to store data on the heap rather than the stack. What remains on the stack is the pointer to the heap data.\n\nWe'll use them in situations such as - \n- When you have a type whose size can’t be known at compile time and you want to use a value of that type in a context that requires an exact size\n- When you have a large amount of data and you want to transfer ownership but ensure the data won’t be copied when you do so.\n- When you want to own a value and you care only that it’s a type that implements a particular trait rather than being of a specific type\n\n### **Using a `Box<T>` to store data on the heap**\n```rust\nfn main() {\n    let b = Box::new(5); // Store the value 5 on the heap\n    println!(\"b = {}\", b); // Dereference the box to access the value\n}\n```\n- `Box::new(5)` allocates memory on the heap to store the value 5.\n- The variable b is a `Box<i32>` that points to this heap-allocated value.\n- When you print `b`, Rust automatically dereferences the box to access the value inside.\n\n### **Enabling recursive types with boxes**\nRust needs to know the size of types at compile time, but recursive types (like linked lists or trees) have an indeterminate size. `Box<T>` can be used to create recursive types by storing the recursive part on the heap.\n\n```rust\nenum List {\n    Cons(i32, Box<List>), // Recursive part is boxed\n    Nil, // Base case\n}\n\nfn main() {\n    let list = List::Cons(1, Box::new(List::Cons(2, Box::new(List::Nil))));\n}\n```\n\n`Box<List>` allows the `Cons` variant to hold another `List` without causing infinite size issues as rust knows the size of a pointer and it  doesn't change based on the amount of data it's pointing to.\n\nThe `Cons` variant needs the size of an `i32` plus the space to store the box’s pointer data. The `Nil` variant stores no values, so it needs less space than the `Cons` variant. We now know that any `List` value will take up the size of an `i32` plus the size of a box’s pointer data. By using a `box`, we’ve broken the infinite, recursive chain, so the compiler can figure out the size it needs to store a `List` value.\n\n![[Pasted image 20250226131333.png]]\n\nBoxes provide only the indirection and heap allocation; they don’t have any other special capabilities.They also don’t have the performance overhead that these special capabilities incur, so they can be useful in cases like the cons list where the indirection is the only feature we need.\n\nThe `Box<T>` type is a smart pointer because it implements the `Deref` trait, which allows `Box<T>` values to be treated like references. When a `Box<T>` value goes out of scope, the heap data that the box is pointing to is cleaned up as well because of the `Drop` trait implementation. \n\n## **Treating Smart Pointers Like Regular References with the `Deref` Trait**\nImplementing the `Deref` trait allows you to customize the behaviour of the dereference operator `*`. By implementing `Deref` lets us to write code that operates on references and use that code with smart pointers too.\n\n### **References**\nThe variable `x` holds value `5` and the variable `y` stores the address of `x`. Therefore when we dereference `y` we get the value stored at address `x` i.e. 5.\n```rust\nfn main() {\n    let x = 5;\n    let y = &x;\n\n    assert_eq!(5, x);\n    assert_eq!(5, *y);\n}\n```\n\nWe can write it using `Box<T>` too cause it implements the `Deref` Trait. The main difference here is we store a copy of x in y which is stored in the heap and we can use the dereference operator to dereference it and get value of y.\n\n```rust\nfn main() {\n    let x = 5;\n    let y = Box::new(x);\n\n    assert_eq!(5, x);\n    assert_eq!(5, *y);\n}\n```\n\n### **Implementing `MyBox<T>`**\n```rust\nuse std::ops::Deref;\n\nstruct MyBox<T>(T);\n\nimpl<T> MyBox<T> {\n    fn new(x: T) -> MyBox<T> {\n        MyBox(x)\n    }\n}\n\nimpl<T> Deref for MyBox<T> {\n    type Target = T;\n\n    fn deref(&self) -> &Self::Target {\n        &self.0;\n    }\n}\n```\n1. **`MyBox<T>`**:\n   - This is a tuple struct that wraps a value of type `T`. It’s similar to `Box<T>`, but it’s a custom implementation.\n\n2. **`new` Constructor**:\n   - The `new` function creates an instance of `MyBox` by wrapping the provided value `x`.\n\n3. **`Deref` Implementation**:\n   - The `Deref` trait is implemented for `MyBox<T>`.\n   - The `type Target = T;` line specifies that the target type for dereferencing is `T`.\n   - The `deref` method returns a reference to the inner value (`&self.0`).\n\n4. **Dereferencing in `main`**:\n   - `*y` works because `MyBox<T>` implements the `Deref` trait. The `*` operator calls the `deref` method, which returns a reference to the inner value (`5` in this case).\n\n### **Implicit Deref Coercions with Functions and Methods**\n#### **What is Deref Coercion?**\nDeref coercion is a convenience in Rust that automatically converts a reference to a type that implements the `Deref` trait into a reference to another type. This happens when you pass a reference to a function or method, and the type of the reference doesn’t exactly match the parameter type expected by the function.\n\nFor example:\n- `&String` can be automatically converted to `&str` because `String` implements the `Deref` trait to return `&str`.\n- Similarly, `&MyBox<String>` can be converted to `&str` through a sequence of `deref` calls.\n\nWhen you pass a reference to a function, Rust checks if the type of the reference implements the `Deref` trait. If it does, Rust calls the `deref` method as many times as necessary to convert the reference into the type expected by the function.\n\nFor example:\n1. If you pass `&MyBox<String>` to a function that expects `&str`, Rust will:\n   - Call `deref` on `&MyBox<String>` to get `&String`.\n   - Call `deref` on `&String` to get `&str`.\n\n### **Example: Deref Coercion in Action**\n\nLet’s use the `MyBox<T>` type and the `hello` function to demonstrate deref coercion.\n\n#### **1. Define `MyBox<T>` and Implement `Deref`**\n\n```rust\nuse std::ops::Deref;\n\nstruct MyBox<T>(T);\n\nimpl<T> MyBox<T> {\n    fn new(x: T) -> MyBox<T> {\n        MyBox(x)\n    }\n}\n\nimpl<T> Deref for MyBox<T> {\n    type Target = T;\n\n    fn deref(&self) -> &Self::Target {\n        &self.0\n    }\n}\n```\n\nHere, `MyBox<T>` is a custom smart pointer that implements the `Deref` trait. The `deref` method returns a reference to the inner value.\n\n```rust\nfn hello(name: &str) {\n    println!(\"Hello, {name}!\");\n}\n\nfn main() {\n    let m = MyBox::new(String::from(\"Rust\"));\n    hello(&m);\n}\n```\n\n1. `m` is a `MyBox<String>` containing the string `\"Rust\"`.\n2. `&m` is a reference to `MyBox<String>`.\n3. Rust calls `deref` on `&MyBox<String>`, which returns `&String`.\n4. Rust calls `deref` on `&String`, which returns `&str`.\n5. The `&str` matches the parameter type of the `hello` function, so the function executes successfully.\n\nIf Rust didn’t have deref coercion, you would need to manually convert `&MyBox<String>` into `&str` using explicit dereferencing and slicing:\n\n```rust\nfn main() {\n    let m = MyBox::new(String::from(\"Rust\"));\n    hello(&(*m)[..]);\n}\n```\n\n1. `*m` dereferences `MyBox<String>` into `String`.\n2. `&(*m)[..]` takes a full slice of the `String` to get `&str`.\n\nThis is much harder to read and write compared to the version with deref coercion.\n\n#### **Why is Deref Coercion Useful?**\n1. **Convenience**:\n   - You don’t need to manually add `&` and `*` operators when passing references or smart pointers to functions.\n   - Code becomes cleaner and easier to read.\n\n2. **Flexibility**:\n   - You can write functions that accept `&str` and still pass `&String`, `&MyBox<String>`, or other types that implement `Deref<Target = str>`.\n\n3. **No Runtime Cost**:\n   - Deref coercion happens at compile time, so there’s no performance penalty.\n\n\n### Deref Coercion and Mutability\nRust does deref coercion when it finds types and trait implementations in three cases:\n\n- From `&T` to `&U` when `T: Deref<Target=U>`\n- From `&mut T` to `&mut U` when `T: DerefMut<Target=U>`\n- From `&mut T` to `&U` when `T: Deref<Target=U>`\n\n> immutable references will never coerce to mutable references.\n\n## **Running Code on Cleanup with the Drop Trait**\nThe `Drop` trait lets you customize what we wanna do with the smart pointer when it goes out of scope such as releasing resources.\n\n- The `Drop` trait has a single method: `fn drop(&mut self)`.\n- It is automatically called when an instance of the type is about to go out of scope.\n\n```rust\nstruct Resource {\n    name: String,\n}\n\nimpl Drop for Resource {\n    fn drop(&mut self) {\n        println!(\"Dropping resource: {}\", self.name);\n    }\n}\n\nfn main() {\n    let _res = Resource { name: String::from(\"MyResource\") };\n    println!(\"Resource created\");\n} // `_res` goes out of scope here, and `drop` is called automatically\n```\n\n### **Dropping a value early with `std::mem::drop`**\n`std::mem::drop` is a function in Rust's standard library that explicitly drops a value before it would naturally go out of scope. This is useful when you want to force resource cleanup at a specific point in your program.\n\n- Moves the value into the function, consuming it.\n- Calls the `Drop` trait (if implemented) for the value.\n- Ensures the value is deallocated and cleaned up immediately.\n- Does **not** require the value to be mutable.\n\n```rust\nstruct Resource {\n    name: String,\n}\n\nimpl Drop for Resource {\n    fn drop(&mut self) {\n        println!(\"Dropping resource: {}\", self.name);\n    }\n}\n\nfn main() {\n    let res = Resource { name: String::from(\"MyResource\") };\n    println!(\"Resource created\");\n\n    std::mem::drop(res); // Explicitly drop `res` here\n\n    println!(\"Resource manually dropped\");\n} // No automatic drop since `res` is already consumed\n```\n\n```\nResource created\nDropping resource: MyResource\nResource manually dropped\n```\n\n## **`Rc<T>`, the Reference Counted Smart Pointer**\n`Rc<T>` (Reference Counted Smart Pointer) is a type in Rust's standard library that allows multiple ownership of a value using reference counting. It enables multiple parts of a program to share ownership of a value, and the value is only dropped when the last reference to it is gone.\n\n1. **Reference Counting:** It keeps track of how many `Rc` instances refer to the same value.\n2. **Shared Ownership:** Multiple `Rc<T>` instances can own the same value.\n3. **Immutable Borrowing:** `Rc<T>` only allows shared (`&T`) access, meaning you cannot mutate the value directly.\n4. **Thread-Local:** `Rc<T>` is **not** thread-safe. Use `Arc<T>` for multi-threading.\n\n```rust\nuse std::rc::Rc;\n\nfn main() {\n    let a = Rc::new(10); // Create a reference-counted integer\n    let b = Rc::clone(&a); // Increase reference count\n    let c = Rc::clone(&a); // Increase reference count\n\n    println!(\"a = {}, reference count = {}\", a, Rc::strong_count(&a));\n}\n```"
  },
  {
    "url": "Courses/Languages/Rust/Structs.html",
    "content": "---\nid: Structs\naliases: \ntags:\n  - \"#Rust/Structs\"\n  - \"#Rust/Impl\"\n  - \"#Rust/Methods\"\n  - Rust\ntitle: Structs\n---\n\nIn Rust, a **struct** (short for \"structure\") is a custom data type that allows you to group together related data. Structs are similar to tuples, but unlike tuples, structs give names to each piece of data, making the code more readable and manageable.\n\n### Defining a Struct\nYou define a struct using the `struct` keyword, followed by the name of the struct and a block of fields. Each field has a name and a type.\n```rust\nstruct User {\n    username: String,\n    email: String,\n    sign_in_count: u64,\n    active: bool,\n}\n```\n\nIn this example, `User` is a struct with four fields:\n- `username` of type `String`\n- `email` of type `String`\n- `sign_in_count` of type `u64`\n- `active` of type `bool`\n\n### Creating an Instance of a Struct\nTo use a struct, you create an **instance** of it by specifying values for each field.\n```rust\nlet user1 = User {\n    username: String::from(\"john_doe\"),\n    email: String::from(\"john@example.com\"),\n    sign_in_count: 1,\n    active: true,\n};\n```\n\nHere, `user1` is an instance of the `User` struct with specific values for each field.\n### Accessing Struct Fields\nYou can access the fields of a struct using dot notation.\n```rust\nprintln!(\"Username: {}\", user1.username);\nprintln!(\"Email: {}\", user1.email);\n```\n\n### Mutable Structs\nIf you want to modify a struct after creating it, you must declare the instance as mutable.\n```rust\nlet mut user1 = User {\n    username: String::from(\"john_doe\"),\n    email: String::from(\"john@example.com\"),\n    sign_in_count: 1,\n    active: true,\n};\n\nuser1.email = String::from(\"john.doe@example.com\");\n```\n\n### Field Init Shorthand\nIf you have variables with the same names as the struct fields, you can use the **field init shorthand** to avoid repetition.\n```rust\nlet username = String::from(\"john_doe\");\nlet email = String::from(\"john@example.com\");\n\nlet user1 = User {\n    username,\n    email,\n    sign_in_count: 1,\n    active: true,\n};\n```\n\n### Struct Update Syntax\n```rust\nlet user2 = User {\n    username: String::from(\"jane_doe\"),\n    email: String::from(\"jane@example.com\"),\n    ..user1\n};\n```\n\nHere, `user2` will have the same `sign_in_count` and `active` values as `user1`, but a different `username` and `email`.\n\n### Tuple Structs\nRust also supports **tuple structs**, which are similar to tuples but have a name. They are useful when you want to give a tuple a meaningful name.\n\n```rust\nstruct Color(i32, i32, i32);\nlet black = Color(0, 0, 0);\n```\n\n### Unit-Like Structs\nYou can define a struct with no fields, called a **unit-like struct**. These are useful when you need to implement a trait but don’t need to store any data.\n\n```rust\nstruct EmptyStruct;\nlet empty = EmptyStruct;\n```\n\n## Methods \n_Methods_ are similar to functions: we declare them with the `fn` keyword and a name, they can have parameters and a return value, and they contain some code that’s run when the method is called from somewhere else but unlike functions, methods are defined within the context of a `struct` , `enum` or trait object and their first parameter is always self.\n\n```rust\n#[derive(Debug)]\nstruct Rectangle {\n    width: u32,\n    height: u32,\n}\n\nimpl Rectangle {\n    fn area(&self) -> u32 {\n        self.width * self.height\n    }\n}\n\nfn main() {\n    let rect1 = Rectangle {\n        width: 30,\n        height: 50,\n    };\n\n    println!(\n        \"The area of the rectangle is {} square pixels.\",\n        rect1.area()\n    );\n}\n```\nTo define a function within context of a `struct` we use `impl` (implementation) block. As we see above the `impl` block contain all the methods that can be called on the struct Rypectangle.\n\nThe first parameters of a methods is `&self` as it is an alias for the type that the `impl` block is. \n\n> Methods can take ownership of `self`, borrow `self` immutably, as we’ve done here, or borrow `self` mutably, just as they can any other parameter.\n\nThe main reason for using `impl` instead of functions, in addition to providing method syntax and not having to repeat the type `self` in every method signature is for **organization**. We can put all the things that are related to an instance in an `impl` block.\n\n### Associated functions\nYou can also define **associated functions** (similar to static methods in other languages) that don’t take `self` as a parameter. These are often used for constructors.\n\n```rust\nimpl Rectangle {\n    fn square(size: u32) -> Self {\n        Self {\n            width: size,\n            height: size,\n        }\n    }\n}\n```\nThe `Self` keywords in the return type and in the body of the function are aliases for the type that appears after the `impl` keyword, which in this case is `Rectangle`.\n\nTo call this associated function, we use the `::` syntax with the struct name; `let sq = Rectangle::square(3);`\n"
  },
  {
    "url": "Courses/Languages/Rust/Test.html",
    "content": "---\nid: Test\naliases: \ntags:\n  - \"#Rust/Tests\"\n  - Rust\ntitle: Test\n---\n\nTODO\n"
  },
  {
    "url": "Courses/Languages/Rust/Traits.html",
    "content": "---\nid: Traits\naliases: \ntags:\n  - \"#Rust/Traits\"\n  - Rust\ntitle: Traits\n---\n\nA trait defines the functionality a particular type has and can share with other types. We can use traits to define shared behavior in an abstract way. We can use trait bounds to specify that a generic type can be any type that has certain behavior.\n\n> Traits are similar to a feature often called interfaces in other languages, although with some differences.\n\n### Defining a trait\nYou define a trait using the trait keyword, followed by the method signatures that types implementing the trait must provide.\n\n```rust\ntrait Summary {\n    fn summarize(&self) -> String;\n}\n```\n- `Summary` is a trait with a single method, `summarize`.\n- Any type that implements the `Summary` trait must provide an implementation for the `summarize` method.\n\n### Implementing a trait\n```rust\nstruct NewsArticle {\n    headline: String,\n    location: String,\n    author: String,\n    content: String,\n}\n\nimpl Summary for NewsArticle {\n    fn summarize(&self) -> String {\n        format!(\"{}, by {} ({})\", self.headline, self.author, self.location)\n    }\n}\n\nstruct Tweet {\n    username: String,\n    content: String,\n    reply: bool,\n    retweet: bool,\n}\n\nimpl Summary for Tweet {\n    fn summarize(&self) -> String {\n        format!(\"{}: {}\", self.username, self.content)\n    }\n}\n```\n\n- `NewsArticle` and `Tweet` both implement the `Summary` trait.\n- Each provides its own implementation of the `summarize` method.\n\n### Default implementation\nYou can provide default implementations for methods in a trait. Types can use the default implementation or override it.\n\n```rust\ntrait Summary {\n    fn summarize(&self) -> String {\n        String::from(\"(Read more...)\")\n    }\n}\n\nimpl Summary for NewsArticle {}\n```\nWe can use this to provide a default method for implementation or can create our own implementation of certain methods.\n\n### Trait Bounds\nTraits can be used as constraints on generic types to ensure they implement specific behavior. This is called a trait bound.\n```rust\nfn notify<T: Summary>(item: &T) {\n    println!(\"Breaking news! {}\", item.summarize());\n}\n```\n- The notify function accepts any type `T` that implements the `Summary` trait.\n- This ensures that the `summarize` method can be called on `item`.\n\n### Using where Clauses\nFor complex trait bounds, you can use a where clause to improve readability.\n```rust\nfn some_function<T, U>(t: &T, u: &U) -> i32\nwhere\n    T: Display + Clone,\n    U: Clone + Debug,\n{\n    println!(\"T: {}\", t);\n    println!(\"U: {:?}\", u);\n    42\n}\n```\n\n### Trait objects\nTraits can be used to achieve dynamic polymorphism through trait objects. A trait object is a pointer to an instance of a type that implements a specific trait.\n\n```rust\nfn notify(item: &dyn Summary) {\n    println!(\"Breaking news! {}\", item.summarize());\n}\n```\n- `dyn Summary` is a trait object that can hold any type implementing the `Summary` trait.\n- Trait objects allow for dynamic dispatch, meaning the method to call is determined at runtime.\n\n### Deriving traits\nMany traits can be automatically derived using the `#[derive]` attribute.\n```rust\n#[derive(Debug, Clone, PartialEq)]\nstruct Point {\n    x: i32,\n    y: i32,\n}\n```\nThe compiler generates implementations for Debug, Clone, and PartialEq.\n\n### Associated types\n```rust\ntrait Iterator {\n    type Item;\n    fn next(&mut self) -> Option<Self::Item>;\n}\n\nstruct Counter {\n    count: u32,\n}\n\nimpl Iterator for Counter {\n    type Item = u32;\n    fn next(&mut self) -> Option<Self::Item> {\n        self.count += 1;\n        Some(self.count)\n    }\n}\n```\n`Item` is an associated type that the implementing type (`Counter`) specifies as `u32`.\n\n### Trait inheritence\nTraits can inherit from other traits, requiring implementors to provide implementations for both the parent and child traits.\n\n```rust\ntrait Printable: Summary {\n    fn print(&self) {\n        println!(\"{}\", self.summarize());\n    }\n}\n\nimpl Printable for NewsArticle {}\n```\n`Printable` requires `Summary` to be implemented first.\n\n### Returning Types that implements Traits\nWe can use `impl Trait` to specify that a function returns a type that implements a particular trait, without naming the concrete type.\n\n```rust\nfn returns_summarizable() -> impl Summary {\n    Tweet {\n        username: String::from(\"horse_ebooks\"),\n        content: String::from(\"of course, as you probably already know, people\"),\n        reply: false,\n        retweet: false,\n    }\n}\n```\n\n\n\n\n\n"
  },
  {
    "url": "Courses/System_Design/Introduction.html",
    "content": "---\nid: Introduction\naliases: []\ntags: []\ntitle: Introduction\n---\n\n## System Design \nIt is the process of the defining the elements of a system, as well as their interactions and relationships, in order to satisfy a set of requirements. It focuses on the high level design of the software, including the architecture and components.\n\n### Scalability VS Performance\nLets understand this with and example. Think of a supermarket. We have one cashier(lets name him dan) that can checkout a customer in 1 minute. If we have one customer come every 1 min, then no customer has to wait. This means our supermarket is scalable for one customer. \n\nNow if two customers come at once. This would lead the second customer to wait 1 minute extra. This is fine but imagine if we have 10 people coming at once(Stonks). This can lead to bad customer experience as they have to wait for longer for their cart to be checked out.\n\nHow can we make it better? Add more dans. Now if we add 10 dans, then each of 10 customers can go to each dan and get the cart checked out. We just scaled up our cashier system but the performance of each dan is still the same.\n\nNow what if we replace dan with a robot(dystopia) which can checkout a cart in 15 seconds. Here we increased performance.\n\n- If you have **performance** problem, your system is slow for one user.\n- If you have **scalability** problem, your system is fine for one user but not for more.\n\n### Latency VS Throughput\n- Latency refers to the amount of time it takes for a system to respond to a request.\n- Throughput refers to the number of requests that a system can handle at the same time.\n"
  },
  {
    "url": "Courses/Web_Dev/Redis/redis-cli.html",
    "content": "i**REDIS** stands for remote dictionary server. It uses the same data data structures as a normal programming languages to create a streamlined process for storing data.\n\n## Understanding Data Types\n\n### Strings\nStrings store a sequence of bytes, text, serialized objects, binary arrays, etc\n\n**Example** - store and get a string of data\n```plaintext\nSET bike:1 \"Process 134\"\nGET bike:1\n```\n\n> A good practice is to put data as in format: `<ENTITY>:<ID>` value\n\n[`SET`](https://redis.io/docs/latest/commands/set/) and the [`GET`](https://redis.io/docs/latest/commands/get/) commands are the way we set and retrieve a string value. SET command is will replace any existing value related to that key. So SET performs and assignment.\n\nThe ability to set or retrieve the value of multiple keys in a single command is also useful for reduced latency. [`MSET`](https://redis.io/docs/latest/commands/mset/) and [`MGET`](https://redis.io/docs/latest/commands/mget/) are for this. MGET returns an array.\n\n```plaintext\n    > mset bike:1 \"Deimos\" bike:2 \"Ares\" bike:3 \"Vanth\"\n    OK\n    > mget bike:1 bike:2 bike:3\n    1) \"Deimos\"\n    2) \"Ares\"\n    3) \"Vanth\"\n```\n\n#### Strings as counters\nThe [`INCR`](https://redis.io/docs/latest/commands/incr/) command parses the string value as an integer, increments it by one, and finally sets the obtained value as the new value. There are other similar commands like [`INCRBY`](https://redis.io/docs/latest/commands/incrby/), [`DECR`](https://redis.io/docs/latest/commands/decr/) and [`DECRBY`](https://redis.io/docs/latest/commands/decrby/). The INCR command is atomic in nature.\n\n**BASIC COMMANDS**\n- [`SET`](https://redis.io/docs/latest/commands/set/) stores a string value.\n- [`SETNX`](https://redis.io/docs/latest/commands/setnx/) stores a string value only if the key doesn't already exist. Useful for implementing locks.\n- [`GET`](https://redis.io/docs/latest/commands/get/) retrieves a string value.\n- [`MGET`](https://redis.io/docs/latest/commands/mget/) retrieves multiple string values in a single operation.\n- [`INCR`](https://redis.io/docs/latest/commands/incr/) atomically increments counters stored at a given key by 1.\n- [`INCRBY`](https://redis.io/docs/latest/commands/incrby/) atomically increments (and decrements when passing a negative number) counters stored at a given key.\n- Another command exists for floating point counters: [`INCRBYFLOAT`](https://redis.io/docs/latest/commands/incrbyfloat/).\n\n> **Limitation** - The max size of value is 512MB.\n\n\n### JSON\nSimilar to string, you can store data as JSON in redis.\n\n**Commands** - \n```plaintext\n> JSON.SET bike $ '\"Hyperion\"' // assign value to key\nOK\n> JSON.GET bike $ // get the value\n\"[\\\"Hyperion\\\"]\"\n> JSON.TYPE bike $ // get the type\n1) \"string\"\n> JSON.STRLEN bike $ // get the length of value\n1) (integer) 8\n> JSON.STRAPPEND bike $ '\" (Enduro bikes)\"'  // append to value\n1) (integer) 23\n> JSON.GET bike $ \n\"[\\\"Hyperion (Enduro bikes)\\\"]\"\n> JSON.SET crashes $ 0  // use it as counter\nOK\n> JSON.NUMINCRBY crashes $ 1\n\"[1]\"\n> JSON.NUMINCRBY crashes $ 1.5\n\"[2.5]\"\n> JSON.NUMINCRBY crashes $ -0.75\n\"[1.75]\"\n> JSON.NUMMULTBY crashes $ 24\n\"[42]\"\n> JSON.SET newbike $ '[\"Deimos\", {\"crashes\": 0}, null]'\nOK\n> JSON.GET newbike $\n\"[[\\\"Deimos\\\",{\\\"crashes\\\":0},null]]\"\n> JSON.GET newbike $[1].crashes\n\"[0]\"\n> JSON.DEL newbike $[-1]\n(integer) 1\n> JSON.GET newbike $\n\"[[\\\"Deimos\\\",{\\\"crashes\\\":0}]]\"\n> JSON.SET riders $ []\nOK\n> JSON.ARRAPPEND riders $ '\"Norem\"'\n1) (integer) 1\n> JSON.GET riders $\n\"[[\\\"Norem\\\"]]\"\n> JSON.ARRINSERT riders $ 1 '\"Prickett\"' '\"Royce\"' '\"Castilla\"'\n1) (integer) 4\n> JSON.GET riders $\n\"[[\\\"Norem\\\",\\\"Prickett\\\",\\\"Royce\\\",\\\"Castilla\\\"]]\"\n> JSON.ARRTRIM riders $ 1 1\n1) (integer) 1\n> JSON.GET riders $\n\"[[\\\"Prickett\\\"]]\"\n> JSON.ARRPOP riders $\n1) \"\\\"Prickett\\\"\"\n> JSON.ARRPOP riders $\n1) (nil)\n> JSON.SET bike:1 $ '{\"model\": \"Deimos\", \"brand\": \"Ergonom\", \"price\": 4972}'\nOK\n> JSON.OBJLEN bike:1 $\n1) (integer) 3\n> JSON.OBJKEYS bike:1 $\n1) 1) \"model\"\n   2) \"brand\"\n   3) \"price\"\n```\n\n#### JSON path\nRedis implements its own way to get elements from a json path.\n\nHere’s the information converted into a **Markdown table**:\n\n| Syntax Element     | Description                                                                                                                                                                                                                                                 |     |     |\n| ------------------ | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --- | --- |\n| `$`                | The root (outermost JSON element), starts the path.                                                                                                                                                                                                         |     |     |\n| `.` or `[]`        | Selects a child element.                                                                                                                                                                                                                                    |     |     |\n| `..`               | Recursively descends through the JSON document.                                                                                                                                                                                                             |     |     |\n| `*`                | Wildcard, returns all elements.                                                                                                                                                                                                                             |     |     |\n| `[]`               | Subscript operator, accesses an array element.                                                                                                                                                                                                              |     |     |\n| `[,]`              | Union, selects multiple elements.                                                                                                                                                                                                                           |     |     |\n| `[start:end:step]` | Array slice where `start`, `end`, and `step` are index values. You can omit values from the slice (e.g., `[3:]`, `[:8:2]`) to use defaults: `start` defaults to the first index, `end` to the last, `step` to 1. Use `[*]` or `[:]` to select all elements. |     |     |\n| `?()`              | Filters a JSON object or array. Supports comparison operators`!=`, `<`, `<=`, `>`, `>=`), logical operators (`&&`, `<br>```), and parentheses (`(`, `)`).                                                                                                   |     |     |\n| `()`               | Script expression.                                                                                                                                                                                                                                          |     |     |\n| `@`                | The current element, used in filter or script expressions.                                                                                                                                                                                                  |     |     |\n\nThis table provides a clear and concise overview of the syntax elements and their descriptions. You can use it in your documentation or notes!\n#### Limitation\n\n> A JSON value passed to a command can have a depth of up to 128."
  },
  {
    "url": "Courses/Web_Dev/Redis/redis.html",
    "content": "---\nid: redis\naliases: []\ntags: []\n---\n\n**Redis** (Remote Dictionary Server) is an open-source, in-memory data structure store, used as a database, cache, and message broker. It is known for its high performance, flexibility, and rich set of features.\n\n### Key features\n- **In-Memory Storage**: Redis primarily stores data in memory, which allows for extremely fast read and write operations. This makes it ideal for use cases where low latency is critical, such as caching, session storage, and real-time analytics.\n- **Persistence**: Although Redis is an in-memory store, it provides options for persistence. You can configure Redis to periodically save snapshots of the dataset to disk (RDB persistence) or log every write operation to an append-only file (AOF persistence). This ensures data durability even in the event of a system crash.\n  - **Data Structures**: Redis supports a variety of data structures, including: \n  - **Strings**: Simple key-value pairs.\n  - **Hashes**: Maps between string fields and string values, useful for representing objects.\n  - **Lists**: Collections of strings sorted by insertion order.\n  - **Sets**: Unordered collections of unique strings.\n  - **Sorted **Sets: Sets where each element is associated with a score, allowing for range queries.\n  - **Bitmaps**: Efficiently store and manipulate binary data.\n  - **HyperLogLogs**: Probabilistic data structure for estimating the cardinality of a set.\n  - **Geospatial Indexes**: Store and query geographic coordinates.\n  - **Atomic Operations**: Redis supports atomic operations on its data structures, which means that complex operations can be executed without the risk of race conditions. For example, you can increment a value, push to a list, or add to a set atomically\t\n\n"
  },
  {
    "url": "Miscellaneous/Self-Hosting Bitwarden.html",
    "content": "- set up a vps\n- enable firewall - allow http, https, ssh\n- Install docker\n```\n# Add Docker's official GPG key:\nsudo apt-get update\nsudo apt-get install ca-certificates curl\nsudo install -m 0755 -d /etc/apt/keyrings\nsudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc\nsudo chmod a+r /etc/apt/keyrings/docker.asc\n\n# Add the repository to Apt sources:\necho \\\n  \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \\\n  $(. /etc/os-release && echo \"${UBUNTU_CODENAME:-$VERSION_CODENAME}\") stable\" | \\\n  sudo tee /etc/apt/sources.list.d/docker.list > /dev/null\nsudo apt-get update\n```\n\n```\nsudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin\n```\n\n```\nsudo docker run hello-world\n```\n\n```\nsudo groupadd docker\n```\n\n```\nsudo usermod -aG docker $USER\n```\n\n```\nnewgrp docker\n```\n\n```\ndocker run hello-world\n```\n- install docker compose\n```\ncurl -SL https://github.com/docker/compose/releases/download/v2.33.1/docker-compose-linux-x86_64 -o /usr/local/bin/docker-compose\n\nchmod +x /usr/local/bin/docker-compose\n```\n\n- create a bitwarden and user dir\n```\nsudo adduser bitwarden\nsudo passwd bitwarden\nsudo usermod -aG docker bitwarden\nsudo mkdir /opt/bitwarden\nsudo chmod -R 700 /opt/bitwarden\nsudo chown -R bitwarden:bitwarden /opt/bitwarden\nusermod -aG sudo bitwarden \ncd /home/bitwarden\nmkdir -p .ssh\ntouch .ssh/authorized_keys\nssh bitwarden@ip_addres0s\n```\n"
  },
  {
    "url": "Miscellaneous/The_Caret_Conundrum.html",
    "content": "[Caret Countdown](https://softwareengineering.stackexchange.com/questions/331388/why-was-the-caret-used-for-xor-instead-of-exponentiation/331392#331392)\n"
  },
  {
    "url": "University/Computer_Networks/Module_1/bandwidth_and_multiplexing.html",
    "content": "---\nid: bandwidth and multiplexing\naliases: []\ntags: []\ntitle: bandwidth and multiplexing\n---\n\n**Bandwidth** refers to the maximum rate at which data can be transferred over a network or communication channel in a given amount of time. It’s typically measured in bits per second (bps)\n\n## Multiplexing\n**Multiplexing** is a technique that combines multiple signals—like data, voice, or video—into a single transmission medium to make efficient use of bandwidth\n\n2. **Frequency-Division Multiplexing (FDM)**  \n   - **Type:** Analog  \n   - **Description:** This technique divides the available frequency bandwidth into separate channels, each allocated a specific frequency range. Multiple signals are transmitted simultaneously, each using its own frequency band, without interfering with others. For example, radio and television broadcasting often use FDM.\n![[Pasted image 20250305015520.png]]\n\n1. **Wavelength-Division Multiplexing (WDM)**  \n   - **Type:** Analog  \n   - **Description:** Commonly used in fiber-optic communication, WDM splits the light spectrum into different wavelength bands (colors of light). Each signal is carried on a different wavelength, allowing multiple data streams to travel over the same optical fiber simultaneously. It’s widely used in high-capacity networks like the internet backbone.\n\n![[Pasted image 20250305015718.png]]\n\n1. **Time-Division Multiplexing (TDM)**  \n   - **Type:** Digital  \n   - **Description:** This method divides the transmission time into slots, and each signal gets a specific time slot to transmit its data. The signals are sent in rapid succession, taking turns to use the entire bandwidth. TDM is common in digital telephone systems and modern network protocols like T1 lines.\n"
  },
  {
    "url": "University/Computer_Networks/Module_1/Data.html",
    "content": "---\nid: Representation of Data and in its flow in networks\naliases: []\ntags: []\ntitle: Representation of Data and in its flow in networks\n---\n\n\n### **Representation of Data**  \nData representation refers to the way data is stored, processed, and transmitted within a system. It defines how various types of data (numbers, characters, images, etc.) are encoded for efficient computation and communication. Some common forms of data representation include:  \n\n1. **Binary Representation**:  \n   - All data in computers is ultimately stored in binary (0s and 1s).  \n   - Example: The number **5** in binary is **101**.  \n\n2. **Number Systems**:  \n   - **Decimal (Base 10)**: Used by humans (0-9).  \n   - **Binary (Base 2)**: Used by computers (0,1).  \n   - **Octal (Base 8)**: Sometimes used in computing (0-7).  \n   - **Hexadecimal (Base 16)**: Common in programming (0-9, A-F).  \n\n3. **Character Representation**:  \n   - **ASCII (American Standard Code for Information Interchange)**: Uses 7 or 8 bits to represent characters.  \n   - **Unicode**: Supports a wide range of characters using 16-bit or more.  \n\n4. **Data Structures**:  \n   - **Primitive Data Types**: Integer, Float, Boolean, Character.  \n   - **Complex Data Types**: Arrays, Linked Lists, Trees, Graphs.  \n\n5. **Images and Multimedia**:  \n   - **Images**: Represented using pixel values (e.g., RGB format).  \n   - **Audio and Video**: Stored as digital signals, often compressed (MP3, MP4).  \n\n---\n\n### **Five Components of Data Communication**\n\n1. **Sender** – The device that initiates the communication (e.g., a computer, phone).\n2. **Message** – The actual data being transmitted (text, audio, video, etc.).\n3. **Medium** – The transmission path that carries the message (wire, fiber optics, radio waves).\n4. **Receiver** – The device that receives and interprets the message.\n5. **Protocol** – A set of rules that governs data communication (e.g., TCP/IP, HTTP).\n\n---\n\n### **Data Flow (Simplex, Half-Duplex, and Full-Duplex)**\n#### **a. Simplex Communication**\n- Data flows **in only one direction** (unidirectional).\n- The sender transmits, and the receiver only receives.\n- Example: **TV broadcasting**, where a station sends signals, and viewers only receive.\n\n#### **b. Half-Duplex Communication**\n- Data flows **in both directions but only one at a time**.\n- Devices take turns transmitting and receiving.\n- Example: **Walkie-talkies**, where one person speaks while the other listens, then switches.\n\n#### **c. Full-Duplex Communication**\n- Data flows **simultaneously in both directions**.\n- Both sender and receiver can transmit and receive at the same time.\n- Example: **Phone calls**, where both parties can talk and listen simultaneously.\n"
  },
  {
    "url": "University/Computer_Networks/Module_1/OSI_model.html",
    "content": "---\nid: OSI Model\naliases: []\ntags: []\ntitle: OSI Model\n---\n\n# **OSI Model (Open Systems Interconnection Model)**  \n\nThe **OSI Model** is a **conceptual framework** used to understand how data flows in a network. It was developed by the **International Organization for Standardization (ISO)** to standardize network communication.  \n\nIt consists of **seven layers**, each with specific functions. These layers work together to **send and receive data** between devices across a network.  \n\n---\n\n## **OSI Model Overview**\n| **Layer No.** | **Layer Name**        | **Function** |\n|--------------|----------------------|-------------|\n| **7** | Application | Interacts with user applications (e.g., web browsers, email clients). |\n| **6** | Presentation | Formats, encrypts, and compresses data. |\n| **5** | Session | Manages sessions (start, maintain, and terminate connections). |\n| **4** | Transport | Ensures reliable or fast delivery of data (TCP/UDP). |\n| **3** | Network | Routes data between devices using IP addresses. |\n| **2** | Data Link | Manages frames and MAC addresses for physical transmission. |\n| **1** | Physical | Transmits raw bits over cables or wireless signals. |\n\n---\n\n## **Physical Layer (Layer 1)**\n    - Handles the **physical connection** between devices.  \n    - Converts data into electrical, optical, or radio signals for transmission.  \n    - When you connect a LAN cable to a router, the **Physical Layer** ensures that bits are transmitted correctly.  \n\n- **Key Components**:  \n    - **Cables** (Ethernet, fiber optics).  \n    - **Wireless signals** (Wi-Fi, Bluetooth).  \n    - **Network adapters and hubs**.  \n\n---\n\n## **Data Link Layer (Layer 2)**\n    - **Formats data into frames** for transmission.  \n    - Adds **MAC addresses** (physical addresses of network devices).  \n    - Detects and corrects errors in data transmission.  \n    - **Switches, Bridges, MAC Addresses**.  \n    - When a switch directs network traffic **based on MAC addresses**, it works at the **Data Link Layer**.  \n\n- **Divided into Two Sublayers**:  \n    1. **LLC (Logical Link Control)** – Error checking & flow control.  \n    2. **MAC (Media Access Control)** – Defines access to the physical network.  \n\n---\n\n## **Network Layer (Layer 3)**\n    - **Routes data** between different networks using **IP addresses**.  \n    - Determines the **best path** for data packets.  \n    - **Routers, IP Addresses (IPv4/IPv6), ARP, ICMP**.  \n    - When you visit a website, your computer contacts a router, which uses **IP addresses** to find the destination server.  \n\n---\n\n## **Transport Layer (Layer 4)**\n    - Ensures **end-to-end delivery** of data between devices.  \n    - Handles **error correction, segmentation, and reassembly**.  \n    - Uses **TCP (reliable) and UDP (fast but unreliable)**.  \n    - **Streaming a video** uses **UDP** for speed, while **downloading a file** uses **TCP** for reliability.  \n\n- **Key Protocols**:  \n    - **TCP (Transmission Control Protocol)** – Ensures reliable delivery, error checking, and acknowledgment.  \n    - **UDP (User Datagram Protocol)** – Faster but doesn’t guarantee delivery.  \n\n---\n\n## **Session Layer (Layer 5)**\n    - **Establishes, maintains, and terminates** communication sessions.  \n    - Manages sessions between applications.  \n    - A **Skype call** maintains a session so both users can communicate.  \n\n- **Key Responsibilities**:  \n    - **Session establishment** (e.g., logging into a remote server).  \n    - **Session synchronization** (e.g., saving a paused video call).  \n\n---\n\n## **Presentation Layer (Layer 6)**\n    - **Translates data** into a format the application can understand.  \n    - Handles **encryption, decryption, compression, and encoding**.  \n    - **Data format conversion** (e.g., converting text to ASCII).  \n    - **Encryption and decryption** (e.g., SSL/TLS for secure browsing).  \n    - **Compression** (e.g., reducing image file size).  \n    - When you **stream a video**, compression (e.g., MP4) is used to reduce file size.  \n\n---\n\n## **Application Layer (Layer 7)**\n    - Directly interacts with **user applications**.  \n    - Provides **network services** like file transfers, web browsing, and email.  \n    - When you type **\"www.google.com\"**, the **DNS** resolves the domain to an IP address.  \n\n- **Key Protocols**:  \n    - **HTTP/HTTPS** (Web browsing).  \n    - **FTP** (File transfers).  \n    - **SMTP/POP3/IMAP** (Email communication).  \n    - **DNS** (Domain name resolution).  \n\n---\n\n## **How Data Moves Through OSI Layers (Encapsulation & Decapsulation)**\n1. **Encapsulation (Sending Data)**:  \n   - Data moves **from the Application Layer (L7) to the Physical Layer (L1)**.  \n   - Each layer **adds headers** (e.g., IP, MAC) before transmission.  \n\n2. **Decapsulation (Receiving Data)**:  \n   - Data moves **from the Physical Layer (L1) to the Application Layer (L7)**.  \n   - Each layer **removes headers** and processes data accordingly.  \n\n---\n\n## **OSI Model vs. TCP/IP Model**\n| **Feature** | **OSI Model** | **TCP/IP Model** |\n|------------|-------------|----------------|\n| **Layers** | 7 | 4 |\n| **Developed by** | ISO | DoD (Department of Defense) |\n| **Main Purpose** | Conceptual framework | Practical implementation |\n| **Structure** | Application, Presentation, Session, Transport, Network, Data Link, Physical | Application, Transport, Internet, Network Access |\n| **Example Protocols** | HTTP, FTP, TCP, UDP, IP, Ethernet | HTTP, FTP, TCP, IP, Ethernet |\n\n---\n\n## **Why is the OSI Model Important?**\n- **Standardization** – Ensures different networks and devices can communicate.  \n- **Troubleshooting** – Helps **identify network issues** at specific layers.  \n- **Scalability** – Allows new technologies to integrate seamlessly.  \n- **Security** – Provides structured security measures at different layers.  \n"
  },
  {
    "url": "University/Computer_Networks/Module_1/Protocols_and_Standards.html",
    "content": "---\nid: Protocols and Standards\naliases: []\ntags: []\ntitle: Protocols and Standards\n---\n### **Protocols and Standards in Networking**  \n\nIn **computer networks**, **protocols** and **standards** define how data is transmitted, received, and processed between devices. They ensure compatibility, security, and efficiency in communication.\n\n---\n\n## **1. What is a Protocol?**  \nA **protocol** is a set of **rules and conventions** that govern how data is exchanged between devices in a network. These rules define:  \n- How data is **formatted**.  \n- How data is **transmitted**.  \n- How devices **respond to errors**.  \n\n### **Types of Protocols**  \nProtocols can be categorized based on the **layer** of communication they operate in:\n\n### **a) Network Communication Protocols**  \nThese protocols handle data transmission across networks.  \n- **TCP (Transmission Control Protocol)** – Ensures reliable, connection-oriented communication.  \n- **UDP (User Datagram Protocol)** – Provides fast, connectionless communication with no error checking.  \n- **IP (Internet Protocol)** – Routes data packets across networks (IPv4, IPv6).  \n- **ICMP (Internet Control Message Protocol)** – Used for error reporting (e.g., \"ping\" command).  \n\n### **b) Data Link & Physical Layer Protocols**  \nThese protocols deal with hardware and transmission methods.  \n- **Ethernet** – Wired communication in LANs.  \n- **Wi-Fi (IEEE 802.11)** – Wireless communication standard.  \n- **PPP (Point-to-Point Protocol)** – Used for direct connections like DSL.  \n\n### **c) Application Layer Protocols**  \nThese protocols enable communication between applications over a network.  \n- **HTTP/HTTPS (HyperText Transfer Protocol Secure)** – Used for web browsing.  \n- **FTP (File Transfer Protocol)** – Transfers files between computers.  \n- **SMTP (Simple Mail Transfer Protocol)** – Used for sending emails.  \n- **DNS (Domain Name System)** – Translates domain names to IP addresses.  \n\n---\n\n## **2. What is a Standard?**  \nA **standard** is an agreed-upon set of guidelines established by organizations to ensure uniformity and interoperability across devices, software, and networks.\n\n### **Types of Standards**  \nThere are two main types:\n\n### **a) De Facto Standards (\"By Fact\")**  \n- Not officially approved but widely adopted due to popularity.  \n- Example: **PDF (Portable Document Format)** for digital documents.  \n\n### **b) De Jure Standards (\"By Law\")**  \n- Officially recognized and enforced by standard organizations.  \n- Example: **IEEE 802.3** (Ethernet standard).  \n\n---\n\n## **3. Standard Organizations**  \nSeveral organizations create and maintain standards for communication networks:\n\n| **Organization** | **Full Name** | **Role** |\n|-----------------|--------------|---------|\n| **ISO** | International Organization for Standardization | Develops global standards (e.g., OSI model). |\n| **IEEE** | Institute of Electrical and Electronics Engineers | Defines networking protocols (e.g., Wi-Fi, Ethernet). |\n| **IETF** | Internet Engineering Task Force | Develops internet protocols (e.g., TCP/IP, HTTP). |\n| **W3C** | World Wide Web Consortium | Standardizes web technologies (e.g., HTML, CSS). |\n| **ITU** | International Telecommunication Union | Regulates global telecommunications and radio communication. |\n\n---\n\n## **4. Relationship Between Protocols and Standards**  \n- **Protocols implement standards** to ensure devices can communicate effectively.  \n- Example: **HTTP (protocol) follows W3C standards** for web communication.  \n- Without standards, different manufacturers would create incompatible technologies.  \n"
  },
  {
    "url": "University/Computer_Networks/Module_1/Topologies.html",
    "content": "---\nid: Connection Topologies\naliases: []\ntags: []\ntitle: Connection Topologies\n---\n\n### **Various Connection Topologies in Networking**  \nA **network topology** defines how devices (nodes) are connected and communicate within a network. The choice of topology affects performance, cost, and fault tolerance. Below are the major types of network topologies:\n\n---\n\n### **1. Bus Topology**  \n- **Structure**:  \n    - All devices share a **single central communication line** (bus).  \n    - Each device is connected via a **drop line** and uses a **terminator** at both ends.  \n\n- **Advantages**:  \n    - Easy to install and cost-effective.  \n    - Requires less cable than other topologies.  \n\n- **Disadvantages**:  \n    - A **single point of failure**—if the main cable fails, the entire network goes down.  \n    - Performance degrades with more devices.  \n\n- **Example**: Used in **small office networks** and **legacy Ethernet networks**.  \n\n---\n\n### **2. Star Topology**  \n- **Structure**:  \n    - All devices connect to a **central hub or switch**.  \n    - Communication occurs via the hub.  \n\n- **Advantages**:  \n    - **Easy to manage** and troubleshoot.  \n    - **Failure of one device doesn’t affect the network** (unless the hub fails).  \n\n- **Disadvantages**:  \n    - If the **central hub fails**, the network goes down.  \n    - Requires **more cables** than a bus topology.  \n\n- **Example**: Used in **modern Ethernet networks** (Wi-Fi routers, office networks).  \n\n---\n\n### **3. Ring Topology**  \n- **Structure**:  \n    - Devices are connected in a **closed loop (ring)**.  \n    - Data travels in **one direction (unidirectional)** or **both directions (bidirectional)**.  \n\n- **Advantages**:  \n    - **Efficient data transmission** (reduces chances of collision).  \n    - Can cover **long distances** compared to bus topology.  \n\n- **Disadvantages**:  \n    - **Single point of failure**—if one device fails, the entire network is affected.  \n    - **Difficult to reconfigure** when adding/removing devices.  \n\n- **Example**: Used in **token ring networks and some fiber optic networks**.  \n\n---\n\n### **4. Mesh Topology**  \n- **Structure**:  \n    - Every device is **connected to every other device** in the network.  \n    - Can be **fully connected** (every node has direct links) or **partially connected** (some nodes are directly connected).  \n\n- **Advantages**:  \n    - **Highly reliable**—failure of one link doesn’t affect communication.  \n    - **No data congestion** as multiple paths exist.  \n\n- **Disadvantages**:  \n    - **Expensive** due to high cable requirements.  \n    - **Complex setup and maintenance**.  \n\n- **Example**: Used in **critical military networks and data centers**.  \n\n---\n\n### **5. Tree Topology**  \n- **Structure**:  \n    - A combination of **bus and star topologies**.  \n    - Devices are grouped in star formations, connected via a **bus backbone**.  \n\n- **Advantages**:  \n    - **Scalable** (easy to expand).  \n    - **Hierarchical control** (useful for structured networks).  \n\n- **Disadvantages**:  \n    - **Failure of the backbone affects the entire network**.  \n    - **Requires more cable** than bus topology.  \n\n- **Example**: Used in **large organizational networks (corporate offices, universities)**.  \n\n---\n\n### **6. Hybrid Topology**  \n- **Structure**:  \n    - **Combination of two or more topologies** (e.g., mesh + star).  \n    - Used when a single topology cannot meet network needs.  \n\n- **Advantages**:  \n    - **Highly flexible and scalable**.  \n    - **Combines benefits of multiple topologies**.  \n\n- **Disadvantages**:  \n    - **Expensive and complex to manage**.  \n\n- **Example**: Used in **large enterprises and ISPs (Internet Service Providers)**.  \n\n---\n\n### **Comparison of Network Topologies**  \n\n| Topology  | Cost  | Scalability | Reliability | Complexity | Common Use Case |\n|-----------|-------|------------|------------|------------|----------------|\n| **Bus**   | Low   | Low        | Low        | Simple     | Small networks |\n| **Star**  | Medium| High       | Medium     | Easy       | Office networks |\n| **Ring**  | Medium| Low        | Medium     | Difficult  | Fiber networks |\n| **Mesh**  | High  | High       | High       | Complex    | Military, Data centers |\n| **Tree**  | Medium| High       | Medium     | Moderate   | Universities, Corporates |\n| **Hybrid**| High  | High       | High       | Complex    | Large ISPs, Enterprises |\n"
  },
  {
    "url": "University/Computer_Networks/Module_1/Transmission_Media.html",
    "content": "---\nid: Transmission Media\naliases: []\ntags: []\ntitle: Transmission Media\n---\n\n## **Transmission Media in Computer Networks**  \n**Transmission media** in computer networks refer to the physical or wireless pathways used to transmit data from one device to another. These media play a crucial role in determining the speed, bandwidth, and reliability of communication.  \n\n---\n\n## **Types of Transmission Media**  \nTransmission media are broadly classified into two categories:  \n\n### **1. Guided (Wired) Media**  \nGuided media involve physical cables through which signals travel. These provide high speed, security, and minimal interference.  \n\n#### **a) Twisted Pair Cable**  \nA **twisted pair cable** is a type of guided transmission medium used to transmit data and voice signals. It consists of pairs of insulated copper wires twisted together to minimize electromagnetic interference and crosstalk.  \n\n- ##### **Structure of Twisted Pair Cable**  \n\tA twisted pair cable consists of:  \n\t1. **Copper Conductors** – Two insulated copper wires that carry electrical signals.  \n\t2. **Twisting of Wires** – The wires are twisted in pairs to reduce interference from external sources and adjacent pairs.  \n\t3. **Outer Insulation** – Protects the inner conductors from physical damage and environmental factors.  \n\n- ##### **Types of Twisted Pair Cable**  \n\tTwisted pair cables are classified into two main types:  \n\n##### **1. Unshielded Twisted Pair (UTP)**  \n- **Description**: Lacks additional shielding, relying on wire twisting to reduce interference.  \n- **Advantages**:  \n  - Cost-effective  \n  - Easy to install and flexible  \n  - Suitable for most networking needs  \n- **Disadvantages**:  \n  - More susceptible to electromagnetic interference  \n  - Limited distance and bandwidth compared to shielded cables  \n- **Usage**:  \n  - Ethernet networks (Cat5, Cat6, Cat7 cables)  \n  - Telephone lines  \n\n###### **2. Shielded Twisted Pair (STP)**  \n- **Description**: Includes an additional shielding layer (metallic foil or braiding) around the twisted pairs to reduce interference.  \n- **Advantages**:  \n  - Better protection against crosstalk and external interference  \n  - Improved performance in electrically noisy environments  \n- **Disadvantages**:  \n  - More expensive than UTP  \n  - Bulkier and harder to install  \n- **Usage**:  \n  - Industrial settings with high electrical noise  \n  - High-speed data transmission networks  \n\n##### **Categories of Twisted Pair Cables**  \nTwisted pair cables are classified into different categories based on their data transmission capabilities:  \n\n| **Category** | **Data Rate (Mbps)** | **Use**                        |\n| ------------ | -------------------- | ------------------------------ |\n| **1**        | < 0.1                | Telephone                      |\n| **2**        | 2                    | T-1 lines                      |\n| **3**        | 10                   | LANs                           |\n| **4**        | 20                   | LANs (Token Ring networks)     |\n| **5**        | 100                  | LANs                           |\n| **5E**       | 125                  | LANs (Reduced crosstalk & EMI) |\n| **6**        | 200                  | LANs (Higher performance)      |\n| **7**        | 600                  | LANs (Shielded, high-speed)    |\n\n##### **Advantages of Twisted Pair Cable**  \n- **Cost-effective** – Cheaper than fiber optics and coaxial cables.  \n- **Easy to Install** – Flexible and easy to work with.  \n- **Widely Available** – Commonly used in networking applications.  \n- **Scalability** – Can support different network speeds based on category.  \n\n##### **Disadvantages of Twisted Pair Cable**  \n- **Limited Distance** – Signal degrades over long distances.  \n- **Susceptible to Interference** – UTP cables are prone to external electrical noise.  \n- **Lower Bandwidth** – Compared to fiber optic cables.  \n\n##### **Applications of Twisted Pair Cable**  \n- **Local Area Networks (LANs)** – Used in home and office Ethernet networks.  \n- **Telephone Systems** – Used in landline communication.  \n- **Security Systems** – Surveillance and alarm systems.  \n- **Industrial Communication** – STP cables are used in noisy environments.  \n\n---\n\n#### **b) Coaxial Cable**  \nA **coaxial cable** is a type of guided transmission medium used for data and signal transmission. It consists of a central conductor surrounded by multiple layers of insulation and shielding, which help reduce interference and improve signal quality.  \n\n---\n\n#### **Structure of a Coaxial Cable**  \nA coaxial cable has the following components:  \n\n1. **Inner Conductor** – A central copper wire (solid or stranded) that carries the electrical signal.  \n2. **Dielectric Insulator** – Surrounds the inner conductor to provide insulation and maintain consistent spacing.  \n3. **Metallic Shield (Braided Shield or Foil Shield)** – Reduces electromagnetic interference (EMI) and prevents signal leakage.  \n4. **Outer Insulation (Plastic Jacket)** – Protects the cable from physical damage and environmental factors.  \n\n---\n\n#### **Types of Coaxial Cables**  \n\nCoaxial cables are classified based on their impedance and applications:  \n\n##### **1. Based on Impedance**  \n- **50-Ohm Coaxial Cable** – Used for data and radio transmission.  \n- **75-Ohm Coaxial Cable** – Used for video signals and cable TV.  \n\n##### **2. Common Coaxial Cable Types**  \n\n| **Type**   | **Impedance** | **Usage** |\n|------------|-------------|----------|\n| **RG-59**  | 75 Ohms     | CCTV, short-distance video transmission |\n| **RG-11**  | 75 Ohms     | Long-distance cable TV, better signal quality |\n| **RG-58**  | 50 Ohms     | Ethernet (Thinnet - older networks) |\n\n---\n\n#### **Advantages of Coaxial Cables**  \n- **Better Shielding** – Reduces interference and crosstalk.  \n- **Higher Bandwidth** – Supports better data transmission compared to twisted pair cables.  \n- **Longer Distance Support** – Can carry signals over greater distances without significant loss.  \n- **Durability** – Resistant to physical and environmental damage.  \n\n#### **Disadvantages of Coaxial Cables**  \n- **Bulkier and Less Flexible** – More difficult to install compared to twisted pair cables.  \n- **Expensive** – Higher cost than twisted pair cables.  \n- **Limited Upgradability** – Less scalable compared to fiber optic technology.  \n\n---\n\n#### **Applications of Coaxial Cables**  \n- **Cable Television (CATV)** – Used for TV signal transmission.  \n- **Broadband Internet** – Used by cable internet service providers.  \n- **CCTV Surveillance Systems** – Commonly used for security camera connections.  \n- **Radio and Communication Networks** – Used in radio antennas and broadcasting.  \n- **Older Ethernet Networks** – Used in Thicknet (10BASE5) and Thinnet (10BASE2) Ethernet networks.  \n\n---\n\n#### **c) Fiber Optic Cable**  \n- **Description**: Uses light signals to transmit data through glass or plastic fibers.  \n- **Advantages**: Extremely high bandwidth, immune to electromagnetic interference, long-distance transmission.  \n- **Usage**: High-speed internet, backbone networks, undersea cables.  \n- **Speed**: Up to several Tbps.  \n\n---\n\n### **2. Unguided (Wireless) Media**  \nUnguided media use electromagnetic waves to transmit data without physical cables. These are widely used for mobility and long-range communication.  \n\n#### **a) Radio Waves**  \n- **Description**: Low-frequency signals that can travel long distances and penetrate walls.  \n- **Usage**: AM/FM radio, mobile phones, wireless LANs (Wi-Fi).  \n- **Range**: A few meters to several kilometers.  \n\n#### **b) Microwaves**  \n- **Description**: High-frequency waves that require a clear line of sight. Used for point-to-point communication.  \n- **Usage**: Satellite communication, cellular networks, long-distance telephone transmission.  \n- **Range**: Up to several kilometers (terrestrial) or global (satellite).  \n\n#### **c) Infrared (IR)**  \n- **Description**: Short-range signals that require direct line-of-sight communication.  \n- **Usage**: Remote controls, short-range wireless communication (e.g., Bluetooth, some IoT devices).  \n- **Range**: A few meters.  \n\n#### **d) Satellite Communication**  \n- **Description**: Uses geostationary or low-earth orbit (LEO) satellites to transmit signals across the globe.  \n- **Usage**: Global broadcasting, GPS, remote areas’ internet access.  \n- **Speed**: Varies but can support broadband connections.  \n\n---\n\n## **Comparison of Transmission Media**  \n\n| Medium         | Speed            | Distance | Interference | Cost | Usage |\n|---------------|----------------|----------|--------------|------|-------|\n| Twisted Pair  | Up to 10 Gbps   | Short    | Moderate     | Low  | LAN, telephony |\n| Coaxial Cable | Up to 10 Gbps   | Medium   | Low          | Medium | Cable TV, broadband |\n| Fiber Optic   | Up to Tbps      | Long     | None         | High  | Backbone networks, ISPs |\n| Radio Waves   | Several Mbps    | Long     | High         | Low   | Wi-Fi, radio |\n| Microwaves    | Up to Gbps      | Medium   | Medium       | Medium | Satellite, cellular networks |\n| Infrared      | Up to 100 Mbps  | Very Short | Low       | Low   | Remote controls, IoT |\n\n---\n\n## **BNC Connector (Bayonet Neill-Concelman)**  \n\nA **BNC (Bayonet Neill-Concelman) connector** is a type of coaxial cable connector used for quick connect and disconnect applications. It features a **bayonet-style locking mechanism**, ensuring a secure and reliable connection.  \n\n#### **Structure of a BNC Connector**  \nA typical BNC connector consists of:  \n1. **Outer Metal Shell** – Provides mechanical strength and shielding.  \n2. **Center Pin (Male/Female)** – Carries the electrical signal.  \n3. **Dielectric Insulator** – Separates the center pin from the outer shell.  \n4. **Bayonet Locking Mechanism** – A twist-and-lock design for secure connections.  \n\n#### **Types of BNC Connectors**  \nBNC connectors are classified based on impedance and application:  \n\n##### **1. Based on Impedance**  \n- **50-Ohm BNC Connector** – Used for data and RF (radio frequency) transmission.  \n- **75-Ohm BNC Connector** – Used for video signals and broadcast applications.  \n\n##### **2. Based on Design**  \n| **Type**        | **Description** | **Usage** |\n|----------------|---------------|-----------|\n| **BNC Male**   | Has a central pin and bayonet locking | Connects to female ports |\n| **BNC Female** | Has a socket to receive the male pin | Used on devices like oscilloscopes |\n| **T-Connector** | Splits a signal into two paths | Used in older Ethernet (10BASE2) |\n| **BNC Terminator** | Ends a signal to prevent reflection | Used in coaxial networks |\n| **BNC Adapter** | Converts BNC to other connector types | Used for mixed systems |\n\n> Replaced by RJ45 in modern LANs.  \n\n---\n\n## **Fiber Optic Cables**  \n\n**Fiber optic cables** are high-speed transmission media that use **light pulses** instead of electrical signals to transmit data. These cables consist of ultra-thin strands of **glass or plastic** that carry data at extremely high speeds over long distances with minimal signal loss.  \n\n---\n\n### **Structure of a Fiber Optic Cable**  \nA typical fiber optic cable consists of:  \n\n1. **Core** – The central part of the cable made of glass or plastic, through which light travels.  \n2. **Cladding** – A layer surrounding the core that reflects light back into the core to prevent signal loss.  \n3. **Buffer Coating** – A protective layer that shields the fiber from damage.  \n4. **Outer Jacket** – The outermost layer that protects the cable from environmental and mechanical damage.  \n\n---\n\n### **Types of Fiber Optic Cables**  \n\nFiber optic cables are mainly classified into two types:  \n\n#### **1. Single-Mode Fiber (SMF)**  \n- **Core Size**: Small (around 8-10 microns in diameter).  \n- **Light Source**: Uses laser light.  \n- **Data Transmission**: Long-distance, high-speed transmission.  \n- **Signal Loss**: Very low.  \n- **Usage**: Long-distance telecommunications, high-speed internet backbone.  \n\n#### **2. Multi-Mode Fiber (MMF)**  \n- **Core Size**: Larger (around 50-62.5 microns in diameter).  \n- **Light Source**: Uses LED light.  \n- **Data Transmission**: Short-distance communication with lower speeds.  \n- **Signal Loss**: Higher compared to SMF.  \n- **Usage**: Local Area Networks (LANs), data centers, and short-range communications.  \n\n---\n\n### **Advantages of Fiber Optic Cables**  \n- **High-Speed Transmission** – Supports speeds up to **Tbps (terabits per second)**.  \n- **Long-Distance Communication** – Can transmit signals over **hundreds of kilometers** without significant loss.  \n- **Immune to Electromagnetic Interference (EMI)** – Unlike copper cables, fiber optics do not suffer from EMI.  \n- **More Secure** – Difficult to tap into, making it ideal for secure communications.  \n- **Lightweight and Durable** – Less bulky compared to coaxial or twisted pair cables.  \n\n---\n\n### **Disadvantages of Fiber Optic Cables**  \n- **Expensive** – Higher installation and maintenance costs than copper cables.  \n- **Fragile** – Glass fibers are more delicate and require careful handling.  \n- **Complex Installation** – Requires specialized equipment and expertise.  \n\n---\n\n### **Applications of Fiber Optic Cables**  \n- **Internet and Broadband Networks** – Used in high-speed internet connections (e.g., fiber-to-the-home (FTTH)).  \n- **Telecommunications** – Backbone for long-distance communication networks.  \n- **Medical Equipment** – Used in endoscopy and laser surgeries.  \n- **Data Centers** – High-speed connections between servers.  \n- **Military and Aerospace** – Secure and high-speed data transmission.  \n\n---\n\n### **Modes of Fiber Optic Transmission**  \nIn fiber optics, the term **\"mode\"** refers to the path that light rays take as they travel through the fiber core. The mode of transmission affects the **speed, distance, and efficiency** of data transfer.  \n\n#### **1. Single-Mode Fiber (SMF)**  \nA type of fiber optic cable that allows only **one** mode (light path) to travel through the core.  \n\n- ##### **Characteristics**:  \n\t- **Core Diameter**: Small (8-10 microns).  \n\t- **Light Source**: Laser light (highly focused).  \n\t- **Bandwidth**: Extremely high (supports speeds up to terabits per second).  \n\t- **Signal Loss**: Very low, making it ideal for long-distance communication.  \n\t- **Distance**: Can transmit data over **hundreds of kilometers** without significant loss.  \n- ##### **Advantages**:  \n\t- High-speed and long-distance transmission.  \n\t- Minimal signal degradation and lower interference.  \n\t- Ideal for backbone networks and telecommunications.  \n\n- ##### **Disadvantages**:  \n\t- More expensive than multi-mode fiber.  \n\t- Requires precise laser alignment.  \n\t\n- ##### **Use Cases**:  \n\t- Long-distance telecommunications.  \n\t- Internet backbone connections.  \n\t- High-speed data transmission between cities.  \n\n#### **2. Multi-Mode Fiber (MMF)**  \nA type of fiber optic cable that allows **multiple** light modes (paths) to travel simultaneously through the core.  \n\n- ##### **Characteristics**:  \n\t- **Core Diameter**: Larger (50-62.5 microns).  \n\t- **Light Source**: LED light (less focused).  \n\t- **Bandwidth**: Lower compared to SMF, as multiple modes create dispersion.  \n\t- **Signal Loss**: Higher due to modal dispersion, which limits distance.  \n\t- **Distance**: Suitable for **short-range communication** (up to a few kilometers).  \n\n- ##### **Advantages**:  \n\t- Lower cost compared to SMF.  \n\t- Easier to install and maintain.  \n\t- Suitable for local networks and data centers.  \n\n- ##### **Disadvantages**:  \n\t- More signal loss and modal dispersion over long distances.  \n\t- Not ideal for high-speed, long-distance applications.  \n\n- ##### **Use Cases**:  \n\t- Local Area Networks (LANs).  \n\t- Data centers and short-distance connections.  \n\t- Audio-visual applications and campus networks.  \n\n---\n\n#### **Comparison: Single-Mode vs. Multi-Mode Fiber**  \n| Feature           | Single-Mode Fiber (SMF)            | Multi-Mode Fiber (MMF)               |\n| ----------------- | ---------------------------------- | ------------------------------------ |\n| **Core Diameter** | 8-10 microns                       | 50-62.5 microns                      |\n| **Light Source**  | Laser                              | LED                                  |\n| **Distance**      | Up to 100+ km                      | Up to a few km                       |\n| **Bandwidth**     | Extremely high                     | Lower due to modal dispersion        |\n| **Cost**          | Higher                             | Lower                                |\n| **Usage**         | Long-distance, high-speed networks | Short-distance LANs and data centers |\n\n---\n\n### **Unguided Media Transmission (Wireless Communication)**  \n**Unguided media transmission**, also known as **wireless communication**, is a type of data transmission where signals are sent through **air, space, or water** without the use of physical cables. It uses **electromagnetic waves** to carry data over long or short distances.  \n\n---\n\n## **Types of Unguided Media**  \nUnguided transmission is classified into three main types based on the frequency range:  \n\n| **Type**          | **Frequency Range** | **Distance**   | **Example Applications**                 |\n| ----------------- | ------------------- | -------------- | ---------------------------------------- |\n| **Radio Waves**   | 3 kHz – 1 GHz       | Short to Long  | AM/FM radio, TV broadcasting, Wi-Fi      |\n| **Microwaves**    | 1 GHz – 300 GHz     | Medium to Long | Mobile networks, satellite communication |\n| **Infrared (IR)** | 300 GHz – 400 THz   | Very Short     | TV remotes, short-range data transfer    |\n\n---\n\n## **1. Radio Wave Transmission**  \n**Definition**: Uses low-frequency electromagnetic waves that can travel long distances and penetrate obstacles like buildings.  \n\n- ### **Characteristics**:  \n\t- **Frequency Range**: 3 kHz – 1 GHz.  \n\t- **Transmission Distance**: From a few meters to thousands of kilometers.  \n\t- **Penetration**: Can pass through walls and obstacles.  \n\t- **Broadcasting Ability**: Suitable for mass communication (radio and TV).  \n\n- ### **Use Cases**:  \n\t- AM/FM radio broadcasting.  \n\t- Television signals.  \n\t- Wi-Fi and Bluetooth.  \n\t- Long-distance communication (military, maritime).  \n\n## **2. Microwave Transmission**  \n- **Definition**: Uses high-frequency electromagnetic waves to transmit data over long distances using point-to-point communication.  \n\n- ### **Characteristics**:  \n\t- **Frequency Range**: 1 GHz – 300 GHz.  \n\t- **Transmission Distance**: Medium to long (up to 50 km per relay station).  \n\t- **Directionality**: Highly directional (requires line-of-sight).  \n\t- **Speed**: High-speed data transmission.  \n\n- ### **Types of Microwave Communication**:  \n\t1. **Terrestrial Microwave** – Uses ground-based relay stations.  \n\t2. **Satellite Microwave** – Uses satellites for global communication.  \n\n- ### **Use Cases**:  \n\t- Mobile networks (3G, 4G, 5G).  \n\t- Satellite TV and GPS.  \n\t- Military and government communications.\n\t- Weather forecasting satellites.  \n\n## **3. Infrared (IR) Transmission**  \n- **Definition**: Uses high-frequency infrared waves for short-range data transmission.  \n\n - ### **Characteristics**:  \n    - **Frequency Range**: 300 GHz – 400 THz.  \n    - **Transmission Distance**: Very short (a few meters).  \n    - **Directionality**: Requires line-of-sight, cannot penetrate walls.  \n    - **Security**: More secure as signals do not travel beyond the intended area.  \n\n - ### **Use Cases**:  \n    - TV and air-conditioner remotes.  \n    - Infrared sensors (motion detectors).  \n    - Short-range data transfer (old mobile IR ports).  \n\n- #### **Advantages of Unguided Media**  \n\t- **No Physical Cables** – Reduces installation and maintenance costs.  \n\t- **Supports Mobility** – Ideal for mobile phones, Wi-Fi, and satellite communication.  \n\t- **Scalability** – Easily expands to cover large areas.  \n\t- **High-Speed Communication** – Especially in microwave and satellite systems.  \n\n- #### **Disadvantages of Unguided Media**  \n\t- **Interference Issues** – Susceptible to environmental factors (weather, obstacles).  \n\t- **Security Concerns** – Signals can be intercepted, requiring encryption.  \n\t- **Limited Distance for Some Types** – Infrared is short-range and requires line-of-sight.  \n\n#### **Comparison: Guided vs. Unguided Media**  \n| Feature                 | Guided Media (Wired)          | Unguided Media (Wireless)             |\n| ----------------------- | ----------------------------- | ------------------------------------- |\n| **Transmission Medium** | Cables (Copper, Fiber)        | Air, Space, Water                     |\n| **Interference**        | Low                           | High (affected by weather, obstacles) |\n| **Mobility**            | Limited                       | High (ideal for mobile devices)       |\n| **Security**            | More secure                   | Less secure (needs encryption)        |\n| **Installation Cost**   | Higher (cable setup required) | Lower (no physical medium needed)     |\n| **Distance**            | Short to Medium               | Medium to Long                        |\n\n### Different bands\n| **Band**                           | **Range**     | **Propagation**    | **Application**                       |\n| ---------------------------------- | ------------- | ------------------ | ------------------------------------- |\n| **VLF (Very Low Frequency)**       | 3–30 kHz      | Ground             | Long-range radio navigation           |\n| **LF (Low Frequency)**             | 30–300 kHz    | Ground             | Radio beacons, navigational locators  |\n| **MF (Middle Frequency)**          | 300 kHz–3 MHz | Sky                | AM radio                              |\n| **HF (High Frequency)**            | 3–30 MHz      | Sky                | CB radio, ship/aircraft communication |\n| **VHF (Very High Frequency)**      | 30–300 MHz    | Sky, Line-of-sight | VHF TV, FM radio                      |\n| **UHF (Ultra High Frequency)**     | 300 MHz–3 GHz | Line-of-sight      | UHF TV, cellular phones, satellite    |\n| **SHF (Super High Frequency)**     | 3–30 GHz      | Line-of-sight      | Satellite communication               |\n| **EHF (Extremely High Frequency)** | 30–300 GHz    | Line-of-sight      | Radar, satellite                      |\n\n"
  },
  {
    "url": "University/Computer_Networks/Module_1/Wired_LAN.html",
    "content": "---\nid: LAN\naliases: []\ntags: []\ntitle: LAN\n---\n\nWired Local Area Networks (LANs) are networks that connect devices within a limited area, such as a home, office, or building, using physical cables. These networks enable devices like computers, printers, and servers to communicate and share resources. Here's a breakdown of key aspects of wired LANs:\n\n### 1. **Components of a Wired LAN**\n   - **Devices**: Computers, printers, servers, and other networked devices.\n   - **Network Interface Cards (NICs)**: Hardware in devices that allows them to connect to the network.\n   - **Cables**: Physical medium for data transmission, typically Ethernet cables (e.g., Cat5e, Cat6, or Cat7).\n   - **Switches**: Devices that connect multiple devices within the LAN and manage data traffic.\n   - **Routers**: Devices that connect the LAN to other networks, such as the internet.\n   - **Protocols**: Rules and standards for communication, such as Ethernet (IEEE 802.3) and TCP/IP.\n\n### 2. **Types of Cables**\n   - **Ethernet Cables**: The most common type, including:\n     - **Cat5e**: Supports speeds up to 1 Gbps.\n     - **Cat6**: Supports speeds up to 10 Gbps over shorter distances.\n     - **Cat7**: Designed for higher speeds and reduced interference.\n   - **Fiber Optic Cables**: Used for high-speed, long-distance connections, often in larger networks.\n\n### 3. **Advantages of Wired LANs**\n   - **Speed**: Wired connections typically offer faster data transfer rates compared to wireless networks.\n   - **Reliability**: Wired networks are less prone to interference and signal loss.\n   - **Security**: Physical access is required to intercept data, making wired LANs more secure than wireless ones.\n   - **Stability**: Wired connections are generally more stable and consistent.\n\n### 4. **Disadvantages of Wired LANs**\n   - **Infrastructure**: Requires physical cables and hardware, which can be costly and complex to install.\n   - **Mobility**: Devices are tethered to the network by cables, limiting mobility.\n   - **Scalability**: Expanding the network may require additional cabling and hardware.\n\n### 6. **Applications**\n   - **Offices**: For reliable and secure internal communication and resource sharing.\n   - **Data Centers**: High-speed connections for servers and storage systems.\n   - **Homes**: Connecting devices like gaming consoles, smart TVs, and computers.\n\n### 7. **Standards and Protocols**\n   - **Ethernet (IEEE 802.3)**: The most widely used standard for wired LANs.\n   - **TCP/IP**: The foundational protocol suite for internet and LAN communication.\n   - **PoE (Power over Ethernet)**: Allows devices to receive power and data over the same cable.\n\n### **IEEE Standard for LAN**\nThese standards define how devices communicate over wired and wireless networks, ensuring interoperability and consistency across different manufacturers and technologies.\n\n---\n### **1. OSI or Internet Model**\nThe OSI model is a conceptual framework used to understand and standardize network communication. It consists of **7 layers**, but the image focuses on the **Data Link Layer** and **Physical Layer**, which are most relevant to IEEE LAN standards.\n\n---\n\n### **2. Data Link Layer**\nThe **Data Link Layer** is divided into two sublayers in the IEEE standards:\n- **Logical Link Control (LLC)**\n- **Media Access Control (MAC)**\n\n#### **Logical Link Control (LLC)**\n- **Purpose**: Provides a common interface between the **Network Layer** (upper layers) and the **MAC Layer**.\n- **Functions**:\n  - Manages flow control.\n  - Ensures error-free data transfer.\n  - Works with multiple MAC protocols (e.g., Ethernet, Token Ring).\n\n#### **Media Access Control (MAC)**\n- **Purpose**: Controls how devices access and transmit data over the network.\n- **Functions**:\n  - Manages addressing (e.g., MAC addresses).\n  - Implements protocols like **CSMA/CD** (for Ethernet) or **Token Passing** (for Token Ring).\n  - Ensures fair access to the transmission medium.\n\n---\n\n### **3. Physical Layer**\nThe **Physical Layer** deals with the actual transmission of data over the network medium. It includes:\n- **Transmission Medium**: The physical cables or wireless signals used to transmit data (e.g., Ethernet cables, fiber optics, radio waves).\n- **Physical Layer Standards**: Define how data is encoded, transmitted, and received over the medium.\n\n---\n\n### **4. IEEE LAN Standards**\nThe image highlights three key IEEE LAN standards, each with its own **MAC** and **Physical Layer** implementations:\n\n#### **Ethernet (IEEE 802.3)**\n- **MAC Protocol**: Uses **CSMA/CD** (Carrier Sense Multiple Access with Collision Detection) to manage access to the network.\n- **Physical Layer**: Supports various cabling types (e.g., twisted-pair, fiber optic) and speeds (e.g., 10 Mbps, 100 Mbps, 1 Gbps, 10 Gbps).\n\n#### **Token Ring (IEEE 802.5)**\n- **MAC Protocol**: Uses **Token Passing**, where a token is passed between devices to control access to the network.\n- **Physical Layer**: Typically uses twisted-pair or fiber optic cables.\n\n#### **Token Bus (IEEE 802.4)**\n- **MAC Protocol**: Combines features of Ethernet (bus topology) and Token Ring (token passing).\n- **Physical Layer**: Uses coaxial or fiber optic cables.\n\n---\n\n### **5. Relationship Between Layers**\n- The **LLC** sublayer acts as a bridge between the **Upper Layers** (e.g., Network Layer) and the **MAC** sublayer.\n- The **MAC** sublayer interacts directly with the **Physical Layer** to transmit data over the network medium.\n\n![[Pasted image 20250223014349.png]]\n\n---\n## **HDLC Frame compared with LLC and MAC frames**\n---\n### **1. HDLC Frame**\n**HDLC (High-Level Data Link Control)** is a widely used protocol for data communication at the **Data Link Layer**. The HDLC frame structure consists of the following fields:\n\n- **Address**: Identifies the destination of the frame.\n- **Control**: Manages flow control, error detection, and frame type (e.g., information, supervisory, or unnumbered frames).\n- **Upper-layer data**: The payload or data being transmitted.\n- **FCS (Frame Check Sequence)**: A checksum for error detection.\n\n---\n\n### **2. LLC PDU (Protocol Data Unit)**\nThe **LLC PDU** is the data unit used by the **Logical Link Control** sublayer of the **Data Link Layer**. It encapsulates the upper-layer data and adds LLC-specific information. The LLC PDU structure includes:\n\n- **DSAP (Destination Service Access Point)**: Identifies the service or protocol at the destination device.\n- **SSAP (Source Service Access Point)**: Identifies the service or protocol at the source device.\n- **Control**: Manages flow control and error detection (similar to the HDLC Control field).\n- **Upper-layer data**: The payload or data being transmitted.\n\n---\n\n### **3. MAC Frame**\nThe **MAC frame** is used by the **Media Access Control** sublayer of the **Data Link Layer**. It encapsulates the LLC PDU and adds MAC-specific information. The MAC frame structure includes:\n\n- **MAC Header**: Contains addressing and control information specific to the MAC protocol (e.g., Ethernet MAC addresses).\n- **MAC Payload**: The LLC PDU (including DSAP, SSAP, Control, and upper-layer data).\n- **FCS (Frame Check Sequence)**: A checksum for error detection.\n\n---\n\n![[video.webm]]\n### **4. Comparison of Frames**\n- **HDLC Frame**: A general-purpose frame used in HDLC protocol, primarily in point-to-point and multipoint communication.\n- **LLC PDU**: Focuses on providing a common interface between the **Network Layer** and the **MAC Layer**, ensuring compatibility across different MAC protocols.\n- **MAC Frame**: Adds MAC-specific addressing and control information to the LLC PDU, enabling communication over the physical network medium.\n\n![[Pasted image 20250223014931.png]]\n## **Ethernet Evolution Overview**\nEthernet has evolved significantly since its inception in the 1970s. Each generation introduced higher speeds, improved performance, and new features to meet the growing demands of networking. The four generations of Ethernet are:\n\n1. **Standard Ethernet (10 Mbps)**\n2. **Fast Ethernet (100 Mbps)**\n3. **Gigabit Ethernet (1 Gbps)**\n4. **10 Gigabit Ethernet (10 Gbps) and beyond**\n\n---\n#### **1. Standard Ethernet (10 Mbps)**\n- **Introduced**: 1980s.\n- **Standards**: IEEE 802.3.\n- **Key Features**:\n  - Speed: 10 Mbps.\n  - Cabling: Coaxial (10BASE5, 10BASE2) and twisted-pair (10BASE-T).\n  - Topology: Bus (coaxial) and Star (twisted-pair).\n- **Use Case**: Early LANs for basic data transfer and file sharing.\n\n#### **2. Fast Ethernet (100 Mbps)**\n- **Introduced**: Mid-1990s.\n- **Standards**: IEEE 802.3u.\n- **Key Features**:\n  - Speed: 100 Mbps.\n  - Cabling: Twisted-pair (100BASE-TX) and fiber optic (100BASE-FX).\n  - Topology: Star.\n- **Use Case**: Improved performance for multimedia and larger networks.\n\n#### **3. Gigabit Ethernet (1 Gbps)**\n- **Introduced**: Late 1990s.\n- **Standards**: IEEE 802.3z (fiber) and IEEE 802.3ab (twisted-pair).\n- **Key Features**:\n  - Speed: 1 Gbps.\n  - Cabling: Twisted-pair (1000BASE-T) and fiber optic (1000BASE-SX, 1000BASE-LX).\n  - Topology: Star.\n- **Use Case**: High-speed networks for data centers, enterprise networks, and bandwidth-intensive applications.\n\n#### **4. 10 Gigabit Ethernet (10 Gbps) and Beyond**\n- **Introduced**: Early 2000s.\n- **Standards**: IEEE 802.3ae (fiber) and IEEE 802.3an (twisted-pair).\n- **Key Features**:\n  - Speed: 10 Gbps.\n  - Cabling: Twisted-pair (10GBASE-T) and fiber optic (10GBASE-SR, 10GBASE-LR).\n  - Topology: Star.\n- **Use Case**: Data centers, high-performance computing, and backbone networks.\n- **Beyond 10 Gbps**:\n  - **40 Gigabit Ethernet (40 Gbps)**: IEEE 802.3ba.\n  - **100 Gigabit Ethernet (100 Gbps)**: IEEE 802.3ba.\n  - **400 Gigabit Ethernet (400 Gbps)**: IEEE 802.3bs.\n\n## **802.3 MAC frame**\n![[Pasted image 20250223014955.png]]\n\n---\n### **1. Preamble**\n- **Size**: 7 bytes (56 bits).\n- **Purpose**: Synchronizes the sender and receiver by providing a series of alternating 1s and 0s. This helps the receiver detect the start of a frame and synchronize its clock with the sender's clock.\n\n---\n\n### **2. Start Frame Delimiter (SFD)**\n- **Size**: 1 byte (8 bits).\n- **Value**: `10101011` (binary).\n- **Purpose**: Marks the end of the preamble and indicates the start of the actual frame. The last two bits (`11`) signal the beginning of the frame.\n\n---\n\n### **3. Destination Address**\n- **Size**: 6 bytes (48 bits).\n- **Purpose**: Specifies the **MAC address** of the intended recipient of the frame. This address is used by switches and devices to determine where to forward the frame.\n\n---\n\n### **4. Source Address**\n- **Size**: 6 bytes (48 bits).\n- **Purpose**: Specifies the **MAC address** of the sender of the frame. This helps the recipient identify the source of the data.\n\n---\n\n### **5. Length or Type**\n- **Size**: 2 bytes (16 bits).\n- **Purpose**:\n  - **Length Field**: Indicates the length of the data field (in bytes) if the frame is using the IEEE 802.3 standard.\n  - **Type Field**: Indicates the type of protocol encapsulated in the data field (e.g., IPv4, IPv6) if the frame is using the Ethernet II standard.\n- **Note**: This field is interpreted differently depending on the Ethernet version being used.\n\n---\n\n### **6. Data and Padding**\n- **Size**: Variable (46 to 1500 bytes for Ethernet).\n- **Purpose**:\n  - **Data**: Contains the actual payload being transmitted (e.g., IP packet, ARP message).\n  - **Padding**: Ensures the frame meets the minimum size requirement of 64 bytes (including headers and CRC). If the data is too small, padding bytes are added.\n- **Minimum Frame Size**: 46 bytes (data + padding).\n- **Maximum Frame Size**: 1500 bytes (data + padding).\n\n---\n\n### **7. Cyclic Redundancy Check (CRC)**\n- **Size**: 4 bytes (32 bits).\n- **Purpose**: Provides error detection. The sender calculates a checksum based on the frame's contents, and the receiver recalculates it to check for errors during transmission. If the checksums don't match, the frame is discarded.\n\n---\n\n### **8. Physical Layer Header**\n- **Purpose**: This is not part of the MAC frame itself but is added by the **Physical Layer** when transmitting the frame over the network medium (e.g., Ethernet cable, fiber optic).\n- **Function**: Includes additional information required for transmission, such as synchronization and signaling.\n\n---\n\n### **9. Summary of the MAC Frame**\n| Field               | Size      | Purpose                                                                 |\n|---------------------|-----------|-------------------------------------------------------------------------|\n| **Preamble**        | 7 bytes   | Synchronizes sender and receiver.                                       |\n| **SFD**             | 1 byte    | Marks the start of the frame.                                           |\n| **Destination Address** | 6 bytes | Specifies the MAC address of the recipient.                             |\n| **Source Address**  | 6 bytes   | Specifies the MAC address of the sender.                                |\n| **Length/Type**     | 2 bytes   | Indicates the length of the data or the type of protocol.               |\n| **Data and Padding**| 46–1500 bytes | Contains the payload and padding to meet minimum frame size.           |\n| **CRC**             | 4 bytes   | Provides error detection.                                               |\n\n\n## **Minimum and Maximum Lengths**\n![[Pasted image 20250223015233.png]]\n\n---\n\n### **1. Ethernet Frame Structure**\nAn Ethernet frame consists of several fields, as shown in the image:\n\n| Field               | Size      | Description                                                                 |\n|---------------------|-----------|-----------------------------------------------------------------------------|\n| **Destination Address** | 6 bytes | The MAC address of the intended recipient.                                  |\n| **Source Address**  | 6 bytes   | The MAC address of the sender.                                              |\n| **Length/PDU**      | 2 bytes   | Indicates the length of the payload or the type of protocol (e.g., IPv4).   |\n| **Data and Padding**| 46–1500 bytes | The payload (data) being transmitted, with padding if necessary.           |\n| **CRC**             | 4 bytes   | Cyclic Redundancy Check for error detection.                                |\n\n---\n\n### **2. Minimum and Maximum Payload Length**\n- **Minimum Payload Length**: 46 bytes.\n  - If the data being transmitted is less than 46 bytes, **padding** is added to meet this minimum requirement.\n  - **Reason**: Ensures that the frame is long enough for collision detection in Ethernet networks.\n- **Maximum Payload Length**: 1500 bytes.\n  - This is the standard maximum size for the payload in Ethernet frames.\n  - **Reason**: Balances efficiency and network performance.\n\n---\n\n### **3. Minimum and Maximum Frame Length**\n- **Minimum Frame Length**: 64 bytes (512 bits).\n  - This includes:\n    - **Destination Address**: 6 bytes.\n    - **Source Address**: 6 bytes.\n    - **Length/PDU**: 2 bytes.\n    - **Data and Padding**: 46 bytes (minimum).\n    - **CRC**: 4 bytes.\n  - **Reason**: Ensures that the frame is long enough for proper collision detection in Ethernet networks.\n- **Maximum Frame Length**: 1518 bytes (12,144 bits).\n  - This includes:\n    - **Destination Address**: 6 bytes.\n    - **Source Address**: 6 bytes.\n    - **Length/PDU**: 2 bytes.\n    - **Data and Padding**: 1500 bytes (maximum).\n    - **CRC**: 4 bytes.\n  - **Reason**: Prevents a single frame from monopolizing the network for too long.\n\n---\n\n### **4. Why These Lengths Matter**\n- **Collision Detection**: Ethernet uses **CSMA/CD** (Carrier Sense Multiple Access with Collision Detection). The minimum frame length ensures that collisions can be detected before the frame transmission completes.\n- **Efficiency**: The maximum frame length balances efficiency and fairness, ensuring that no single device dominates the network for an extended period.\n- **Interoperability**: Standardizing frame sizes ensures that all devices on an Ethernet network can communicate effectively.\n\n---\n\n### **5. Key Takeaways**\n- **Minimum Payload**: 46 bytes (padding added if necessary).\n- **Maximum Payload**: 1500 bytes.\n- **Minimum Frame Length**: 64 bytes (including headers and CRC).\n- **Maximum Frame Length**: 1518 bytes (including headers and CRC).\n\n## **Unicast and Multicast Addresses**\n---\n\n### **1. Unicast Address**\nA **unicast address** is used for **one-to-one communication**, where data is sent from a single source to a single destination.\n\n#### **Characteristics**:\n- **Destination**: A unique address assigned to a specific device (e.g., a MAC address or IP address).\n- **Transmission**: The data is delivered only to the intended recipient.\n- **Use Case**: Common in most network communications, such as web browsing, email, or file transfers.\n\n#### **Examples**:\n- **MAC Unicast Address**: A unique 48-bit hardware address assigned to a network interface card (NIC). Example: `00:1A:2B:3C:4D:5E`.\n- **IP Unicast Address**: A unique IP address assigned to a device. Example: `192.168.1.10` (IPv4) or `2001:0db8:85a3::8a2e:0370:7334` (IPv6).\n\n#### **Advantages**:\n- Efficient for point-to-point communication.\n- Ensures data is delivered only to the intended recipient.\n\n#### **Disadvantages**:\n- Inefficient for sending the same data to multiple recipients (requires multiple transmissions).\n\n---\n\n### **2. Multicast Address**\nA **multicast address** is used for **one-to-many communication**, where data is sent from a single source to multiple destinations simultaneously.\n\n#### **Characteristics**:\n- **Destination**: A special address that represents a group of devices interested in receiving the data.\n- **Transmission**: The data is delivered to all devices in the multicast group.\n- **Use Case**: Common in applications like video streaming, online gaming, and live broadcasts.\n\n#### **Examples**:\n- **MAC Multicast Address**: A special 48-bit address where the least significant bit of the first byte is set to `1`. Example: `01:00:5E:00:00:01`.\n- **IP Multicast Address**: A special range of IP addresses reserved for multicast. Example:\n  - IPv4: `224.0.0.0` to `239.255.255.255`.\n  - IPv6: Addresses starting with `FF00::/8`.\n\n#### **Advantages**:\n- Efficient for sending the same data to multiple recipients (requires only one transmission).\n- Reduces network traffic compared to sending multiple unicast transmissions.\n\n#### **Disadvantages**:\n- Requires devices to join the multicast group to receive data.\n- More complex to manage than unicast.\n\n---\n\n### **3. Comparison of Unicast and Multicast**\n\n| Feature               | Unicast                          | Multicast                        |\n|-----------------------|----------------------------------|----------------------------------|\n| **Communication Type** | One-to-one                      | One-to-many                     |\n| **Destination**        | Single device                   | Group of devices                |\n| **Efficiency**         | Efficient for single recipients | Efficient for multiple recipients |\n| **Use Cases**          | Web browsing, email, file transfer | Video streaming, live broadcasts, online gaming |\n| **Address Examples**   | MAC: `00:1A:2B:3C:4D:5E`        | MAC: `01:00:5E:00:00:01`        |\n|                       | IP: `192.168.1.10`              | IP: `224.0.0.1`                 |\n\n---\n\n\n## **Standard Ethernet Common Implementations**\n   - This is the overarching category shown at the top of the diagram, representing the family of Ethernet standards operating at a data rate of 10 Mbps (megabits per second). These implementations are part of the IEEE 802.3 standard, which specifies the physical and data link layer protocols for Ethernet.\n\n### **10Base5**\n   - **Topology**: Bus\n   - **Cable Type**: Thick coaxial cable\n   - **Description**: \n     - 10Base5, also known as \"Thick Ethernet\" or \"Thicknet,\" was one of the earliest Ethernet standards.\n     - It uses a thick coaxial cable (typically 10mm in diameter) as the transmission medium.\n     - The \"10\" indicates a data rate of 10 Mbps, \"Base\" means baseband transmission (using the entire bandwidth for a single signal), and \"5\" refers to the maximum segment length of 500 meters.\n     - Devices are connected to the bus topology via vampire taps or transceivers, which clamp onto the cable.\n     - This implementation is largely obsolete today due to its rigid installation requirements and susceptibility to failures.\n![[Pasted image 20250223020811.png]]\n### **10Base2**\n   - **Topology**: Bus\n   - **Cable Type**: Thin coaxial cable\n   - **Description**:\n     - 10Base2, also known as \"Thin Ethernet\" or \"Thinnet,\" is a later and more flexible version of 10Base5.\n     - It uses a thinner coaxial cable (typically 5mm in diameter, such as RG-58).\n     - Like 10Base5, it operates at 10 Mbps using baseband transmission, but the \"2\" indicates a maximum segment length of 185 meters (approximately 200 meters, hence the name).\n     - Devices are connected using BNC connectors and T-connectors in a bus topology.\n     - It was more affordable and easier to install than 10Base5 but is also considered obsolete, replaced by more modern standards.\n\n![[Pasted image 20250223020830.png]]\n### **10Base-T**\n   - **Topology**: Star\n   - **Cable Type**: UTP (Unshielded Twisted Pair)\n   - **Description**:\n     - 10Base-T is one of the most well-known and widely used Ethernet standards historically.\n     - It operates at 10 Mbps using baseband transmission, with \"T\" standing for twisted pair cabling, specifically Category 3 or higher UTP cables.\n     - It uses a star topology, where all devices are connected to a central hub or switch via point-to-point connections.\n     - The maximum segment length is 100 meters.\n     - 10Base-T became popular in the 1990s and laid the groundwork for faster Ethernet standards like 100Base-TX and Gigabit Ethernet.\n\n![[Pasted image 20250223020846.png]]\n### **10Base-F**\n   - **Topology**: Star\n   - **Cable Type**: Fiber\n   - **Description**:\n     - 10Base-F refers to Ethernet over fiber-optic cable, operating at 10 Mbps using baseband transmission.\n     - \"F\" stands for fiber, indicating the use of optical fiber as the transmission medium.\n     - It uses a star topology, typically with devices connected to a central hub or switch via fiber-optic cables.\n     - Fiber-optic cables allow for longer distances (up to 2 kilometers in some configurations) and are immune to electromagnetic interference, making 10Base-F suitable for environments requiring high reliability or long-distance connections.\n     - While effective, 10Base-F is less common today, as faster fiber-based standards like 100Base-FX and Gigabit Ethernet have become more prevalent.\n\n![[Pasted image 20250223022003.png]]\n## **Encoding in standard ethernet implementation**\n\n![[Pasted image 20250223020742.png]]\n### Key Components and Flow\n1. **10 Mbps Data (Input)**:\n   - The process begins with 10 Mbps digital data generated by the station. This data consists of binary signals (0s and 1s) that need to be transmitted over the network.\n\n2. **Manchester Encoder**:\n   - Located at the transmitting end (within the station), the Manchester encoder converts the raw 10 Mbps binary data into a Manchester-encoded signal.\n   - **Manchester Encoding**:\n     - Manchester encoding is a line coding technique used in Ethernet to ensure reliable data transmission. It encodes each bit of data as a transition in the signal:\n       - A binary \"0\" is represented by a low-to-high transition (falling edge) in the middle of the bit period.\n       - A binary \"1\" is represented by a high-to-low transition (rising edge) in the middle of the bit period.\n     - This encoding method provides several advantages:\n       - It includes a clock signal within the data, allowing the receiver to synchronize with the transmitter (self-clocking).\n       - It ensures that there is at least one transition per bit, which helps detect errors and maintain signal integrity.\n       - It eliminates long sequences of 0s or 1s, reducing the risk of signal degradation or loss of synchronization.\n     - The encoded signal is then sent over the transmission medium, which can be twisted pair cables (e.g., in 10Base-T) or fiber-optic cables (e.g., in 10Base-F).\n\n3. **Twisted Pairs or Fibers**:\n   - This represents the physical medium used to transmit the Manchester-encoded signal. In the context of Standard Ethernet implementations like 10Base-T, twisted pair cables (UTP) are commonly used, while 10Base-F uses fiber-optic cables.\n   - The medium carries the encoded signal from the transmitting station to the receiving station.\n\n4. **Manchester Decoder**:\n   - Located at the receiving end, the Manchester decoder receives the Manchester-encoded signal and converts it back into the original 10 Mbps binary data.\n   - The decoder interprets the transitions in the signal (high-to-low or low-to-high) to reconstruct the binary data:\n     - A low-to-high transition in the middle of a bit period is decoded as a \"0.\"\n     - A high-to-low transition in the middle of a bit period is decoded as a \"1.\"\n   - This process ensures that the receiving station can accurately recover the original data sent by the transmitter.\n\n5. **10 Mbps Data (Output)**:\n   - The decoded data, now restored to its original binary form, is output as 10 Mbps data at the receiving station, ready for processing or further transmission.\n\n### Why Manchester Encoding?\n- **Self-Clocking**: The transitions in the signal allow the receiver to extract the clock signal, ensuring synchronization between sender and receiver without needing a separate clock line.\n- **Error Detection**: The presence of transitions helps detect errors, as a lack of transitions could indicate a problem with the signal or cable.\n- **DC Balance**: Manchester encoding ensures that the signal has no net DC component, which is important for maintaining signal quality over long distances or through certain types of cables.\n\n## **Scaling Ethernet**\n---\n1. **Bridged Ethernet**:\n   - Bridged Ethernet refers to the use of bridges to connect multiple Ethernet segments or LANs, improving network efficiency and scalability.\n   - Bridges operate at the data link layer (Layer 2 of the OSI model) and forward frames only to the segment where the destination device is located, reducing unnecessary traffic and collisions in the network.\n   - This was a significant advancement over the original bus topology Ethernet (e.g., 10Base5 and 10Base2), which suffered from performance issues due to collisions in shared media.\n   - Bridging helped lay the groundwork for larger, more segmented networks, paving the way for higher data rates by reducing congestion.\n\n2. **Switched Ethernet**:\n   - Switched Ethernet builds on the concept of bridging but uses switches instead of bridges. Switches are more advanced devices that can handle multiple simultaneous connections and provide dedicated bandwidth to each port.\n   - In a switched Ethernet network, each device is connected to a switch port in a star topology (as seen in 10Base-T), eliminating the collision domain issues of bus-based Ethernet.\n   - Switches improved network performance by enabling full utilization of the 10 Mbps bandwidth per connection and later supported higher speeds (e.g., 100 Mbps, 1 Gbps).\n   - This change was crucial for scaling Ethernet to handle higher data rates and modern network demands, making it compatible with other high-data-rate LAN technologies.\n\n3. **Full-Duplex Ethernet**:\n   - Full-Duplex Ethernet allows simultaneous two-way communication between devices, meaning data can be sent and received at the same time on the same connection.\n   - In contrast, the original 10-Mbps Ethernet (e.g., 10Base5, 10Base2, and early 10Base-T) operated in half-duplex mode, where devices could either send or receive data but not both simultaneously, leading to potential collisions and reduced efficiency.\n   - Full-duplex operation, enabled by switches and point-to-point connections (e.g., in 10Base-T with switches), doubled the effective bandwidth (e.g., 20 Mbps total for 10 Mbps send and 10 Mbps receive) and eliminated collisions, significantly improving performance.\n   - This capability was essential for Ethernet to support higher data rates and integrate with other high-speed LANs, as it provided a foundation for faster standards like Fast Ethernet (100 Mbps) and Gigabit Ethernet.\n\n## **Fast Ethernet**\n\n### Key Characteristics of Fast Ethernet\n1. **Data Rate**:\n   - Fast Ethernet operates at 100 Mbps, which is ten times faster than the original 10-Mbps Ethernet. This increase in speed accommodates the growing need for higher bandwidth in LANs.\n\n2. **Backward Compatibility**:\n   - Fast Ethernet is designed to be backward compatible with 10-Mbps Ethernet, allowing devices and networks to operate at either speed on the same infrastructure. This compatibility ensures a smooth transition for organizations upgrading their networks.\n\n3. **Physical Media and Standards**:\n   Fast Ethernet supports several physical layer implementations, each using different cabling types and topologies. The most common standards are:\n   - **100Base-TX**:\n     - Uses two pairs of Category 5 (Cat5) or better unshielded twisted pair (UTP) cables.\n     - Operates in a star topology with hubs or switches.\n     - Maximum segment length is 100 meters (328 feet).\n     - This is the most widely used Fast Ethernet standard due to its affordability and compatibility with existing twisted pair wiring.\n   - **100Base-FX**:\n     - Uses two strands of multimode fiber-optic cable.\n     - Also operates in a star topology, typically with switches or hubs.\n     - Supports longer distances, up to 2 kilometers (1.24 miles), making it suitable for campus or building backbone networks.\n     - Fiber-optic cables provide immunity to electromagnetic interference and higher reliability over long distances.\n   - **100Base-T4** (less common):\n     - Uses four pairs of Category 3, 4, or 5 UTP cables.\n     - Supports older wiring infrastructure but is rarely used today due to its complexity and lower adoption compared to 100Base-TX.\n\n4. **Encoding and Signaling**:\n   - Fast Ethernet uses more advanced encoding schemes than the Manchester encoding used in 10-Mbps Ethernet. For example:\n     - **100Base-TX** uses 4B/5B encoding combined with MLT-3 (Multi-Level Transmit) signaling to transmit data efficiently over twisted pair cables.\n     - **100Base-FX** uses 4B/5B encoding with NRZI (Non-Return to Zero Inverted) signaling over fiber-optic cables.\n   - These encoding methods allow for higher data rates while maintaining signal integrity over the specified media.\n\n5. **Topology**:\n   - Fast Ethernet primarily uses a star topology, where devices are connected to a central hub or switch. This contrasts with the bus topology of older 10Base5 and 10Base2 standards, reducing collisions and improving performance.\n   - Hubs can operate in half-duplex mode (shared bandwidth), but switches enable full-duplex communication, doubling the effective throughput to 200 Mbps per connection (100 Mbps send and 100 Mbps receive).\n\n6. **Frame Format**:\n   - Fast Ethernet retains the same Ethernet frame format as 10-Mbps Ethernet (defined in IEEE 802.3), including the preamble, start frame delimiter, destination/source addresses, data payload, and frame check sequence (FCS). This ensures interoperability between 10-Mbps and 100-Mbps devices.\n\n### Advantages of Fast Ethernet\n- **Higher Speed**: 100 Mbps significantly improves network performance compared to 10 Mbps, supporting more users and data-intensive applications.\n- **Cost-Effective Upgrade**: Leverages existing Cat5 or better UTP cabling and hubs/switches, reducing the need for complete infrastructure overhauls.\n- **Reliability**: Uses advanced encoding and signaling to maintain signal integrity over longer distances (especially with fiber in 100Base-FX).\n- **Scalability**: Supports full-duplex operation and switched networks, enabling efficient scaling for larger organizations.\n\n### Limitations\n- While fast for its time, 100 Mbps is now considered slow compared to modern Gigabit Ethernet (1 Gbps) or 10 Gigabit Ethernet (10 Gbps), which are standard in many networks as of 2025.\n- The maximum segment length (100 meters for UTP, 2 km for fiber) can be a constraint for very large networks, though this is less of an issue with fiber upgrades.\n- It requires compatible network interface cards (NICs), switches, and cabling to achieve full performance, which can pose challenges in mixed-speed environments.\n\n---\n### Fast Ethernet Implementation\n\n![[Pasted image 20250223022523.png]]\n\n### Key Components of the Diagram\nEach section of the diagram represents one Fast Ethernet standard, showing how 100 Mbps data is encoded at the transmitting station, transmitted over the physical medium, and decoded at the receiving station. The standards are:\n\n#### 1. **100Base-TX**\n   - **Physical Medium**: Two pairs of Category 5 UTP (unshielded twisted pair) cables.\n   - **Encoding Process**:\n     - **Input**: 100 Mbps data is divided into four streams of 25 Mbps each (4 × 25 Mbps).\n     - **4B/5B Encoder**: The 25 Mbps data streams are first passed through a 4B/5B encoder. This encoding scheme maps every 4 bits of data into 5 bits, increasing the signal rate to 125 Mbps (4 × 25 Mbps × 5/4 = 125 Mbps). This adds extra bits to ensure sufficient transitions for clock recovery and to maintain signal integrity, reducing the likelihood of long sequences of 0s or 1s.\n     - **MLT-3 Encoder**: The 125 Mbps output from the 4B/5B encoder is then processed by an MLT-3 (Multi-Level Transmit-3) encoder. MLT-3 is a line coding technique that uses three voltage levels (+1, 0, -1) to represent data, reducing electromagnetic interference and allowing the signal to travel efficiently over UTP cables. It converts the digital signal into a form suitable for transmission over the twisted pair medium.\n     - **Transmission Medium**: The encoded signal is sent over two UTP Category 5 cables to the receiving station.\n     - **MLT-3 Decoder**: At the receiving end, an MLT-3 decoder converts the MLT-3 signal back into a 125 Mbps digital signal.\n     - **4B/5B Decoder**: The 4B/5B decoder then reverses the 4B/5B encoding, recovering the original 100 Mbps data (25 Mbps × 4 streams) for use by the receiving station.\n   - **Purpose**: 100Base-TX is the most common Fast Ethernet standard, leveraging affordable and widely available Cat5 UTP cabling, typically in a star topology with switches or hubs.\n\n#### 2. **100Base-FX**\n   - **Physical Medium**: Two strands of multimode fiber-optic cables.\n   - **Encoding Process**:\n     - **Input**: Similar to 100Base-TX, 100 Mbps data is divided into four streams of 25 Mbps each (4 × 25 Mbps).\n     - **4B/5B Encoder**: The 25 Mbps data streams are encoded using a 4B/5B encoder, increasing the signal rate to 125 Mbps, as described for 100Base-TX.\n     - **NRZ-I Encoder**: The 125 Mbps output is then processed by an NRZ-I (Non-Return to Zero Inverted) encoder. NRZ-I is a line coding technique where a binary \"1\" is represented by a change in signal level, and a \"0\" is represented by no change. This method is well-suited for fiber-optic transmission, which uses light pulses to represent data (e.g., light on for \"1,\" light off for \"0\" or vice versa).\n     - **Transmission Medium**: The encoded signal is transmitted over two fiber-optic cables to the receiving station.\n     - **NRZ-I Decoder**: At the receiving end, an NRZ-I decoder converts the NRZ-I signal back into a 125 Mbps digital signal.\n     - **4B/5B Decoder**: The 4B/5B decoder then recovers the original 100 Mbps data (25 Mbps × 4 streams) for the receiving station.\n   - **Purpose**: 100Base-FX is used for longer distances (up to 2 km) and in environments requiring high reliability or immunity to electromagnetic interference, such as campus or backbone networks.\n\n#### 3. **100Base-T4**\n   - **Physical Medium**: Four pairs of Category 3 UTP cables (or better, like Cat5).\n   - **Encoding Process**:\n     - **Input**: 100 Mbps data is processed as a single stream.\n     - **8B/6T Encoder**: The 100 Mbps data is encoded using an 8B/6T encoding scheme. This maps every 8 bits of data into 6 ternary symbols (using three levels: +1, 0, -1), allowing the data to be transmitted over four pairs of UTP cables. The 8B/6T encoding reduces the signal rate per pair, making it possible to use lower-quality Cat3 cables, which were common in older installations.\n     - **Transmission Medium**: The encoded signal is sent over four UTP Category 3 cables to the receiving station.\n     - **8B/6T Decoder**: At the receiving end, an 8B/6T decoder reverses the encoding, recovering the original 100 Mbps data for the receiving station.\n   - **Purpose**: 100Base-T4 was designed to support older Cat3 wiring infrastructure, but it is less common today due to its complexity and the prevalence of Cat5 wiring for 100Base-TX. It’s rarely used in modern networks as of 2025.\n\n\n![[Pasted image 20250223022650.png]]\n\n## **Gigabit Ethernet Implementations**\n\n![[Pasted image 20250223022921.png]]\n#### **1000Base-SX**\n   - **Medium**: Two-wire short-wave fiber (multimode fiber-optic cable).\n   - **Description**:\n     - \"1000\" indicates a data rate of 1 Gbps.\n     - \"Base\" refers to baseband transmission (using the entire bandwidth for a single signal).\n     - \"SX\" stands for short-wavelength, typically using 850 nm lasers or LEDs over multimode fiber.\n     - Maximum segment length is typically up to 550 meters, depending on the fiber quality (e.g., 62.5/125 μm or 50/125 μm multimode fiber).\n     - This is commonly used for short-distance connections within buildings or data centers due to its cost-effectiveness and compatibility with multimode fiber infrastructure.\n\n#### **1000Base-LX**\n   - **Medium**: Two-wire long-wave fiber (single-mode or multimode fiber-optic cable).\n   - **Description**:\n     - \"LX\" stands for long-wavelength, typically using 1310 nm lasers over single-mode or multimode fiber.\n     - Supports longer distances than 1000Base-SX, up to 5 kilometers on single-mode fiber or 550 meters on multimode fiber.\n     - Ideal for campus or metropolitan area networks where longer distances are required, offering higher reliability and lower signal attenuation over fiber.\n\n#### **1000Base-CX**\n   - **Medium**: Two-wire copper (shielded twisted pair, STP).\n   - **Description**:\n     - Uses short-haul copper cabling, specifically shielded twisted pair (STP), often with IBM’s Type 1 cabling or similar.\n     - Maximum segment length is limited to 25 meters, making it suitable for very short connections, such as within server racks or between nearby equipment.\n     - This standard is less common today due to its short range and the prevalence of UTP solutions, but it was used in early Gigabit Ethernet deployments.\n\n#### **1000Base-T**\n   - **Medium**: Four-wire UTP (unshielded twisted pair).\n   - **Description**:\n     - Uses four pairs of Category 5e or better UTP cables, operating in a star topology with switches.\n     - Supports a maximum segment length of 100 meters, making it widely used in office and enterprise networks.\n     - This is the most common Gigabit Ethernet standard as of 2025, leveraging existing twisted pair infrastructure and providing a cost-effective solution for high-speed LANs.\n\n---\n\n### **Encoding in Gigabit Ethernet Implementations**\n![[Pasted image 20250223022940.png]]\n#### 1. **1000Base-SX, 1000Base-LX, and 1000Base-CX (Left Side)**\n   - **Physical Medium**: Two fibers (for SX and LX) or two STPs (for CX).\n   - **Encoding Process**:\n     - **Input**: 1 Gbps data is divided into eight streams of 125 Mbps each (8 × 125 Mbps = 1 Gbps).\n     - **8B/10B Block Encoder**: The 125 Mbps streams are encoded using an 8B/10B block encoding scheme. This maps every 8 bits of data into 10 bits, increasing the signal rate to 1.25 Gbps (8 × 125 Mbps × 10/8 = 1.25 Gbps). The extra bits ensure sufficient transitions for clock recovery, maintain DC balance, and prevent long sequences of 0s or 1s, which could cause synchronization issues.\n     - **NRZ Line Encoder**: The 1.25 Gbps output from the 8B/10B encoder is processed by a Non-Return to Zero (NRZ) line encoder. NRZ is a simple line coding technique where a \"1\" is represented by a high voltage and a \"0\" by a low voltage (or vice versa), with no return to zero between bits. This is suitable for fiber-optic and STP media, which can handle high-speed digital signals.\n     - **Transmission Medium**: The encoded signal is transmitted over two fibers (for SX and LX) or two STPs (for CX) to the receiving station.\n     - **NRZ Line Decoder**: At the receiving end, an NRZ line decoder converts the NRZ signal back into a 1.25 Gbps digital signal.\n     - **8B/10B Block Decoder**: The 8B/10B block decoder reverses the encoding, recovering the original 1 Gbps data (125 Mbps × 8 streams) for the receiving station.\n   - **Purpose**: This encoding scheme ensures reliable 1 Gbps transmission over fiber-optic cables (SX, LX) or STP (CX), leveraging the high bandwidth and low attenuation of these media for short to long distances.\n\n#### 2. **1000Base-T (Right Side)**\n   - **Physical Medium**: Four UTP (unshielded twisted pair) cables, typically Category 5e or better.\n   - **Encoding Process**:\n     - **Input**: 1 Gbps data is divided into eight streams of 125 Mbps each (8 × 125 Mbps = 1 Gbps).\n     - **4D-PAM5 Encoder**: The 125 Mbps streams are encoded using a 4D-PAM5 (Four-Dimensional Pulse Amplitude Modulation with 5 levels) encoding scheme. PAM5 uses five voltage levels (-2, -1, 0, +1, +2) to represent data, allowing multiple bits to be transmitted per symbol. This enables 1 Gbps data to be sent over four UTP pairs, with each pair carrying 250 Mbps (using advanced signal processing to combine multiple streams).\n     - **Transmission Medium**: The encoded signal is transmitted over four UTP cables to the receiving station, using all four pairs simultaneously for both sending and receiving (full-duplex operation).\n     - **4D-PAM5 Decoder**: At the receiving end, a 4D-PAM5 decoder reverses the encoding, recovering the original 1 Gbps data (125 Mbps × 8 streams) for the receiving station.\n   - **Purpose**: 1000Base-T is designed to use existing UTP infrastructure (Cat5e or better) in a star topology, making it the most widely used Gigabit Ethernet standard for office and enterprise networks as of 2025. The 4D-PAM5 encoding allows high-speed transmission over copper wires while managing crosstalk and signal attenuation.\n\n![[Pasted image 20250223023016.png]]\n\n![[Pasted image 20250223023029.png]]\n"
  },
  {
    "url": "University/Computer_Networks/Module_1/Wireless_LAN.html",
    "content": "---\nid: Wireless LAN\naliases: []\ntags: []\ntitle: Wireless LAN\n---\n\n# **IEEE 802.11 Overview**\nIEEE 802.11 defines the specifications for a wireless LAN, covering both physical and data link layers.\n\n---\n\n### **Architecture**\nWireless networks can be categorized into two main types:\n- **Basic Service Set (BSS)**\n- **Extended Service Set (ESS)**\n\n---\n\n### **Basic Service Set (BSS)**\nBSS is the fundamental building block of a WLAN. There are two types:\n- **Independent BSS (IBSS) / Ad-hoc network**  \n  - This consists of wireless stations (devices) communicating directly with each other **without** an access point (AP).\n  - It is a peer-to-peer setup.\n  - Used in temporary or small-scale networks where infrastructure is not needed.\n\n- **Infrastructure BSS**  \n  - This consists of wireless stations communicating through a **central access point (AP)**.\n  - The AP manages the network, allowing communication between devices and providing internet access.\n  - It is commonly used in homes, offices, and businesses.\n\n![[Pasted image 20250223181108.png]]\n\n---\n### **Extended Service Set (ESS)**\n- An **ESS** consists of **multiple BSSs connected together** using a **distribution system (DS)**.\n- The **distribution system** is usually a wired LAN (such as Ethernet) that links multiple APs.\n- This allows devices to roam between different BSSs while remaining connected to the network.\n\n![[Pasted image 20250223181139.png]]\n\n---\n\n### **5. Station Types**\nIEEE 802.11 classifies stations based on their mobility:\n1. **No-transition stations** – Remain within a single BSS.\n2. **BSS-transition stations** – Move between BSSs within an ESS.\n3. **ESS-transition stations** – Move between different ESSs.\n---\n![[Pasted image 20250223181637.png]]\n### **Overall Layer Structure**\n   - The diagram shows the relationship between the **Data Link Layer** and the **Physical Layer** in the IEEE 802.11 standard, which follows the OSI model.\n   - The Data Link Layer is divided into two sublayers:\n     - **LLC Sublayer (Logical Link Control)**: This is the upper sublayer, shown in yellow, and it interfaces with higher layers (like the network layer) to provide a common interface for different types of physical layers.\n     - **MAC Sublayer (Medium Access Control)**: This is the lower sublayer of the Data Link Layer, shown in blue and pink, and it handles access to the physical medium (e.g., radio frequencies for Wi-Fi).\n\n   - Below the MAC sublayer is the **Physical Layer**, which includes various technologies for transmitting data over the air or through infrared.\n\n### **MAC Sublayer Components**\n   The MAC sublayer is split into two key functions for managing access to the wireless medium:\n   - **Distributed Coordination Function (DCF)** (shown in pink): \n     - This is the default access method in IEEE 802.11, based on a contention-based protocol called CSMA/CA (Carrier Sense Multiple Access with Collision Avoidance).\n     - Devices listen to the medium before transmitting to avoid collisions. If the medium is busy, they wait and use a random backoff timer to reduce the likelihood of collisions.\n     - DCF is used for contention service, meaning multiple devices compete for access to the medium.\n   - **Point Coordination Function (PCF)** (shown in blue):\n     - This is an optional, contention-free access method that provides prioritized, controlled access to the medium.\n     - PCF is managed by a point coordinator (typically an access point) that polls stations to give them access to the medium in an orderly fashion, ensuring no collisions occur.\n     - It’s used for time-sensitive applications but is less common in modern Wi-Fi networks.\n\n   The diagram shows that PCF operates above DCF, indicating that PCF can coexist with DCF in a network, but DCF is always active as the base mechanism.\n\n### **Contention-Free vs. Contention Service**\n   - The pink arrow labeled “Contention service” points to DCF, indicating that this function allows devices to contend for the medium, which might lead to delays or collisions but is flexible for general use.\n   - The magenta arrow labeled “Contention-free service” points to PCF, showing that this function provides a collision-free, controlled access method, ideal for real-time applications like voice or video.\n\n### **Physical Layer**\n   - The Physical Layer, shown at the bottom, includes various standards and technologies for transmitting data wirelessly:\n     - **802.11 FHSS**: Frequency-Hopping Spread Spectrum, an early method using different frequencies to reduce interference.\n     - **802.11 DSSS**: Direct-Sequence Spread Spectrum, another early method that spreads data over a wider frequency band for reliability.\n     - **802.11 Infrared**: Uses infrared light for short-range communication (less common today).\n     - **802.11a DSSS and OFDM**: Uses Direct-Sequence Spread Spectrum and Orthogonal Frequency Division Multiplexing for higher data rates.\n     - **802.11g DSSS**: Combines DSSS with other techniques for improved performance in the 2.4 GHz band.\n\n   These physical layer standards define how data is transmitted over the air, while the MAC layer ensures proper access and coordination.\n\n### **IEEE 802.1**\n   - The yellow box at the top represents the IEEE 802.1 standard, which deals with higher-layer LAN/MAN (Local Area Network/Metropolitan Area Network) management and bridging. It interfaces with the LLC sublayer.\n\n---\n\n## **CSMA/CA flowchart**\n![[Pasted image 20250223181906.png]]\n\n### 1. **Start**\n   - The process begins at the “Start” oval, indicating the initiation of a device attempting to transmit data over the wireless network.\n\n### 2. **Set Back-off to Zero**\n   - The device resets its back-off timer to zero. The back-off timer is used to manage delays before attempting to transmit, helping to reduce the chance of collisions in a busy network.\n\n### 3. **Persistence Strategy**\n   - The device applies a persistence strategy, which determines how it senses the medium. In CSMA/CA, the device listens to the wireless medium to check if it’s idle or busy (carrier sensing).\n\n### 4. **Wait DIFS**\n   - DIFS stands for Distributed Interframe Space, a specific time interval that the device must wait before attempting to transmit. This ensures that the medium has been idle long enough to proceed, giving priority to other types of traffic (like acknowledgments or control frames) that use shorter interframe spaces.\n\n### 5. **Send RTS**\n   - If the medium is idle after DIFS, the device sends a Request to Send (RTS) frame. The RTS frame is part of the optional RTS/CTS (Clear to Send) mechanism, which helps avoid collisions in hidden node scenarios (where some devices can’t hear each other).\n\n### 6. **Set a Timer**\n   - After sending RTS, the device sets a timer to wait for a response (CTS) from the receiver (e.g., an access point or another device).\n\n### 7. **CTS Received Before Time-out?**\n   - The device checks if it receives a Clear to Send (CTS) frame from the receiver within the allotted time.\n     - **Yes**: If CTS is received, the process continues.\n     - **No**: If no CTS is received before the timer expires (indicating a potential collision or interference), the device moves to handle the failure.\n\n### 8. **Wait SIFS**\n   - SIFS stands for Short Interframe Space, a shorter time interval than DIFS. The device waits this brief period after receiving CTS to ensure the medium remains clear before sending the actual data frame.\n\n### 9. **Send the Frame**\n   - The device sends its data frame (the actual information it wants to transmit) over the wireless medium.\n\n### 10. **Set a Timer**\n   - Another timer is set to wait for an acknowledgment (ACK) from the receiver, confirming that the frame was successfully received.\n\n### 11. **ACK Received Before Time-out?**\n   - The device checks if it receives an Acknowledgment (ACK) frame from the receiver within the allotted time.\n     - **Yes**: If ACK is received, the transmission is successful, and the process ends with “Success.”\n     - **No**: If no ACK is received before the timer expires (indicating a possible failure or collision), the device handles the error.\n\n### 12. **Back-off Limit?**\n   - If there’s a failure (no CTS or no ACK), the device checks if it has reached the maximum number of back-off attempts (a limit to prevent endless retries).\n     - **Yes**: If the back-off limit is reached, the process aborts, and the transmission attempt fails.\n     - **No**: If the limit hasn’t been reached, the device increments the back-off time (making it wait longer before retrying) and returns to the “Wait back-off time” step.\n\n### 13. **Wait Back-off Time**\n   - The device waits for a random back-off period (determined by the incremented back-off time) before attempting to retransmit. This random delay helps reduce the likelihood of repeated collisions with other devices also trying to transmit.\n\n### 14. **Increment Back-off**\n   - If the back-off limit hasn’t been reached, the device increases the back-off time (e.g., by doubling it or using an exponential back-off algorithm) to further reduce the chance of collisions on the next attempt.\n\n### 15. **Abort or Success**\n   - If the back-off limit is exceeded, the process ends with “Abort,” meaning the transmission attempt is abandoned.\n   - If an ACK is received, the process ends with “Success,” indicating the data was successfully transmitted and acknowledged.\n\n## **CSMA/CA and NAV**\n![[Pasted image 20250223182415.png]]\n### 1. **Key Components**\n   - **Source**: The device initiating the data transmission (e.g., a laptop or smartphone).\n   - **Destination**: The device receiving the data (e.g., a Wi-Fi access point or another device).\n   - **All Other Stations**: Other devices in the network that are not directly involved in this transmission but are listening to the medium.\n   - **Time**: The vertical axis represents the progression of time, with events occurring sequentially from top to bottom.\n\n### 2. **Sequence of Events (Source and Destination)**\n   The left and center parts of the diagram show the interaction between the source and destination, with specific timing intervals (DIFS and SIFS) and frames (RTS, CTS, Data, ACK):\n\n   - **DIFS (Distributed Interframe Space)**:\n     - Before transmitting, the source waits for a DIFS period to ensure the wireless medium is idle. DIFS is a longer interframe space that gives priority to control frames and ensures the medium is clear.\n\n   - **RTS (Request to Send)**:\n     - The source sends an RTS frame to the destination. This frame signals the source’s intent to transmit data and reserves the medium, helping to avoid collisions, especially in scenarios with hidden nodes (devices that can’t hear each other).\n\n   - **SIFS (Short Interframe Space)**:\n     - After receiving RTS, the destination waits a shorter SIFS period before responding. SIFS is used for high-priority, time-sensitive responses like CTS, ensuring quick acknowledgment without interference.\n\n   - **CTS (Clear to Send)**:\n     - The destination responds with a CTS frame, indicating it is ready to receive data. The CTS frame also helps reserve the medium and informs other nearby devices (including hidden nodes) to back off.\n\n   - **Data**:\n     - After receiving CTS, the source sends the actual data frame to the destination, again separated by an SIFS interval to maintain priority and minimize delays.\n\n   - **ACK (Acknowledgment)**:\n     - The destination, after receiving the data, waits another SIFS period and sends an ACK frame back to the source, confirming successful reception of the data.\n\n   - **DIFS Again**:\n     - After the ACK, the medium is free again, and the source (or any other device) must wait DIFS before attempting another transmission.\n\n### 3. **Network Allocation Vector (NAV) and Other Stations**\n   - The right part of the diagram shows how “All other stations” (other devices in the network) behave during this transmission.\n   - When other stations hear the RTS or CTS frames, they set their Network Allocation Vector (NAV), represented by the yellow box labeled “NAV (No carrier sensing).”\n   - The NAV is a virtual timer that indicates the medium is busy for a specific duration, preventing these stations from transmitting during that time. This helps avoid collisions by ensuring other devices remain silent while the source and destination complete their communication.\n   - The NAV is set based on the duration field in the RTS and CTS frames, which specifies how long the medium will be occupied (including time for data and ACK transmission).\n\n### 4. **Purpose of CSMA/CA and NAV**\n   - **CSMA/CA**: This protocol minimizes collisions in wireless networks by having devices sense the medium (carrier sensing) and use random back-offs (as seen in the previous flowchart). The RTS/CTS mechanism adds an extra layer of collision avoidance, particularly for hidden node problems, where two devices might not hear each other but could interfere with a common destination.\n   - **NAV**: The Network Allocation Vector ensures that all stations in the network respect the reservation of the medium, even if they can’t directly sense the carrier (e.g., due to distance or interference). This improves efficiency and reduces the likelihood of collisions in a busy Wi-Fi network.\n\n\n## **Repetition Interval**\n![[Pasted image 20250223182529.png]]\n### 1. **Key Components**\n   - **AP (Access Point)**: The central device managing the wireless network, responsible for coordinating access to the medium in PCF mode.\n   - **Polled Station**: A specific station (e.g., a device like a laptop) that the AP polls to allow it to transmit data.\n   - **Others**: Other stations in the network that are not currently polled but are part of the network.\n   - **Time**: The horizontal axis represents the progression of time, with events occurring from left to right.\n   - **Repetition Interval**: The overall time period during which the contention-free period (CFP) occurs, followed by a contention period (CP).\n\n### 2. **Sequence of Events in the Repetition Interval**\n   The diagram shows a structured sequence of frames and timing intervals within the repetition interval, which alternates between contention-free and contention periods:\n\n   - **Beacon Frame (B)**:\n     - The repetition interval begins with the AP broadcasting a Beacon frame (shown in pink). Beacons are periodic management frames that synchronize the network, announce the network’s presence, and indicate the start of the contention-free period (CFP).\n     - The Beacon is sent after a PIFS (PCF Interframe Space), which is shorter than DIFS and gives the AP priority to access the medium.\n\n   - **Poll**:\n     - After the Beacon, the AP sends a Poll frame (also in pink) to a specific polled station, granting it permission to transmit data. This is part of the contention-free service, where the AP controls access to avoid collisions.\n     - The Poll is separated from the Beacon by an SIFS (Short Interframe Space), ensuring quick and prioritized communication.\n\n   - **ACK + Data**:\n     - The polled station responds with an acknowledgment (ACK) and its data frame (shown in blue), also separated by an SIFS. This ensures the AP knows the data was received, and the data transmission happens without contention.\n     - The ACK and data are combined into one frame for efficiency in this context.\n\n   - **ACK + CF-Poll (Contention-Free Poll)**:\n     - The AP acknowledges the data with an ACK and sends another CF-Poll (Contention-Free Poll) frame (in pink) to either the same station or another station, allowing further contention-free transmission.\n     - This process can repeat, with dots (“...”) indicating potential additional polls until the end of the contention-free period.\n     - The contention-free period ends with a CF-End frame, signaling that the medium is now available for contention-based access.\n\n   - **Contention Period (CP)**:\n     - After the contention-free period, the network switches to the contention period, where devices use CSMA/CA (as shown in previous diagrams) to compete for medium access, potentially leading to collisions but allowing flexibility for all devices.\n\n### 3. **Network Allocation Vector (NAV)**\n   - The yellow box labeled “NAV” at the bottom represents the Network Allocation Vector for other stations (those not polled).\n   - During the contention-free period, other stations set their NAV based on the Beacon or Poll frames, indicating that the medium is busy. This prevents them from transmitting, ensuring the AP and polled stations can communicate without interference.\n   - The NAV lasts throughout the contention-free period, after which other stations can attempt to transmit during the contention period using CSMA/CA.\n\n### 4. **Timing Intervals**\n   - **PIFS (PCF Interframe Space)**: Used by the AP to gain priority access to the medium before sending the Beacon, shorter than DIFS to ensure contention-free operation.\n   - **SIFS (Short Interframe Space)**: Used between frames (e.g., Beacon to Poll, Poll to ACK+Data, etc.) to maintain high-priority, collision-free communication within the CFP.\n\n### 5. **Purpose of PCF and This Diagram**\n   - **PCF**: Unlike DCF, which relies on contention and can lead to collisions, PCF provides a controlled, contention-free access method ideal for time-sensitive applications like voice or video. The AP acts as a coordinator, polling stations to ensure orderly and predictable access to the medium.\n   - **Repetition Interval**: This diagram shows how the network alternates between contention-free and contention periods within a repetitive cycle, balancing efficiency for prioritized traffic with flexibility for general use.\n\n## **Frame Format*\n![[Pasted image 20250223182741.png]]\n### 1. **Overall Frame Structure**\n   - The frame consists of several fields, each with a specific size in bytes, totaling the frame length (excluding any preamble or physical layer headers).\n   - The fields are:\n     - **FC (Frame Control)**: 2 bytes\n     - **D (Duration)**: 2 bytes\n     - **Address 1**: 6 bytes\n     - **Address 2**: 6 bytes\n     - **Address 3**: 6 bytes\n     - **SC (Sequence Control)**: 2 bytes\n     - **Address 4**: 6 bytes (optional, used in specific scenarios like wireless bridging)\n     - **Frame Body**: 0 to 2312 bytes (contains the actual data or management/control information)\n     - **FCS (Frame Check Sequence)**: 4 bytes\n\n   - The frame is divided into a header (FC through Address 4) and a payload (Frame Body), with FCS at the end for error detection.\n\n### 2. **Detailed Breakdown of Fields**\n\n#### **Frame Control (FC) - 2 bytes**\n   - This field, shown in pink, contains critical control information about the frame. It’s further broken down into:\n     - **Protocol Version**: 2 bits – Indicates the version of the 802.11 protocol (typically 0 for current standards).\n     - **Type**: 2 bits – Specifies the type of frame (e.g., Management, Control, or Data).\n     - **Subtype**: 4 bits – Provides more specific information about the frame type (e.g., Beacon, RTS, CTS, Data, ACK, etc.).\n     - **To DS**: 1 bit – Indicates if the frame is destined for the Distribution System (e.g., an access point or wired network).\n     - **From DS**: 1 bit – Indicates if the frame is coming from the Distribution System.\n     - **More Frag**: 1 bit – Indicates if more fragments of the frame follow (used for fragmented data).\n     - **Retry**: 1 bit – Indicates if this is a retransmitted frame.\n     - **Pwr Mgt**: 1 bit – Indicates the power management state of the sending station (e.g., active or power-saving mode).\n     - **More Data**: 1 bit – Indicates if more data frames are buffered for the receiving station.\n     - **WEP**: 1 bit – Indicates if Wired Equivalent Privacy (WEP) encryption is used (an older security mechanism, now largely deprecated).\n     - **Rsvd**: 1 bit – Reserved for future use.\n\n   - The FC field is crucial for interpreting the frame’s purpose and handling it appropriately in the network.\n\n#### **Duration (D) - 2 bytes**\n   - Shown in yellow, this field specifies the duration (in microseconds) for which the medium will be busy. It’s used to set the Network Allocation Vector (NAV) for other stations, preventing them from transmitting and causing collisions. This is particularly important in CSMA/CA for managing medium access.\n\n#### **Address Fields - 6 bytes each**\n   - There are up to four address fields (Address 1, 2, 3, and 4), shown in pink and light blue, depending on the frame type and network configuration:\n     - **Address 1**: Typically the receiver’s MAC address (e.g., the destination).\n     - **Address 2**: Typically the transmitter’s MAC address (e.g., the source).\n     - **Address 3**: Used for additional addressing, such as the final destination or source in infrastructure networks (e.g., the access point or another network segment).\n     - **Address 4**: Optional, used in rare cases like wireless bridging between two access points.\n   - These addresses are 48-bit MAC addresses, uniquely identifying devices on the network.\n\n#### **Sequence Control (SC) - 2 bytes**\n   - Shown in light blue, this field manages frame ordering and prevents duplicate frames. It includes a sequence number and fragment number to track fragmented or reordered frames.\n\n#### **Frame Body - 0 to 2312 bytes**\n   - This variable-length field, shown in white, contains the payload of the frame. It can include:\n     - Data for upper-layer protocols (e.g., IP packets).\n     - Management information (e.g., Beacon frames, association requests).\n     - Control information (e.g., RTS, CTS, ACK).\n   - The size can vary depending on the type of frame and the amount of data being transmitted.\n\n#### **Frame Check Sequence (FCS) - 4 bytes**\n   - Shown in green, this field contains a cyclic redundancy check (CRC) value to detect errors in the frame. The receiver calculates the CRC and compares it with the FCS to ensure the frame was received correctly. If there’s a mismatch, the frame is discarded.\n\n### 3. **Purpose of the Frame Format**\n   - The IEEE 802.11 frame format ensures reliable and structured communication in Wi-Fi networks. It supports various frame types (management, control, data) and handles addressing, error detection, and medium access control.\n   - The format is flexible, allowing for different configurations (e.g., varying numbers of addresses or frame body sizes) depending on the network setup (e.g., ad-hoc vs. infrastructure mode) and the specific frame’s purpose.\n\n## **Subfields in FC Field**\n![[Pasted image 20250223183031.png]]\n\n## **Control Frames**\n![[Pasted image 20250223183226.png]]\n### 1. **Overall Structure of Control Frames**\n   - Control frames are a category of IEEE 802.11 frames used for coordinating access to the wireless medium and confirming successful transmissions. They are shorter than data or management frames and have no frame body, as they carry minimal control information.\n   - The structure includes the following fields, which are consistent with the general frame format you saw in Figure 14.7, but with specific adaptations for control frames:\n     - **FC (Frame Control)**: 2 bytes – Specifies the frame type and subtype (e.g., RTS, CTS, or ACK).\n     - **D (Duration)**: 2 bytes – Indicates how long the medium will be busy, used to set the Network Allocation Vector (NAV) for other stations.\n     - **Address 1 and Address 2**: 6 bytes each – Identify the sender and receiver of the frame.\n     - **FCS (Frame Check Sequence)**: 4 bytes – Ensures error detection by verifying the integrity of the frame.\n\n   - Unlike the general frame format, control frames do not include Address 3, Address 4, Sequence Control, or a Frame Body, as they are lightweight and focused on coordination rather than carrying data.\n\n### 2. **RTS Frame Format**\n   - **Size**: 20 bytes total.\n   - **Fields**:\n     - **FC (Frame Control)**: 2 bytes (pink) – Indicates this is an RTS frame (a control subtype).\n     - **D (Duration)**: 2 bytes (yellow) – Specifies the duration the medium will be reserved, including time for CTS, data, and ACK frames, to prevent other stations from transmitting.\n     - **Address 1**: 6 bytes (pink) – The MAC address of the intended recipient (e.g., the destination device or access point).\n     - **Address 2**: 6 bytes (pink) – The MAC address of the sender (e.g., the source device initiating the transmission).\n     - **FCS (Frame Check Sequence)**: 4 bytes (green) – A CRC value to detect errors in the frame.\n\n   - **Purpose**: The RTS frame is sent by a device to request permission to transmit data, helping avoid collisions, especially in hidden node scenarios. It’s part of the optional RTS/CTS mechanism in CSMA/CA, as shown in earlier diagrams (e.g., Figure 14.5).\n\n### 3. **CTS or ACK Frame Format**\n   - **Size**: 14 bytes total.\n   - **Fields**:\n     - **FC (Frame Control)**: 2 bytes (pink) – Indicates whether this is a CTS or ACK frame (a control subtype).\n     - **D (Duration)**: 2 bytes (yellow) – Specifies the remaining duration the medium will be busy (e.g., for data and ACK in the case of CTS, or just ending the reservation for ACK).\n     - **Address 1**: 6 bytes (pink) – The MAC address of the recipient (e.g., the sender of the RTS for CTS, or the sender of the data for ACK).\n     - **FCS (Frame Check Sequence)**: 4 bytes (green) – A CRC value for error detection.\n\n   - **Purpose**:\n     - **CTS (Clear to Send)**: Sent by the destination in response to an RTS, indicating it’s ready to receive data and reserving the medium for the upcoming transmission.\n     - **ACK (Acknowledgment)**: Sent by the destination after receiving data, confirming successful reception and ending the medium reservation.\n\n   - The diagram notes “CTS or ACK” because both use the same frame format, differing only in the Frame Control field’s subtype. They both serve to manage medium access and ensure reliable communication but have different roles in the transmission process.\n\n### 4. **Key Differences from General Frame Format**\n   - Control frames are simpler than management or data frames, omitting fields like Address 3, Address 4, Sequence Control, and Frame Body.\n   - They prioritize speed and efficiency for medium access control, as they are used for short, critical interactions like reserving the medium or acknowledging transmissions.\n\n### 5. **Role in Wi-Fi Communication**\n   - These control frames are integral to the CSMA/CA protocol (Distributed Coordination Function, DCF) and can also support the Point Coordination Function (PCF) in contention-free scenarios.\n   - **RTS/CTS**: Helps prevent collisions in busy networks or with hidden nodes by reserving the medium before data transmission.\n   - **ACK**: Ensures reliability by confirming that data frames were received correctly, triggering retransmissions if needed.\n\n![[Pasted image 20250223183256.png]]\n\n![[Pasted image 20250223183306.png]]\n\n## **Addressing Mechanisms**\n![[Pasted image 20250223183431.png]]\n### 1. **Key Concepts**\n   - **BSS (Basic Service Set)**: A group of devices communicating via a single access point or in an ad-hoc network. Each BSS is identified by a BSS-ID (similar to a MAC address of the AP or a unique identifier in ad-hoc mode).\n   - **AP (Access Point)**: A device that connects wireless devices to a wired network (Distribution System) or another BSS.\n   - **Distribution System (DS)**: A system (typically wired, like Ethernet) that connects multiple BSSs or APs, allowing communication between them.\n   - **Wireless Distribution System (WDS)**: An extension of the DS using wireless links between APs, instead of wired connections.\n   - **Addresses**: Wi-Fi frames can include up to four address fields (Address 1, 2, 3, and 4) to specify the source, destination, and intermediate points in the network, depending on the frame type and network topology.\n\n### 2. **Case-by-Case Explanation**\n\n#### **a. Case 1: Ad-Hoc Mode (Independent BSS)**\n   - **Setup**: No access point or distribution system—devices communicate directly in an ad-hoc network (IBSS, Independent Basic Service Set).\n   - **Devices**: Two stations, B and A, within the same BSS, identified by the BSS-ID.\n   - **Addressing**:\n     - **Address 1**: Destination (e.g., A, the receiver).\n     - **Address 2**: Source (e.g., B, the sender).\n     - **Address 3**: BSS-ID (identifies the network for routing within the BSS).\n     - **Address 4**: Not used (empty) since there’s no DS or AP involved.\n   - **Flow**: B sends a frame to A directly, using the BSS-ID to ensure they’re in the same network. This is a simple peer-to-peer communication without infrastructure.\n\n#### **b. Case 2: Infrastructure Mode with DS (Single AP)**\n   - **Setup**: A single AP connects two stations, B and A, within the same BSS, with the AP linked to a Distribution System (e.g., a wired network).\n   - **Devices**: B (station), A (station), and AP (access point) within the BSS, with the DS connecting the AP to other networks.\n   - **Addressing**:\n     - **Address 1**: Destination (e.g., A, the receiver, or the AP if B is sending to the DS).\n     - **Address 2**: Source (e.g., B, the sender).\n     - **Address 3**: AP or DS address (e.g., the AP’s MAC address or the final destination in the DS).\n     - **Address 4**: Not used (empty) since there’s only one AP and no need for additional routing.\n   - **Flow**: B sends a frame to A via the AP. The AP acts as an intermediary, forwarding the frame within the BSS or to the DS if needed. The DS might route the frame to another BSS or network.\n\n#### **c. Case 3: Infrastructure Mode with DS (Single AP, Extended)**\n   - **Setup**: Similar to Case 2, but explicitly shows the AP connecting two BSSs via a Distribution System (wired).\n   - **Devices**: B and A in different BSSs, with an AP bridging them through the DS.\n   - **Addressing**:\n     - **Address 1**: Destination (e.g., A, the receiver in the other BSS).\n     - **Address 2**: Source (e.g., B, the sender in its BSS).\n     - **Address 3**: AP or DS address (e.g., the AP’s MAC address or the DS endpoint).\n     - **Address 4**: Not used (empty) since there’s only one AP involved.\n   - **Flow**: B sends a frame to A through the AP and DS. The AP handles the frame within its BSS, and the DS routes it to the destination BSS, ensuring communication across the network.\n\n#### **d. Case 4: Wireless Distribution System (WDS) with Two APs**\n   - **Setup**: Two access points (AP1 and AP2) connect two BSSs wirelessly via a Wireless Distribution System, without a wired DS.\n   - **Devices**: B in AP1’s BSS, A in AP2’s BSS, with AP1 and AP2 communicating wirelessly.\n   - **Addressing**:\n     - **Address 1**: Destination (e.g., A, the receiver in AP2’s BSS).\n     - **Address 2**: Source (e.g., B, the sender in AP1’s BSS).\n     - **Address 3**: AP1 or AP2 address (e.g., AP1’s MAC for forwarding to AP2).\n     - **Address 4**: AP2’s MAC address (used because there are two APs in the wireless link, requiring additional routing information).\n   - **Flow**: B sends a frame to A through AP1, which forwards it wirelessly to AP2 via WDS. AP2 then delivers the frame to A. The use of Address 4 accommodates the two-hop wireless path between APs.\n\n### 3. **Common Elements Across Cases**\n   - **BSS-ID**: Identifies the BSS, ensuring devices are part of the same network.\n   - **Distribution System (DS or WDS)**: Facilitates communication between BSSs, either wired (DS) or wireless (WDS).\n   - **Address Usage**: The number of address fields used depends on the network topology—ad-hoc networks use fewer addresses, while multi-AP or WDS setups may require all four.\n\n### 4. **Purpose of Addressing Mechanisms**\n   - The addressing in IEEE 802.11 frames allows flexible routing of data within and across BSSs, supporting various network configurations (ad-hoc, infrastructure, or extended networks).\n   - It ensures frames are correctly directed to their destinations, whether within a single BSS, through an AP to a DS, or across multiple APs in a WDS, while minimizing collisions and maintaining network efficiency.\n\n## **Use of Handshaking to prevent hidden station problem**\n\nThe use of handshaking, specifically the RTS/CTS (Request to Send/Clear to Send) mechanism, is a key strategy in the IEEE 802.11 Wi-Fi standard to prevent the hidden station problem. This problem occurs in wireless networks when two or more stations are within range of a common receiver but out of range of each other, potentially causing collisions at the receiver. The RTS/CTS handshake, part of the CSMA/CA (Carrier Sense Multiple Access with Collision Avoidance) protocol, mitigates this issue by reserving the wireless medium and notifying all relevant stations, even those that can’t hear each other. Let’s break it down:\n\n---\n\n### **What is the Hidden Station Problem?**\n- The hidden station problem arises when, for example, Station B and Station C can both communicate with Station A (the receiver) but cannot detect each other’s transmissions because they are out of range or separated by obstacles (e.g., walls).\n- If B and C transmit to A simultaneously, their signals collide at A, corrupting the data, even though B and C don’t realize a collision is occurring because they can’t hear each other.\n- This is a limitation of CSMA/CA’s carrier sensing, as stations rely on listening to the medium before transmitting, but hidden stations won’t detect each other’s activity.\n\n---\n\n### **How Handshaking (RTS/CTS) Prevents the Hidden Station Problem**\nThe RTS/CTS handshake adds an explicit medium reservation step to CSMA/CA, ensuring that all stations near the receiver are aware of an impending transmission, even if they can’t hear the sender. Here’s how it works, as illustrated in Figure 14.11 from your diagrams:\n\n#### **1. RTS (Request to Send)**\n   - A station wanting to transmit (e.g., Station B) first sends an RTS frame to the intended receiver (e.g., Station A).\n   - The RTS frame includes:\n     - The MAC address of the sender (B) and receiver (A).\n     - A Duration field specifying how long the medium will be busy for the upcoming transmission (including time for CTS, data, and ACK frames).\n   - B sends the RTS only after ensuring the medium is idle for a DIFS (Distributed Interframe Space) period, as per CSMA/CA.\n\n#### **2. CTS (Clear to Send)**\n   - If Station A receives the RTS successfully, it responds with a CTS frame after a short SIFS (Short Interframe Space) interval.\n   - The CTS frame includes:\n     - The MAC address of the sender of the RTS (B, now the receiver of the data).\n     - The same Duration value from the RTS, indicating how long the medium will remain busy.\n   - The CTS is broadcast and can be heard by all stations within A’s transmission range, including any hidden stations (e.g., Station C) that couldn’t hear B’s RTS.\n\n#### **3. NAV (Network Allocation Vector)**\n   - Stations that hear the CTS (e.g., C) set their Network Allocation Vector (NAV), a virtual timer that indicates the medium is busy for the specified duration.\n   - This prevents C (and other stations within A’s range) from transmitting during this period, avoiding a collision at A even though C couldn’t hear B’s RTS.\n\n#### **4. Data and ACK**\n   - After receiving CTS, B sends its data frame to A, followed by A sending an ACK (Acknowledgment) frame to confirm successful reception.\n   - The NAV ensures that no other stations interfere during this exchange, protecting the transmission from hidden stations like C.\n\n---\n\n## **Exposed Station Problem?**\nThe exposed station problem occurs in wireless networks when a station (device) unnecessarily delays or defers its transmission because it detects activity on the medium, even though its transmission wouldn’t interfere with the ongoing communication. This leads to reduced network efficiency and throughput, as the station waits when it could safely transmit without causing collisions.\n\n### **Key Characteristics:**\n- **Stations Involved**: Consider three stations: Station B, Station A, and Station D. B and D are within range of A, but B and D are not within range of each other.\n- **Scenario**: If A is transmitting data to B, Station D (within A’s range) senses the medium as busy and defers its transmission. However, D’s transmission to another station (e.g., not shown in the diagram) wouldn’t interfere with A’s communication to B, as D is out of B’s range.\n- **Problem**: D is “exposed” to A’s transmission but unnecessarily restricted from transmitting, wasting potential network capacity and reducing efficiency.\n\n### **Why It Happens:**\n- In CSMA/CA (Carrier Sense Multiple Access with Collision Avoidance), stations listen to the medium before transmitting. If D hears A’s transmission to B, it assumes the medium is busy and waits, even though D’s transmission wouldn’t cause a collision at B (or any other relevant receiver).\n- This conservative approach to carrier sensing can lead to inefficiency, as D delays its transmission unnecessarily, even when it could communicate with another station without interference.\n\n---\n### **Use of Handshaking (RTS/CTS) in the Exposed Station Problem**\nUnlike the hidden station problem, the RTS/CTS (Request to Send/Clear to Send) handshake does not directly solve or mitigate the exposed station problem. In fact, it can sometimes exacerbate it. Here’s why and how it works in this context:\n\n#### **How RTS/CTS Works in General**\n- In CSMA/CA, a station (e.g., A) wanting to transmit to B sends an RTS frame, and B responds with a CTS frame. The Duration field in RTS and CTS sets the NAV (Network Allocation Vector) for other stations, preventing them from transmitting during the reserved time.\n- This handshake is effective for avoiding collisions from hidden stations (as seen in the hidden station problem) by ensuring all stations near the receiver (B) defer transmission.\n\n#### **Impact on Exposed Stations**\n- **No Direct Solution**: The RTS/CTS mechanism doesn’t address the exposed station problem because it reserves the medium for a longer duration, potentially causing more stations (like D) to defer unnecessarily, even if their transmissions wouldn’t interfere.\n- For example, in the scenario where A sends RTS to B and B responds with CTS, Station D (within A’s range) hears the CTS and sets its NAV, deferring its transmission. However, D could safely transmit to another station outside B’s range without causing a collision, but the NAV forces it to wait, worsening the exposed station issue.\n- **Potential Exacerbation**: The additional overhead of RTS/CTS (extra frames and delays) can further reduce efficiency in networks with exposed stations, as it increases the time the medium appears busy, leading to more unnecessary deferrals.\n\n#### **Why RTS/CTS Doesn’t Help**\n- The exposed station problem stems from the conservative nature of carrier sensing in CSMA/CA, where a station defers even when its transmission wouldn’t interfere. RTS/CTS reinforces this conservatism by broadcasting the medium reservation, but it doesn’t distinguish between stations that would cause interference and those that wouldn’t.\n- The handshake assumes all stations within range of the sender (A) or receiver (B) should defer, which is overly restrictive for exposed stations like D.\n\n![[Pasted image 20250223184617.png]]\n\n![[Pasted image 20250223184627.png]]\n\n\n## **IEEE 802.11 FHSS physical layer**\n![[Pasted image 20250223184754.png]]\n\n- **Overview**: Illustrates the Frequency-Hopping Spread Spectrum (FHSS) physical layer in IEEE 802.11, operating in the 2.4 GHz band with data rates of 1 or 2 Mbps.\n- **Digital Data Input**: Accepts 1 or 2 Mbps digital data from the MAC layer for transmission.\n- **Modulator (2-Level or 4-Level FSK)**: Converts digital data into a 1-MHz analog signal using Frequency Shift Keying (FSK):\n  - 2-Level FSK for 1 Mbps (two frequencies for 0 and 1).\n  - 4-Level FSK for 2 Mbps (four frequencies for bit combinations).\n- **Pseudorandom Sequence**: Generates a pseudorandom hopping pattern to switch frequencies, enhancing security and reducing interference.\n- **Frequency Synthesizer**: Uses the pseudorandom sequence to dynamically adjust the carrier frequency, hopping across 1-MHz channels at ~2.5 hops/second.\n- **Analog Signal Output**: Produces a 1-MHz analog signal for wireless transmission, spread across frequencies to resist interference and multipath fading.\n- **Advantages**: Reduces interference, improves robustness, and coexists with other 2.4 GHz devices.\n- **Limitations**: Low data rates (1–2 Mbps), hardware complexity, and obsolescence compared to modern Wi-Fi standards.\n\n## **Physical layer of IEEE 802.11 DSSS**\n![[Pasted image 20250223184812.png]]\n\n- **Overview**: Illustrates the Direct-Sequence Spread Spectrum (DSSS) physical layer in IEEE 802.11, operating in the 2.4 GHz band with data rates of 1 or 2 Mbps.\n- **Digital Data Input**: Accepts 1 or 2 Mbps digital data from the MAC layer for transmission.\n- **11-Chip Barker Sequence**: Spreads the digital data using an 11-chip Barker sequence, increasing the signal bandwidth to 11 Mbps (spreading) while maintaining the original data rate, improving resistance to interference and noise.\n- **Modulator (BPSK or QPSK)**: Converts the spread data into an 11-MHz analog signal using phase modulation:\n  - BPSK (Binary Phase Shift Keying) for 1 Mbps (one bit per symbol).\n  - QPSK (Quadrature Phase Shift Keying) for 2 Mbps (two bits per symbol).\n- **Analog Signal Output**: Produces an 11-MHz analog signal for wireless transmission, spread across a wider frequency band to enhance reliability and reduce interference.\n- **Advantages**: Offers better interference resistance and robustness than FHSS, simpler hardware than frequency hopping, and supports coexistence in the 2.4 GHz band.\n- **Limitations**: Lower data rates (1–2 Mbps) compared to modern Wi-Fi standards, and susceptibility to multipath fading, though less than FHSS. Now outdated but foundational for early 802.11 and 802.11b.\n\n## **Physical layer of IEEE  802.11 infrared\n![[Pasted image 20250223184919.png]]\n\n- **Overview**: Illustrates the infrared physical layer in IEEE 802.11, using infrared light for short-range wireless communication with data rates of 1 or 2 Mbps.\n- **Digital Data Input**: Accepts 1 or 2 Mbps digital data from the MAC layer for transmission.\n- **Encoder (4 to 16 or 2 to 4)**: Encodes the digital data into a format suitable for infrared transmission:\n  - 4 to 16 encoding for 1 Mbps (expanding 4 bits to 16 pulses or symbols).\n  - 2 to 4 encoding for 2 Mbps (expanding 2 bits to 4 pulses or symbols).\n- **Modulator (Pulse Position Modulation)**: Converts the encoded data into an analog infrared signal using pulse position modulation (PPM), where data is represented by the position of pulses in a time frame.\n- **Analog Signal Output**: Produces an analog infrared signal for transmission via infrared LEDs, limited to line-of-sight, short-range communication.\n- **Advantages**: Immune to radio frequency interference, secure due to line-of-sight requirement, and simple for short-range applications.\n- **Limitations**: Limited range (typically a few meters), requires line-of-sight, low data rates (1–2 Mbps), and now obsolete compared to RF-based Wi-Fi standards like DSSS and OFDM.\n\n## **Physical layer for IEEE 802.11b**\n![[Pasted image 20250223185001.png]]\n\n- **Overview**: Illustrates the Direct-Sequence Spread Spectrum (DSSS) physical layer in IEEE 802.11b, operating in the 2.4 GHz band with data rates of 5.5 Mbps or 11 Mbps.\n- **Digital Data Input**: Accepts 5.5 Mbps or 11 Mbps digital data from the MAC layer for transmission.\n- **1:4 or 1:8 Spreading**: Spreads the data using a spreading factor:\n  - 1:4 for 5.5 Mbps (one data bit spread into four chips).\n  - 1:8 for 11 Mbps (one data bit spread into eight chips), increasing bandwidth to 11 Mbps to enhance resistance to interference.\n- **CCK (Complementary Code Keying) Selector**: Encodes the spread data using CCK, producing 5.5 Mbps (2 bits) or 11 Mbps (6 bits) streams, improving efficiency over Barker sequences used in earlier DSSS.\n- **Modulator (QPSK)**: Converts the CCK-encoded data into an 11-MHz analog signal using Quadrature Phase Shift Keying (QPSK), where four phase states represent two bits per symbol.\n- **Analog Signal Output**: Produces an 11-MHz analog signal for wireless transmission, spread across a wider frequency band for robustness and interference resistance.\n- **Advantages**: Higher data rates (up to 11 Mbps) than earlier 802.11 standards, better interference resistance, and compatibility with 802.11 DSSS (1–2 Mbps).\n- **Limitations**: Operates in the crowded 2.4 GHz band, susceptible to interference from other devices (e.g., microwaves, Bluetooth), and now outdated compared to later standards like 802.11a/g/n/ac/ax.\n\n"
  },
  {
    "url": "University/Computer_Networks/Module_2/Error_Detection_and_Correction.html",
    "content": "### 1. Types of Errors\n\n**What is it?**\nErrors occur when data bits are altered during transmission or storage due to noise, interference, or hardware faults. Understanding error types helps in designing appropriate detection and correction mechanisms.\n\n**Key Types:**\n- **Single-Bit Error**:\n  - Only one bit in the data flips (e.g., `1010` → `1000`).\n  - Common in low-noise environments.\n  - Example: A cosmic ray flips a single bit in memory.\n- **Burst Error**:\n  - A sequence of consecutive bits is corrupted.\n  - Length of the burst is the number of bits from the first to the last error (e.g., `101010` → `100110`, burst length = 3).\n  - Common in noisy channels like wireless communication.\n- **Multiple-Bit Error (Non-Burst)**:\n  - Multiple bits are corrupted, but not consecutively (e.g., `101010` → `111100`, errors in positions 2 and 5).\n  - Less common but harder to detect/correct.\n\n![[Pasted image 20250503182607.png]]\n### Sender Side (Encoder)\nThe sender’s job is to encode the original message with redundancy to enable error detection or correction at the receiver.\n\n1. **Message**:\n   - This is the original data the sender wants to transmit (e.g., a binary string like `1011`).\n   - It consists of `k` bits of actual information.\n\n2. **Generator**:\n   - The generator is the component (or algorithm) that adds redundancy to the message.\n   - It takes the original message and appends redundant bits to create a codeword.\n   - **How it Works**:\n     - Redundancy can be added using techniques like parity bits, Hamming Code, or CRC.\n     - For example, in CRC, the generator polynomial (e.g., `x^3 + 1`) is used to compute a check value that’s appended to the message.\n   - **Output**: A codeword consisting of the original message plus redundant bits.\n     - If the message is `k` bits, and `r` redundant bits are added, the codeword is `n = k + r` bits.\n\n3. **Message and Redundancy**:\n   - This block represents the final codeword ready for transmission.\n   - It includes:\n     - The original message (`k` bits).\n     - Redundant bits (`r` bits) for error detection/correction.\n   - Example: For a message `1101` with a 3-bit CRC `100`, the transmitted codeword is `1101100`.\n\n4. **Unreliable Transmission**:\n   - The codeword is sent over an unreliable channel (e.g., a noisy wireless link).\n   - Errors may occur during transmission (e.g., `1101100` might become `1100100` if a bit flips).\n\n### Receiver Side (Decoder)\nThe receiver’s job is to process the received data, detect any errors, and either correct them or discard the data if errors are uncorrectable.\n\n1. **Received Information**:\n   - This is the data the receiver gets after transmission.\n   - It may be identical to the sent codeword (`message + redundancy`) or may contain errors due to the unreliable channel.\n   - Example: Sent `1101100`, but received `1100100` (bit 4 flipped).\n\n2. **Checker**:\n   - The checker is the component that examines the received codeword to detect errors.\n   - **How it Works**:\n     - It uses the redundant bits to verify the integrity of the data.\n     - Depending on the technique:\n       - **Error Detection**: Determines if an error exists (e.g., CRC checks if the remainder is 0).\n       - **Error Correction**: Identifies and fixes errors (e.g., Hamming Code uses a syndrome to locate the error).\n   - **Examples**:\n     - **CRC**: Divide the received codeword by the generator polynomial. If the remainder is 0, no error; otherwise, an error is detected.\n     - **Hamming Code**: Compute a syndrome to detect and correct a single-bit error.\n   - **Outcome**:\n     - If no errors are detected, the message is accepted.\n     - If errors are detected:\n       - For error correction: Fix the error (e.g., Hamming Code flips the erroneous bit).\n       - For error detection only: Discard the data or request retransmission (e.g., CRC in Ethernet).\n\n3. **Correct or Discard**:\n   - This step indicates the action taken by the decoder:\n     - **Correct**: If the system supports error correction (e.g., Hamming Code), the checker fixes the error, and the original message is recovered.\n     - **Discard**: If the system only supports error detection (e.g., CRC), or if the errors are uncorrectable (e.g., too many bit flips for Hamming Code), the data is discarded.\n     - In systems with retransmission (e.g., ARQ protocols), the receiver may request the sender to retransmit the data.\n\n4. **Message**:\n   - This is the final output at the receiver.\n   - If the checker successfully detects and corrects errors (or if no errors occurred), this is the original message (e.g., `1101`).\n   - If the data is discarded, no message is output, and the receiver may take further action (e.g., request retransmission).\n\n### What is Block Coding?\n\nBlock coding is a method used to add redundancy to digital data to enable error detection or correction. It works by dividing the data into fixed-size blocks and appending redundant bits to each block, creating a codeword that can be transmitted or stored reliably. The receiver uses these redundant bits to detect or correct errors introduced during transmission or storage.\n\n**Key Idea**: Each block of data is treated independently, and redundancy ensures the receiver can identify or fix errors without needing to retransmit the data (in the case of correction).\n\n---\n\n### How Block Coding Works\n\n1. **Data Division**:\n   - The message (data to be sent) is divided into blocks of **k** bits. Each block is processed independently.\n   - Example: A 16-bit message `1011001110101100` might be split into four 4-bit blocks: `1011`, `0011`, `1010`, `1100`.\n\n2. **Adding Redundancy**:\n   - For each k-bit block, **r** redundant bits are added to form an **n-bit codeword**, where `n = k + r`.\n   - These redundant bits are calculated based on the data bits using a specific coding scheme.\n   - The redundant bits enable the receiver to detect or correct errors.\n\n3. **Codeword**:\n   - The resulting n-bit codeword consists of the original k data bits plus the r redundant bits.\n   - Example: A 4-bit data block `1011` with 1 parity bit (r = 1) becomes a 5-bit codeword `10111` (even parity).\n\n4. **Transmission**:\n   - The codeword is transmitted over a communication channel or stored in a medium (e.g., disk, memory).\n\n5. **Receiver Processing**:\n   - The receiver checks the received codeword using the redundant bits:\n     - **Error Detection**: Verifies if the codeword is valid (e.g., parity check fails if the number of 1s is odd).\n     - **Error Correction**: Identifies and corrects errors (e.g., Hamming Code locates and fixes a single-bit error).\n\n---\n\n### Key Properties of Block Coding\n\n- **Code Rate**:\n  - Defined as `k/n`, the ratio of data bits to total bits in the codeword.\n  - A higher code rate (closer to 1) means less redundancy but weaker error handling.\n  - Example: For `k = 4`, `r = 3`, `n = 7`, the code rate is `4/7 ≈ 0.57`.\n\n- **Systematic vs. Non-Systematic**:\n  - **Systematic**: The codeword contains the original data bits followed by the redundant bits (e.g., `1011` + parity `1` = `10111`).\n  - **Non-Systematic**: The codeword is a transformed version of the data, not directly containing the original bits (less common).\n\n### Advantages of Block Coding\n\n- **Reliability**: Enables detection and correction of errors, ensuring data integrity.\n- **Simplicity**: Fixed block size makes implementation straightforward (e.g., in hardware).\n- **Flexibility**: Different block codes (e.g., Hamming, CRC) can be chosen based on the type of errors expected (single-bit vs. burst).\n- **No Feedback Required**: For error correction, no retransmission is needed, unlike detection-only methods.\n\n---\n\n### Limitations of Block Coding\n\n- **Overhead**: Adding redundant bits increases the data size, reducing the effective data rate.\n- **Limited Error Handling**:\n  - Simple codes like parity can’t correct errors or detect all multi-bit errors.\n  - Hamming Code corrects only single-bit errors.\n- **Complexity**: Advanced codes like Reed-Solomon require more computational resources for encoding/decoding.\n- **Fixed Block Size**: May not be efficient for variable-length data streams (unlike convolutional coding).\n\n\n### Applications of Block Coding\n\n- **Communication Systems**:\n  - Hamming Codes: Used in memory systems (e.g., ECC RAM) to correct single-bit errors.\n  - CRC: Used in Ethernet, Wi-Fi, and USB to detect burst errors.\n- **Storage Systems**:\n  - Reed-Solomon: Used in CDs, DVDs, and SSDs to correct errors due to scratches or defects.\n- **Networking**:\n  - CRC in packet headers (e.g., Ethernet frames) ensures data integrity.\n- **Space Communication**:\n  - Block codes like Reed-Solomon are used in satellite and deep-space communication to handle high error rates.\n  \n---\n\n### Hamming Distance\nThe **Hamming Distance** between two codewords (or binary strings) of equal length is the number of positions at which their bits differ. It’s a metric used to quantify how \"different\" two codewords are, which directly impacts a code’s ability to detect and correct errors.\n\n- **Formal Definition**: For two codewords `C1` and `C2` of length `n`, the Hamming Distance `d(C1, C2)` is the number of bit positions where `C1[i] ≠ C2[i]`.\n- **Example**:\n  - `C1 = 10110`\n  - `C2 = 10011`\n  - Compare bit by bit: `10110` vs `10011`\n    - Position 1: `1` vs `1` → Same\n    - Position 2: `0` vs `0` → Same\n    - Position 3: `1` vs `0` → Different\n    - Position 4: `1` vs `1` → Same\n    - Position 5: `0` vs `1` → Different\n  - Hamming Distance = 2 (differ at positions 3 and 5).\n\n\n### Minimum Hamming Distance (d_min)\n\nThe **Minimum Hamming Distance** (`d_min`) of a code is the smallest Hamming Distance between any two distinct valid codewords in the code. It’s a critical property that determines the error-handling capability of the code.\n\n- **How to Calculate**:\n  - List all valid codewords in the code.\n  - Compute the Hamming Distance between every pair of codewords.\n  - The smallest distance is `d_min`.\n- **Example**:\n  - Code with codewords: `{000, 011, 101, 110}`\n  - Pairwise Hamming Distances:\n    - `000` vs `011`: Differ at positions 2, 3 → Distance = 2\n    - `000` vs `101`: Differ at positions 1, 3 → Distance = 2\n    - `000` vs `110`: Differ at positions 1, 2 → Distance = 2\n    - `011` vs `101`: Differ at positions 1, 2 → Distance = 2\n    - `011` vs `110`: Differ at positions 1, 3 → Distance = 2\n    - `101` vs `110`: Differ at positions 2, 3 → Distance = 2\n  - `d_min = 2` (smallest distance among all pairs).\n\n\n### Significance of Hamming Distance in Error Detection and Correction\n\nThe Hamming Distance, particularly `d_min`, determines how many errors a code can detect or correct:\n\n1. **Error Detection**:\n   - A code can detect up to `d_min - 1` errors.\n   - **Reason**: If fewer than `d_min` bits are flipped, the received word cannot match another valid codeword, so an error is detected.\n   - **Example**:\n     - Code with `d_min = 2` (e.g., `{000, 011, 101, 110}`).\n     - Can detect `2 - 1 = 1` error.\n     - Sent: `000`, Received: `001` (1 bit flipped) → Not a valid codeword → Error detected.\n     - Sent: `000`, Received: `011` (2 bits flipped) → Matches a valid codeword → Error not detected.\n\n2. **Error Correction**:\n   - A code can correct up to `t = floor((d_min - 1)/2)` errors.\n   - **Reason**: To correct an error, the received word must be closer to the correct codeword than any other valid codeword. This requires the Hamming Distance to the correct codeword to be less than half the distance to any other codeword.\n   - **Example**:\n     - Code with `d_min = 3` (e.g., Hamming Code).\n     - Can correct `floor((3-1)/2) = 1` error.\n     - Sent: `000`, Received: `001` (1 bit flipped) → Closer to `000` than any other codeword → Correct to `000`.\n     - Sent: `000`, Received: `011` (2 bits flipped) → May be equidistant from multiple codewords → Cannot reliably correct.\n\n### Hamming Distance in Block Coding\n\nBlock coding relies on Hamming Distance to design codes with desired error-handling capabilities:\n\n- **Parity Check Code**:\n  - Adds a single parity bit (e.g., even parity).\n  - Example Code: `{0000, 0011, 0101, 0110, 1001, 1010, 1100, 1111}` (4-bit codewords with even parity).\n  - `d_min = 2` (e.g., `0000` vs `0011` differ in 2 bits).\n  - Detects `2 - 1 = 1` error, corrects `floor((2-1)/2) = 0` errors (no correction).\n\n- **Hamming Code**:\n  - Designed to have `d_min = 3`.\n  - Example: (7,4) Hamming Code (4 data bits, 3 parity bits).\n    - Codewords like `0000000`, `0110011`, etc.\n    - `d_min = 3`.\n    - Detects `3 - 1 = 2` errors, corrects `floor((3-1)/2) = 1` error.\n  - **How Correction Works**:\n    - Sent: `0110011`, Received: `0111011` (bit 4 flipped).\n    - Compute syndrome (based on parity checks) → Points to bit 4 → Flip to correct.\n\n- **Increasing d_min**:\n  - To improve error handling, increase `d_min` by adding more redundancy.\n  - Example: A code with `d_min = 5` (e.g., Reed-Solomon) can correct `floor((5-1)/2) = 2` errors.\n\n### Practical Example: Hamming Code and Hamming Distance\n\n**Problem**: Consider a (7,4) Hamming Code with 4 data bits and 3 parity bits. Verify its error correction capability using Hamming Distance.\n\n1. **Code Structure**:\n   - Data bits: 4 (`k = 4`).\n   - Parity bits: 3 (`r = 3`), since `2^3 = 8 ≥ 4 + 3 + 1`.\n   - Codeword length: `n = 7`.\n   - `d_min = 3` (by design of Hamming Code).\n\n2. **Sample Codewords**:\n   - Data `0000` → Codeword `0000000`.\n   - Data `0110` → Codeword `0110110` (after calculating parity bits).\n   - Hamming Distance between `0000000` and `0110110`:\n     - Differ at positions 2, 3, 5, 6 → Distance = 4.\n   - For any two codewords in a Hamming Code, the minimum distance is 3.\n\n3. **Error Handling**:\n   - `d_min = 3`.\n   - Detects `3 - 1 = 2` errors.\n   - Corrects `floor((3-1)/2) = 1` error.\n   - Example:\n     - Sent: `0000000`, Received: `0100000` (bit 2 flipped).\n     - Syndrome points to bit 2 → Correct to `0000000`.\n\n### Applications of Hamming Distance\n\n- **Error Detection/Correction**:\n  - Determines the capability of codes like Hamming, CRC, and Reed-Solomon.\n- **Code Design**:\n  - Engineers design codes with a specific `d_min` to meet error-handling requirements.\n  - Example: Hamming Code ensures `d_min = 3` for single-bit correction.\n- **Communication Systems**:\n  - Used in memory systems (ECC RAM), networking (Ethernet CRC), and storage (CDs/DVDs).\n- **Cryptography**:\n  - Hamming Distance is used in some cryptographic algorithms to measure differences between keys or hashes.\n\n---\n### Linear Block Codes\n\nA **Linear Block Code** is a type of block code where the codewords form a linear subspace over a finite field (typically GF(2) for binary codes). This means that the codewords are generated using linear combinations of basis vectors, and the code has algebraic properties that simplify encoding, decoding, and error handling.\n\n\n- **Block Code**: Data is divided into fixed-size blocks, and redundant bits are added to each block to form a codeword.\n- **Linear**: The codewords satisfy the property of linearity—any linear combination of codewords (using modulo-2 arithmetic for binary codes) is also a valid codeword.\n\n---\n\n### Key Properties of Linear Block Codes\n\n1. **Linearity**:\n   - For any two codewords `C1` and `C2` in the code, their sum (modulo-2, i.e., XOR) is also a codeword.\n   - Example: If `0000` and `1101` are codewords, then `0000 XOR 1101 = 1101` must also be a codeword.\n   - This property simplifies encoding and decoding, as the code can be described using a **generator matrix**.\n\n2. **Block Structure**:\n   - Each codeword has a fixed length `n`.\n   - Consists of `k` data bits and `r = n - k` redundant bits (parity or check bits).\n   - Example: A (7,4) code has `n = 7` bits total, `k = 4` data bits, and `r = 3` redundant bits.\n\n3. **Code Rate**:\n   - The ratio of data bits to total bits: `k/n`.\n   - Example: For a (7,4) code, code rate = `4/7 ≈ 0.57`.\n\n4. **Minimum Hamming Distance (d_min)**:\n   - The smallest Hamming Distance (number of bit differences) between any two distinct codewords.\n   - For linear codes, `d_min` is equal to the minimum weight of any non-zero codeword (weight = number of 1s in a codeword).\n   - Determines error-handling capability:\n     - Detects up to `d_min - 1` errors.\n     - Corrects up to `t = floor((d_min - 1)/2)` errors.\n\n5. **Systematic Form**:\n   - Most linear block codes are systematic, meaning the codeword consists of the original `k` data bits followed by `r` check bits.\n   - Example: Data `1011` with 3 check bits might become `1011001` (data + check bits).\n\n---\n\n### Encoding and decoding for simple parity check rule\n\n![[Pasted image 20250503190829.png]]\n\n### Sender Side (Encoder)\n\nThe sender’s role is to encode the data by adding a parity bit to enable error detection at the receiver.\n\n1. **Dataword (`a_3, a_2, a_1, a_0`)**:\n   - The dataword is the original 4-bit data to be transmitted: `a_3 a_2 a_1 a_0`.\n   - Example: `1011` (`a_3 = 1, a_2 = 0, a_1 = 1, a_0 = 1`).\n\n2. **Generator**:\n   - The generator computes the parity bit `r_0` based on the data bits.\n   - **How it Works**:\n     - In a simple parity-check code, the parity bit is calculated to ensure the total number of 1s in the codeword (data bits + parity bit) is even (for even parity) or odd (for odd parity).\n     - The diagram shows the parity bit `r_0` being computed as the XOR of the data bits:\n       - `r_0 = a_3 ⊕ a_2 ⊕ a_1 ⊕ a_0`\n     - **XOR Operation**: \n       - `0 ⊕ 0 = 0`, `0 ⊕ 1 = 1`, `1 ⊕ 0 = 1`, `1 ⊕ 1 = 0`.\n     - This ensures even parity (the number of 1s in `a_3 a_2 a_1 a_0 r_0` is even).\n   - **Example**:\n     - Dataword: `1011`.\n     - Number of 1s: 3 (odd).\n     - `r_0 = 1 ⊕ 0 ⊕ 1 ⊕ 1`:\n       - `1 ⊕ 0 = 1`\n       - `1 ⊕ 1 = 0`\n       - `0 ⊕ 1 = 1`\n     - So, `r_0 = 1`.\n\n3. **Parity Bit (`r_0`)**:\n   - The parity bit `r_0` is appended to the dataword to form the codeword.\n   - In this diagram, `r_0` is the redundant bit added to the 4-bit dataword, making the codeword 5 bits long.\n\n4. **Codeword (`a_3, a_2, a_1, a_0, r_0`)**:\n   - The codeword is the 5-bit string: `a_3 a_2 a_1 a_0 r_0`.\n   - Example: For dataword `1011`, `r_0 = 1`, so the codeword is `10111`.\n   - Total number of 1s in `10111`: 4 (even), which satisfies even parity.\n\n5. **Unreliable Transmission**:\n   - The codeword is sent over an unreliable channel, where errors (bit flips) may occur.\n   - Example: Sent `10111`, but received `10101` (bit 3 flipped from 1 to 0).\n\n### Receiver Side (Decoder)\n\nThe receiver’s role is to check the received codeword for errors using the parity bit and decide whether to accept the data or discard it.\n\n1. **Codeword (`b_3, b_2, b_1, b_0, q_0`)**:\n   - The received codeword is labeled as `b_3 b_2 b_1 b_0 q_0`, where:\n     - `b_3 b_2 b_1 b_0` correspond to the received data bits (originally `a_3 a_2 a_1 a_0`).\n     - `q_0` is the received parity bit (originally `r_0`).\n   - Example: Received `10101` (bit 3 flipped):\n     - `b_3 = 1, b_2 = 0, b_1 = 1, b_0 = 0, q_0 = 1`.\n\n2. **Checker**:\n   - The checker computes a **syndrome** to detect errors.\n   - **How it Works**:\n     - The syndrome `s_0` is calculated by XORing all bits of the received codeword (data bits + parity bit):\n       - `s_0 = b_3 ⊕ b_2 ⊕ b_1 ⊕ b_0 ⊕ q_0`\n     - For even parity, if `s_0 = 0`, the number of 1s is even → No error (or an even number of errors, which is undetectable).\n     - If `s_0 = 1`, the number of 1s is odd → Error detected (e.g., a single-bit error).\n   - **Example**:\n     - Received: `10101`.\n     - `s_0 = 1 ⊕ 0 ⊕ 1 ⊕ 0 ⊕ 1`:\n       - `1 ⊕ 0 = 1`\n       - `1 ⊕ 1 = 0`\n       - `0 ⊕ 0 = 0`\n       - `0 ⊕ 1 = 1`\n     - `s_0 = 1` → Error detected (odd number of 1s: 3).\n\n3. **Syndrome (`s_0`)**:\n   - The syndrome `s_0` is the output of the checker.\n   - `s_0 = 0`: No detectable error.\n   - `s_0 = 1`: Error detected (e.g., single-bit error or any odd number of errors).\n\n4. **Decision Logic**:\n   - The decision logic uses the syndrome to determine the action:\n     - If `s_0 = 0`: The codeword is accepted, and the dataword `b_3 b_2 b_1 b_0` is output as the recovered data.\n     - If `s_0 = 1`: The codeword is discarded (indicated by the `D` output), as an error is detected but cannot be corrected with a simple parity-check code.\n   - **Example**:\n     - `s_0 = 1` → Error detected → Discard the codeword.\n     - In a real system, the receiver might request retransmission (e.g., using ARQ).\n\n5. **Dataword (`a_3, a_2, a_1, a_0`)**:\n   - If the codeword is accepted (`s_0 = 0`), the dataword `b_3 b_2 b_1 b_0` is output as the recovered data, ideally matching the original `a_3 a_2 a_1 a_0`.\n   - If discarded, no dataword is output, and further action (e.g., retransmission) may be taken.\n\n### How It All Ties Together\n\n- **Sender (Encoder)**:\n  - Takes a 4-bit dataword `a_3 a_2 a_1 a_0`.\n  - Computes the parity bit `r_0` using XOR to ensure even parity.\n  - Forms the 5-bit codeword `a_3 a_2 a_1 a_0 r_0` and transmits it.\n- **Receiver (Decoder)**:\n  - Receives the codeword `b_3 b_2 b_1 b_0 q_0`, which may have errors.\n  - Computes the syndrome `s_0` by XORing all bits.\n  - Uses the syndrome to decide whether to accept the data (output `b_3 b_2 b_1 b_0`) or discard it.\n\n### Example Walkthrough\n\n1. **Sender**:\n   - **Dataword**: `1011`.\n   - **Parity Bit**: `r_0 = 1 ⊕ 0 ⊕ 1 ⊕ 1 = 1`.\n   - **Codeword**: `10111`.\n   - Number of 1s: 4 (even) → Satisfies even parity.\n\n2. **Unreliable Transmission**:\n   - Sent: `10111`.\n   - Received: `10101` (bit 3 flipped from 1 to 0).\n\n3. **Receiver**:\n   - **Received Codeword**: `10101`.\n   - **Syndrome**: `s_0 = 1 ⊕ 0 ⊕ 1 ⊕ 0 ⊕ 1 = 1`.\n   - **Decision**: `s_0 = 1` → Error detected → Discard the codeword.\n\n**No Error Case**:\n- Received: `10111` (no errors).\n- `s_0 = 1 ⊕ 0 ⊕ 1 ⊕ 1 ⊕ 1 = 0`.\n- `s_0 = 0` → Accept → Output dataword: `1011`.\n\n---\n\n\n### Types of Linear Block Codes\n\n1. **Hamming Codes**:\n   - Designed for single-bit error correction.\n   - `d_min = 3` → Corrects 1 error, detects 2 errors.\n   - Example: (7,4) Hamming Code (as above).\n\n2. **Cyclic Codes**:\n   - A subset of linear block codes where a cyclic shift of a codeword is also a codeword.\n   - Example: CRC (Cyclic Redundancy Check).\n   - Efficient for burst error detection.\n\n3. **Reed-Solomon Codes**:\n   - Linear block codes that operate on symbols (groups of bits).\n   - Used for correcting multiple errors.\n   - Applications: CDs, DVDs, QR codes.\n\n---\n\n### Encoder and decoder for a hamming code\n![[Pasted image 20250503191117.png]]\n\n**Figure 10.12: The structure of the encoder and decoder for a Hamming code** illustrates the encoding and decoding process for a Hamming code, a linear block code designed to correct single-bit errors.\n\n### Sender Side (Encoder):\n- **Dataword (`a_3, a_2, a_1, a_0`)**: The 4-bit input data (e.g., `1011`).\n- **Generator**: Adds 3 parity bits (`r_2, r_1, r_0`) using XOR operations based on specific data bit positions (Hamming code rules).\n  - Example: For `1011`, parity bits are computed to form a 7-bit codeword `a_3 a_2 a_1 a_0 r_2 r_1 r_0` (e.g., `1011010`).\n- **Codeword**: The 7-bit output (`a_3 a_2 a_1 a_0 r_2 r_1 r_0`) is transmitted over an unreliable channel.\n\n### Receiver Side (Decoder):\n- **Codeword (`b_3, b_2, b_1, b_0, q_2, q_1, q_0`)**: The received 7-bit codeword, which may have errors (e.g., `1010010`, bit 4 flipped).\n- **Checker**: Computes a 3-bit syndrome (`s_2, s_1, s_0`) using XOR operations on specific bit positions.\n  - Example: Syndrome `011` (binary 3) indicates an error in bit 4.\n- **Correction Logic**: Uses the syndrome to locate and correct the error (e.g., flip bit 4: `1010010` → `1011010`).\n- **Dataword (`a_3, a_2, a_1, a_0`)**: Outputs the corrected 4-bit data (e.g., `1011`).\n\n![[Pasted image 20250503191233.png]]\n### Key Points:\n- Hamming code corrects single-bit errors (`d_min = 3`).\n- Encoding adds parity bits; decoding uses the syndrome to correct errors.\n- Example: Encode `1011` → `1011010`, receive `1010010`, correct to `1011010`, output `1011`.\n\n---\n### Burst error correction using Hamming code\n![[Pasted image 20250503191421.png]]\n\n### Sender Side:\n- Four Hamming codewords (Codeword 1 to 4) are shown, each with 7 bits (e.g., Codeword 1: `1111111`, Codeword 2: `1100010`).\n- Bits are interleaved column-wise into a single data unit:\n  - Bit 1 of all codewords: `0111` (from Codewords 4, 3, 2, 1).\n  - Bit 2 of all codewords: `0011`, and so on.\n- Resulting data unit: `011100110101...` (28 bits total).\n\n### Transmission:\n- A burst error corrupts 4 consecutive bits in the data unit (highlighted as \"Corrupted bits\").\n\n### Receiver Side:\n- The received data unit is de-interleaved back into the four codewords:\n  - Codeword 1: `1111011` (bit 3 corrupted).\n  - Codeword 2: `1000110` (bit 3 corrupted).\n  - Codeword 3: `0110000` (bit 3 corrupted).\n  - Codeword 4: `0001001` (bit 3 corrupted).\n- Each codeword now has only a single-bit error, which a Hamming code (`d_min = 3`) can correct.\n- Hamming decoding corrects each codeword back to its original form (e.g., `1111011` → `1111111`).\n\n### Key Points:\n- Interleaving spreads a burst error across multiple codewords, converting it into single-bit errors per codeword.\n- Hamming code corrects these single-bit errors, effectively handling the burst error.\n### Advantages of Linear Block Codes\n- **Simplicity**: Encoding/decoding is efficient using matrix operations.\n- **Error Handling**: Well-defined error detection/correction capabilities based on `d_min`.\n- **Hardware-Friendly**: Matrix operations (e.g., XOR, AND) are easy to implement in hardware.\n- **Systematic Form**: Easy to extract the original data from the codeword.\n\n---\n### Cyclic Codes\n\nA **Cyclic Code** is a type of linear block code with an additional property: if a codeword is cyclically shifted (i.e., bits are rotated left or right), the result is another valid codeword in the same code. This cyclic property makes them efficient for implementation and particularly good at detecting burst errors.\n\n- **Linear**: Cyclic codes are linear block codes, meaning the XOR of any two codewords is another valid codeword.\n- **Block Code**: Data is divided into blocks of `k` bits, and `r` redundant bits are added to form an `n`-bit codeword (`n = k + r`).\n- **Cyclic**: A cyclic shift of any codeword produces another codeword.\n\n**Example**:\n- Code: `{000, 110, 011, 101}`.\n- Codeword: `110`.\n- Cyclic shift (left): `110` → `101` (shift left, move the leftmost bit to the right).\n- `101` is also a codeword, confirming the cyclic property.\n\n### Key Properties of Cyclic Codes\n\n1. **Cyclic Property**:\n   - A cyclic shift of a codeword is another codeword.\n   - Example: For a 3-bit code, shifting `110` to `101` or `011` (both directions) must yield valid codewords if the code is cyclic.\n\n2. **Linearity**:\n   - As a linear block code, the XOR of any two codewords is another codeword.\n   - Example: `110 ⊕ 011 = 101`, which is also a codeword in the example above.\n\n3. **Polynomial Representation**:\n   - Cyclic codes are defined using polynomials over GF(2) (binary field).\n   - Each `n`-bit codeword `c_0 c_1 ... c_{n-1}` is represented as a polynomial:\n     - `C(x) = c_0 + c_1x + c_2x^2 + ... + c_{n-1}x^{n-1}`\n   - Example: Codeword `110` → `C(x) = 1 + 1x + 0x^2 = 1 + x`.\n   - Cyclic shift corresponds to polynomial multiplication by `x` modulo `x^n - 1`:\n     - Shift `110` to `101`: `C(x) = 1 + x` → `xC(x) = x + x^2` → Modulo `x^3 - 1` → `1 + x^2` (which is `101`).\n\n4. **Generator Polynomial**:\n   - A cyclic code is generated by a single polynomial `G(x)` of degree `r = n - k`, which divides `x^n - 1`.\n   - All codewords are multiples of `G(x)` (modulo `x^n - 1`).\n   - Example: For an (n,k) cyclic code, `G(x)` has degree `r`, and codewords are of the form `C(x) = M(x) · G(x)`, where `M(x)` is the message polynomial.\n\n5. **Minimum Hamming Distance (d_min)**:\n   - Determines error-handling capability:\n     - Detects up to `d_min - 1` errors.\n     - Corrects up to `t = floor((d_min - 1)/2)` errors.\n   - Cyclic codes can be designed with specific `d_min` (e.g., CRC has high `d_min` for burst error detection).\n\n### Structure of Cyclic Codes\nCyclic codes are typically systematic, meaning the codeword contains the original data bits followed by redundant bits.\n\n#### Polynomial Representation:\n- **Message Polynomial**: A `k`-bit message `m_0 m_1 ... m_{k-1}` → `M(x) = m_0 + m_1x + ... + m_{k-1}x^{k-1}`.\n- **Codeword Polynomial**: An `n`-bit codeword → `C(x) = c_0 + c_1x + ... + c_{n-1}x^{n-1}`.\n- **Generator Polynomial**: `G(x)` of degree `r = n - k`.\n\n#### Encoding:\n1. Represent the message as `M(x)`.\n2. Multiply by `x^r` to shift left by `r` bits (append `r` zeros): `x^r · M(x)`.\n3. Divide by `G(x)` to get the remainder `R(x)` (degree < `r`):\n   - `x^r · M(x) = Q(x) · G(x) + R(x)`\n4. Codeword: `C(x) = x^r · M(x) - R(x)` (in GF(2), subtraction is XOR).\n   - This ensures `C(x)` is a multiple of `G(x)`.\n\n#### Decoding:\n- Use the parity-check matrix or polynomial division to compute the syndrome.\n- Syndrome `S(x) = R(x) mod G(x)`:\n  - If `S(x) = 0`, no error.\n  - If `S(x) ≠ 0`, an error is detected, and error patterns can be corrected (for error-correcting cyclic codes).\n\n### CRC encoder and decoder\n![[Pasted image 20250503194106.png]]\n\n### Sender Side (Encoder)\n\nThe sender encodes the data by appending a CRC remainder to enable error detection at the receiver.\n\n1. **Dataword (`a_3, a_2, a_1, a_0`)**:\n   - The 4-bit input data: `a_3 a_2 a_1 a_0`.\n   - Example: `1101`.\n\n2. **Generator**:\n   - The generator computes the CRC remainder using polynomial division (modulo-2).\n   - **Process**:\n     - Append `r` zeros to the dataword (where `r` is the degree of the generator polynomial).\n     - In the diagram, `r = 3` (three check bits: `r_2, r_1, r_0`), so append `000`.\n     - Example: `1101` → `1101000`.\n     - Divide this by the generator polynomial (represented as the \"Divisor\").\n     - The divisor is typically `G(x)` (e.g., `x^3 + x + 1` → `1011` for a degree-3 polynomial).\n     - Division is done using XOR (modulo-2 arithmetic).\n   - **Example**:\n     - Data: `1101000`.\n     - Divisor: `1011`.\n     - Divide `1101000` by `1011` → Remainder = `100` (`d_2 d_1 d_0`).\n\n3. **Remainder (`d_2, d_1, d_0`)**:\n   - The remainder from the division is the CRC (3 bits in this case).\n   - Example: Remainder `100` → `r_2 = 1, r_1 = 0, r_0 = 0`.\n\n4. **Codeword (`a_3, a_2, a_1, a_0, r_2, r_1, r_0`)**:\n   - The codeword is the dataword plus the CRC remainder: `a_3 a_2 a_1 a_0 r_2 r_1 r_0`.\n   - Example: `1101` + `100` → `1101100`.\n   - This codeword is a multiple of the generator polynomial (i.e., divisible by `G(x)` with no remainder).\n\n5. **Unreliable Transmission**:\n   - The codeword is sent over an unreliable channel, where errors may occur.\n   - Example: Sent `1101100`, received `1100100` (bit 4 flipped).\n\n### Receiver Side (Decoder)\n\nThe receiver checks the received codeword for errors using the CRC and decides whether to accept or discard the data.\n\n1. **Codeword (`b_3, b_2, b_1, b_0, q_2, q_1, q_0`)**:\n   - The received codeword: `b_3 b_2 b_1 b_0 q_2 q_1 q_0`.\n   - `b_3 b_2 b_1 b_0` are the data bits, `q_2 q_1 q_0` are the received CRC bits.\n   - Example: Received `1100100`.\n\n2. **Checker**:\n   - The checker recomputes the remainder by dividing the received codeword by the same divisor (generator polynomial).\n   - **Process**:\n     - Divide `b_3 b_2 b_1 b_0 q_2 q_1 q_0` by `G(x)` (e.g., `1011`).\n     - The result is the syndrome (`s_2 s_1 s_0`).\n     - If the syndrome is `000`, the codeword is valid (no detectable error).\n     - If the syndrome is non-zero, an error is detected.\n   - **Example**:\n     - Received: `1100100`.\n     - Divide `1100100` by `1011` → Remainder ≠ 0 (e.g., `101`).\n     - Syndrome: `s_2 s_1 s_0 = 101`.\n\n3. **Syndrome (`s_2, s_1, s_0`)**:\n   - The syndrome indicates whether an error occurred:\n     - `s_2 s_1 s_0 = 000`: No error (or undetectable error).\n     - `s_2 s_1 s_0 ≠ 000`: Error detected.\n   - Example: `s_2 s_1 s_0 = 101` → Error detected.\n\n4. **Decision Logic**:\n   - Based on the syndrome:\n     - If `s_2 s_1 s_0 = 000`: Accept the codeword, output `b_3 b_2 b_1 b_0` as the dataword.\n     - If `s_2 s_1 s_0 ≠ 000`: Discard the codeword (indicated by the \"Discard\" output).\n   - Example: Syndrome `101` → Discard (error detected).\n   - In a real system, the receiver might request retransmission (e.g., using ARQ).\n\n5. **Dataword (`a_3, a_2, a_1, a_0`)**:\n   - If accepted, the dataword `b_3 b_2 b_1 b_0` is output as the recovered data.\n   - If discarded, no dataword is output.\n\n### Example Walkthrough\n\n1. **Sender**:\n   - **Dataword**: `1101`.\n   - **Append Zeros**: `1101000`.\n   - **Divide by `1011`**: Remainder = `100`.\n   - **Codeword**: `1101100`.\n\n2. **Transmission**:\n   - Sent: `1101100`.\n   - Received: `1100100` (bit 4 flipped).\n\n3. **Receiver**:\n   - **Received Codeword**: `1100100`.\n   - **Divide by `1011`**: Remainder = `101`.\n   - **Syndrome**: `s_2 s_1 s_0 = 101`.\n   - **Decision**: Discard (error detected).\n\n**No Error Case**:\n- Received: `1101100`.\n- Divide by `1011` → Remainder = `000`.\n- Syndrome: `000` → Accept → Output dataword: `1101`.\n\n### Encoding Example (CRC as a Cyclic Code)\n\nConsider an (7,4) cyclic code (n = 7, k = 4, r = 3) with `G(x) = x^3 + x + 1` (`1011`).\n\n1. **Message**: `1101` → `M(x) = x^3 + x^2 + 1`.\n2. **Shift Left**: `x^r · M(x) = x^3 · (x^3 + x^2 + 1) = x^6 + x^5 + x^3`.\n   - As bits: `1101000`.\n3. **Divide by `G(x)`**:\n   - `G(x) = x^3 + x + 1` (`1011`).\n   - Divide `1101000` by `1011` (modulo-2):\n     - `1101000 ÷ 1011` → Remainder = `100` (`R(x) = x^2`).\n4. **Codeword**:\n   - `C(x) = x^r · M(x) - R(x)` → `1101000 ⊕ 0000100 = 1101100`.\n   - Codeword: `1101100` (message `1101` + check bits `100`).\n\n### Decoding and Error Detection\n\n1. **Received Codeword**: `R(x) = 1100100` (bit 4 flipped).\n2. **Syndrome**:\n   - Divide `R(x)` by `G(x)`:\n     - `1100100 ÷ 1011` → Remainder ≠ 0 → Error detected.\n3. **Correction** (if designed for correction):\n   - Cyclic codes like BCH codes (a subset) can correct errors by mapping syndromes to error patterns.\n   - For CRC, typically used for detection only, the receiver requests retransmission.\n\n### Types of Cyclic Codes\n\n1. **Cyclic Redundancy Check (CRC)**:\n   - Primarily for error detection.\n   - High `d_min` for detecting burst errors.\n   - Example: CRC-32 (`G(x) = x^32 + x^26 + ... + 1`), used in Ethernet.\n\n2. **BCH Codes**:\n   - Cyclic codes designed for multiple error correction.\n   - Example: A BCH code with `d_min = 5` corrects `floor((5-1)/2) = 2` errors.\n\n### Advantages of Cyclic Codes\n\n- **Efficiency**: The cyclic property allows encoding/decoding using shift registers (hardware-friendly).\n- **Burst Error Detection**: Excellent for detecting burst errors (e.g., CRC detects all bursts of length ≤ degree of `G(x)`).\n- **Algebraic Structure**: Polynomial representation simplifies design and analysis.\n\n### Limitations\n\n- **Error Correction Complexity**: While detection is simple (e.g., CRC), correction (e.g., BCH) can be computationally intensive.\n- **Fixed Length**: Like all block codes, they work with fixed block sizes.\n- **Redundancy Overhead**: Adding check bits reduces the effective data rate.\n\n### Applications\n\n- **CRC**: Networking (Ethernet, Wi-Fi), storage (disk drives), file transfer (ZIP files).\n- **BCH Codes**: Satellite communication, memory systems.\n\n### Checksum\nIn computer networks, a **checksum** is a value used to verify the integrity of data during transmission. It helps detect errors that may have occurred while data was being sent over the network.\n### Key Points :\n1. **Purpose**:  \n    To **detect errors** in transmitted data.\n2. **How it Works**:\n    - The sender calculates a checksum value based on the **binary data** (usually by summing up segments of the data).\n    - This checksum is **sent along with the data** to the receiver.\n    - The receiver recalculates the checksum from the received data.\n    - If the recalculated checksum **matches** the received checksum, the data is considered **error-free**.\n    - If not, it means the data was **corrupted** during transmission.\n3. **Common Methods**:\n    - **Internet Checksum** (used in protocols like IP, TCP, UDP): Sums up 16-bit words and adds any overflow (carry).\n    - **CRC (Cyclic Redundancy Check)**: More complex but more accurate; used in Ethernet.\n4. **Limitations**:\n    - Can detect **most** errors, but not all.\n    - Cannot correct errors — only **detect** them.\n\n### **At the Sender Site**:\n1. **Message is divided into 16-bit words**\n   * The data (message) is split into chunks of 16 bits (2 bytes each).\n1. **Checksum word is set to 0**\n   * Before calculating, a placeholder for the checksum is initialized to `0000000000000000`.\n1. **All words are added using one’s complement addition**\n   * The 16-bit words are added together using one's complement addition (carry from the MSB is wrapped around to the LSB).\n1. **The sum is complemented → this becomes the checksum**\n   * The final sum is inverted (all bits flipped) to get the checksum.\n1. **Checksum is sent with the data**\n   * This checksum is now attached to the message and sent to the receiver.\n### **At the Receiver Site**:\n1. **Message (with checksum) is divided into 16-bit words**\n   * The received message, including the checksum, is split again into 16-bit chunks.\n1. **All words are added using one’s complement addition**\n   * Just like the sender, the receiver adds all the 16-bit chunks including the checksum.\n1. **Sum is complemented to get new checksum**\n   * After adding, the receiver flips the bits of the total sum.\n1. **If the result is 0 → message is valid**\n   * If the final result is **all 0s (i.e., 0000000000000000)**, it means **no error**.\n   * If it’s **not zero**, then the message was **corrupted**.\n"
  },
  {
    "url": "University/Computer_Networks/Module_2/Flow_Control.html",
    "content": "The most important reponsibiliteies of data link layer are flow control and error control. Collectively these functions are called data link control \n## **Flow Control**\nFlow control is a technique used to **manage the rate of data transmission** between a sender and a receiver so that the receiver is not overwhelmed.\n###  Purpose:\nTo ensure that a **fast sender** does not send data faster than a **slow receiver** can process.\n###  Key Concepts:\n- **Buffer management**: The receiver may have limited buffer space; flow control ensures it doesn't overflow.\n- **Transmission rate control**: Slows down the sender if the receiver is busy or slow.\n###  Common Techniques:\n1. **Stop-and-Wait Protocol**\n    - Sender sends one frame and waits for an acknowledgment (ACK) before sending the next.\n2. **Sliding Window Protocol**\n    - Sender can send multiple frames before needing an ACK, depending on window size.\n    - More efficient than stop-and-wait.\n## **Error Control**\nError control ensures **reliable delivery of data** by detecting and correcting errors that occur during transmission.\n### Purpose:\nTo ensure that the data received is **correct and complete**, even if errors occur in the transmission.\n###  Key Functions:\n1. **Error Detection**\n    - Uses techniques like **parity check**, **checksum**, or **CRC** to detect errors.\n2. **Error Correction**\n    - Uses **ARQ (Automatic Repeat reQuest)** to ask for retransmission if an error is found.\n\n| Feature           | Flow Control                   | Error Control                           |\n| ----------------- | ------------------------------ | --------------------------------------- |\n| Goal              | Prevent receiver overflow      | Ensure data is accurate and complete    |\n| Deals with        | Speed mismatch                 | Transmission errors                     |\n| Methods Used      | Stop-and-Wait, Sliding Window  | ARQ, Checksum, CRC                      |\n| Receiver Role<br> | Controls rate of data received | Detects/corrects errors, sends ACK/NACK |\n|                   |                                |                                         |\n\n## Noiseless Protocols in Computer Networks\nNoiseless protocols are idealized models in the data link layer used to understand reliable communication **in the absence of transmission errors**. These protocols assume that:\n- The communication channel is perfect (no bits are lost or corrupted).\n- Frames are received exactly as they are sent.\n- Acknowledgments, if used, are never lost.\n\nThese protocols help illustrate the **concept of flow control** without the complexity of dealing with transmission errors.\n\nThere are two main types of noiseless protocols:\n### 1. **Simplest Protocol**\n![[Pasted image 20250503224633.png]]\n#### Characteristics:\n- Assumes a perfect channel with no possibility of frame loss or corruption.\n- Sender sends data continuously without waiting for any acknowledgment.\n- Receiver is always ready to accept data.\n#### Working:\n- The sender simply sends one frame after another.\n- The receiver processes each frame as it arrives.\n- There is no synchronization or control mechanism between sender and receiver.\n#### Limitation:\n- There is **no flow control**. If the sender is faster than the receiver, the receiver's buffer may overflow, leading to data loss (in practical systems).\n- It is not practical for real-world use, but it demonstrates basic data transfer.\n### 2. **Stop-and-Wait Protocol**\n![[Pasted image 20250503224620.png]]\n#### Characteristics:\n- Still assumes a noiseless channel (no frame or ACK is lost or corrupted).\n- Introduces **flow control** by ensuring the sender waits for a response from the receiver before sending the next frame.\n#### Working:\n1. The sender transmits a single frame.\n2. After sending the frame, the sender **waits for an acknowledgment (ACK)** from the receiver.\n3. The receiver receives the frame, processes it, and sends an ACK back.\n4. Once the sender receives the ACK, it sends the next frame.\n#### Advantages:\n- Provides **simple flow control**.\n- Ensures that the receiver is not overwhelmed since only one frame is in transmission at a time.\n#### Limitations:\n- **Inefficient** in high-latency networks because the sender remains idle while waiting for the ACK.\n- Only one frame is transmitted at a time, so bandwidth utilization is low.\n\n## Noisy Channel?\nA **noisy channel** refers to a communication medium where:\n- **Bits may flip** due to interference, signal degradation, or other noise sources.\n- **Frames (data packets)** may get **lost, corrupted, or delivered multiple times**.\n- **Acknowledgments (ACKs)** can also be lost or corrupted.\n\n## 2. How Do Noisy Channel Protocols Work?\nTo ensure reliable communication over a noisy channel, protocols must handle two main tasks:\n- **Error Detection**: Identify if data was corrupted (using techniques like checksums, CRC, parity bits).\n- **Error Control**: Take action when an error is detected (usually by retransmitting the data).\n\nThis is usually done through **ARQ (Automatic Repeat reQuest)** protocols.\n## 3. Types of Noisy Channel Protocols\n### a) **Stop-and-Wait ARQ**\n![[Pasted image 20250503225127.png]]\n#### Working:\n- The sender sends one frame and waits for an ACK.\n- If the ACK is received within a time limit, the sender sends the next frame.\n- If the ACK is **not received** (due to frame or ACK loss), the sender **resends** the frame after a **timeout**.\n- The receiver **discards duplicates** using sequence numbers (e.g., 0 and 1).\n\n#### Characteristics:\n- Handles errors by **retransmitting lost or corrupted frames**.\n- Uses a simple sequence number (usually 1 bit) to identify frames.\n\n#### Limitation:\n- **Inefficient** for long-delay or high-throughput channels because the sender waits a lot.\n\n### b) **Go-Back-N ARQ**\n![[Pasted image 20250503225203.png]]\n#### Working:\n- The sender can send **multiple frames** (up to a window size `N`) **without waiting for individual ACKs**.\n- Receiver sends **cumulative ACKs** for the last correctly received frame.\n- If an error is detected or a frame is lost, the receiver **discards all subsequent frames**, and the sender must **go back and retransmit** from the lost frame onward.\n#### Characteristics:\n- Improves efficiency by keeping the sender busy.\n- Still wastes bandwidth when errors occur because **all frames after an error are resent**.\n\n### c) **Selective Repeat ARQ**\n\n#### Working:\n- Like Go-Back-N, but the receiver **accepts and buffers out-of-order frames**.\n- Only the **specific frame** that was lost or corrupted is **retransmitted**.\n- Receiver sends individual ACKs for each frame.\n#### Characteristics:\n- More efficient than Go-Back-N in high-error environments.\n- More complex due to buffering and tracking multiple ACKs and sequence numbers.\n\n## Summary Table\n\n| Protocol             | Window Size | ACK Type   | On Error                     | Receiver Behavior            | Efficiency |\n| -------------------- | ----------- | ---------- | ---------------------------- | ---------------------------- | ---------- |\n| Stop-and-Wait ARQ    | 1           | Per frame  | Retransmit one               | Processes one at a time      | Low        |\n| Go-Back-N ARQ        | N           | Cumulative | Retransmit from error onward | Discards out-of-order frames | Medium     |\n| Selective Repeat ARQ | N           | Individual | Retransmit only lost         | Buffers out-of-order frames  | High       |\n\n## **HDLC?**\n**HDLC (High-level Data Link Control)** is a **bit-oriented** data link layer protocol developed by the International Organization for Standardization (ISO). It is used for reliable communication over both:\n- **Point-to-point** links (between two devices)\n- **Multipoint** links (one sender, multiple receivers)\n\nIt supports **error control** using **ARQ (Automatic Repeat reQuest)** mechanisms, ensuring data is delivered accurately and in the correct order.\n## **Bit-oriented Protocol**\nThis means HDLC treats the data in the form of a **continuous stream of bits**, not bytes or characters. Control information (like frame boundaries) is identified using specific bit patterns, not characters. This allows HDLC to be **more flexible and efficient**, especially for binary data transmission.\n## **ARQ Mechanisms in HDLC**\nHDLC uses ARQ techniques (like those used in noisy channels) to:\n- Detect errors in frames (via CRC).\n- Request retransmission of corrupted or lost frames.\n- Ensure acknowledgment of correctly received frames.\n## **Topics Discussed in the Section**\n### 1. **Configuration**\nThis defines the roles of devices in communication:\n- **Primary Station**: Controls the link and sends commands.\n- **Secondary Station**: Responds to commands from the primary.\n- **Combined Station**: Can act as both primary and secondary.\n### 2. **Transfer Modes**\nThese define how communication is managed:\n- **Normal Response Mode (NRM)**: Secondary can send data only when asked by the primary (used in unbalanced configurations).\n- **Asynchronous Response Mode (ARM)**: Secondary can initiate communication without permission.\n- **Asynchronous Balanced Mode (ABM)**: Both stations are equal and can initiate communication at any time (used in balanced configurations).\n### 3. **Frames**\n\nHDLC uses three types of frames:\n- **Information (I) frames**: Carry user data.\n- **Supervisory (S) frames**: Provide control information like ACK, NAK.\n- **Unnumbered (U) frames**: Used for control functions such as link setup or disconnection.\n## **Common HDLC Frame Fields**\nEach HDLC frame, regardless of type, consists of the following key fields:\n1. **Flag (01111110)**\n    - This is a special bit pattern that marks the **beginning and end** of a frame.\n    - It helps in **frame synchronization**.\n    - Always has the value `01111110` (in binary).\n2. **Address**\n    - Identifies the **destination** station or device.\n    - Can be 1 or more bytes, depending on configuration.\n    - Important in **multipoint networks**, where multiple receivers exist.\n3. **Control**\n    - This is the **heart** of the frame. It determines the **type of frame** (I, S, or U).\n    - Also used for **sequencing**, **acknowledgments**, **flow control**, and **error control**.\n4. **FCS (Frame Check Sequence)**\n    - Used for **error detection**.\n    - Typically a 16-bit or 32-bit CRC (Cyclic Redundancy Check).\n    - Ensures data integrity.\n## **I-frame (Information Frame)**\nUsed for: **Transmitting user data** along with flow and error control information.\n### Structure:\n- `Flag | Address | Control | User Information | FCS | Flag`\n### Details:\n- **User Information**: Actual data from higher layers.\n- **Control field**:\n    - Contains **send and receive sequence numbers**.\n    - Used for **error control** (ARQ) and **flow control**.\n    - Bit structure includes:\n        - `N(S)`: Send sequence number.\n        - `N(R)`: Receive sequence number (acknowledgment).\n        - P/F (Poll/Final) bit for command-response coordination.\n## **S-frame (Supervisory Frame)**\nUsed for: **Supervision (control)** without data transmission. For example, **ACKs**, **NAKs**, and **flow control**.\n### Structure:\n- `Flag | Address | Control | FCS | Flag`\n### Details:\n- **No data payload**.\n- **Control field** includes:\n    - Type of supervisory function:\n        - **RR (Receive Ready)**: Receiver is ready.\n        - **RNR (Receive Not Ready)**: Receiver cannot accept more frames.\n        - **REJ (Reject)**: Negative acknowledgment (request retransmission).\n        - **SREJ (Selective Reject)**: Request for retransmission of specific frame.\n    - Also includes **N(R)**: Sequence number being acknowledged.\n## **3. U-frame (Unnumbered Frame)**\nUsed for: **Link management** and **control signals**. Example: establishing or terminating a connection.\n### Structure:\n- `Flag | Address | Control | Management Information | FCS | Flag`\n### Details:\n- **Control field**:\n    - Indicates the **type of command or response** (like link setup, disconnect, reset).\n    - Does **not use sequence numbers**.\n- **Management Information**:\n    - Used for various management functions (e.g., protocol negotiation).\n    - Optional, depending on frame type.\n\n\n### Connection and Disconnection\n![[Pasted image 20250503230606.png]]\n\n## **Connection Establishment**\n### **U-frame (SABM)**: Sent from Node A to Node B\n- **SABM** stands for **Set Asynchronous Balanced Mode**.\n- It is used to **initiate a connection** with balanced (equal) roles between nodes.\n- The **control field** in binary: `11 11 100`\n    - First two bits `11` = U-frame.\n    - Next bits identify this specific U-frame type (SABM).\n- **Mg. data** (Management Data): May contain parameters for the connection.\n- **FCS**: Ensures data integrity.\n- **Flag**: Marks the beginning and end of the frame.\n\n### **U-frame (UA)**: Sent from Node B to Node A\n- **UA** stands for **Unnumbered Acknowledgment**.\n- Sent as a response to SABM to confirm the connection setup.\n- Control field: `11 00 110` (UA code).\n\n## **2. Data Transfer**\n- This phase is not shown in detail but happens after the connection is established.\n- **I-frames** would be used here to carry actual data with sequence numbers, acknowledgments, etc.\n\n## **3. Connection Release**\n### **U-frame (DISC)**: Sent from Node A to Node B\n- **DISC** stands for **Disconnect**.\n- Requests termination of the data link connection.\n- Control field: `11 00 010`.\n### **U-frame (UA)**: Sent from Node B to Node A\n- Again, **UA** is used to acknowledge the **disconnect** request.\n- Same control field: `11 00 110`.\n\n### **Piggybacking**\nPiggybacking is a technique where the acknowledgment for a received data frame is combined (\"piggybacked\") onto an outgoing data frame travelling in the reverse direction. This saves bandwidth by avoiding the need to send separate acknowledgment frames. In the I-frames shown, the Control field typically contains both a send sequence number (for the data being sent) and a receive sequence number (acknowledging data received from the other node).\n\n1. **Node A sends I-frame (data frame 0) to Node B:**\n    - This is an Information frame (I-frame) carrying data segment 0.\n    - The Control field shows 0 0. The first 0 is the Send Sequence Number (N(S)) for this frame. The second 0 is the Receive Sequence Number (N(R)), acknowledging that Node A has correctly received frames up to sequence number -1 from Node B (essentially, it's expecting frame 0 from B next). This second number is the piggybacked acknowledgment.\n    - Node B receives this frame successfully.\n2. **Node A sends I-frame (data frame 1) to Node B:**\n    - This I-frame carries data segment 1.\n    - Control field: 1 0. N(S)=1, N(R)=0 (still expecting frame 0 from B).\n    - **Error:** This frame is marked as **Lost** during transmission. Node B never receives it.\n3. **Node A sends I-frame (data frame 2) to Node B:**\n    - Node A, unaware of the loss, continues sending the next frame in sequence.\n    - This I-frame carries data segment 2.\n    - Control field: 2 0. N(S)=2, N(R)=0.\n    - Node B receives this frame.\n4. **Node B's Reaction to I-frame 2:**\n    - Node B successfully received frame 0. It was expecting frame 1 next.\n    - However, it receives frame 2 instead. This indicates that frame 1 was missed (lost or corrupted).\n    - According to the protocol rules (likely a Go-Back-N or Selective Reject variant), Node B **Discards** frame 2 because it's out of order.\n5. **Node B sends S-frame (REJ 1) to Node A:**\n    - To signal the error, Node B sends a Supervisory frame (S-frame).\n    - Type: **REJ (Reject)**, which acts as a Negative Acknowledgment (NAK).\n    - Control Field: 10 REJ 1. The 1 associated with REJ indicates that Node B is requesting the retransmission of I-frame starting from sequence number 1. It implicitly acknowledges receipt of frames up to 0. (10 likely represents control bits defining the S-frame type).\n6. **Node A's Reaction to REJ 1:**\n    - Node A receives the REJ 1. It understands that frame 1 (and any subsequent frames it sent, like frame 2) were not correctly received by B.\n    - Node A prepares to retransmit starting from frame 1.\n7. **Node A resends I-frame (data frame 1) to Node B:**\n    - This is a retransmission of the previously lost frame.\n    - Control field: 1 0. N(S)=1, N(R)=0.\n    - Node B receives this frame successfully. Now it has frame 0 and frame 1 in order.\n8. **Node A resends I-frame (data frame 2) to Node B:**\n    - Node A continues the retransmission sequence.\n    - Control field: 2 0. N(S)=2, N(R)=0.\n    - Node B receives this frame successfully. Now it has frames 0, 1, and 2 in order.\n9. **Node B sends S-frame (RR 3) to Node A:**\n\t- Node B has now successfully received frames 0, 1, and 2 in sequence.\n    - It sends an S-frame of type **RR (Receiver Ready)**, which acts as a positive Acknowledgment (ACK).\n    - Control Field: 10 RR 3. The 3 associated with RR indicates that Node B has received all frames up to sequence number 2 correctly and is now ready for (expecting) frame number 3.\n\n### Point to Point protocol\nThis is a specific protocol under HDLC, designed for point-to-point connections. It’s byte-oriented, meaning it handles data in bytes (8-bit units). PPP is widely used to establish direct connections, like between a computer and an ISP (Internet Service Provider) over a serial link.\n\n### Topics Covered in the Section\n1. **Framing**:\n   - Framing in PPP refers to how data is packaged into frames for transmission. A frame is a unit of data that includes the actual data (payload) plus control information like headers and trailers.\n   - PPP uses a specific frame structure derived from HDLC. The frame typically includes:\n     - **Flag**: A special byte (usually 0x7E) to mark the start and end of a frame.\n     - **Address and Control Fields**: In PPP, these are often simplified since it’s point-to-point (no need for complex addressing).\n     - **Protocol Field**: Identifies the type of data in the payload (e.g., IP, IPv6).\n     - **Payload**: The actual data being sent.\n     - **Checksum (FCS)**: Frame Check Sequence for error detection.\n   - PPP ensures that the flag byte doesn’t appear in the payload by using a process called **byte stuffing** (if 0x7E appears in the data, it’s escaped with a special character).\n\n2. **Transition Phases**:\n   - PPP connections go through several phases to establish, maintain, and terminate a link. These phases are part of the PPP state machine:\n     - **Dead Phase**: No connection exists; the link is down.\n     - **Establish Phase**: The two devices negotiate connection parameters using the Link Control Protocol (LCP). They agree on settings like authentication, compression, and maximum frame size.\n     - **Authenticate Phase**: Optional authentication (e.g., using PAP or CHAP) to verify the identity of the devices.\n     - **Network Phase**: Network-layer protocols (like IP) are configured using protocols like IPCP (IP Control Protocol).\n     - **Open Phase**: Data transfer happens here; the link is fully operational.\n     - **Terminate Phase**: The connection is closed, and the link returns to the Dead phase.\n   - Understanding these phases is key for troubleshooting PPP connections.\n\n3. **Multiplexing**:\n   - Multiplexing in PPP refers to its ability to carry multiple network-layer protocols (e.g., IP, IPX) over the same link.\n   - The **Protocol Field** in the PPP frame identifies which protocol the payload belongs to (e.g., 0x0021 for IP, 0xC021 for LCP).\n   - This allows PPP to support different types of traffic simultaneously, making it versatile for various network setups.\n\n4. **Multilink PPP**:\n   - Multilink PPP (MLPPP) is an extension of PPP that allows multiple physical links to be combined into a single logical link.\n   - For example, if you have two slow connections, MLPPP can bundle them to increase bandwidth and provide redundancy.\n   - It splits data into fragments, sends them over multiple links, and reassembles them at the other end. This requires sequence numbers to ensure fragments are reassembled in the correct order.\n   - MLPPP is useful for improving throughput and reliability in scenarios like connecting remote offices.\n\n### LCP Packets\nLCP is a protocol within the PPP suite that operates at the data link layer. Its primary job is to negotiate and set up the parameters of the PPP link between two devices (like a computer and an ISP). This includes things like agreeing on frame size, authentication methods, and whether to use compression. LCP packets are exchanged during the **Establish Phase** of a PPP connection (one of the transition phases mentioned in your image) to handle this negotiation.\n\n### LCP Packet Structure\nLCP packets are encapsulated within PPP frames. Let’s break down the structure step by step:\n\n1. **PPP Frame Wrapping**:\n   - Since LCP is part of PPP, an LCP packet is carried inside a PPP frame.\n   - A typical PPP frame looks like this:\n     - **Flag**: 0x7E (marks the start and end of the frame).\n     - **Address**: Usually 0xFF (all stations, simplified in PPP).\n     - **Control**: Usually 0x03 (unnumbered information, simplified in PPP).\n     - **Protocol**: For LCP packets, this field is set to **0xC021** (indicating LCP).\n     - **Information**: This is where the LCP packet itself goes.\n     - **FCS**: Frame Check Sequence (a checksum for error detection).\n     - **Flag**: 0x7E (end of frame).\n\n2. **LCP Packet Fields** (inside the Information field of the PPP frame):\n   - **Code**: 1 byte. Identifies the type of LCP packet (e.g., a request, acknowledgment, or rejection). I’ll list the common types below.\n   - **Identifier**: 1 byte. A unique number to match requests with responses. For example, if Device A sends a request with Identifier 0x01, Device B’s response will also use 0x01.\n   - **Length**: 2 bytes. The total length of the LCP packet (including Code, Identifier, Length, and Data fields) in bytes.\n   - **Data**: Variable length. Contains the specific options being negotiated or messages being exchanged. The format of this field depends on the Code.\n\nSo, the LCP packet structure inside the PPP frame’s Information field is:\n```\n| Code (1 byte) | Identifier (1 byte) | Length (2 bytes) | Data (variable) |\n```\n\n### Types of LCP Packets (Based on the Code Field)\nLCP packets are categorized into three main groups based on their purpose: link configuration, link termination, and link maintenance. The Code field determines the packet type. Here are the most common ones:\n\n1. **Link Configuration Packets** (used to negotiate link parameters):\n   - **Configure-Request (Code 0x01)**: Sent by a device to propose configuration options (e.g., maximum frame size, authentication protocol). The Data field contains a list of options in Type-Length-Value (TLV) format:\n     - **Type**: The option type (e.g., 0x01 for Maximum Receive Unit, MRU).\n     - **Length**: Length of the option (including Type and Length fields).\n     - **Value**: The value for the option (e.g., MRU = 1500 bytes).\n   - **Configure-Ack (Code 0x02)**: Sent to accept all options in a Configure-Request. The Identifier matches the request, and the Data field echoes the accepted options.\n   - **Configure-Nak (Code 0x03)**: Sent to reject some options in a Configure-Request but suggest alternatives. For example, if Device A requests an MRU of 2000 but Device B only supports 1500, the Nak will suggest 1500.\n   - **Configure-Reject (Code 0x04)**: Sent to reject options that the receiving device doesn’t understand or support. The Data field lists the rejected options.\n\n1. **Link Termination Packets** (used to close the link):\n   - **Terminate-Request (Code 0x05)**: Sent by a device to request closing the PPP link.\n   - **Terminate-Ack (Code 0x06)**: Sent to acknowledge the termination request and confirm the link is closing.\n\n3. **Link Maintenance Packets** (used to monitor the link):\n   - **Code-Reject (Code 0x07)**: Sent when a device receives an LCP packet with an unknown Code value. The Data field includes the rejected packet.\n   - **Protocol-Reject (Code 0x08)**: Sent when a device receives a PPP frame with an unsupported protocol (e.g., if the Protocol field isn’t recognized). This isn’t specific to LCP but can be used in the context of LCP.\n   - **Echo-Request (Code 0x09)** and **Echo-Reply (Code 0x0A)**: Used to test the link’s status. Echo-Request sends a message, and Echo-Reply confirms the link is alive.\n   - **Discard-Request (Code 0x0B)**: Sent to test the link by asking the other device to discard the packet (used for debugging).\n\n### Common LCP Options (in the Data Field)\nDuring configuration, the Data field of Configure-Request, Configure-Ack, Configure-Nak, and Configure-Reject packets contains options in TLV format. Some key options include:\n- **Maximum Receive Unit (MRU, Type 0x01)**: Specifies the maximum frame size the device can receive (default is 1500 bytes).\n- **Authentication Protocol (Type 0x03)**: Specifies the authentication method, e.g., PAP (0xC023) or CHAP (0xC223).\n- **Magic Number (Type 0x05)**: A random number used to detect looped-back links (if a device receives its own magic number, the link is looped).\n- **Protocol Compression (Type 0x07)**: Enables compression of the Protocol field in PPP frames.\n- **Address/Control Field Compression (Type 0x08)**: Allows omitting the Address and Control fields in PPP frames to save bandwidth.\n\n### How LCP Packets Work in PPP Phases\nLCP packets are primarily used during the **Establish Phase** of a PPP connection:\n1. Both devices exchange Configure-Request packets to propose their desired options.\n2. They respond with Configure-Ack (if all options are accepted), Configure-Nak (if some options need adjustment), or Configure-Reject (if some options are unsupported).\n3. This negotiation continues until both sides agree on the link parameters.\n4. Once the link is established, LCP can use Echo-Request/Echo-Reply to monitor the link.\n5. When the connection needs to end (Terminate Phase), Terminate-Request and Terminate-Ack are exchanged.\n\n### PAP packets\nPAP is a simple authentication protocol used within PPP to verify a device’s identity by sending a username and password in plain text. It’s not secure (since the credentials aren’t encrypted), but it’s still used in some scenarios where security isn’t a major concern or when the underlying link is already secure. PAP operates after the Link Control Protocol (LCP) establishes the link, during the Authenticate Phase of PPP.\n\n### PAP Packet Structure\nPAP packets are encapsulated within PPP frames, just like LCP packets. Here’s how they fit in:\n\n1. **PPP Frame Wrapping**:\n   - PAP packets are carried inside a PPP frame.\n   - The PPP frame structure is:\n     - **Flag**: 0x7E (start/end of frame).\n     - **Address**: 0xFF (simplified in PPP).\n     - **Control**: 0x03 (simplified in PPP).\n     - **Protocol**: For PAP, this is **0xC023** (indicating PAP).\n     - **Information**: This contains the PAP packet.\n     - **FCS**: Frame Check Sequence (error detection).\n     - **Flag**: 0x7E (end of frame).\n\n2. **PAP Packet Fields** (inside the Information field of the PPP frame):\n   - **Code** (1 byte): Identifies the type of PAP packet (e.g., request, success, or failure).\n   - **Identifier** (1 byte): A unique number to match requests with responses. For example, a PAP request with Identifier 0x01 will get a response with the same Identifier.\n   - **Length** (2 bytes): Total length of the PAP packet (including Code, Identifier, Length, and Data fields) in bytes.\n   - **Data** (variable): Contains the authentication details (e.g., username and password) or response messages.\n\nSo, the PAP packet structure is:\n```\n| Code (1 byte) | Identifier (1 byte) | Length (2 bytes) | Data (variable) |\n```\n\n### Types of PAP Packets (Based on the Code Field)\nPAP uses three main packet types, identified by the Code field:\n\n1. **Authenticate-Request (Code 0x01)**:\n   - Sent by the device being authenticated (the \"peer\") to the authenticator (e.g., a server).\n   - The Data field contains:\n     - **Peer-ID Length** (1 byte): Length of the username.\n     - **Peer-ID** (variable): The username (e.g., \"user123\").\n     - **Password Length** (1 byte): Length of the password.\n     - **Password** (variable): The password (e.g., \"pass456\").\n   - Example Data field: If the username is \"user123\" and password is \"pass456\", the Data field would be:\n     ```\n     | 0x07 (Peer-ID Length) | user123 (7 bytes) | 0x07 (Password Length) | pass456 (7 bytes) |\n     ```\n   - Note: The username and password are sent in plain text, making PAP vulnerable to eavesdropping.\n\n2. **Authenticate-Ack (Code 0x02)**:\n   - Sent by the authenticator to the peer if authentication succeeds (i.e., the username and password match).\n   - The Data field contains:\n     - **Message Length** (1 byte): Length of the optional message.\n     - **Message** (variable): An optional message (e.g., \"Welcome!\").\n   - Example: If the authenticator sends a \"Welcome!\" message:\n     ```\n     | 0x08 (Message Length) | Welcome! (8 bytes) |\n     ```\n   - The Identifier matches the Authenticate-Request’s Identifier.\n\n3. **Authenticate-Nak (Code 0x03)**:\n   - Sent by the authenticator if authentication fails (e.g., wrong username or password).\n   - The Data field contains:\n     - **Message Length** (1 byte): Length of the optional message.\n     - **Message** (variable): An optional message (e.g., \"Invalid credentials\").\n   - Example: If the authenticator sends \"Invalid credentials\":\n     ```\n     | 0x12 (Message Length) | Invalid credentials (18 bytes) |\n     ```\n   - The Identifier matches the Authenticate-Request’s Identifier.\n\n### How PAP Authentication Works in PPP\nHere’s the step-by-step process of PAP in the PPP Authenticate Phase:\n1. **LCP Negotiation**: During the Establish Phase, LCP negotiates the authentication protocol. If PAP is chosen (option Type 0x03, Value 0xC023 in LCP’s Configure-Request), the link moves to the Authenticate Phase.\n2. **Authenticate-Request**: The peer sends an Authenticate-Request packet with its username and password.\n3. **Authenticator Response**:\n   - The authenticator checks the credentials against its database.\n   - If correct, it sends an Authenticate-Ack, and the PPP link moves to the Network Phase (e.g., to configure IP with IPCP).\n   - If incorrect, it sends an Authenticate-Nak, and the link may terminate or retry (depending on implementation).\n4. **Retries**: PAP doesn’t have a built-in retry limit, but implementations often allow a few attempts before terminating the link.\n\n### Example Exchange\n- Peer sends: Authenticate-Request (Code 0x01, Identifier 0x01, Peer-ID = \"user123\", Password = \"pass456\").\n- Authenticator checks credentials:\n  - If valid, it responds with Authenticate-Ack (Code 0x02, Identifier 0x01, Message = \"Welcome!\").\n  - If invalid, it responds with Authenticate-Nak (Code 0x03, Identifier 0x01, Message = \"Invalid credentials\").\n\n### Key Characteristics of PAP\n- **Plain Text**: Username and password are sent unencrypted, making PAP insecure over untrusted networks.\n- **Two-Way Handshake**: Only the peer is authenticated (client-to-server); the authenticator isn’t verified.\n- **Simple**: Easy to implement but not recommended unless the link is already secure (e.g., over a VPN).\n\n### Comparison with CHAP (Since It’s an Alternative)\n- PAP sends credentials in plain text; CHAP (Challenge Handshake Authentication Protocol) uses a hashed challenge-response mechanism, making it more secure.\n- PAP is a two-way handshake; CHAP is a three-way handshake (challenge, response, success/failure).\n- During LCP negotiation, the authentication protocol is chosen (PAP = 0xC023, CHAP = 0xC223).\n\n### CHAP\nCHAP is an authentication protocol within PPP that verifies a device’s identity using a three-way handshake and a shared secret (password). Instead of sending the password directly, CHAP uses a challenge-response mechanism with hashing, making it more secure than PAP. It’s negotiated during the LCP phase (authentication protocol option, Type 0x03, Value 0xC223) and executed in the Authenticate Phase.\n\n### CHAP Packet Structure\nCHAP packets are encapsulated in PPP frames, similar to PAP and LCP packets. Here’s the breakdown:\n\n1. **PPP Frame Wrapping**:\n   - CHAP packets are carried inside a PPP frame.\n   - The PPP frame structure is:\n     - **Flag**: 0x7E (start/end of frame).\n     - **Address**: 0xFF (simplified in PPP).\n     - **Control**: 0x03 (simplified in PPP).\n     - **Protocol**: For CHAP, this is **0xC223** (indicating CHAP).\n     - **Information**: Contains the CHAP packet.\n     - **FCS**: Frame Check Sequence (error detection).\n     - **Flag**: 0x7E (end of frame).\n\n2. **CHAP Packet Fields** (inside the Information field of the PPP frame):\n   - **Code** (1 byte): Identifies the type of CHAP packet (e.g., challenge, response, success, or failure).\n   - **Identifier** (1 byte): A unique number to match requests with responses (e.g., a challenge and its response share the same Identifier).\n   - **Length** (2 bytes): Total length of the CHAP packet (including Code, Identifier, Length, and Data fields).\n   - **Data** (variable): Contains the challenge, response, or result message, depending on the packet type.\n\nSo, the CHAP packet structure is:\n```\n| Code (1 byte) | Identifier (1 byte) | Length (2 bytes) | Data (variable) |\n```\n\n### Types of CHAP Packets (Based on the Code Field)\nCHAP uses four main packet types, identified by the Code field:\n\n1. **Challenge (Code 0x01)**:\n   - Sent by the authenticator (e.g., a server) to the peer (e.g., a client) to start the authentication process.\n   - The Data field contains:\n     - **Value-Size** (1 byte): Length of the challenge value.\n     - **Value** (variable): A random challenge string (usually 16 bytes or more, generated by the authenticator).\n     - **Name** (variable): The authenticator’s name (used by the peer to look up the shared secret).\n   - Example: If the challenge value is a 16-byte random string and the authenticator’s name is \"Server1\":\n     ```\n     | 0x10 (Value-Size) | <16-byte random string> | Server1 (7 bytes) |\n     ```\n\n2. **Response (Code 0x02)**:\n   - Sent by the peer back to the authenticator in response to the challenge.\n   - The Data field contains:\n     - **Value-Size** (1 byte): Length of the response value (usually 16 bytes for MD5 hashing).\n     - **Value** (variable): The hashed response. The peer calculates this by hashing the Identifier, the shared secret (password), and the challenge value using MD5:\n       - Hash = MD5(Identifier + Secret + Challenge).\n     - **Name** (variable): The peer’s name (used by the authenticator to look up the shared secret).\n   - Example: If the response value is a 16-byte MD5 hash and the peer’s name is \"Client1\":\n     ```\n     | 0x10 (Value-Size) | <16-byte MD5 hash> | Client1 (7 bytes) |\n     ```\n\n3. **Success (Code 0x03)**:\n   - Sent by the authenticator if the peer’s response matches the expected hash (authentication succeeds).\n   - The Data field contains:\n     - **Message** (variable, optional): A success message (e.g., \"Authentication successful\").\n   - Example: If the message is \"Auth OK\":\n     ```\n     | Auth OK (7 bytes) |\n     ```\n\n4. **Failure (Code 0x04)**:\n   - Sent by the authenticator if the peer’s response doesn’t match the expected hash (authentication fails).\n   - The Data field contains:\n     - **Message** (variable, optional): A failure message (e.g., \"Authentication failed\").\n   - Example: If the message is \"Auth Failed\":\n     ```\n     | Auth Failed (11 bytes) |\n     ```\n\n### How CHAP Authentication Works in PPP\nCHAP uses a three-way handshake during the PPP Authenticate Phase:\n1. **LCP Negotiation**: During the Establish Phase, LCP negotiates CHAP as the authentication protocol (Type 0x03, Value 0xC223 in LCP’s Configure-Request).\n2. **Challenge**: The authenticator sends a Challenge packet with a random value and its name.\n3. **Response**:\n   - The peer looks up the shared secret (password) based on the authenticator’s name.\n   - It computes the hash: MD5(Identifier + Secret + Challenge).\n   - The peer sends a Response packet with the hash and its name.\n4. **Verification**:\n   - The authenticator looks up the shared secret using the peer’s name.\n   - It computes the expected hash using the same formula: MD5(Identifier + Secret + Challenge).\n   - If the peer’s hash matches the expected hash, the authenticator sends a Success packet; otherwise, it sends a Failure packet.\n5. **Outcome**:\n   - Success: The PPP link moves to the Network Phase (e.g., to configure IP with IPCP).\n   - Failure: The link may terminate or retry (depending on implementation).\n\n### Example Exchange\n- Authenticator sends: Challenge (Code 0x01, Identifier 0x01, Value = <16-byte random string>, Name = \"Server1\").\n- Peer calculates: Hash = MD5(`0x01 + <shared secret> + <16-byte random string>)`.\n- Peer sends: Response (`Code 0x02, Identifier 0x01, Value = <16-byte hash>, Name = \"Client1\")`.\n- Authenticator verifies the hash:\n  - If it matches: Success (Code 0x03, Identifier 0x01, Message = \"Auth OK\").\n  - If it doesn’t: Failure (Code 0x04, Identifier 0x01, Message = \"Auth Failed\").\n\n### Key Characteristics of CHAP\n- **Secure**: Passwords aren’t sent over the link; only hashed values are exchanged.\n- **Three-Way Handshake**: Challenge → Response → Success/Failure.\n- **Periodic Re-authentication**: CHAP can re-challenge the peer during the session to ensure continued security.\n- **Hashing**: Uses MD5 by default (though modern implementations may use stronger algorithms like SHA).\n\n### Comparison with PAP\n- PAP sends username/password in plain text; CHAP uses a hashed challenge-response.\n- PAP is a two-way handshake; CHAP is a three-way handshake.\n- CHAP’s Protocol field in the PPP frame is 0xC223; PAP’s is 0xC023.\n\n### IPCP\nIPCP is a Network Control Protocol (NCP) within PPP, specifically for configuring IP (IPv4) over a PPP link. After LCP sets up the link (Establish Phase) and authentication (e.g., PAP/CHAP) succeeds, IPCP negotiates IP-related parameters like IP addresses, DNS servers, and compression settings during the Network Phase.\n\n### IPCP Packet Structure\nIPCP packets are encapsulated in PPP frames, similar to LCP, PAP, and CHAP packets:\n1. **PPP Frame Wrapping**:\n   - **Flag**: 0x7E (start/end of frame).\n   - **Address**: 0xFF (simplified in PPP).\n   - **Control**: 0x03 (simplified in PPP).\n   - **Protocol**: For IPCP, this is **0x8021** (indicating IPCP).\n   - **Information**: Contains the IPCP packet.\n   - **FCS**: Frame Check Sequence (error detection).\n   - **Flag**: 0x7E (end of frame).\n\n2. **IPCP Packet Fields** (inside the Information field):\n   - **Code** (1 byte): Identifies the packet type (e.g., request, ack).\n   - **Identifier** (1 byte): Matches requests with responses.\n   - **Length** (2 bytes): Total length of the IPCP packet.\n   - **Data** (variable): Contains configuration options in Type-Length-Value (TLV) format.\n\nStructure:\n```\n| Code (1 byte) | Identifier (1 byte) | Length (2 bytes) | Data (variable) |\n```\n\n### Types of IPCP Packets (Based on the Code Field)\nIPCP packets are similar to LCP in terms of negotiation. Common types include:\n1. **Configure-Request (Code 0x01)**:\n   - Proposes IP configuration options (e.g., IP address).\n   - Data field: Options in TLV format (e.g., Type 0x03 for IP Address, Value = 192.168.1.10).\n2. **Configure-Ack (Code 0x02)**:\n   - Accepts all options in the Configure-Request.\n   - Data field: Echoes the accepted options.\n3. **Configure-Nak (Code 0x03)**:\n   - Rejects some options but suggests alternatives (e.g., suggests a different IP address).\n4. **Configure-Reject (Code 0x04)**:\n   - Rejects unsupported options.\n5. **Terminate-Request (Code 0x05)** and **Terminate-Ack (Code 0x06)**:\n   - Used to close the IP layer of the PPP link.\n6. **Code-Reject (Code 0x07)**:\n   - Rejects unknown IPCP packet types.\n\n### Common IPCP Options (in the Data Field)\nOptions are in TLV format:\n- **IP-Address (Type 0x03)**: Specifies the device’s IP address (e.g., 192.168.1.10).\n- **Primary-DNS-Server (Type 0x81)**: Specifies the primary DNS server address.\n- **Secondary-DNS-Server (Type 0x83)**: Specifies the secondary DNS server address.\n- **IP-Compression-Protocol (Type 0x02)**: Negotiates compression (e.g., Van Jacobson TCP/IP header compression).\n\n### How IPCP Works in PPP\n1. **After LCP and Authentication**: Once the PPP link is up (post-LCP) and authenticated (post-PAP/CHAP), the Network Phase begins.\n2. **IPCP Negotiation**:\n   - The peer sends a Configure-Request with desired options (e.g., IP-Address = 0.0.0.0 to request an address).\n   - The other device responds:\n     - Configure-Ack: Accepts the options.\n     - Configure-Nak: Suggests alternatives (e.g., assigns an IP like 192.168.1.10).\n     - Configure-Reject: Rejects unsupported options.\n   - Negotiation continues until both sides agree.\n3. **IP Communication**: Once IPCP negotiation succeeds, IP data can flow over the PPP link.\n\n### Example Exchange\n- Peer sends: Configure-Request (Code 0x01, Identifier 0x01, IP-Address = 0.0.0.0, requesting an IP).\n- Server responds: Configure-Nak (Code 0x03, Identifier 0x01, IP-Address = 192.168.1.10, suggesting an IP).\n- Peer sends: Configure-Request (Code 0x01, Identifier 0x02, IP-Address = 192.168.1.10).\n- Server responds: Configure-Ack (Code 0x02, Identifier 0x02, IP-Address = 192.168.1.10)."
  },
  {
    "url": "University/Computer_Networks/Module_2/Multiple_Access_protocols.html",
    "content": "## **1. Pure ALOHA**\n### **Concept:**\n- Developed in the **1970s** for early wireless networks.\n- **Completely decentralized**—no synchronization required.\n- Stations transmit **whenever they have data**.\n- If a collision occurs, they wait for a **random backoff time** before retransmitting.\n\n### **How It Works:**\n1. **Transmission:**\n   - A station sends data immediately when ready.\n2. **Collision Detection:**\n   - If two stations transmit at the same time, their packets collide and are destroyed.\n3. **Retransmission:**\n   - After a collision, stations wait for a **random delay** before trying again.\n\n### **Efficiency:**\n- **Maximum throughput: ~18.4%** (due to high collision probability).\n- **Vulnerable Period:** Two packets can collide if sent within **2 × packet transmission time (2T)**.\n\n### **Advantages:**\n- Simple to implement.\n- No need for synchronization.\n\n### **Disadvantages:**\n- Low efficiency due to high collision rate.\n- Poor performance in high-traffic networks.\n\n### **Use Case:**\n- Early satellite and wireless networks.\n\n---\n\n## **2. Slotted ALOHA**\n### **Concept:**\n- An **improvement over Pure ALOHA**.\n- Time is divided into **fixed-length slots** (equal to packet transmission time).\n- Stations can **only transmit at the start of a slot** (synchronized).\n\n### **How It Works:**\n1. **Slot Synchronization:**\n   - All stations agree on slot boundaries.\n2. **Transmission:**\n   - A station transmits **only at the beginning of a slot**.\n3. **Collision Handling:**\n   - If two stations transmit in the same slot, they collide and retry after a random delay.\n\n### **Efficiency:**\n- **Maximum throughput: ~36.8%** (twice as efficient as Pure ALOHA).\n- **Vulnerable Period:** Only **1 × slot time (T)** (better than Pure ALOHA).\n\n### **Advantages:**\n- Higher efficiency than Pure ALOHA.\n- Still simple to implement.\n\n### **Disadvantages:**\n- Requires **time synchronization**.\n- Still suffers from collisions in high-load scenarios.\n\n### **Use Case:**\n- Early satellite communications, RFID systems.\n\n---\n\n## **3. CSMA/CD (Carrier Sense Multiple Access with Collision Detection)**\n### **Concept:**\n- Used in **Ethernet (wired networks)**.\n- Stations **sense the channel before transmitting**.\n- If a collision is detected, transmission is **aborted immediately**.\n\n### **How It Works:**\n1. **Carrier Sensing:**\n   - A station listens to the medium before sending.\n   - If idle, it transmits; if busy, it waits.\n2. **Collision Detection:**\n   - If two stations transmit simultaneously, a collision occurs.\n   - Both detect the collision and **stop transmission**.\n3. **Backoff & Retransmission:**\n   - Stations wait for a **random time (binary exponential backoff)** before retrying.\n\n### **Efficiency:**\n- Works well in **low to moderate traffic**.\n- **Breaks down in high-traffic or large networks** (due to increased collisions).\n\n### **Advantages:**\n- Reduces collisions compared to ALOHA.\n- Widely used in wired Ethernet.\n\n### **Disadvantages:**\n- **Not suitable for wireless networks** (collision detection is hard in wireless).\n- Performance degrades with network size.\n\n### **Use Case:**\n- Traditional **Ethernet (IEEE 802.3)**.\n\n---\n\n## **4. CSMA/CA (Carrier Sense Multiple Access with Collision Avoidance)**\n### **Concept:**\n- Used in **Wi-Fi (wireless networks)**.\n- Since **collision detection is difficult in wireless**, CSMA/CA **avoids collisions** rather than detecting them.\n- Uses **RTS/CTS (Request-to-Send / Clear-to-Send)** for reservation.\n\n### **How It Works:**\n1. **Carrier Sensing:**\n   - Station checks if the channel is idle.\n2. **Random Backoff (IFS - Interframe Space):**\n   - Waits for a **DIFS (DCF Interframe Space)** period.\n   - If idle, it picks a **random backoff timer** before transmitting.\n3. **Virtual Sensing (NAV - Network Allocation Vector):**\n   - Uses **RTS/CTS** to reserve the channel.\n   - Other stations defer transmission based on NAV.\n4. **Acknowledgment (ACK):**\n   - Receiver sends an **ACK** after successful reception.\n\n### **Efficiency:**\n- Better suited for **wireless networks** than CSMA/CD.\n- **Slower than CSMA/CD** due to overhead (RTS/CTS/ACK).\n\n### **Advantages:**\n- Avoids hidden terminal problem (using RTS/CTS).\n- Works well in wireless environments.\n\n### **Disadvantages:**\n- **Higher overhead** (RTS/CTS/ACK).\n- **Slower than CSMA/CD**.\n\n### **Use Case:**\n- **Wi-Fi (IEEE 802.11)**.\n\n---\n\n## **5. Comparison of Multiple Access Protocols**\n| Protocol          | Type             | Key Feature                                | Efficiency          | Used in                 |\n| ----------------- | ---------------- | ------------------------------------------ | ------------------- | ----------------------- |\n| **Pure ALOHA**    | Random Access    | No synchronization, immediate transmission | ~18.4%              | Early wireless networks |\n| **Slotted ALOHA** | Random Access    | Time-slotted transmission                  | ~36.8%              | Satellite comms, RFID   |\n| **CSMA/CD**       | Contention-Based | Detects collisions, aborts transmission    | High (wired)        | Ethernet (802.3)        |\n| **CSMA/CA**       | Contention-Based | Avoids collisions (RTS/CTS)                | Moderate (wireless) | Wi-Fi (802.11)          |"
  },
  {
    "url": "University/Computer_Networks/Module_3/Address_Mapping.html",
    "content": "The Address Resolution Protocol (ARP) is a protocol used in IP networks to map an IP address (Layer 3) to a physical or MAC address (Layer 2) within a local area network (LAN). This mapping is crucial because devices on a LAN communicate using MAC addresses, but higher-level protocols like IP use IP addresses.\n\n### How ARP Works:\n1. **ARP Request**: When a device (e.g., a host or router) needs to send a packet to an IP address on the same LAN but doesn’t know the corresponding MAC address, it broadcasts an ARP request. This request says, \"Who has this IP address? Please send me your MAC address.\"\n   - The request includes the sender’s IP and MAC addresses, the target IP, and a broadcast MAC address (since the target MAC is unknown).\n\n2. **ARP Reply**: The device with the matching IP address responds with an ARP reply, unicast directly to the sender, providing its MAC address.\n   - Other devices on the LAN ignore the request if the IP doesn’t match theirs.\n\n3. **ARP Cache**: The sender stores the IP-to-MAC mapping in its ARP cache (a temporary table) to avoid repeated ARP requests for the same IP. Entries in the cache typically expire after a set time (e.g., 20 minutes).\n\n### Four Types\n- **Case 1: A host sends a packet to another host on the same network.**\n  - The sender knows the target IP (destination address in the IP datagram).\n  - Since both hosts are on the same LAN, the sender uses ARP to resolve the target IP to the receiver’s MAC address.\n  - The packet is sent directly to the receiver using the resolved MAC address.\n\n- **Case 2: A host sends a packet to a host on another network.**\n  - The sender identifies that the target IP belongs to a different network.\n  - The sender uses ARP to resolve the IP address of the router (gateway) on its LAN.\n  - The packet is sent to the router’s MAC address, which then forwards it toward the destination network.\n\n- **Case 3: A router receives a packet to be sent to a host on another network.**\n  - The router knows the target IP (destination address in the IP datagram).\n  - The router looks up the next hop in its routing table, which points to another router.\n  - The router uses ARP to resolve the IP address of the next router to its MAC address and forwards the packet to that router.\n\n- **Case 4: A router receives a packet to be sent to a host on the same network.**\n  - The router recognizes that the target IP is on its local network (LAN).\n  - The router uses ARP to resolve the target IP to the host’s MAC address.\n  - The packet is sent directly to the host using the resolved MAC address.\n\n### RARP\nThe Reverse Address Resolution Protocol (RARP) is a protocol used to map a physical (MAC) address to an IP address, essentially the opposite of ARP. It was primarily used in older network environments to allow diskless workstations or devices without permanent storage to discover their IP addresses during boot.\n\n### How RARP Works:\n1. **RARP Request**: A device (e.g., a diskless workstation) knows its own MAC address but not its IP address. It broadcasts a RARP request on the local network, asking, \"My MAC address is X; what’s my IP address?\"\n   - The request includes the device’s MAC address and is sent to a broadcast address.\n\n2. **RARP Reply**: A RARP server (typically a host or router on the same LAN) hears the request and looks up the MAC address in its RARP table (a manually configured mapping of MAC-to-IP addresses). The server then sends a RARP reply directly to the requesting device with its assigned IP address.\n\n3. **Usage**: The device uses the received IP address to configure its network interface and proceed with communication, often as part of a boot process using protocols like BOOTP or TFTP to load an operating system.\n\n### Key Points:\n- **Limited Scope**: RARP operates within a single LAN (broadcast domain) and requires a dedicated RARP server with a preconfigured MAC-to-IP mapping table.\n- **Obsolete**: RARP is largely obsolete today, replaced by more advanced protocols like BOOTP (Bootstrap Protocol) and DHCP (Dynamic Host Configuration Protocol). These protocols are more flexible, support dynamic IP assignment, and can provide additional configuration details (e.g., subnet mask, gateway).\n- **Comparison to ARP**: While ARP resolves an IP address to a MAC address for packet delivery, RARP resolves a MAC address to an IP address for device configuration. Both operate at the link layer but serve different purposes.\n\n### Why RARP Fell Out of Use:\n- **Scalability Issues**: RARP required manual configuration of MAC-to-IP mappings, which was impractical for large networks.\n- **Limited Functionality**: It only provided an IP address, lacking support for other configuration parameters.\n- **Modern Alternatives**: DHCP, introduced in the 1990s, automates IP assignment, supports dynamic allocation, and provides additional network configuration details, making RARP unnecessary.\n\n### BOOTP\nThe Bootstrap Protocol (BOOTP) is a network protocol used to automatically assign IP addresses and other network configuration parameters to devices (clients) on a network, primarily during the boot process. It was designed to improve upon RARP by providing more configuration details and supporting diskless workstations or devices that need to load their operating system over the network.\n\n### How BOOTP Works:\n1. **BOOTP Request**: A client (e.g., a diskless workstation) broadcasts a BOOTP request on the network during boot. This request includes the client’s MAC address and is sent to a broadcast address (255.255.255.255) on UDP port 67.\n   - The client may also include a vendor-specific field to request additional information.\n\n2. **BOOTP Reply**: A BOOTP server on the network receives the request and looks up the client’s MAC address in its configuration file (a manually maintained table). The server responds with a BOOTP reply (sent to UDP port 68) containing:\n   - The client’s assigned IP address.\n   - Subnet mask.\n   - Default gateway (router) IP address.\n   - IP address of a server (e.g., TFTP server) for downloading a boot file (like an operating system image).\n   - The name of the boot file.\n   - Optionally, other parameters like DNS server addresses.\n\n3. **Client Configuration**: The client uses the received information to configure its network settings and may proceed to download a boot file (e.g., via TFTP) to complete its boot process.\n\n### Key Features:\n- **Static Mapping**: BOOTP relies on a manually configured table on the server that maps MAC addresses to IP addresses and other parameters. This means IP assignments are static and predefined.\n- **Cross-Network Support**: Unlike RARP, BOOTP can work across networks if a BOOTP relay agent (often a router) forwards the broadcast request to a server on another subnet.\n- **UDP-Based**: BOOTP uses UDP for communication, with the server listening on port 67 and the client on port 68.\n\n### Limitations:\n- **No Dynamic Allocation**: BOOTP doesn’t support dynamic IP address allocation; mappings must be manually configured, which is inefficient for large or changing networks.\n- **No Lease Time**: IP assignments are permanent unless manually changed, lacking the temporary lease mechanism of modern protocols.\n- **Limited Flexibility**: While more capable than RARP, BOOTP still lacks the extensibility needed for modern networks.\n\n### DHCP\nThe Dynamic Host Configuration Protocol (DHCP) is a network protocol that automatically assigns IP addresses and other network configuration parameters to devices (clients) on a network, enabling them to communicate using IP. It builds on BOOTP, offering more flexibility and scalability, and is widely used in modern networks to manage IP address allocation dynamically.\n\n### How DHCP Works:\nDHCP operates in a client-server model, typically using UDP (ports 67 for the server, 68 for the client). The process follows the **DORA** cycle (Discover, Offer, Request, Acknowledge):\n\n1. **Discover**: A client (e.g., a device booting up) broadcasts a DHCP Discover message to find a DHCP server. This message includes the client’s MAC address and a transaction ID.\n   - Sent to 255.255.255.255 (broadcast) since the client doesn’t yet have an IP address.\n\n2. **Offer**: DHCP servers on the network respond with a DHCP Offer message, providing an available IP address from their pool, along with configuration details like subnet mask, default gateway, DNS server IPs, and a lease time (how long the IP can be used).\n   - The offer is sent to the client’s MAC address via broadcast (since the client has no IP yet).\n\n3. **Request**: The client selects one offer (if multiple servers respond) and broadcasts a DHCP Request message, indicating the chosen server and requested IP address.\n   - This also informs other servers that their offers were not selected, so they can reclaim the offered IPs.\n\n4. **Acknowledge**: The chosen DHCP server responds with a DHCP Acknowledge (ACK) message, confirming the IP assignment and providing the full configuration (e.g., lease time, gateway, DNS).\n   - If there’s an issue (e.g., IP already taken), the server sends a DHCP NAK (negative acknowledgment), and the client restarts the process.\n\n### Key Features:\n- **Dynamic IP Allocation**: DHCP assigns IPs from a pool, reusing them as devices leave the network, unlike BOOTP’s static mappings.\n- **Lease Time**: IPs are leased for a specific duration (e.g., 24 hours). Clients must renew their lease before it expires, typically at 50% and 87.5% of the lease period, using a DHCP Request.\n- **Cross-Network Support**: DHCP relay agents (often on routers) forward DHCP messages between subnets, allowing a central DHCP server to manage multiple networks.\n- **Extensibility**: DHCP supports many options (e.g., DNS servers, time servers, domain names) via a flexible options field in its messages.\n\n### DHCP Message Types (Beyond DORA):\n- **DHCP Release**: A client sends this to release its IP address before the lease expires (e.g., when shutting down).\n- **DHCP Inform**: A client uses this to request configuration parameters without needing an IP (e.g., if the IP is statically assigned).\n- **DHCP Decline**: A client sends this if it detects the offered IP is already in use (e.g., via an ARP check).\n\n### Advantages Over BOOTP:\n- Dynamic allocation and IP reuse make it scalable for large networks.\n- Lease times prevent IP exhaustion and allow temporary assignments.\n- More configuration options and better support for modern network needs.\n\n### Use Case:\nDHCP is used in most networks (e.g., home Wi-Fi, enterprise LANs) to automate IP configuration for devices like computers, phones, and IoT devices. It reduces manual configuration errors and simplifies network management.\n\n### Limitations:\n- **Security Risks**: Rogue DHCP servers can assign incorrect IPs or redirect traffic (e.g., DHCP spoofing).\n- **Dependency on Server**: If the DHCP server is down, new devices can’t get IPs unless they use a fallback (e.g., APIPA, which assigns a 169.254.x.x address).\n- **Broadcast Traffic**: Initial DHCP messages are broadcasts, which can add network overhead in large setups."
  },
  {
    "url": "University/Computer_Networks/Module_3/Congestion_Control.html",
    "content": "## **Congestion Control**\nCongestion occurs when network traffic exceeds its capacity, leading to **packet loss, increased delay, and reduced throughput**. Congestion control mechanisms aim to **prevent or mitigate** network overload.\n\n### **Causes of Congestion:**\n- **High Traffic Load:** Too many packets sent simultaneously.\n- **Slow Receivers:** If a receiver cannot process data fast enough.\n- **Bottleneck Links:** Low-bandwidth links in the network path.\n- **Buffer Overflow:** Routers dropping packets when queues are full.\n\n### **Congestion Control vs. Flow Control**\n| Feature       | Congestion Control                                      | Flow Control                                    |\n| ------------- | ------------------------------------------------------- | ----------------------------------------------- |\n| **Scope**     | Network-wide (prevents traffic overload)                | End-to-end (prevents receiver overload)         |\n| **Mechanism** | Adjusts sending rate based on network conditions        | Adjusts sending rate based on receiver’s buffer |\n| **Example**   | TCP’s AIMD (Additive Increase, Multiplicative Decrease) | TCP’s Sliding Window                            |\n\n## **Quality of Service (QoS)**\nQoS refers to **prioritizing certain types of traffic** to ensure better performance for critical applications (e.g., VoIP, video streaming).\n\n### **QoS Parameters:**\n1. **Bandwidth:** Minimum guaranteed data rate.\n2. **Delay:** Maximum tolerable latency.\n3. **Jitter:** Variation in delay (critical for real-time apps).\n4. **Packet Loss:** Acceptable loss percentage.\n\n### **QoS Improving Techniques:**\n1. **Traffic Shaping:** Controls the rate of data transmission (e.g., **Leaky Bucket, Token Bucket**).\n2. **Packet Scheduling:** Prioritizes packets (e.g., **Priority Queuing, Weighted Fair Queuing**).\n3. **Resource Reservation:** Allocates bandwidth in advance (e.g., **RSVP - Resource Reservation Protocol**).\n4. **Admission Control:** Rejects new flows if the network is congested.\n\n---\n\n## **Leaky Bucket Algorithm**\n### **Concept:**\n- Models traffic flow as **water leaking from a bucket** at a **constant rate**.\n- Used for **smoothing bursty traffic** into a steady stream.\n\n### **Working:**\n1. **Bucket Analogy:**\n   - **Incoming Packets:** Represented as water poured into the bucket.\n   - **Leak Rate (Output Rate):** Fixed, regardless of input burst.\n   - **Bucket Size:** If full, excess packets are **discarded or marked**.\n\n2. **Algorithm Steps:**\n   - Packets arrive at **variable rates**.\n   - The bucket **stores them temporarily**.\n   - Packets exit at a **fixed rate (R)**.\n\n### **Advantages:**\n- **Smooths Traffic:** Converts bursty traffic into a steady flow.\n- **Prevents Network Overload:** Limits peak data rate.\n\n### **Disadvantages:**\n- **Does Not Adapt to Bursts:** Drops excess packets.\n- **Fixed Rate:** May not be optimal for all applications.\n\n### **Use Cases:**\n- **VoIP Traffic:** Ensures smooth voice transmission.\n- **Network Traffic Policing:** Enforces bandwidth limits.\n\n---\n\n## **4. Token Bucket Algorithm**\n### **Concept:**\n- More flexible than Leaky Bucket.\n- **Tokens** are added to a bucket at a **fixed rate**.\n- A packet can be transmitted **only if a token is available**.\n\n### **Working:**\n1. **Bucket Analogy:**\n   - **Tokens:** Represent permission to send data.\n   - **Token Generation Rate (R):** Tokens added at fixed intervals.\n   - **Bucket Capacity (C):** Maximum tokens stored.\n\n2. **Algorithm Steps:**\n   - Tokens are **added periodically** (e.g., 1 token every 1/R seconds).\n   - When a packet arrives:\n     - If **tokens available**, it is transmitted, and a token is **consumed**.\n     - If **no tokens**, the packet is **buffered or dropped**.\n   - **Burst Handling:** Allows short bursts up to bucket capacity.\n\n### **Advantages:**\n- **Allows Controlled Bursts:** Better for variable traffic.\n- **More Flexible:** Adapts better than Leaky Bucket.\n\n### **Disadvantages:**\n- **Complexity:** Requires token management.\n- **Not Strictly Rate-Limiting:** Bursts can still cause congestion.\n\n### **Use Cases:**\n- **Video Streaming:** Handles variable bitrate traffic.\n- **Traffic Shaping in ISPs:** Manages user bandwidth.\n\n---\n\n## **Leaky Bucket vs. Token Bucket**\n| Feature             | Leaky Bucket                   | Token Bucket                       |\n| ------------------- | ------------------------------ | ---------------------------------- |\n| **Traffic Shaping** | Strictly enforces a fixed rate | Allows controlled bursts           |\n| **Burst Handling**  | Drops excess packets           | Permits bursts if tokens available |\n| **Complexity**      | Simpler                        | More complex (token management)    |\n| **Flexibility**     | Less flexible                  | More flexible                      |\n| **Use Cases**       | VoIP, policing                 | Video streaming, traffic shaping   |\n"
  },
  {
    "url": "University/Computer_Networks/Module_3/Delivery.html",
    "content": "In networking, **delivery** refers to the process of transmitting a packet from a source to a destination across a network. Delivery can be categorized into two types: **direct delivery** and **indirect delivery**, depending on whether the source and destination are on the same network (subnet) or different networks.\n\n### Direct Delivery:\n- **Definition**: Direct delivery occurs when the source and destination devices are on the same network (same subnet or LAN). The packet is sent directly from the source to the destination without involving intermediate routers.\n- **How It Works**:\n  1. The source device checks the destination IP address and compares it with its own subnet mask to determine if the destination is on the same network.\n  2. If it is, the source uses ARP (Address Resolution Protocol) to resolve the destination IP to its MAC address.\n  3. The packet is encapsulated in a frame with the destination’s MAC address and sent directly over the LAN to the destination.\n- **Example (from the Image - Case 1)**: A host sends a packet to another host on the same LAN. The target IP is the destination address in the IP datagram, and ARP resolves it to the receiver’s MAC address for direct delivery.\n- **Key Point**: No routers are involved; the delivery is handled entirely at the data link layer (Layer 2).\n\n### Indirect Delivery:\n- **Definition**: Indirect delivery occurs when the source and destination are on different networks (subnets). The packet must pass through one or more routers to reach the destination.\n- **How It Works**:\n  1. The source device determines that the destination IP is on a different network by comparing it with its subnet mask.\n  2. The source sends the packet to its default gateway (a router) on its LAN. It uses ARP to resolve the router’s IP to its MAC address and sends the packet to the router.\n  3. The router looks up the destination IP in its routing table to determine the next hop (another router or the final destination).\n  4. This process repeats across routers (indirect hops) until the packet reaches a router on the destination’s network.\n  5. The final router performs direct delivery to the destination host using ARP to resolve the destination’s MAC address.\n- **Examples (from the Image)**:\n  - **Case 2**: A host sends a packet to a host on another network. The packet is first sent to the router (indirect delivery), which forwards it toward the destination network.\n  - **Case 3**: A router forwards a packet to another router (indirect delivery) because the destination is on a different network.\n  - **Case 4**: The final router delivers the packet to a host on its own network (this step is direct delivery, but the overall process involved indirect delivery through prior routers).\n- **Key Point**: Indirect delivery involves multiple hops across routers, operating at the network layer (Layer 3), with each hop potentially involving direct delivery at the link layer within a subnet.\n\n![[Pasted image 20250504024524.png]]\n\n### Forwarding\nForwarding is the process by which a router or network device determines where to send a packet toward its destination based on the destination IP address. It involves looking up the next hop (the next device in the path) and sending the packet there. Forwarding occurs at the network layer (Layer 3) and is a key part of packet delivery across networks, especially in **indirect delivery** (as seen in Cases 2, 3, and 4 in the image).\n\n### Forwarding Techniques:\nForwarding techniques describe how routers decide the next hop for a packet. The main techniques are:\n\n1. **Next-Hop Forwarding**:\n   - The router uses the destination IP address to look up the next hop in its routing table.\n   - The routing table provides the IP address of the next device (router or host) and the outgoing interface.\n   - Example: In Case 3 of the image, a router receives a packet, looks up the next router’s IP in its routing table, and forwards the packet to that router (indirect delivery).\n\n2. **Network-Specific Forwarding**:\n   - The router forwards packets based on the destination network rather than the specific host.\n   - The routing table has entries for networks (e.g., 192.168.1.0/24), and the router matches the destination IP to the appropriate network entry.\n   - This reduces the size of routing tables by grouping hosts into networks.\n\n3. **Host-Specific Forwarding**:\n   - The router forwards packets to a specific host, not just a network.\n   - This is less common and used for special cases (e.g., a specific server needing unique routing).\n\n4. **Default Forwarding (Default Route)**:\n   - If no specific match is found in the routing table, the router uses a default route (often 0.0.0.0/0) to forward the packet to a default gateway.\n   - Example: In Case 2, the host sends a packet to a different network via its default gateway (router), which then forwards it further.\n\n### Forwarding Process:\nThe forwarding process outlines the steps a router takes to forward a packet:\n\n1. **Receive Packet**: The router receives a packet on one of its interfaces.\n   - Example: In Case 3, a router receives a packet destined for a host on another network.\n\n2. **Extract Destination IP**: The router examines the packet’s header to get the destination IP address.\n   - Example: In Case 4, the router sees the destination IP (a host on its own network).\n\n3. **Routing Table Lookup**:\n   - The router consults its routing table to find the best match for the destination IP.\n   - It uses the longest prefix match (most specific route). For example, a route for 192.168.1.0/24 is chosen over 192.168.0.0/16 if the destination is 192.168.1.10.\n\n4. **Determine Next Hop**:\n   - The routing table provides the next-hop IP address (another router or the final host) and the outgoing interface.\n   - Example: In Case 3, the routing table points to another router as the next hop (as indicated by “IP address of the appropriate router found in the routing table”).\n\n5. **ARP Resolution (if needed)**:\n   - If the next hop is on the same network, the router uses ARP to resolve the next hop’s IP to a MAC address.\n   - Example: In Case 4, the router resolves the host’s IP to its MAC address for direct delivery.\n\n6. **Forward Packet**:\n   - The router encapsulates the packet in a new frame with the next hop’s MAC address and sends it out the appropriate interface.\n   - Example: In Case 2, the host forwards the packet to the router, which then forwards it toward the destination network.\n\n7. **Repeat (if Indirect)**:\n   - If the next hop is another router, the process repeats until the packet reaches the destination network for direct delivery (as in Case 4).\n\n### Routing Table:\nA routing table is a data structure stored in a router that maps destination IP addresses (or networks) to next-hop addresses and outgoing interfaces. It’s the core of the forwarding process.\n\n#### Structure of a Routing Table:\n- **Destination**: The target network or host IP (e.g., 192.168.1.0/24 for a network).\n- **Mask**: The subnet mask to determine the range of IPs covered (e.g., /24 means the first 24 bits must match).\n- **Next Hop**: The IP address of the next device to send the packet to (e.g., another router or the final host).\n- **Interface**: The outgoing interface on the router to use (e.g., eth0).\n- **Metric (optional)**: A value indicating the route’s preference (lower is better) if multiple routes exist.\n- **Gateway (optional)**: For default routes, the default gateway IP.\n\n#### Example Routing Table:\n| Destination | Mask | Next Hop      | Interface |\n| ----------- | ---- | ------------- | --------- |\n| 192.168.1.0 | /24  | Direct        | eth0      |\n| 10.0.0.0    | /8   | 192.168.1.1   | eth1      |\n| 0.0.0.0     | /0   | 192.168.1.254 | eth1      |\n\n- If a packet is destined for 192.168.1.10, it matches 192.168.1.0/24, and the router delivers it directly via eth0 (direct delivery, like Case 4).\n- If a packet is destined for 10.0.0.5, it matches 10.0.0.0/8, and the router forwards it to 192.168.1.1 via eth1 (indirect delivery, like Case 3).\n- If a packet is destined for 172.16.1.1 (no specific match), it uses the default route (0.0.0.0/0) and forwards to 192.168.1.254 (like Case 2).\n"
  },
  {
    "url": "University/Computer_Networks/Module_3/Process_To_Process_Delivery.html",
    "content": "Process-to-process delivery is a fundamental concept in computer networking where data is transmitted between applications (processes) running on different hosts. This is achieved using **transport layer protocols** such as **UDP (User Datagram Protocol), TCP (Transmission Control Protocol), and SCTP (Stream Control Transmission Protocol)**. Each protocol has distinct characteristics, making them suitable for different types of communication.\n\n## **1. Process-to-Process Delivery**\nBefore diving into UDP, TCP, and SCTP, it's essential to understand how data moves between processes.\n\n### **Key Concepts:**\n- **Host-to-Host vs. Process-to-Process:**\n  - **Host-to-Host (Network Layer - IP):** Ensures data reaches the correct machine.\n  - **Process-to-Process (Transport Layer - UDP/TCP/SCTP):** Ensures data reaches the correct application on that machine.\n  \n- **Port Numbers:**\n  - Used to identify processes (applications).\n  - **Well-known ports (0–1023):** HTTP (80), FTP (21), SSH (22).\n  - **Registered ports (1024–49151):** Assigned by IANA for specific services.\n  - **Dynamic/Private ports (49152–65535):** Used temporarily by clients.\n\n- **Multiplexing & Demultiplexing:**\n  - **Multiplexing:** Combining multiple application data streams into one transport layer segment.\n  - **Demultiplexing:** Separating received data and delivering it to the correct application.\n\n---\n\n## **2. UDP (User Datagram Protocol)**\n### **Overview:**\n- **Connectionless:** No handshaking before sending data.\n- **Unreliable:** No guarantees for delivery, ordering, or duplicate protection.\n- **Lightweight:** Low overhead (small header, no flow/error control).\n\n### **UDP Header (8 Bytes)**\n| Field            | Size (Bytes) | Description                        |\n| ---------------- | ------------ | ---------------------------------- |\n| Source Port      | 2            | Sender’s port (optional, can be 0) |\n| Destination Port | 2            | Receiver’s port                    |\n| Length           | 2            | Total length (header + data)       |\n| Checksum         | 2            | Error detection (optional)         |\n\n### **Characteristics of UDP:**\n1. **No Connection Establishment:** Data is sent immediately.\n2. **No Acknowledgments (ACKs):** No retransmission of lost packets.\n3. **No Flow Control:** Sender can overwhelm the receiver.\n4. **No Congestion Control:** Can contribute to network congestion.\n5. **Supports Multicast & Broadcast:** Useful for streaming, DNS, DHCP.\n\n### **Use Cases:**\n- **DNS (Domain Name System):** Fast lookups.\n- **VoIP (Voice over IP):** Real-time communication.\n- **Online Gaming:** Low latency preferred over reliability.\n- **IoT & Sensor Data:** Small, frequent transmissions.\n\n---\n\n## **3. TCP (Transmission Control Protocol)**\n### **Overview:**\n- **Connection-Oriented:** Requires a **three-way handshake** before data transfer.\n- **Reliable:** Guarantees delivery, ordering, and error detection.\n- **Flow & Congestion Control:** Prevents overwhelming the receiver or network.\n\n### **TCP Header (20–60 Bytes)**\n| Field                 | Size (Bytes) | Description                             |\n| --------------------- | ------------ | --------------------------------------- |\n| Source Port           | 2            | Sender’s port                           |\n| Destination Port      | 2            | Receiver’s port                         |\n| Sequence Number       | 4            | Byte position in the stream             |\n| Acknowledgment Number | 4            | Next expected byte                      |\n| Header Length         | 1.5          | Size of the header (in 32-bit words)    |\n| Control Flags         | 1.5          | SYN, ACK, FIN, RST, etc.                |\n| Window Size           | 2            | Receiver’s buffer size (flow control)   |\n| Checksum              | 2            | Error detection                         |\n| Urgent Pointer        | 2            | Points to urgent data (if URG flag set) |\n| Options               | 0–40         | Additional features (MSS, SACK, etc.)   |\n\n### **Key Features of TCP:**\n1. **Three-Way Handshake (Connection Establishment):**\n   - **SYN** → **SYN-ACK** → **ACK**\n   - Ensures both sides are ready.\n\n2. **Reliable Data Transfer:**\n   - **Sequence Numbers:** Track byte order.\n   - **ACKs:** Confirm received data.\n   - **Retransmission:** Lost packets are resent.\n\n3. **Flow Control (Sliding Window):**\n   - Adjusts sending rate based on receiver’s buffer.\n\n4. **Congestion Control (AIMD, Slow Start):**\n   - Prevents network overload.\n\n5. **Connection Termination (Four-Way Handshake):**\n   - **FIN** → **ACK** → **FIN** → **ACK**\n\n### **Use Cases:**\n- **HTTP/HTTPS (Web Browsing):** Reliable page loading.\n- **FTP (File Transfer):** Ensures complete file delivery.\n- **Email (SMTP):** Guarantees message integrity.\n- **SSH (Secure Shell):** Secure remote access.\n\n---\n\n## **4. SCTP (Stream Control Transmission Protocol)**\n### **Overview:**\n- **Combines features of TCP & UDP:** Reliable like TCP, but message-oriented like UDP.\n- **Multi-homing & Multi-streaming:** Supports multiple IP paths and parallel streams.\n- **Resistant to DoS attacks:** Better security than TCP.\n\n### **SCTP Header (12+ Bytes)**\n| Field            | Size (Bytes) | Description                      |\n| ---------------- | ------------ | -------------------------------- |\n| Source Port      | 2            | Sender’s port                    |\n| Destination Port | 2            | Receiver’s port                  |\n| Verification Tag | 4            | Protects against blind attacks   |\n| Checksum         | 4            | Error detection                  |\n| Chunks           | Variable     | Data, control, or error messages |\n\n### **Key Features of SCTP:**\n1. **Message-Oriented (Like UDP):** Preserves message boundaries.\n2. **Reliable (Like TCP):** ACKs, retransmissions, and sequencing.\n3. **Multi-Streaming:** Multiple independent data streams in one connection.\n4. **Multi-Homing:** Can use multiple network paths for redundancy.\n5. **No Head-of-Line Blocking:** Lost packet in one stream doesn’t block others.\n\n### **Use Cases:**\n- **VoIP & Video Conferencing:** Handles multiple streams efficiently.\n- **Telecom Signaling (SIGTRAN):** SS7 over IP.\n- **WebRTC:** Real-time communication.\n- **High-Availability Systems:** Multi-homing for failover.\n\n---\n\n## **5. Comparison: UDP vs. TCP vs. SCTP**\n| Feature                | UDP               | TCP                 | SCTP                  |\n| ---------------------- | ----------------- | ------------------- | --------------------- |\n| **Connection Type**    | Connectionless    | Connection-Oriented | Connection-Oriented   |\n| **Reliability**        | Unreliable        | Reliable            | Reliable              |\n| **Ordering**           | No                | Yes                 | Yes                   |\n| **Flow Control**       | No                | Yes                 | Yes                   |\n| **Congestion Control** | No                | Yes                 | Yes                   |\n| **Message Boundaries** | Preserved         | Byte-stream         | Preserved             |\n| **Multi-Streaming**    | No                | No                  | Yes                   |\n| **Multi-Homing**       | No                | No                  | Yes                   |\n| **Use Cases**          | DNS, VoIP, Gaming | Web, Email, FTP     | VoIP, Telecom, WebRTC |\n"
  },
  {
    "url": "University/Computer_Networks/Module_3/Routing Protocols.html",
    "content": "### **Unicast Routing**\nUnicast routing involves sending data from one source to one specific destination, as opposed to multicast (one-to-many) or broadcast (one-to-all). Routing protocols help routers exchange information about network topology and compute optimal paths for data packets based on metrics like hop count, bandwidth, or delay.\n\n### **Types of Unicast Routing Protocols**\nUnicast routing protocols are broadly classified into three categories based on their operation and scope:\n\n#### 1. **Distance Vector Protocols**\n- **How they work**: Routers share their entire routing table with directly connected neighbors periodically. Each router uses this information to calculate the shortest path to a destination based on a metric (e.g., hop count).\n- **Key features**:\n  - Simple to implement but slower to converge (update routing tables after topology changes).\n  - Prone to routing loops, mitigated by techniques like split horizon and route poisoning.\n- **Examples**:\n  - **RIP (Routing Information Protocol)**:\n    - Uses hop count as the metric (maximum 15 hops).\n    - Updates every 30 seconds.\n    - Suitable for small networks due to its simplicity.\n  - **IGRP (Interior Gateway Routing Protocol)**:\n    - Cisco proprietary, uses a composite metric (bandwidth, delay, etc.).\n    - Obsolete, replaced by EIGRP.\n- **Advantages**: Easy to configure, low resource usage.\n- **Disadvantages**: Limited scalability, slow convergence, and potential for routing loops.\n\n#### 2. **Link-State Protocols**\n- **How they work**: Each router floods the network with information about its directly connected links (link-state advertisements, LSAs). Routers use this data to build a complete topology map and compute the shortest path using Dijkstra’s algorithm.\n- **Key features**:\n  - Fast convergence and loop-free routing.\n  - Scalable for larger networks but requires more processing power and memory.\n  - Supports areas to reduce routing overhead in large networks.\n- **Examples**:\n  - **OSPF (Open Shortest Path First)**:\n    - Widely used in enterprise networks.\n    - Organizes networks into areas for efficiency.\n    - Uses cost (based on bandwidth) as the metric.\n  - **IS-IS (Intermediate System to Intermediate System)**:\n    - Common in ISP networks.\n    - Similar to OSPF but supports larger networks and is protocol-independent (works with IPv4 and IPv6).\n- **Advantages**: Fast convergence, scalability, and robustness.\n- **Disadvantages**: Complex configuration and higher resource demands.\n\n#### 3. **Path Vector Protocols**\n- **How they work**: Routers maintain a table of paths (or routes) to destinations, including the entire path’s attributes (e.g., AS numbers in BGP). Routes are selected based on policies rather than just metrics.\n- **Key features**:\n  - Used primarily for inter-domain routing (between autonomous systems).\n  - Highly scalable and flexible due to policy-based routing.\n- **Example**:\n  - **BGP (Border Gateway Protocol)**:\n    - **eBGP**: Used between different autonomous systems (e.g., ISPs).\n    - **iBGP**: Used within a single autonomous system.\n    - Selects paths based on attributes like AS path length, local preference, etc.\n- **Advantages**: Scalable, supports complex routing policies, and is the backbone of the Internet.\n- **Disadvantages**: Slow convergence and complex configuration.\n\n### **Interior vs. Exterior Gateway Protocols**\nUnicast routing protocols are also categorized by their scope:\n- **Interior Gateway Protocols (IGPs)**: Operate within a single autonomous system (AS). Examples: RIP, OSPF, IS-IS, EIGRP.\n- **Exterior Gateway Protocols (EGPs)**: Operate between autonomous systems. Example: BGP.\n\n### **Key Concepts in Unicast Routing Protocols**\n- **Routing Table**: A database in each router listing the best paths to destinations.\n- **Convergence**: The process of all routers updating their routing tables to reflect network changes. Faster convergence is critical for minimizing packet loss.\n- **Metrics**: Criteria for path selection (e.g., hop count, bandwidth, cost).\n- **Scalability**: The ability to handle large networks without performance degradation.\n- **Loop Prevention**: Techniques like split horizon, route poisoning, or path attributes to avoid routing loops.\n\n### **Comparison of Unicast Routing Protocols**\n\n| **Protocol** | **Type**                 | **Metric**             | **Convergence** | **Scalability** | **Use Case**                    |\n| ------------ | ------------------------ | ---------------------- | --------------- | --------------- | ------------------------------- |\n| RIP          | Distance Vector          | Hop count              | Slow            | Low             | Small networks                  |\n| OSPF         | Link-State               | Cost (bandwidth)       | Fast            | High            | Enterprise networks             |\n| IS-IS        | Link-State               | Cost                   | Fast            | High            | ISP networks                    |\n| BGP          | Path Vector              | Path attributes        | Slow            | Very High       | Internet, inter-AS routing      |\n| EIGRP        | Advanced Distance Vector | Bandwidth, delay, etc. | Fast            | High            | Cisco-based enterprise networks |\n### **Routing Protocol**\nA routing protocol is a set of rules that routers use to communicate and share information about network topology, allowing them to select the best path for forwarding packets. These protocols help in:\n- **Path Determination**: Choosing the best route based on metrics like hop count, bandwidth, delay, etc.\n- **Route Maintenance**: Updating routing tables when network changes occur (e.g., link failures).\n- **Loop Prevention**: Avoiding routing loops that can cause packet loss or inefficiency.\n\n### **Types of Routing Protocols**\nRouting protocols can be broadly classified into three categories:\n\n#### **A. Static Routing**\n- Routes are manually configured by a network administrator.\n- No dynamic updates; changes require manual intervention.\n- Suitable for small, stable networks.\n- **Advantages**: Low overhead, no bandwidth usage for updates.\n- **Disadvantages**: Not scalable, inflexible to network changes.\n\n#### **B. Dynamic Routing**\n- Routers automatically exchange routing information.\n- Adapts to topology changes (e.g., link failures, new networks).\n- Classified into:\n  1. **Distance Vector Protocols**\n     - Routers share their entire routing table with neighbors periodically.\n     - Use metrics like hop count to determine the best path.\n     - Examples: **RIP (Routing Information Protocol)**, **IGRP (Interior Gateway Routing Protocol)**.\n     - **Disadvantages**: Slow convergence, prone to routing loops.\n\n  2. **Link-State Protocols**\n     - Routers share information about their directly connected links (link-state advertisements).\n     - Each router builds a complete topology map and computes the shortest path (e.g., using Dijkstra’s algorithm).\n     - Examples: **OSPF (Open Shortest Path First)**, **IS-IS (Intermediate System to Intermediate System)**.\n     - **Advantages**: Faster convergence, more scalable.\n\n  3. **Hybrid Protocols**\n     - Combine features of distance vector and link-state protocols.\n     - Example: **EIGRP (Enhanced Interior Gateway Routing Protocol)** (Cisco proprietary).\n     - Uses **DUAL (Diffusing Update Algorithm)** for fast convergence.\n\n#### **C. Path Vector Protocols**\n- Used in large-scale networks like the Internet (Exterior Gateway Protocols).\n- Focus on policy-based routing and loop prevention.\n- Example: **BGP (Border Gateway Protocol)**.\n\n### **Classification Based on Network Scope**\n- **Interior Gateway Protocols (IGPs)**: Used within an **autonomous system (AS)** (e.g., OSPF, RIP, EIGRP).\n- **Exterior Gateway Protocols (EGPs)**: Used between different ASes (e.g., BGP).\n\n### **Routing Protocol Comparison**\n| Feature          | RIP             | OSPF                | EIGRP          | BGP              |\n| ---------------- | --------------- | ------------------- | -------------- | ---------------- |\n| **Type**         | Distance Vector | Link-State          | Hybrid         | Path Vector      |\n| **Metric**       | Hop Count       | Cost                | Composite      | Path Attributes  |\n| **Convergence**  | Slow            | Fast                | Very Fast      | Slow             |\n| **Scalability**  | Low             | High                | High           | Very High        |\n| **Use Case**<br> | Small Networks  | Enterprise Networks | Cisco Networks | Internet Routing |\n|                  |                 |                     |                |                  |"
  },
  {
    "url": "University/Data_Mining/Module_1/Data Mining.html",
    "content": "---\nid: Data Mining\naliases: []\ntags: []\ntitle: Data Mining\n---\n\n## Data Mining Architecture\nThe architecture of a data mining system outlines how components interact to extract knowledge from data\n\n1. **Data Sources**\n   - The raw input—databases, data warehouses, files (CSV, JSON), web data, or real-time streams.\n   - Provides the foundation for mining.\n\n2. **Data Preprocessing Layer**\n   - Cleans and prepares data for mining (more on this in your preprocessing question, but it’s critical here too).\n   - Ensures data quality by handling noise, missing values, and inconsistencies.\n   - **Example:** Removing duplicate customer entries or normalizing sales figures.\n\n3. **Data Mining Engine**\n   - The core algorithms and techniques that perform the actual pattern discovery.\n   - Executes tasks like classification, clustering, or association rule mining.\n   - **Example:** Running a decision tree algorithm to predict customer churn.\n\n4. **Pattern Evaluation Module**\n   - Assesses the mined patterns for validity, novelty, and usefulness.\n   - Filters out trivial or irrelevant results (e.g., “all customers buy something” isn’t insightful).\n   - Using a threshold (like lift or support) to evaluate association rules.\n\n5. **Knowledge Base**\n   - Stores domain knowledge to guide or refine the mining process.\n   - Helps interpret results or constrain the search (e.g., “focus on high-value customers”).\n   - A rule stating “sales peak in December” to prioritize seasonal patterns.\n\n6. **User Interface**\n   - The front-end for users to interact with the system, define tasks, and visualize results.\n   - Makes the system accessible and actionable.\n   - A dashboard showing clusters of customer behavior with clickable filters.\n\n**Architecture Flow:**\n- Data flows from sources → preprocessing → mining engine → evaluation → presentation, with the knowledge base influencing each step.\n- It’s iterative—users might tweak parameters or refine data based on initial results.\n\n**Types of Architectures:**\n- **Centralized:** All components on one server (simpler, less scalable).\n- **Distributed:** Data and processing spread across multiple nodes (e.g., Hadoop-based systems for big data).\n- **Coupled vs. Loose:** Tightly integrated with a database (e.g., SQL Server) vs. standalone tools (e.g., Python libraries).\n\n---\n\n### **Predictive Models**\nPredictive models use historical data to forecast future outcomes or classify data into categories. They’re about “what will happen” or “what belongs where.” Here’s the detailed rundown:\n\n1. **Definition**\n   - Predicts unknown values or events based on patterns in past data.\n   - Output is typically numerical (regression) or categorical (classification).\n\n2. **Key Techniques**\n   - **Classification:**\n     - Assigns items to predefined categories.\n     -  Decision Trees, Random Forests, Support Vector Machines (SVM), Neural Networks, Naive Bayes.\n     - **Example:** Predicting if an email is spam (yes/no) based on word patterns.\n     - **Detail:** Uses a training set with labeled data (e.g., “spam” or “not spam”) to learn decision boundaries.\n   - **Regression:**\n     - Predicts continuous values.\n     - Linear Regression, Polynomial Regression, Gradient Boosting.\n     - **Example:** Forecasting next month’s sales based on past trends.\n     - **Detail:** Fits a mathematical function (e.g., y = ax + b) to minimize prediction error.\n   - **Time Series Analysis:**\n     - Predicts future values in sequential data.\n     - ARIMA, LSTM (a type of neural network).\n     - **Example:** Predicting stock prices over time.\n     - **Detail:** Considers trends, seasonality, and lagged variables.\n\n3. **Characteristics**\n   - **Supervised Learning:** Relies on labeled training data (input-output pairs).\n   - **Evaluation Metrics:** Accuracy, precision, recall, F1-score (classification); RMSE, MAE (regression).\n   - **Challenges:** Overfitting (model too specific to training data), underfitting (too general), or insufficient data.\n\n4. **Applications**\n   - Fraud detection, customer churn prediction, weather forecasting, credit scoring.\n\n---\n\n### **Descriptive Models**\nDescriptive models summarize or describe patterns in data without predicting future outcomes. They’re about “what’s happening” or “what’s in the data.” Here’s the detailed scoop:\n\n1. **Definition**\n   - Identifies patterns, relationships, or structures in historical data.\n   - Output is often groupings, rules, or summaries.\n\n2. **Key Techniques**\n   - **Clustering:**\n     - Groups similar items without predefined labels.\n     - K-Means, Hierarchical Clustering, DBSCAN.\n     - **Example:** Segmenting customers into “budget” vs. “premium” buyers based on purchase behavior.\n     - **Detail:** Uses distance metrics (e.g., Euclidean) to measure similarity; requires choosing the number of clusters (e.g., K).\n   - **Association Rule Mining:**\n     - Finds relationships between items or events.\n     - Apriori, FP-Growth.\n     - **Example:** “If bread is bought, then butter is likely too” (market basket analysis).\n     - **Detail:** Measured by support (frequency), confidence (strength), and lift (improvement over random).\n   - **Summarization:**\n     - Provides concise descriptions of data.\n     - Statistical measures (mean, median), data cube aggregation.\n     - **Example:** Average sales per region.\n     - **Detail:** Often used in OLAP systems for reporting.\n\n3. **Characteristics**\n   - **Unsupervised Learning:** No labeled data needed—discovers structure organically.\n   - **Evaluation Metrics:** Silhouette score (clustering), support/confidence (association), or qualitative usefulness.\n   - **Challenges:** Interpretability (are clusters meaningful?), scalability with large datasets.\n\n4. **Applications**\n   - Market segmentation, anomaly detection, recommendation systems, trend analysis.\n\n---\n\n### **Predictive vs. Descriptive: Key Differences**\n- **Goal:**\n  - Predictive: Forecast or classify (future-focused).\n  - Descriptive: Summarize or group (present/past-focused).\n- **Learning Type:**\n  - Predictive: Supervised.\n  - Descriptive: Unsupervised.\n- **Example Question:**\n  - Predictive: “Will this customer buy again?”\n  - Descriptive: “What types of customers do we have?”\n\n---\n### **What Are Data Mining Primitives?**\nData mining primitives are the fundamental building blocks or components used to define and execute a data mining task. These primitives guide the process of discovering patterns, relationships, or insights from large volumes of data. They’re essential because raw data is often messy, and without clear directives, the mining process could churn out irrelevant or overwhelming results.\n\nThe concept of primitives comes from the idea of breaking down complex tasks into simpler, manageable units. In data mining, these units help bridge the gap between a user’s high-level goals (e.g., \"find fraud patterns\") and the low-level operations a system performs (e.g., scanning transaction records). Typically, data mining primitives include the following key elements:\n\n1. **Task-Relevant Data**: Specifies the dataset or subset of data to mine.\n2. **Type of Knowledge to Be Discovered**: Defines what kind of patterns or insights you’re after (e.g., clusters, associations, classifications).\n3. **Background Knowledge**: Incorporates domain-specific info or constraints to refine the process.\n4. **Interestingness Measures**: Criteria to evaluate whether the discovered patterns are useful or significant.\n5. **Representation of Discovered Patterns**: How the results should be presented (e.g., rules, graphs, trees).\n\n#### **1. Task-Relevant Data**\n- **What It Is**: This is the specific portion of data you want to analyze—like a database table, a CSV file, or a subset filtered by conditions (e.g., sales data from 2024).\n- **Why It Matters**: Mining an entire database might be overkill or computationally infeasible. Narrowing it down focuses the effort.\n- **Example**: If you’re studying customer churn for a telecom company, you’d select data like call logs, billing history, and customer demographics, ignoring unrelated data like server maintenance logs.\n- **Application**: In practice, tools like SQL queries or data preprocessing steps (e.g., in Python’s Pandas library) are used to extract this subset.\n\n#### **2. Type of Knowledge to Be Discovered**\n- **What It Is**: Defines the goal of the mining process. Common types include:\n  - **Classification**: Predicting a category (e.g., spam vs. not spam).\n  - **Clustering**: Grouping similar items (e.g., customer segments).\n  - **Association Rules**: Finding relationships (e.g., \"if bread, then butter\").\n  - **Sequential Patterns**: Identifying time-based sequences (e.g., purchase trends).\n  - **Regression**: Predicting numerical values (e.g., house prices).\n- **Why It Matters**: This tells the algorithm what to look for, shaping the techniques used (e.g., decision trees for classification, Apriori for association rules).\n- **Example**: In e-commerce, you might mine for association rules to uncover \"frequently bought together\" items.\n- **Application**: Retailers like Amazon use this to power recommendation engines.\n\n#### **3. Background Knowledge**\n- **What It Is**: Pre-existing knowledge or constraints from the domain, like rules, hierarchies, or assumptions (e.g., \"sales spike in December\").\n- **Why It Matters**: It prevents the system from rediscovering obvious or irrelevant patterns and improves efficiency.\n- **Example**: In healthcare, background knowledge might include \"patients over 60 are at higher risk for X,\" guiding the mining of medical records.\n- **Application**: Fraud detection systems use domain rules (e.g., \"transactions over $10,000 need scrutiny\") to prioritize anomalies.\n\n#### **4. Interestingness Measures**\n- **What It Is**: Metrics to filter out trivial or redundant findings. Common measures include:\n  - **Support**: How frequently a pattern occurs (e.g., 5% of transactions).\n  - **Confidence**: How reliable a rule is (e.g., 90% of bread buyers also buy butter).\n  - **Lift**: How much more likely a pattern is compared to random chance.\n  - **Novelty**: How unexpected or new the pattern is.\n- **Why It Matters**: Without this, you’d drown in meaningless results (e.g., \"everyone breathes air\" isn’t insightful).\n- **Example**: In market basket analysis, a rule like \"diapers → beer\" might have high support and confidence, making it \"interesting.\"\n- **Application**: Marketing teams use lift to identify cross-selling opportunities that beat random guessing.\n\n#### **5. Representation of Discovered Patterns**\n- **What It Is**: The format of the output, such as rules (if-then statements), decision trees, clusters, or visualizations (e.g., heatmaps).\n- **Why It Matters**: Different stakeholders need results in digestible forms—executives want summaries, analysts want details.\n- **Example**: A retailer might get \"if milk, then cookies (confidence: 85%)\" as a rule, or a cluster graph showing customer segments.\n- **Application**: Business intelligence tools like Tableau often visualize mined patterns for decision-making.\n\n---\n\n### **Applications of Data Mining Primitives**\n#### **1. Retail and E-Commerce**\n- **Primitive Used**: Association rules + interestingness measures (support, confidence, lift).\n- **Application**: Market basket analysis to optimize product placement or recommend items. Example: Walmart might discover \"diapers and beer\" sell together on Fridays, adjusting store layouts accordingly.\n\n#### **2. Healthcare**\n- **Primitive Used**: Classification + background knowledge.\n- **Application**: Predicting patient outcomes (e.g., diabetes risk) using medical histories, with domain rules like \"high BMI increases risk\" guiding the model.\n\n#### **3. Finance**\n- **Primitive Used**: Clustering + task-relevant data.\n- **Application**: Segmenting customers for targeted credit offers or detecting fraud by clustering unusual transaction patterns (e.g., sudden large withdrawals).\n\n#### **4. Marketing**\n- **Primitive Used**: Sequential patterns + representation (visualizations).\n- **Application**: Analyzing customer journeys (e.g., website → cart → purchase) to optimize campaigns, often visualized as funnels.\n\n#### **5. Telecommunications**\n- **Primitive Used**: Regression + interestingness measures.\n- **Application**: Predicting network usage to allocate resources, with measures like \"correlation strength\" ensuring actionable insights.\n\n#### **6. Social Media**\n- **Primitive Used**: Clustering + task-relevant data.\n- **Application**: Grouping users by interests based on posts and interactions, helping advertisers target niche audiences.\n\n### **Major issues in data mining**\n### **1. Data Quality Issues**\n- Algorithms rely on patterns. If the data is incomplete (e.g., missing customer ages) or inconsistent (e.g., \"NY\" vs. \"New York\"), the results will be unreliable or misleading.\n- **Example**: In healthcare, if patient records have missing blood pressure readings, a model predicting heart disease risk might fail.\n- **Real-World Impact**: A retailer analyzing sales data with duplicate transactions might overestimate demand, leading to overstocking.\n- **Mitigation**: Data preprocessing (cleaning, normalization) is critical, but it’s time-consuming and requires domain expertise.\n### **2. Scalability and Performance**\n- Traditional algorithms like K-means or Apriori can choke on massive datasets, requiring huge computational resources and time.\n- **Example**: Mining social media posts from millions of X users in real-time to detect trends would overwhelm a standard system.\n- **Real-World Impact**: Companies like Google or Amazon need distributed systems (e.g., Hadoop, Spark) to handle their scale, but smaller firms might lack the infrastructure.\n- **Mitigation**: Parallel processing, sampling, or approximate algorithms help, but they can trade off accuracy for speed.\n### **3. Overfitting and Underfitting**\n- Overfit models fail on new data (poor generalization), while underfit models miss the point entirely.\n- **Example**: A fraud detection system overfit to past credit card fraud might flag every unusual purchase, annoying customers with false positives.\n- **Real-World Impact**: In marketing, an underfit model might predict everyone loves the same ad, wasting budget on ineffective campaigns.\n- **Mitigation**: Techniques like cross-validation, regularization, or pruning decision trees help balance the fit.\n### **4. High Dimensionality**\n- More dimensions increase sparsity (data points spread too thin), making patterns harder to find and computations more expensive.\n- **Example**: Genomic data with thousands of gene expression variables for a small patient sample can confuse clustering algorithms.\n- **Real-World Impact**: In customer profiling, including every possible trait (e.g., age, income, shoe size) might obscure meaningful segments.\n- **Mitigation**: Dimensionality reduction (e.g., PCA) or feature selection can trim the fat, but choosing the right features is tricky.\n### **5. Privacy and Ethical Concerns**\n- People don’t want their data exploited, and breaches can lead to legal or reputational damage.\n- **Example**: Target famously predicted a teen’s pregnancy from shopping habits before her family knew, sparking privacy backlash.\n- **Real-World Impact**: GDPR and similar laws impose strict rules on data use, and violations can cost millions (e.g., Meta’s fines).\n- **Mitigation**: Anonymization, differential privacy, or explicit user consent help, but they can limit data utility.\n### **6. Handling Heterogeneous and Dynamic Data**\n- Integrating disparate formats or adapting to evolving patterns (concept drift) is tough.\n- **Example**: Mining X posts for sentiment requires handling text, emojis, and shifting slang—yesterday’s \"sick\" might mean \"cool\" today.\n- **Real-World Impact**: A stock prediction model trained on 2020 data might flop in 2025 due to market shifts.\n- **Mitigation**: Preprocessing (e.g., text tokenization) and online learning (updating models in real-time) help, but they’re resource-intensive.\n### **7. Interestingness and Relevance**\n- Not all discovered patterns are useful—some are obvious, redundant, or irrelevant to the user’s goals.\n- **Example**: In e-commerce, \"if socks, then shoes\" might have high confidence but be too obvious to act on.\n- **Real-World Impact**: Marketing teams might ignore mined insights if they don’t align with business needs.\n- **Mitigation**: Custom interestingness measures (e.g., lift, novelty) and user feedback loops refine focus, but defining \"useful\" is subjective.\n### **8. Computational Complexity**\n- Some data mining tasks (e.g., finding all association rules) have exponential complexity, making them impractical for large datasets.\n- **Example**: Mining every possible item combination in Walmart’s inventory could take years without constraints.\n- **Real-World Impact**: Companies might settle for suboptimal insights due to processing limits.\n- **Mitigation**: Heuristics, pruning techniques, or approximate algorithms (e.g., FP-growth instead of Apriori) reduce complexity.\n"
  },
  {
    "url": "University/Data_Mining/Module_1/Data Preprocessing.html",
    "content": "### **Data Preprocessing**\nData preprocessing transforms raw, messy data into a clean, structured format suitable for analysis. It’s often considered the most time-consuming part of data mining (taking up to 70-80% of the effort), but it’s essential for reliable results.\n\n---\n### **Data Cleaning**\n**Definition:** Data cleaning (or cleansing) involves detecting and correcting errors, inconsistencies, and missing values in the dataset to improve its quality.\n\nReal-world data is rarely perfect—think typos, duplicates, or gaps from faulty sensors. Cleaning ensures the mined patterns reflect reality, not noise.\n#### **Key Tasks in Data Cleaning**\n1. **Handling Missing Values**\n   - **Problem:** Data points are absent (e.g., a customer’s age is blank).\n   - **Techniques:**\n     - **Ignore:** Skip incomplete records (if minor and random).\n       - *Example:* Dropping 5 rows out of 10,000 where age is missing.\n       - *Pros:* Simple. *Cons:* Loses data.\n     - **Imputation:** Fill in missing values.\n       - *Mean/Median/Mode:* Use average (numerical) or most frequent (categorical) value.\n         - *Example:* Age missing? Use the dataset’s average age (e.g., 35).\n       - *Regression/KNN:* Predict missing values based on other features.\n         - *Example:* Predict age using income and location via a model.\n       - *Manual/Default:* Assign a placeholder (e.g., “Unknown” or -1).\n     - **Detail:** Choice depends on data type and missingness pattern (random vs. systematic).\n   - **Challenge:** Over-imputation can bias results (e.g., too many “average” ages).\n\n2. **Removing Noise**\n   - **Problem:** Erroneous or irrelevant data (e.g., a temperature reading of -500°C).\n   - **Techniques:**\n     - **Smoothing:** Average out fluctuations (e.g., moving average).\n       - *Example:* Replace a spiked sales value with a 3-day average.\n     - **Outlier Detection:** Identify and remove anomalies.\n       - *Methods:* Z-score (>3 standard deviations), IQR (outside 1.5× interquartile range).\n       - *Example:* A $10M purchase in a dataset of $10-$100 items is flagged.\n     - **Detail:** Noise vs. outlier depends on context—outliers might be valid (e.g., a billionaire’s purchase).\n   - **Challenge:** Distinguishing noise from meaningful rare events.\n\n3. **Resolving Inconsistencies**\n   - **Problem:** Data contradicts itself (e.g., “Male” in one column, “Pregnant” in another).\n   - **Techniques:**\n     - **Standardization:** Uniform formats (e.g., “USA” vs. “U.S.” → “United States”).\n       - *Example:* Convert all dates to YYYY-MM-DD.\n     - **Validation Rules:** Check against domain knowledge (e.g., age can’t be negative).\n       - *Example:* Flag records where birth year > current year.\n     - **Deduplication:** Remove redundant entries.\n       - *Example:* Merge two “John Doe” records with the same ID.\n   - **Detail:** Often requires domain expertise or external reference data (e.g., postal code lists).\n\n4. **Correcting Errors**\n   - **Problem:** Typos or data entry mistakes (e.g., “Nwe York” instead of “New York”).\n   - **Techniques:**\n     - **String Matching:** Fuzzy matching to fix typos.\n       - *Example:* “Nwe York” → “New York” using Levenshtein distance.\n     - **Data Profiling:** Analyze patterns to spot errors (e.g., all weights should be positive).\n   - **Challenge:** Automated fixes can introduce new errors if not validated.\n\n#### **Tools & Methods**\n- **Software:** Python (Pandas, NumPy), R, SQL, or ETL tools (Talend, Informatica).\n- **Metrics:** Completeness (%), accuracy (error rate), consistency (mismatch rate).\n\n#### **Example Workflow**\n- Dataset: Customer records with age, name, purchase amount.\n- Issues: Missing ages, duplicate names, negative purchases.\n- Cleaning: Impute ages with median, merge duplicates by ID, set negative purchases to zero.\n\n---\n\n### **Discretization**\n**Definition:** Discretization transforms continuous data (e.g., numerical ranges) into discrete categories or intervals, making it easier to analyze or use in certain algorithms.\n\n Many data mining techniques (e.g., decision trees, association rules) work better with categorical data. Plus, it simplifies interpretation.\n#### **Key Types of Discretization**\n1. **Unsupervised Discretization**\n   - **No prior knowledge or target variable used.**\n   - **Techniques:**\n     - **Equal-Width Binning:**\n       - *What it does:* Divides range into equal-sized intervals.\n       - *Example:* Age 0-100 into 5 bins: 0-20, 21-40, 41-60, 61-80, 81-100.\n       - *Formula:* Bin width = (max - min) / number of bins.\n       - *Pros:* Simple, uniform. *Cons:* Sensitive to outliers (e.g., one 99 skews bins).\n     - **Equal-Frequency Binning:**\n       - *What it does:* Divides data so each bin has roughly equal number of records.\n       - *Example:* 100 ages into 5 bins, each with 20 values (e.g., 0-25, 26-35, …).\n       - *Pros:* Balances data distribution. *Cons:* Bin ranges vary, less intuitive.\n   - **Detail:** Fast but may not capture meaningful patterns.\n\n2. **Supervised Discretization**\n   - **Uses a target variable to guide binning (common in predictive modeling).**\n   - **Techniques:**\n     - **Entropy-Based (e.g., Fayyad & Irani’s Method):**\n       - *What it does:* Splits based on minimizing entropy (information loss) relative to a class label.\n       - *Example:* Age split at 30 and 50 if those boundaries best predict “buys product” vs. “doesn’t.”\n       - *Detail:* Recursive partitioning, often used with decision trees.\n     - **Chi-Merge:**\n       - *What it does:* Merges adjacent intervals if they’re statistically similar (via Chi-square test).\n       - *Example:* Ages 20-25 and 26-30 merged if purchase behavior isn’t significantly different.\n   - **Pros:** Tailored to the task. *Cons:* Computationally intensive.\n\n3. **Custom Discretization**\n   - **Manually defined based on domain knowledge.**\n   - **Example:** Age bins like “Child (0-12),” “Teen (13-19),” “Adult (20-64),” “Senior (65+).”\n   - **Detail:** Intuitive but requires expertise.\n\n#### **Steps in Discretization**\n1. **Choose Attribute:** Pick the continuous variable (e.g., income).\n2. **Determine Method:** Equal-width, equal-frequency, or supervised.\n3. **Set Number of Bins:** Fixed (e.g., 5) or dynamic (algorithm-driven).\n4. **Apply Transformation:** Replace values with bin labels or midpoints.\n   - *Example:* Income $10K-$50K → “Low,” $51K-$100K → “Medium.”\n\n#### **Benefits**\n- Simplifies data (e.g., “High” vs. exact $87,432).\n- Reduces noise sensitivity.\n- Enables categorical algorithms (e.g., Naive Bayes).\n\n#### **Challenges**\n- **Information Loss:** Binning discards precision (e.g., 49.9 vs. 50.1 lumped together).\n- **Bin Choice:** Too few bins oversimplify; too many retain complexity.\n- **Outliers:** Can distort unsupervised methods.\n\n#### **Example Workflow**\n- Data: Salaries from $20K to $200K.\n- Method: Equal-width, 4 bins.\n- Result: $20K-65K (“Low”), $66K-110K (“Medium”), $111K-155K (“High”), $156K-200K (“Very High”).\n\n---\n\n### **Cleaning vs. Discretization**\n- **Cleaning:** Fixes errors and prepares raw data (e.g., fills missing ages).\n- **Discretization:** Transforms clean continuous data into categories (e.g., bins ages into groups).\n- **Order:** Cleaning comes first—discretizing dirty data risks amplifying errors."
  },
  {
    "url": "University/OOP/Module_1/Intro.html",
    "content": "---\nid: Intro\naliases: []\ntags: []\ntitle: Intro\n---\n\n## Object Oriented Methodology\nOOM is an approach to software development that focuses on designing and structuring programs around objects rather than functions or logic. **OOP** is a programming paradigm based on the concept of objects. Objects contain data (fields, attributes or properties) and have action they can perform (procedures and methods).\n\n### Key concepts of OOM\n#### Objects\n- Objects are instances of a class with specifically defined data. \n- They represent real-world entities (e.g., a Car, a Bank Account, a Student).\n- Each object has attributes (data) and methods (functions).\n\n#### Classes\n- A class is a blueprint for creating objects.\n- It defines the attributes (variables) and behaviors (methods) of objects.\n\n#### Methods\n- These are the functions that are defined inside a class that describe the behaviour of an object. \n- They are useful for re-usability or keeping functionality encapsulated inside one object at a time.\n\n#### Attributes\n- These are defined in the class template and represent the state of an object. Objects contain data stored in the attribute field.\n\n```java\npublic class Car {\n    private String brand;\n    private int speed;\n\n    public Car(String brand, int speed) {\n        this.brand = brand;\n        this.speed = speed;\n    }\n\n    public void accelerate(int increase) {\n        this.speed += increase;\n    }\n\n    // Getters\n    public String getBrand() {\n        return brand;\n    }\n\n    public int getSpeed() {\n        return speed;\n    }\n\n    // Setters\n    public void setBrand(String brand) {\n        this.brand = brand;\n    }\n\n    public void setSpeed(int speed) {\n        this.speed = speed;\n    }\n}\n```\n\n## Programming paradigms\nA **programming paradigm** is a fundamental style or approach to programming that defines how code is structured and executed.\n\n### Imperative Paradigm\n- In imperative paradigm, programs are written as a sequence of instructions that change the program's state.\n- It focuses on **how** a task should be performed.\n\n#### Procedural\n- Based on procedures (functions) that operate on data.\n- Code is executed step by step.\n- Uses loops, conditional and variables.\n- Ex - C, Python, JavaScript (when using functions)\n\n```py\ndef factorial(n):\n    result = 1\n    for i in range(1, n + 1):\n        result *= i\n    return result\n\nprint(factorial(5))  # Output: 120\n```\n\n#### Object Oriented Programming\n- Based on objects that contain both data and their behaviors.\n- Uses classes, objects, encapsulation, abstraction, inheritance and polymorphism.\n- Ex - Java, C++, Python.\n\n```ts\nclass Car {\n    constructor(public brand: string, public speed: number) {}\n\n    accelerate(increase: number) {\n        this.speed += increase;\n    }\n}\n\nconst myCar = new Car(\"Tesla\", 100);\nmyCar.accelerate(20);\nconsole.log(myCar.speed); // Output: 120\n```\n\n### Declarative Paradigm\n- In it, **what** needs to be done is specified rather than **how** it needs to be done. \n- It focuses on describing the problem rather than specifying the steps to solve it.\n\n#### Functional \n- Based on pure functions i.e a function should be not change non-local state and should be deterministic.\n- Uses recursion, higher-order functions, currying. \n- Avoids changing state i.e. variables are immutable.\n- Ex - Haskell, Lisp.\n```js\nconst square = x => x * x;\nconst numbers = [1, 2, 3, 4, 5];\nconst squaredNumbers = numbers.map(square);\nconsole.log(squaredNumbers); // Output: [1, 4, 9, 16, 25]\n\n```\n#### Logic Programming\n- Based on rules and facts instead of explicit instructions.\n- Uses Predicate logic to derive conclusions\n- Ex - Prolog\n```prolog\nfather(john, bob).\nfather(bob, alice).\ngrandfather(X, Y) :- father(X, Z), father(Z, Y).\n```\n\n## Evolution\n**Object-Oriented Methodology (OOM)** evolved as a response to the increasing complexity of software development. It introduced a way to model real-world entities in a more structured, modular, and reusable manner.\n\n### **Origins in Simula (1960s)**\n- **Before Object-Oriented Programming (OOP),** programming was mostly procedural (e.g., using languages like Fortran, COBOL, and Assembly).  \n- **Simula (1967)** – Developed by `Ole-Johan Dahl` and `Kristen Nygaard` in Norway.\n  - Introduced **classes, objects, and inheritance.**\n  - Used for simulation and modeling of real-world systems.\n  - Laid the groundwork for OOP principles.\n\n### **Birth of OOP - Smalltalk (1970s)**\n- Developed by `Alan Kay` and `Xerox PARC` in the early 1970s.\n- Introduced **fully object-oriented concepts**:\n  - **Encapsulation** – Data and methods bundled in objects.\n  - **Message Passing** – Objects communicate by sending messages.\n  - **Dynamic Binding** – Methods can be overridden at runtime.\n- **Smalltalk became the first true object-oriented language.**\n\n### **Growth and adoption - C++ (1980s) – Bridging Procedural and OO Paradigms**\n- **Bjarne Stroustrup** developed **C++** as an extension of C.\n- Combined procedural programming with object-oriented features.\n- Added features like:\n  - **Classes and Objects**\n  - **Constructors & Destructors**\n  - **Operator Overloading**\n  - **Inheritance & Polymorphism**\n- **Impact:** C++ became widely used in system software, games, and applications.\n\n### **OOP Gains Popularity (1990s)**\n- **Objective-C (1983)** – Combined Smalltalk’s messaging with C syntax.\n- **Eiffel (1986)** – Focused on software reliability and reusability.\n- **Python (1991)** – Introduced a simpler, beginner-friendly approach to OOP.\n- **Java (1995)** – Created by **James Gosling** at Sun Microsystems.\n  - Designed to be **platform-independent** (WORA – Write Once, Run Anywhere).\n  - Used in **enterprise applications, web applications, and mobile development (Android).**\n  - Popularized concepts like **interfaces, garbage collection, and abstraction.**\n\n### **The Rise of Enterprise Applications (2000s)**\n- **C# (2000)** – Microsoft's alternative to Java, used in Windows applications.\n- **Ruby (1995, but popular in 2000s)** – Brought simplicity with OOP and metaprogramming.\n- **Object-Oriented Databases (OODBs)** – Emerged to store objects directly.\n\n### **Hybrid and Multi-Paradigm Languages (2010s – Present)**\n- **JavaScript & TypeScript** – Became dominant for web development.\n  - JavaScript was initially procedural but later adopted OOP concepts.\n  - TypeScript (2012) added static typing and better OOP support.\n- **Swift (2014)** – Apple’s modern take on OOP, replacing Objective-C.\n- **Kotlin (2016)** – A modern alternative to Java, widely used in Android development.\n\n### **Emergence of Functional & Object-Oriented Fusion**\n- **Languages like Python, JavaScript, and Swift** now support both **OOP and functional programming.**\n- **Microservices and Cloud Computing** reduced reliance on monolithic OO systems.\n- **Design Patterns** (e.g., Singleton, Factory, MVC) became essential for scalable applications.\n\n\n## Benefits of OOP\n- Modularity - OOP allows code to be divided into self-contained objects, each representing a specific module or entity\n- Improves code readability and organization.\n- Simplifies debugging and make maintenance of code easier.\n- Make code reusable due to inheritance.\n- Encapsulation enhances security by hiding implementation details and only exposing what is necessary.\n- Polymorphism makes systems easier to extend and modify without altering existing code\n- OOP’s structured approach (classes, objects, encapsulation) makes it easier to update or fix code.\n- OOP mimics real-world entities by representing them as objects with properties and behaviors, making it intuitive to design software.\n- Inheritance and polymorphism allow new features to be added by extending existing classes or implementing new interfaces, without modifying the original code\n"
  },
  {
    "url": "University/Data_Mining/Module_1/KDD.html",
    "content": "---\nid: KDD\naliases: []\ntags: []\ntitle: KDD\n---\n\n## KDD\n\nThe **KDD process** stands for **Knowledge Discovery in Databases**, a methodology used in data mining to extract useful knowledge from large datasets. It’s a structured approach to identifying patterns, trends, and insights from raw data. Introduced by Fayyad et al. in 1996, it’s widely used in fields like machine learning, business intelligence, and scientific research. Here’s a breakdown of the steps:\n\n### **Selection**\n- Choosing the relevant data from a larger dataset or multiple sources to focus on for analysis.\n- Not all data is useful—selecting the right subset ensures efficiency and relevance.\n- If you’re analyzing customer behavior, you might select only purchase history and demographics from a massive company database.\n\n### **Preprocessing**\n- Cleaning and preparing the selected data by handling missing values, removing noise, and resolving inconsistencies.\n- Real-world data is often messy (e.g., typos, duplicates, or incomplete entries), and this step improves quality.\n- Filling in missing ages with an average or removing outlier transactions that don’t make sense (like a $1M purchase from a toddler).\n\n### **Transformation**\n- Converting the preprocessed data into a suitable format for analysis, often by reducing dimensionality, normalizing, or aggregating it.\n- Makes the data easier to work with for algorithms or tools (e.g., turning text into numerical values).\n- Converting sales dates into \"month of sale\" or scaling income values to a 0–1 range.\n\n### **Data Mining**\n- Applying algorithms to uncover patterns, relationships, or anomalies in the transformed data.\n- This is the core step where insights are generated—think clustering, classification, or association rules.\n-  Using a clustering algorithm to group customers by spending habits or a decision tree to predict churn.\n\n### **Interpretation/Evaluation**\n- Analyzing the mined patterns to determine their usefulness, validity, and relevance, often visualizing or testing them.\n- Not all patterns are meaningful—interpretation ensures the results align with goals and aren’t just noise.\n- Checking if a discovered trend (e.g., “younger customers buy more on weekends”) holds up across regions or makes business sense.\n"
  },
  {
    "url": "University/Data_Mining/Module_1/OLAP.html",
    "content": "---\nid: OLAP\naliases: []\ntags: []\n---\n\n## OLAP Servers\nAn OLAP server sits between the data warehouse (where data is stored) and the end-user tools (like dashboards or data mining software). Its job is to process multidimensional queries—like “What were total sales by product category across all regions in Q3?”—quickly and efficiently. Unlike traditional databases (OLTP systems) optimized for transactional updates (e.g., recording a sale), OLAP servers are tuned for reading and aggregating historical data.\n\n### Key Features:\n- **Multidimensional View**: Data is organized into \"cubes\" with dimensions (e.g., time, product, location) and measures (e.g., sales, profit).\n- **Aggregation**: Precomputes summaries (e.g., monthly totals) for faster retrieval.\n- **Interactivity**: Supports slicing, dicing, drilling down, and rolling up data for flexible analysis.\n- **Performance**: Handles complex queries over massive datasets without bogging down.\n\n---\n\n### Role in Data Warehousing and Data Mining\nIn a data warehouse architecture (like the ones we discussed), the OLAP server lives in the **data access layer**. It takes the structured data from the warehouse—organized in star, snowflake, or galaxy schemas—and presents it in a way that’s optimized for analysis. For data mining, OLAP servers provide a foundation by:\n- Delivering pre-aggregated data that mining algorithms can use as input.\n- Enabling exploratory analysis to identify trends or patterns before deeper mining.\n- Supporting multidimensional queries that refine datasets for specific mining tasks (e.g., clustering sales by customer segments).\n\n---\n\n### Types of OLAP Servers\nOLAP servers come in different flavors, depending on how they store and process data. Here are the main types:\n\n#### 1. MOLAP (Multidimensional OLAP)\n- Stores data in a multidimensional cube structure, precomputed and optimized for analysis.\n- Data is physically stored as cubes, separate from the relational warehouse.\n- A cube with axes for `Time`, `Product`, and `Region`, holding pre-aggregated sales totals.\n- **Pros**:\n  - Lightning-fast queries due to precomputed aggregates.\n  - Ideal for complex, multidimensional analysis.\n- **Cons**:\n  - Limited by cube size—can struggle with very large or sparse datasets.\n  - Requires preprocessing time to build cubes.\n- **Tools**: IBM Cognos, Oracle Essbase.\n- **Use Case**: Analyzing sales trends across fixed dimensions with predictable query patterns.\n\n#### 2. ROLAP (Relational OLAP)\n- Works directly on relational data in the warehouse (e.g., star schemas), translating OLAP queries into SQL.\n- No separate cube—uses the warehouse’s relational tables (fact and dimension tables).\n- **Example**: A query like “Sum sales by region” runs SQL against a star schema’s `Fact_Sales` and `Dim_Region`.\n- **Pros**:\n  - Scales well with large datasets—no cube size limits.\n  - Leverages existing relational databases.\n- **Cons**:\n  - Slower than MOLAP due to real-time SQL processing and joins.\n  - Performance depends on schema optimization (e.g., indexing).\n- **Tools**: Microsoft SQL Server Analysis Services (SSAS) in ROLAP mode, MicroStrategy.\n- **Use Case**: Ad-hoc queries on massive, dynamic datasets where precomputing isn’t practical.\n\n#### 3. HOLAP (Hybrid OLAP)\n- Combines MOLAP and ROLAP—stores some data in cubes (for speed) and leaves detailed data in the relational database (for scale).\n- Aggregates in cubes, raw data in tables.\n- High-level summaries (e.g., yearly sales) in a cube, drill-down details (e.g., daily transactions) fetched via SQL.\n- **Pros**:\n  - Balances speed and scalability.\n  - Flexible for varied workloads.\n- **Cons**:\n  - More complex to manage (two storage systems).\n  - Trade-offs depend on where the MOLAP/ROLAP line is drawn.\n- **Tools**: SAP BW, SSAS in hybrid mode.\n- **Use Case**: Mixed needs—fast dashboards plus deep, detailed analysis.\n\n#### 4. DOLAP (Desktop OLAP) – Less Common\n- Lightweight OLAP on a user’s local machine, often with a small data subset downloaded from the warehouse.\n- Portable, good for offline analysis.\n- **Cons**: Limited by local resources, not suited for big data.\n- **Tools**: Early tools like Cognos PowerPlay.\n\n---\n\n### OLAP Server Architecture\nWhile specific implementations vary, a typical OLAP server architecture includes these components:\n1. **Data Source Connector**: Links to the data warehouse (e.g., via JDBC/ODBC) to fetch data from fact and dimension tables.\n2. **Storage Engine**:\n   - MOLAP: Multidimensional cube storage.\n   - ROLAP: Relational database engine.\n   - HOLAP: Hybrid of both.\n3. **Query Processor**: Interprets user requests (e.g., MDX queries—Multidimensional Expressions) and retrieves or computes results.\n4. **Cache Layer**: Stores frequently accessed aggregates to boost performance.\n5. **Client Interface**: Connects to BI tools, data mining software, or custom apps for output (e.g., charts, tables).\n\n#### Data Flow:\n- Warehouse → OLAP Server (loads or queries data) → Cubes or SQL execution → Results to user/tool.\n- Example: A data mining tool asks, “Cluster sales by region and quarter.” The OLAP server pulls data from a star schema, aggregates it (if ROLAP) or uses a prebuilt cube (if MOLAP), and delivers a multidimensional dataset.\n\n---\n\n### Operations Supported by OLAP Servers\nThese are the analytical actions OLAP servers excel at, which also feed into data mining:\n- **Slice**: Select one dimension (e.g., sales for 2024 only).\n- **Dice**: Select a subset across dimensions (e.g., sales for electronics in Q1 across two regions).\n- **Drill-Down**: Go from summary to detail (e.g., yearly → monthly sales).\n- **Roll-Up**: Aggregate up (e.g., daily → yearly totals).\n- **Pivot**: Rotate the view (e.g., swap rows and columns to see sales by product vs. region).\n\n---\n\n### OLAP vs. OLTP (Quick Comparison)\n| Feature     | OLAP Server        | OLTP System      |\n| ----------- | ------------------ | ---------------- |\n| **Purpose** | Analysis/reporting | Transactions     |\n| **Data**    | Historical         | Current          |\n| **Queries** | Complex, aggregate | Simple, updates  |\n| **Speed**   | Fast reads         | Fast writes      |\n| **Example** | Sales trends       | Order processing |\n\n---\n\n### Why OLAP Servers Matter for Data Mining\n- **Pre-Aggregation**: MOLAP cubes provide ready-made summaries for mining algorithms (e.g., regression on yearly trends).\n- **Multidimensionality**: Supports mining across dimensions (e.g., “Find patterns in sales by region and time”).\n- **Speed**: Quick data access lets miners iterate faster, refining models or hypotheses.\n- **Exploration**: OLAP’s interactivity helps identify areas worth mining before running heavy algorithms.\n"
  },
  {
    "url": "University/Data_Mining/Module_1/WareHouse_Schema.html",
    "content": "---\nid: WareHouse Schema\naliases: []\ntags: []\ntitle: WareHouse Schema\n---\n\nData warehouse schemas are the logical blueprints that define how data is organized and stored within a data warehouse. They structure the relationships between tables to optimize storage and querying. Unlike operational databases (which often use normalized schemas for efficiency in transactions), data warehouse schemas prioritize fast retrieval and analysis of large datasets. The two most common schemas in data warehousing are the **Star Schema** and the **Snowflake Schema**, with a less common variant being the **Galaxy Schema**. \n\n## Star Schema\nThe star schema is the simplest and most widely used data warehouse schema.\n\n### Structure:\n- **Fact Table**: The center of the star, containing quantitative data (metrics) you want to analyze, like sales amounts, quantities sold, or revenue. It stores numerical measures and foreign keys linking to dimension tables.\n  - Example: A \"Sales\" fact table with columns like `Sale_Amount`, `Units_Sold`, `Date_ID`, `Product_ID`, `Customer_ID`.\n- **Dimension Tables**: Surround the fact table like points of a star. These hold descriptive attributes (qualitative data) providing context to the facts, such as time, product details, or customer info.\n  - Example: A \"Time\" dimension table with `Date_ID`, `Day`, `Month`, `Year`; a \"Product\" dimension with `Product_ID`, `Name`, `Category`.\n\n![[Pasted image 20250302191101.png]]\n### Characteristics:\n- **Denormalized**: Dimension tables are typically not broken down further (no normalization), reducing the number of joins needed for queries.\n- **Simple Joins**: The fact table connects directly to dimension tables with one-to-many relationships, making queries fast and straightforward.\n- **Example Layout**:\n  ```\n  Fact_Sales: [Sale_Amount, Date_ID, Product_ID, Customer_ID]\n  Dim_Time: [Date_ID, Day, Month, Year]\n  Dim_Product: [Product_ID, Name, Category, Price]\n  Dim_Customer: [Customer_ID, Name, Region]\n  ```\n\n### Advantages:\n- **Query Performance**: Fewer joins mean faster execution, ideal for data mining and OLAP operations.\n- **Simplicity**: Easy to understand and design, even for non-technical users.\n- **Scalability**: Works well with large datasets and aggregation-heavy tasks (e.g., “Total sales by region”).\n\n### Disadvantages:\n- **Redundancy**: Denormalization can lead to duplicate data in dimension tables, increasing storage needs.\n- **Less Flexibility**: Harder to adapt to complex hierarchies without modification.\n\n---\n\n## Snowflake Schema\nThe snowflake schema is an extension of the star schema, adding normalization to the dimension tables. It’s called \"snowflake\" because the dimensions branch out like a snowflake’s intricate arms.\n\n### Structure:\n- **Fact Table**: Same as in the star schema—central, holding measures and keys to dimension tables.\n  - Example: `Fact_Sales` with `Sale_Amount`, `Date_ID`, `Product_ID`, `Customer_ID`.\n- **Dimension Tables**: These are normalized into multiple related tables, creating a hierarchy.\n  - Example: The \"Time\" dimension might split into:\n    - `Dim_Time: [Date_ID, Day, Month_ID]`\n    - `Dim_Month: [Month_ID, Month, Year_ID]`\n    - `Dim_Year: [Year_ID, Year]`\n  - Similarly, \"Product\" might split into `Dim_Product` (basic info) and `Dim_Category` (category details).\n\n![[Pasted image 20250302191929.png]]\n### Characteristics:\n- **Normalized**: Dimension tables are broken into sub-tables to eliminate redundancy, following database normalization rules.\n- **Complex Joins**: More tables mean more joins in queries, as you navigate the hierarchy.\n- **Example Layout**:\n  ```\n  Fact_Sales: [Sale_Amount, Date_ID, Product_ID, Customer_ID]\n  Dim_Time: [Date_ID, Day, Month_ID]\n  Dim_Month: [Month_ID, Month, Year_ID]\n  Dim_Year: [Year_ID, Year]\n  Dim_Product: [Product_ID, Name, Category_ID]\n  Dim_Category: [Category_ID, Category_Name]\n  ```\n\n### Advantages:\n- **Storage Efficiency**: Normalization reduces data duplication (e.g., storing \"Year\" once, not repeated across rows).\n- **Complex Hierarchies**: Better suited for detailed, multi-level dimensions (e.g., product categories nesting into subcategories).\n- **Data Integrity**: Less redundancy means fewer chances for inconsistencies.\n\n### Disadvantages:\n- **Query Complexity**: More joins slow down performance, especially for large-scale data mining or real-time analytics.\n- **Design Complexity**: Harder to build and maintain compared to the star schema.\n\n---\n\n## Galaxy Schema (Fact Constellation Schema)\nThis is a more advanced variant, combining multiple fact tables that share dimension tables. It’s called \"galaxy\" or \"constellation\" because it looks like multiple stars connected in a network.\n\n### Structure:\n- **Multiple Fact Tables**: Each tracks different measures (e.g., `Fact_Sales` for revenue, `Fact_Inventory` for stock levels).\n- **Shared Dimension Tables**: Common dimensions (e.g., `Dim_Time`, `Dim_Product`) link the fact tables.\n- **Example Layout**:\n  ```\n  Fact_Sales: [Sale_Amount, Date_ID, Product_ID]\n  Fact_Inventory: [Stock_Level, Date_ID, Product_ID]\n  Dim_Time: [Date_ID, Day, Month, Year]\n  Dim_Product: [Product_ID, Name, Category]\n  ```\n  ![[Pasted image 20250302192204.png]]\n\n### Characteristics:\n- **Interconnected**: Fact tables can relate to each other through shared dimensions.\n- **Complex**: More flexible but harder to manage than a single star or snowflake.\n\n### Advantages:\n- **Flexibility**: Supports multiple business processes (e.g., sales and inventory analysis) in one warehouse.\n- **Comprehensive Analysis**: Ideal for data mining across related datasets.\n\n### Disadvantages:\n- **Complexity**: Design and queries get intricate with multiple fact tables.\n- **Performance**: Can be slower due to additional relationships.\n\n---\n\n### Comparison Table\n\n| Feature           | Star Schema         | Snowflake Schema     | Galaxy Schema       |\n| ----------------- | ------------------- | -------------------- | ------------------- |\n| **Normalization** | Denormalized        | Normalized           | Mixed               |\n| **Complexity**    | Simple              | Moderate             | High                |\n| **Query Speed**   | Fast                | Slower (more joins)  | Varies              |\n| **Storage**       | Higher (redundancy) | Lower (efficient)    | Depends on design   |\n| **Use Case**      | Basic analytics     | Detailed hierarchies | Multi-fact analysis |\n\n---\n\n### Real-World Example\nImagine a data warehouse for an e-commerce platform:\n- **Star Schema**: `Fact_Orders` (order totals) with `Dim_Customer`, `Dim_Product`, `Dim_Time`—quickly mines top-selling products by month.\n- **Snowflake Schema**: Adds `Dim_Category` and `Dim_Subcategory` to `Dim_Product`—mines deeper trends like \"electronics subcategories in Q4.\"\n- **Galaxy Schema**: Adds `Fact_Returns`—mines relationships between orders and returns by customer type.\n"
  },
  {
    "url": "University/Data_Mining/Module_2/Advanced Pattern Mining.html",
    "content": "### Advanced Pattern Mining\nAdvanced pattern mining builds on foundational methods to handle:\n- **Complex data types**: Sequences, graphs, streams, multi-dimensional data.\n- **Constraints**: User-defined rules to focus on meaningful patterns.\n- **Scalability**: Large-scale or dynamic datasets.\n- **Specialized patterns**: Beyond simple itemsets (e.g., maximal, closed, or rare patterns).\n\n### 1. Advanced Pattern Types\nBeyond frequent itemsets, advanced mining uncovers richer patterns:\n\n- **Maximal Frequent Itemsets (MFI)**:\n  - An itemset is maximal if it’s frequent and none of its supersets are frequent.\n  - Example: If {A, B, C} is frequent but {A, B, C, D} isn’t, {A, B, C} is maximal.\n  - Benefit: Reduces redundancy (fewer patterns to store).\n\n- **Closed Frequent Itemsets**:\n  - An itemset is closed if it’s frequent and no superset has the same support.\n  - Example: If {A, B} has support 50% and {A, B, C} also has 50%, only {A, B, C} is closed.\n  - Benefit: Compact representation without losing information.\n\n- **Rare or Infrequent Patterns**:\n  - Focus on patterns with low support but high significance (e.g., fraud detection).\n  - Challenge: Traditional algorithms like Apriori miss these due to high min-support thresholds.\n\n- **High-Utility Itemsets (HUI)**:\n  - Considers item importance (e.g., profit, cost) beyond frequency.\n  - Example: {diamond ring} may appear rarely but has high utility (profit).\n  - Algorithms: HUI-Miner, FHM.\n### 2. Advanced Algorithms\nTo mine these patterns efficiently, we go beyond Apriori and FP-Growth:\n\n- **PrefixSpan (Sequential Pattern Mining)**:\n  - Mines patterns in ordered sequences (e.g., customer purchase sequences: {milk} → {bread} → {butter}).\n  - How it works: Projects the database into smaller prefix-based subsets, avoiding candidate generation.\n  - Use case: Web clickstream analysis, DNA sequence mining.\n\n- **CM-SPADE (Sequential Mining with Constraints)**:\n  - Extends sequential mining with user constraints (e.g., length, time gaps).\n  - Faster than PrefixSpan for constrained problems.\n\n- **Graph Pattern Mining (e.g., gSpan)**:\n  - Mines frequent subgraphs in graph datasets (e.g., social networks, chemical compounds).\n  - How it works: Uses a depth-first search to explore canonical graph representations.\n  - Use case: Drug discovery (finding common molecular structures).\n\n- **Vertical Data Mining (ECLAT)**:\n  - Uses a vertical database format (item-to-transaction mapping) instead of horizontal (transaction-to-item).\n  - Benefit: Faster intersection operations, memory-efficient for sparse data.\n### 3. Constraint-Based Mining\nReal-world applications often need specific patterns, not just frequent ones. Constraints refine the search:\n\n- **Monotonic Constraints**: If a pattern satisfies it, all supersets do too (e.g., support ≥ 5%).\n- **Anti-Monotonic Constraints**: If a pattern violates it, all supersets do too (e.g., cost ≤ $100).\n- **Succinct Constraints**: Directly expressible (e.g., item = \"milk\").\n- Example: Find rules where {milk} appears on the left-hand side with confidence > 70%.\n\nAlgorithms like Apriori can be adapted to push constraints deep into the mining process, pruning irrelevant patterns early.\n### 4. Mining Dynamic and Streaming Data\nStatic datasets are one thing, but real-time data (e.g., IoT, stock trades) requires advanced techniques:\n\n- **Incremental Mining**:\n  - Updates patterns as new data arrives without re-mining everything.\n  - Example: IncSpan for sequences, UF-Growth for FP-Trees.\n\n- **Stream Mining**:\n  - Handles unbounded data with sliding windows or decay factors.\n  - Algorithms: Lossy Counting, Moment (for closed patterns).\n  - Challenge: Limited memory, one-pass processing.\n### 5. Multi-Dimensional and Multi-Level Mining\nReal data often has attributes beyond items (e.g., time, location, category):\n\n- **Multi-Dimensional Patterns**:\n  - Example: {milk, bread} in {summer, NYC} with support 30%.\n  - Approach: Treat dimensions as items or use cube-based mining (e.g., BUC algorithm).\n\n- **Multi-Level Patterns**:\n  - Mines at different abstraction levels (e.g., {milk} → {bread} vs. {dairy} → {bakery}).\n  - Uses concept hierarchies to generalize or specialize patterns.\n### 6. Practical Example\nImagine an e-commerce dataset:\n- **Basic Mining**: {laptop, charger} → {mouse} (support 10%, confidence 80%).\n- **Advanced Mining**:\n  - **Maximal**: {laptop, charger, mouse} is maximal if no larger set is frequent.\n  - **Sequential**: {laptop} → {charger} → {mouse} over three days.\n  - **High-Utility**: {laptop, warranty} has low frequency but high profit.\n  - **Constraint**: Rules where total cost > $500.\n### Challenges in Advanced Mining\n- **Scalability**: More complex patterns mean higher computational cost.\n- **Interpretability**: Too many patterns can overwhelm users.\n- **Noise**: Real data is messy, requiring robust preprocessing.\n"
  },
  {
    "url": "University/Data_Mining/Module_2/Association Rule Mining.html",
    "content": "---\nid: Association Rule Mining\naliases: []\ntags: []\ntitle: Association Rule Mining\n---\n\n### Support and Confidence in Association Rule Mining\nAssociation rule mining finds relationships like \"If A, then B\" (written as A → B) in transactional datasets.\n\n- **Support**: The frequency of a pattern or rule in the dataset.\n  - For an itemset (e.g., {milk, bread}):  \n    **Support = (Number of transactions with {milk, bread}) / (Total transactions)**.\n  - For a rule (e.g., {milk} → {bread}):  \n    **Support = (Number of transactions with both milk and bread) / (Total transactions)**.\n  - Purpose: Filters out rare patterns. If support is too low, the pattern isn’t significant.\n\n- **Confidence**: The reliability of the rule.\n  - Formula: **Confidence(A → B) = Support(A ∪ B) / Support(A)**.\n  - Example: If 50 out of 100 transactions have milk, and 40 of those also have bread, then:  \n    Confidence({milk} → {bread}) = 40 / 50 = 80%.\n  - Purpose: Measures how often B appears when A is present.\n\n**Example Transaction Data**:\n```\nT1: {milk, bread, butter}\nT2: {milk, bread}\nT3: {milk, beer}\nT4: {bread, butter}\nT5: {milk}\n```\n- Support({milk, bread}) = 2 / 5 = 40%.\n- Confidence({milk} → {bread}) = Support({milk, bread}) / Support({milk}) = (2/5) / (4/5) = 50%.\n\n---\n\n### Apriori Algorithm\n\nThe **Apriori algorithm** mines frequent itemsets and generates association rules efficiently by using a key principle: *If an itemset is frequent, all its subsets must also be frequent*. It prunes infrequent itemsets early.\n\n#### How It Works\n1. **Set a minimum support threshold** (e.g., 40%).\n2. **Step 1: Find frequent 1-itemsets** (items meeting min support).\n   - {milk}: 4/5 = 80% ✓\n   - {bread}: 3/5 = 60% ✓\n   - {butter}: 2/5 = 40% ✓\n   - {beer}: 1/5 = 20% ✗\n3. **Step 2: Generate candidate 2-itemsets** from frequent 1-itemsets.\n   - {milk, bread}, {milk, butter}, {bread, butter}.\n4. **Check support for 2-itemsets**:\n   - {milk, bread}: 2/5 = 40% ✓\n   - {milk, butter}: 1/5 = 20% ✗\n   - {bread, butter}: 2/5 = 40% ✓\n5. **Repeat for larger itemsets** until no more frequent itemsets are found.\n6. **Generate rules** (e.g., {milk} → {bread}) and compute confidence.\n\n#### Pros and Cons\n- **Pros**: Simple, intuitive, leverages pruning to reduce computation.\n- **Cons**: Requires multiple database scans, slow for large datasets or low min support due to many candidates.\n\n---\n\n### FP-Growth Algorithm\n\nThe **FP-Growth (Frequent Pattern Growth) algorithm** is a more efficient alternative to Apriori. Instead of generating candidates, it builds a compact tree structure called an **FP-Tree** and mines patterns directly.\n\n#### How It Works\n1. **Set a minimum support threshold** (e.g., 40%).\n2. **Step 1: Scan data to find frequent 1-itemsets** (same as Apriori).\n   - {milk}: 80%, {bread}: 60%, {butter}: 40%, {beer}: 20% (drop {beer}).\n3. **Step 2: Sort items by frequency** and build the FP-Tree.\n   - Order: {milk} > {bread} > {butter}.\n   - Transactions are inserted into the tree, sharing prefixes:\n     - T1: {milk, bread, butter} → Tree path: milk → bread → butter.\n     - T2: {milk, bread} → Shares milk → bread.\n     - T3: {milk} → Shares milk.\n     - T4: {bread, butter} → New path: bread → butter.\n     - T5: {milk} → Increments milk count.\n4. **Step 3: Mine the FP-Tree**:\n   - Start from the least frequent item (e.g., {butter}).\n   - Trace paths to find conditional patterns (e.g., {milk, bread} with {butter}).\n   - Recursively build smaller trees and extract frequent patterns.\n\n#### Pros and Cons\n- **Pros**: Single-pass compression with FP-Tree, no candidate generation, faster for dense datasets.\n- **Cons**: FP-Tree can be memory-intensive for sparse data, harder to implement.\n\n---\n### Apriori vs. FP-Growth\n| Feature            | Apriori                   | FP-Growth                     |\n| ------------------ | ------------------------- | ----------------------------- |\n| **Approach**       | Candidate generation      | Tree-based                    |\n| **Database Scans** | Multiple                  | Two (initial + tree)          |\n| **Memory Use**     | Low (but many candidates) | Higher (FP-Tree)              |\n| **Speed**          | Slower on large data      | Faster, especially dense data |\n| **Complexity**     | Simpler to code           | More complex                  |\n"
  },
  {
    "url": "University/Data_Mining/Module_2/Associations and Correlations.html",
    "content": "## Association Rules\nAssociation rules take frequent patterns a step further by identifying relationships between items, often in the form \"If A, then B.\"\n\n- **Example**: {milk, bread} → {butter} means people who buy milk and bread often buy butter.\n- **Key Metrics**:\n  - **Confidence**: How often the rule holds true.  \n    - Formula: Confidence(A → B) = Support(A ∪ B) / Support(A).\n  - **Lift**: Measures how much more likely B occurs with A compared to if they were independent.  \n    - Formula: Lift(A → B) = Support(A ∪ B) / (Support(A) × Support(B)).\n- **Use Case**: Retailers use this for product placement or recommendations.\n\n## Correlations\nCorrelation analysis looks at how strongly two variables (or items) are related, often beyond simple co-occurrence.\n\n- **Key Metric**: Correlation coefficient (e.g., Pearson correlation), ranging from -1 (negative correlation) to +1 (positive correlation), with 0 meaning no correlation.\n- **Difference from Association**: Correlation measures strength and direction of relationships (not just presence), and it’s often applied to numerical data rather than categorical itemsets.\n- **Example**: If sales of ice cream and sunscreen both rise in summer, they might have a positive correlation."
  },
  {
    "url": "University/Data_Mining/Module_2/Cluster Analysis.html",
    "content": "---\nid: Cluster Analysis\naliases: []\ntags: []\n---\n\nCluster analysis groups data points into clusters where objects within a cluster are more similar to each other than to those in other clusters. It’s unsupervised—no predefined labels, just patterns in the data.\n### 1. Types of Data in Cluster Analysis\nThe type of data dictates how clustering is performed and which measures or methods work best. Here are the main categories:\n\n- **Numerical Data (Quantitative)**:\n  - Continuous: Real numbers (e.g., height: 1.75m, temperature: 23.5°C).\n  - Discrete: Integers (e.g., number of purchases: 3, 5).\n  - Use case: Common in scientific and financial data.\n  - Example measures: Euclidean distance, Manhattan distance.\n\n- **Categorical Data (Qualitative)**:\n  - Nominal: Unordered categories (e.g., colors: red, blue; gender: male, female).\n  - Ordinal: Ordered categories (e.g., ratings: low, medium, high).\n  - Challenge: No inherent numerical distance.\n  - Example measures: Hamming distance, Jaccard similarity.\n\n- **Binary Data**:\n  - Two states (e.g., 0/1, yes/no, true/false).\n  - Example: Feature presence (e.g., has_feature: 1 or 0).\n  - Measures: Jaccard coefficient, simple matching coefficient.\n\n- **Mixed Data**:\n  - Combines numerical and categorical (e.g., {age: 25, gender: female, income: $50K}).\n  - Challenge: Requires hybrid distance measures (e.g., Gower’s distance).\n\n- **Text Data**:\n  - Words or documents (e.g., customer reviews).\n  - Converted to vectors (e.g., TF-IDF, word embeddings).\n  - Measures: Cosine similarity, Euclidean distance on vectors.\n\n- **Time Series/Sequential Data**:\n  - Ordered sequences (e.g., stock prices over time, purchase histories).\n  - Measures: Dynamic Time Warping (DTW), correlation-based distances.\n\n- **Spatial Data**:\n  - Coordinates or geometric data (e.g., latitude/longitude).\n  - Measures: Euclidean distance, geodesic distance.\n---\n### 2. Similarity and Distance Measures\nClustering relies on quantifying how \"similar\" or \"dissimilar\" data points are. **Distance measures** (dissimilarity) and **similarity measures** are two sides of the same coin.\n\n#### Distance Measures (Dissimilarity)\n- **Euclidean Distance** (Numerical):\n  - Formula: \\( d(x, y) = \\sqrt{\\sum (x_i - y_i)^2} \\).\n  - Example: Points (1, 2) and (4, 6) → \\( d = \\sqrt{(4-1)^2 + (6-2)^2} = 5 \\).\n  - Use: General-purpose, assumes spherical clusters.\n\n- **Manhattan Distance** (Numerical):\n  - Formula: \\( d(x, y) = \\sum |x_i - y_i| \\).\n  - Example: (1, 2) and (4, 6) → \\( d = |4-1| + |6-2| = 7 \\).\n  - Use: Grid-like data, less sensitive to outliers than Euclidean.\n\n- **Minkowski Distance** (Numerical):\n  - Generalization: \\( d(x, y) = (\\sum |x_i - y_i|^p)^{1/p} \\).\n  - \\( p = 1 \\): Manhattan; \\( p = 2 \\): Euclidean.\n  - Use: Flexible for different data shapes.\n\n- **Hamming Distance** (Categorical/Binary):\n  - Counts mismatches between two equal-length strings.\n  - Example: \"red\" vs. \"blue\" (encoded as vectors) → Compare positions.\n  - Use: Nominal data, binary attributes.\n\n- **Dynamic Time Warping (DTW)** (Time Series):\n  - Aligns sequences by warping time axis.\n  - Use: Time series with varying speeds (e.g., speech patterns).\n\n#### Similarity Measures\n- **Cosine Similarity** (Text/Numerical):\n  - Formula: \\( \\text{cos}(\\theta) = \\frac{x \\cdot y}{|x| |y|} \\).\n  - Range: 0 to 1 (1 = identical direction).\n  - Use: Text data, high-dimensional sparse data.\n\n- **Jaccard Similarity** (Binary/Sets):\n  - Formula: \\( J(A, B) = \\frac{|A \\cap B|}{|A \\cup B|} \\).\n  - Example: Sets {a, b} and {b, c} → \\( J = 1/3 \\).\n  - Use: Binary or set-based data (e.g., purchased items).\n\n- **Gower’s Distance** (Mixed Data):\n  - Combines normalized distances for numerical, categorical, and binary attributes.\n  - Use: Heterogeneous datasets.\n---\n### 3. Partitioning Methods\nPartitioning methods divide data into \\( k \\) non-overlapping clusters. You specify \\( k \\) (number of clusters) beforehand.\n\n#### K-Means\n- **How it works**:\n  1. Randomly initialize \\( k \\) centroids.\n  2. Assign each point to the nearest centroid (Euclidean distance).\n  3. Update centroids as the mean of assigned points.\n  4. Repeat until convergence.\n- **Data type**: Numerical.\n- **Pros**: Fast, scalable, works well with spherical clusters.\n- **Cons**: Sensitive to outliers, assumes equal-sized clusters, needs \\( k \\) specified.\n- **Example**: Group customers by {age, income}.\n\n#### K-Medoids (PAM - Partitioning Around Medoids)\n- **How it works**:\n  - Similar to K-Means, but uses actual data points (medoids) as cluster centers instead of means.\n  - Minimizes total distance to medoids.\n- **Data type**: Numerical, categorical (with appropriate distance measures).\n- **Pros**: Robust to outliers, flexible with distance measures (e.g., Manhattan).\n- **Cons**: Slower than K-Means (computes pairwise distances).\n- **Example**: Cluster cities by {latitude, longitude} with outliers.\n\n#### K-Modes\n- **How it works**:\n  - Adapts K-Means for categorical data.\n  - Uses modes (most frequent category) instead of means, Hamming distance instead of Euclidean.\n- **Data type**: Categorical.\n- **Pros**: Simple, efficient for nominal data.\n- **Cons**: Limited to categorical attributes.\n- **Example**: Cluster survey responses {gender, preference}.\n\n#### CLARA (Clustering Large Applications)\n- **How it works**:\n  - A scalable version of K-Medoids.\n  - Samples the dataset, applies PAM on the sample, and extends results.\n- **Data type**: Numerical, categorical.\n- **Pros**: Handles large datasets, robust like K-Medoids.\n- **Cons**: Sampling may miss small clusters.\n- **Example**: Cluster millions of customer transactions.\n\n### Choosing the Right Approach\n- **Data Type**: Numerical → K-Means; Categorical → K-Modes; Mixed → Gower’s + K-Medoids.\n- **Scale**: Small → K-Means/K-Medoids; Large → CLARA.\n- **Shape**: Spherical idclusters → K-Means; Arbitrary → K-Medoids.\n"
  },
  {
    "url": "University/Data_Mining/Module_2/Clustering with constriants.html",
    "content": "### Clustering with Constraints?\nTraditional clustering is fully unsupervised—grouping is based solely on data similarity or density. Clustering with constraints introduces **prior knowledge** as rules or conditions to refine the output. These constraints act like guardrails, ensuring clusters align with practical needs or expert insights.\n\n- **Why Use Constraints?**\n  - Improve interpretability (e.g., ensure certain items stay together).\n  - Incorporate domain expertise (e.g., business rules).\n  - Handle limitations of unsupervised methods (e.g., avoiding meaningless splits).\n\n### Types of Constraints\nConstraints are typically classified by what they enforce and how they’re applied. Here are the main types:\n\n1. **Instance-Level Constraints**:\n   - Focus on specific data points and their relationships.\n   - **Must-Link (ML)**:\n     - Two points must be in the same cluster.\n     - Example: \"Customer A and B have identical purchase histories—group them together.\"\n   - **Cannot-Link (CL)**:\n     - Two points must be in different clusters.\n     - Example: \"Product X and Y are substitutes—don’t cluster them.\"\n   - Use Case: Social networks (friends must-link, rivals cannot-link).\n\n2. **Cluster-Level Constraints**:\n   - Apply to properties of entire clusters.\n   - **Size Constraints**: Minimum or maximum number of points per cluster.\n     - Example: \"Each cluster must have at least 10 customers.\"\n   - **Diameter Constraints**: Maximum distance between points in a cluster.\n     - Example: \"No cluster can span more than 5 km.\"\n   - **Balance Constraints**: Clusters should have roughly equal sizes.\n     - Example: \"Distribute 1000 users evenly across 5 clusters.\"\n\n3. **Domain-Specific Constraints**:\n   - Derived from application context.\n   - Example: In spatial clustering, \"Clusters must not cross a river\" (geographic barrier).\n   - Example: In scheduling, \"Tasks clustered together must fit within an 8-hour shift.\"\n\n4. **Semi-Supervised Constraints**:\n   - Use partial labels or expert input.\n   - Example: \"These 10 points are known to belong to Cluster A—respect that.\"\n\n### How Constraints are Integrated\nConstraints modify traditional clustering algorithms by altering their objective functions, assignment rules, or merging/splitting strategies. Here’s how they fit into common methods:\n\n1. **Partitioning Methods (e.g., Constrained K-Means)**:\n   - **Approach**:\n     - Extend K-Means to enforce must-link and cannot-link constraints.\n     - Assign points to clusters while respecting constraints; if a conflict arises (e.g., cannot-link points assigned to the same cluster), reassign or flag as infeasible.\n   - **Algorithm** (COP-KMeans):\n     1. Initialize \\( k \\) centroids.\n     2. Assign points to nearest centroid, but check constraints:\n        - Must-link: Ensure linked points share a cluster.\n        - Cannot-link: Prevent assignment to the same cluster.\n     3. Update centroids, repeat until convergence or constraints can’t be satisfied.\n   - **Challenge**: May fail if constraints are contradictory or overly strict.\n\n2. **Hierarchical Methods**:\n   - **Agglomerative**:\n     - During merging, only combine clusters if it doesn’t violate constraints (e.g., no cannot-link pairs merge).\n     - Example: Merge {A, B} and {C} only if no A-C cannot-link exists.\n   - **Divisive**:\n     - Split clusters while ensuring must-link pairs stay together.\n   - **Modification**: Adjust linkage criteria to penalize constraint violations.\n\n3. **Density-Based Methods (e.g., Constrained DBSCAN)**:\n   - **Approach**:\n     - Adapt DBSCAN’s density-reachability:\n       - Must-link: Force points to be density-connected (even if slightly outside \\( \\epsilon \\)).\n       - Cannot-link: Prevent density connection (e.g., treat as a barrier).\n   - **Challenge**: Density may conflict with constraints in sparse regions.\n\n4. **Objective Function Modification**:\n   - Add a penalty term to the clustering cost:\n     - \\( Cost = \\text{Traditional Cost (e.g., SSE)} + \\lambda \\cdot \\text{Constraint Violation Penalty} \\).\n     - \\( \\lambda \\) balances clustering quality and constraint adherence.\n   - Example: In K-Means, penalize if must-link points are in different clusters.\n\n### Key Algorithms\n\n1. **COP-KMeans**:\n   - Constrained K-Means with must-link and cannot-link.\n   - Pros: Simple, builds on K-Means efficiency.\n   - Cons: Inflexible—fails if constraints can’t be met.\n\n2. **PCCL (Pairwise Constrained Clustering)**:\n   - Optimizes a constrained objective function iteratively.\n   - Pros: Flexible, handles partial constraints.\n   - Cons: Computationally intensive.\n\n3. **HMRF-KMeans (Hidden Markov Random Field)**:\n   - Models constraints as a probabilistic framework.\n   - Pros: Robust to noisy constraints, good for semi-supervised settings.\n   - Cons: Complex, requires tuning.\n\n4. **Constrained Spectral Clustering**:\n   - Uses constraints in a graph-based approach (e.g., must-link as edges).\n   - Pros: Handles arbitrary shapes, integrates well with constraints.\n   - Cons: Scalability issues for large datasets.\n\n---\n### Pros and Cons\n- **Pros**:\n  - Produces meaningful, application-specific clusters.\n  - Bridges unsupervised and supervised learning (semi-supervised).\n  - Reduces irrelevant or impractical solutions.\n- **Cons**:\n  - Increased complexity (algorithm modifications, tuning).\n  - Risk of infeasibility (e.g., conflicting constraints).\n  - May sacrifice some clustering quality for constraint satisfaction.\n\n---\n\n### Applications\n- **Retail**: Cluster stores, ensuring nearby locations stay together (must-link) and competitors separate (cannot-link).\n- **Bioinformatics**: Group genes with known interactions (must-link) while respecting functional differences (cannot-link).\n- **Urban Planning**: Cluster neighborhoods, ensuring no cluster crosses a highway (domain constraint).\n\n---\n\n### Challenges\n- **Constraint Conflicts**: Must-link and cannot-link may contradict (e.g., A-B must-link, B-C cannot-link, A-C must-link).\n- **Scalability**: Checking constraints for large datasets is costly.\n- **Parameter Tuning**: Balancing constraint weight vs. clustering objective.\n"
  },
  {
    "url": "University/Data_Mining/Module_2/Density Based Methods.html",
    "content": "### Density-Based Methods\nDensity-based clustering identifies clusters as regions of high point density separated by areas of low density. Points in sparse regions are typically labeled as noise or outliers.\n\n- **Core Idea**: A cluster grows as long as there are enough nearby points (high density) within a specified radius.\n- **Key Advantage**: No need to specify the number of clusters (\\( k \\)) upfront, unlike K-Means.\n\n### Core Concepts\n1. **Core Point**:\n   - A point with at least \\( MinPts \\) other points (including itself) within a distance \\( \\epsilon \\) (epsilon).\n   - These points form the \"heart\" of a cluster.\n\n2. **Border Point**:\n   - A point within \\( \\epsilon \\) of a core point but with fewer than \\( MinPts \\) neighbors.\n   - These are on the edge of a cluster.\n\n3. **Noise Point**:\n   - A point that’s neither a core nor a border point (isolated, low-density).\n   - Treated as outliers.\n\n4. **Density-Reachability**:\n   - A point \\( q \\) is density-reachable from \\( p \\) if there’s a chain of core points connecting them, each within \\( \\epsilon \\).\n\n5. **Density-Connected**:\n   - Two points are density-connected if there’s a core point from which both are density-reachable.\n   - This defines a cluster.\n\n6. **Parameters**:\n   - \\( \\epsilon \\): Radius of the neighborhood (distance threshold).\n   - \\( MinPts \\): Minimum number of points to form a dense region.\n\n### Key Algorithm: DBSCAN (Density-Based Spatial Clustering of Applications with Noise)\nDBSCAN is the most popular density-based method. It’s intuitive and widely used.\n\n#### How It Works\n1. **Input**: Dataset, \\( \\epsilon \\), \\( MinPts \\).\n2. **Start**: Pick an unvisited point.\n3. **Core Check**: If it has \\( \\geq MinPts \\) neighbors within \\( \\epsilon \\), it’s a core point; start a new cluster.\n4. **Expand Cluster**: Add all density-reachable points (core and border) to the cluster.\n5. **Repeat**: Move to the next unvisited point until all points are processed.\n6. **Output**: Clusters and noise points.\n\n#### Example\nDataset: Points A(1, 1), B(1, 2), C(2, 1), D(5, 5), E(6, 6), F(10, 10).  \nParameters: \\( \\epsilon = 1.5 \\), \\( MinPts = 3 \\), Euclidean distance.\n- **A(1, 1)**: Neighbors = {B(1, 2), C(2, 1)} (distance ≈ 1) → 3 points (including A) → Core point.\n- **B(1, 2)**: Neighbors = {A, C} → Core point.\n- **C(2, 1)**: Neighbors = {A, B} → Core point.\n- **D(5, 5)**: Neighbor = {E(6, 6)} (distance ≈ 1.41) → 2 points < \\( MinPts \\) → Not core.\n- **E(6, 6)**: Neighbor = {D} → Not core.\n- **F(10, 10)**: No neighbors → Noise.\n\n**Result**:\n- Cluster 1: {A, B, C} (density-connected core points).\n- Noise: {D, E, F} (not dense enough).\n\n#### Pros and Cons\n- **Pros**:\n  - Finds arbitrary shapes (e.g., rings, crescents).\n  - Handles noise/outliers naturally.\n  - No need to specify \\( k \\).\n- **Cons**:\n  - Sensitive to \\( \\epsilon \\) and \\( MinPts \\) (hard to tune).\n  - Struggles with varying density across clusters.\n  - O(n²) time complexity without indexing (O(n log n) with spatial indexing).\n\n### Other Density-Based Methods\n\n1. **OPTICS (Ordering Points To Identify the Clustering Structure)**:\n   - Extends DBSCAN to handle varying densities.\n   - How it works:\n     - Orders points by core distance (distance to nearest \\( MinPts \\)-th neighbor) and reachability distance.\n     - Produces a hierarchical structure (like a dendrogram).\n   - Pros: More flexible than DBSCAN, extracts clusters at multiple density levels.\n   - Cons: Complex output, slower computation.\n\n2. **DENCLUE (DENsity CLUstering)**:\n   - Uses a density function (e.g., Gaussian kernel) to model data density.\n   - Clusters are peaks in the density landscape.\n   - Pros: Smooth clusters, handles noise well.\n   - Cons: Requires tuning kernel parameters, computationally intensive.\n\n3. **HDBSCAN (Hierarchical DBSCAN)**:\n   - Combines DBSCAN with hierarchical clustering.\n   - How it works: Builds a hierarchy of DBSCAN clusters over varying \\( \\epsilon \\), selects stable clusters.\n   - Pros: Robust to varying density, no single \\( \\epsilon \\) choice.\n   - Cons: More complex, slower than DBSCAN.\n\n#### Example Application\n- **Customer Segmentation**: Cluster shopping locations {latitude, longitude}. Dense urban areas form clusters; rural outliers are noise.\n- **Anomaly Detection**: In network traffic, dense patterns are normal; sparse points are potential threats.\n\n---\n### Comparison with Other Methods\n\n| Feature            | Density-Based (DBSCAN)   | Partitioning (K-Means) | Hierarchical (Agglomerative) |\n| ------------------ | ------------------------ | ---------------------- | ---------------------------- |\n| **Cluster Shape**  | Arbitrary                | Spherical              | Depends on linkage           |\n| **Noise Handling** | Excellent (explicit)     | Poor                   | Poor (merges all)            |\n| **# Clusters**     | Automatic                | Must specify \\( k \\)   | Flexible (cut dendrogram)    |\n| **Scalability**    | Moderate (with indexing) | High                   | Low (O(n³))                  |\n\n---\n### Visual Intuition\nImagine points on a map:\n- **DBSCAN**: Groups dense neighborhoods into clusters, leaves isolated houses as noise.\n- **K-Means**: Forces everything into \\( k \\) circular regions, even outliers.\n- **Hierarchical**: Builds a tree, merging or splitting based on proximity.\n"
  },
  {
    "url": "University/Data_Mining/Module_2/Frequent Pattern Mining.html",
    "content": "### Frequent Pattern Mining\nFrequent pattern mining is about discovering recurring patterns or itemsets in large datasets, often used in transactional data (e.g., market basket analysis). The goal is to find items that frequently appear together.\n\n- **Example**: In a grocery store dataset, if {milk, bread} appears in many transactions, it’s a frequent pattern.\n- **Key Metric**: **Support**—the percentage of transactions containing a specific pattern.  \n  - Formula: Support(A) = (Number of transactions with A) / (Total transactions).\n- **Algorithms**: Apriori, FP-Growth, and ECLAT are popular methods to mine these patterns efficiently.\n"
  },
  {
    "url": "University/Data_Mining/Module_2/Hierarchical Methods.html",
    "content": "---\nid: Hierarchical Methods\naliases: []\ntags: []\n---\n\n### **1. Hierarchical Clustering Methods**\nHierarchical clustering creates a tree-like structure (dendrogram) to represent data groupings at different levels of granularity.\n\n#### **A. Agglomerative (Bottom-Up) Method**\n- **Approach**: Starts with each data point as a single cluster and merges the closest pairs iteratively.\n- **Steps**:\n  1. Treat each data point as a singleton cluster.\n  2. Compute pairwise distances between clusters.\n  3. Merge the two closest clusters.\n  4. Repeat until all points are in one cluster.\n- **Linkage Criteria** (How to measure distance between clusters):\n  - **Single Linkage**: Minimum distance between clusters (sensitive to noise).\n  - **Complete Linkage**: Maximum distance between clusters (compact clusters).\n  - **Average Linkage**: Average distance between clusters (balanced).\n  - **Ward’s Method**: Minimizes variance when merging clusters.\n\n#### **B. Divisive (Top-Down) Method**\n- **Approach**: Starts with all points in one cluster and recursively splits them.\n- **Steps**:\n  1. Start with one cluster containing all points.\n  2. Split the cluster into sub-clusters using a flat clustering method (e.g., k-means).\n  3. Repeat recursively until each point is a cluster.\n- **Less common** due to computational complexity.\n\n---\n\n### **2. Density-Based Methods**\nThese methods identify clusters as dense regions separated by sparse regions.\n\n#### **A. DBSCAN (Density-Based Spatial Clustering of Applications with Noise)**\n- **Key Parameters**:\n  - **ε (eps)**: Maximum distance for two points to be neighbors.\n  - **MinPts**: Minimum number of points to form a dense region.\n- **Concepts**:\n  - **Core Point**: Has ≥ MinPts within ε.\n  - **Border Point**: Has < MinPts but is reachable from a core point.\n  - **Noise Point**: Neither core nor border.\n- **Steps**:\n  1. Randomly pick a point, find its neighbors.\n  2. If it’s a core point, form a cluster.\n  3. Expand cluster by adding reachable points.\n  4. Repeat for unvisited points.\n- **Advantages**:\n  - Handles arbitrary-shaped clusters.\n  - Robust to noise.\n- **Disadvantages**:\n  - Struggles with varying densities.\n  - Sensitive to ε and MinPts.\n\n#### **B. OPTICS (Ordering Points To Identify the Clustering Structure)**\n- Extension of DBSCAN that handles varying densities.\n- Creates a reachability plot to extract clusters at different densities.\n\n---\n\n### **3. Clustering with Constraints**\nIncorporates user-defined constraints to guide clustering.\n\n#### **Types of Constraints**:\n- **Must-Link (ML)**: Two points must be in the same cluster.\n- **Cannot-Link (CL)**: Two points must not be in the same cluster.\n- **Constrained Algorithms**:\n  - **COP-KMeans**: Modifies k-means to respect constraints.\n  - **Constrained Hierarchical Clustering**: Adjusts merges/splits based on constraints.\n- **Applications**: Semi-supervised learning, domain-specific clustering.\n\n---\n\n### **4. Outlier Detection**\nIdentifies data points that deviate significantly from the majority.\n\n#### **A. Statistical Methods**\n- Assumes data follows a distribution (e.g., Gaussian).\n- **Z-Score**: Points with |Z| > 3 are outliers.\n- **Grubbs’ Test**: Detects outliers in univariate data.\n\n#### **B. Distance-Based Methods**\n- **k-NN Outlier Detection**: Points with large distances to their k-nearest neighbors are outliers.\n- **Mahalanobis Distance**: Accounts for covariance in data.\n\n#### **C. Density-Based Methods**\n- **Local Outlier Factor (LOF)**: Compares local density of a point with its neighbors.\n  - LOF ≫ 1 → Outlier.\n\n#### **D. Clustering-Based Methods**\n- Points not belonging to any cluster (e.g., noise in DBSCAN) are outliers.\n\n#### **E. Isolation Forest**\n- Uses decision trees to isolate outliers (fewer splits needed).\n\n---\n\n### **Summary Table**\n| **Method**               | **Key Idea**                              | **Pros**                          | **Cons**                          |\n|--------------------------|------------------------------------------|-----------------------------------|-----------------------------------|\n| Agglomerative            | Bottom-up merging                        | No need for k, interpretable      | O(n³) complexity                 |\n| Divisive                 | Top-down splitting                       | Better for large clusters         | Computationally expensive        |\n| DBSCAN                   | Density-based clusters                   | Handles noise, arbitrary shapes   | Sensitive to parameters          |\n| Clustering with Constraints | Uses ML/CL constraints                | Incorporates domain knowledge     | Constraints may be hard to define |\n| Outlier Detection (LOF)  | Density deviation                        | Works for local outliers          | Computationally heavy            |\n"
  },
  {
    "url": "University/Data_Mining/Module_2/Outlier Detection.html",
    "content": "### Outlier Detection?\nOutlier detection (or anomaly detection) finds data points that differ markedly from the majority of the dataset. These points don’t conform to expected patterns or distributions.\n\n- **Examples**:\n  - A $10,000 transaction in a dataset of $50 purchases.\n  - A temperature reading of -50°C in a tropical climate dataset.\n- **Types**:\n  - **Point Outliers**: Individual anomalies (e.g., a single fraudulent transaction).\n  - **Contextual Outliers**: Anomalous within a specific context (e.g., 30°C in winter).\n  - **Collective Outliers**: A group behaving oddly together (e.g., a sudden spike in network traffic).\n  \n### Why Detect Outliers?\n- **Data Quality**: Identify errors or noise (e.g., sensor malfunctions).\n- **Insight**: Uncover rare events (e.g., disease outbreaks).\n- **Security**: Detect fraud or intrusions (e.g., unusual login patterns).\n- **Preprocessing**: Clean data for better modeling (e.g., remove outliers before clustering).\n\n### Methods for Outlier Detection\nOutlier detection methods vary based on data type, assumptions, and whether the approach is supervised or unsupervised. Let’s explore the main categories:\n#### 1. Statistical Methods\n- **Assumption**: Data follows a known distribution (e.g., Gaussian).\n- **Techniques**:\n  - **Z-Score**: Measures how many standard deviations a point is from the mean.\n    - Formula: \\( z = \\frac{x - \\mu}{\\sigma} \\).\n    - Threshold: \\( |z| > 3 \\) often flags outliers (assuming normality).\n    - Example: In {1, 2, 3, 4, 100}, \\( \\mu = 22 \\), \\( \\sigma \\approx 43.8 \\), \\( z_{100} = 1.78 \\) (not extreme, but adjust threshold for small datasets).\n  - **IQR (Interquartile Range)**:\n    - Q1 (25th percentile), Q3 (75th percentile), IQR = Q3 - Q1.\n    - Outliers: Below \\( Q1 - 1.5 \\cdot IQR \\) or above \\( Q3 + 1.5 \\cdot IQR \\).\n    - Example: {1, 2, 3, 4, 100} → Q1 = 2, Q3 = 4, IQR = 2, limits = [-1, 7], so 100 is an outlier.\n- **Pros**: Simple, interpretable.\n- **Cons**: Assumes distribution, struggles with high-dimensional or non-numeric data.\n\n#### 2. Distance-Based Methods\n- **Assumption**: Outliers are far from most other points.\n- **Techniques**:\n  - **K-Nearest Neighbors (KNN)**:\n    - Compute distance to \\( k \\)-th nearest neighbor for each point.\n    - Outliers have larger distances.\n    - Example: In 2D points, if point A’s 5th neighbor is 10 units away while most are < 2 units, A is an outlier.\n  - **Thresholding**: Set a distance cutoff based on dataset density.\n- **Pros**: No distribution assumption, works with numerical data.\n- **Cons**: Sensitive to \\( k \\), computationally expensive (O(n²) without indexing).\n\n#### 3. Density-Based Methods\n- **Assumption**: Outliers lie in low-density regions.\n- **Techniques**:\n  - **DBSCAN**:\n    - Points labeled as noise (not core or border) are outliers.\n    - Example: In {A(1, 1), B(1, 2), C(2, 1), D(5, 5)}, with \\( \\epsilon = 1.5 \\), \\( MinPts = 3 \\), D is noise (outlier).\n  - **LOF (Local Outlier Factor)**:\n    - Compares a point’s local density to its neighbors’ density.\n    - Formula: \\( LOF(p) = \\frac{\\text{Avg local reachability density of neighbors}}{\\text{Local reachability density of } p} \\).\n    - LOF > 1: Lower density than neighbors → outlier.\n    - Example: A point in a sparse region surrounded by dense clusters has high LOF.\n- **Pros**: Handles arbitrary shapes, robust to varying density.\n- **Cons**: Parameter tuning (\\( \\epsilon \\), \\( MinPts \\)), LOF is complex to compute.\n\n#### 4. Clustering-Based Methods\n- **Assumption**: Outliers don’t fit well into any cluster.\n- **Techniques**:\n  - **K-Means**:\n    - Points far from their assigned centroid (e.g., high squared error) are outliers.\n    - Example: After clustering {1, 2, 3, 100} into \\( k = 2 \\), 100 is far from its centroid.\n  - **Hierarchical Clustering**:\n    - Points merged late in the dendrogram (high height) or left unclustered are outliers.\n  - **DBSCAN**: Noise points are outliers (already covered).\n- **Pros**: Leverages existing clustering, intuitive.\n- **Cons**: Depends on clustering quality, may mislabel small clusters as outliers.\n\n#### 5. Machine Learning-Based Methods\n- **Supervised**: Train a model (e.g., SVM, Random Forest) on labeled data (normal vs. outlier).\n- **Unsupervised**:\n  - **Isolation Forest**:\n    - Builds random trees; outliers are isolated in fewer splits (shorter paths).\n    - Example: In {1, 2, 3, 100}, 100 splits off early.\n  - **Autoencoders**:\n    - Neural network reconstructs data; high reconstruction error = outlier.\n- **Pros**: Powerful for complex data, scalable with trees.\n- **Cons**: Requires tuning, supervised needs labeled data.\n\n### Choosing a Method\n- **Data Type**: Numerical → Z-Score, KNN; Categorical → LOF with appropriate distance; Mixed → Isolation Forest.\n- **Scale**: Small → Statistical; Large → Isolation Forest, DBSCAN with indexing.\n- **Noise**: High → Density-based or ML methods; Low → Distance-based.\n- **Domain**: Fraud → LOF, Isolation Forest; Quality control → Statistical.\n\n### Challenges\n- **High Dimensions**: Distance measures lose meaning (\"curse of dimensionality\").\n- **Context**: Outliers may be valid (e.g., a luxury purchase isn’t fraud).\n- **Thresholds**: Setting cutoffs (e.g., Z > 3, LOF > 2) is subjective.\n\n### Applications\n- **Finance**: Detect fraudulent transactions (e.g., $10,000 vs. $50 norms).\n- **Healthcare**: Spot abnormal vitals (e.g., heart rate spike).\n- **Network Security**: Identify unusual traffic patterns (e.g., DDoS attacks).\n"
  },
  {
    "url": "University/Data_Mining/Module_2/Sequential Pattern mining.html",
    "content": "---\nid: Sequential Pattern mining\naliases: []\ntags: []\ntitle: Sequential Pattern mining\n---\n\nSequential pattern mining finds frequent subsequences in a dataset of sequences. A sequence is an ordered list of events or itemsets, often tied to time or position.\n- **Example**: In a customer shopping dataset:\n  - Sequence: <{milk}, {bread}, {butter}> means a customer bought milk, then bread, then butter over time.\n  - Goal: Find patterns like <{milk}, {bread}> that appear frequently across many customers.\n\n- **Applications**:\n  - Web navigation: <homepage, product page, checkout>.\n  - Bioinformatics: DNA sequences (e.g., <A, C, G, T>).\n  - Retail: Purchase sequences over months.\n\n### Key Concepts\n\n1. **Sequence**:\n   - An ordered list of itemsets (events).\n   - Notation: <{a}, {b, c}, {d}> means \"a happens, then b and c together, then d.\"\n   - Itemsets within a step (e.g., {b, c}) are unordered, but the steps are ordered.\n\n2. **Subsequence**:\n   - A sequence S1 is a subsequence of S2 if all items of S1 appear in S2 in the same order (not necessarily consecutive).\n   - Example: <{a}, {c}> is a subsequence of <{a}, {b}, {c, d}>.\n\n3. **Support**:\n   - The percentage of sequences in the dataset that contain a given subsequence.\n   - Formula: **Support(S) = (Number of sequences containing S) / (Total sequences)**.\n   - Example: If <{milk}, {bread}> appears in 3 out of 5 customer sequences, support = 3/5 = 60%.\n\n4. **Frequent Sequential Pattern**:\n   - A subsequence with support ≥ a user-defined **minimum support threshold** (min_sup).\n   - Example: If min_sup = 50%, <{milk}, {bread}> (60%) is frequent.\n\n5. **Constraints** (optional):\n   - Time gaps: Events must occur within a certain time window (e.g., 1 day).\n   - Length: Limit pattern length (e.g., max 3 steps).\n   - Item constraints: Include specific items (e.g., must contain {milk}).\n\n### Example Dataset\nLet’s use a simple dataset of customer purchase sequences:\n\n| Customer ID | Sequence                    |\n| ----------- | --------------------------- |\n| C1          | <{milk}, {bread}, {butter}> |\n| C2          | <{milk}, {bread}>           |\n| C3          | <{beer}, {milk}, {butter}>  |\n| C4          | <{milk}, {bread}, {beer}>   |\n| C5          | <{bread}, {butter}>         |\n\n- Total sequences: 5.\n- Min_sup: 40% (i.e., 2/5 = 2 sequences).\n\n**Frequent Patterns**:\n- <{milk}>: 4/5 = 80% ✓\n- <{bread}>: 4/5 = 80% ✓\n- <{butter}>: 3/5 = 60% ✓\n- <{milk}, {bread}>: 3/5 = 60% ✓\n- <{bread}, {butter}>: 2/5 = 40% ✓\n- <{milk}, {butter}>: 2/5 = 40% ✓\n\n### Key Algorithms\n\n1. **GSP (Generalized Sequential Patterns)**:\n   - How it works:\n     - Similar to Apriori: Starts with frequent 1-sequences, then builds longer candidates.\n     - Uses a level-wise approach, scanning the database multiple times.\n   - Steps:\n     1. Find frequent 1-sequences (e.g., <{milk}>).\n     2. Generate candidate 2-sequences (e.g., <{milk}, {bread}>) and check support.\n     3. Repeat until no more frequent sequences.\n   - Pros: Simple, supports constraints like time gaps.\n   - Cons: Multiple scans, slow for large datasets.\n\n2. **PrefixSpan (Prefix-Projected Sequential Pattern Mining)**:\n   - How it works:\n     - Projects the database into smaller subsets based on prefixes, avoiding candidate generation.\n     - Grows patterns recursively.\n   - Steps (for above dataset):\n     1. Start with <{milk}> (support 4):\n        - Project database: Look at what follows <{milk}> in C1, C2, C3, C4.\n        - Sub-sequences: <{bread}> (3), <{butter}> (2).\n     2. Extend: <{milk}, {bread}> (support 3), <{milk}, {butter}> (support 2).\n     3. Repeat for other prefixes (e.g., <{bread}>).\n   - Pros: Faster, single-pass after projection, memory-efficient.\n   - Cons: Complex to implement.\n\n3. **SPADE (Sequential PAttern Discovery using Equivalence classes)**:\n   - How it works:\n     - Uses a vertical database format (item-to-sequence ID mapping).\n     - Finds patterns via intersection of ID lists.\n   - Example: <{milk}> in [C1, C2, C3, C4], <{bread}> in [C1, C2, C4, C5]; intersect to find <{milk}, {bread}> in [C1, C2, C4].\n   - Pros: Efficient for dense data, single-pass possible.\n   - Cons: Memory overhead for sparse data.\n   \n### Advanced Concepts\n\n1. **Closed Sequential Patterns**:\n   - A sequence is closed if no super-sequence has the same support.\n   - Example: If <{milk}, {bread}> and <{milk}, {bread}, {butter}> both have support 3, only the latter is closed.\n   - Benefit: Reduces output size.\n\n2. **Maximal Sequential Patterns**:\n   - A sequence is maximal if no super-sequence is frequent.\n   - Example: <{milk}, {bread}, {butter}> might be maximal if <{milk}, {bread}, {butter}, {beer}> isn’t frequent.\n\n3. **Time Constraints**:\n   - Min_gap/Max_gap: Events must occur within a time window.\n   - Example: <{milk}, {bread}> only counts if bread is bought within 7 days of milk.\n\n4. **Sliding Windows**:\n   - For streaming data, patterns are mined over a fixed recent window (e.g., last 100 transactions).\n   \n"
  },
  {
    "url": "University/Data_Mining/Module_2/Similarity and Distance Measure.html",
    "content": ""
  },
  {
    "url": "University/Data_Mining/Module_3/BackPropogation_In_NL.html",
    "content": "---\nid: BackPropogation_In_NL\naliases: []\ntags: []\ntitle: BackPropogation In NL\n---\n\n### **Backpropagation in Neural Networks: A Step-by-Step Guide**\nBackpropagation is the **core algorithm** for training neural networks. It efficiently computes gradients of the loss function with respect to each weight using the **chain rule of calculus**, enabling optimization via gradient descent.\n\n---\n\n## **1. Key Concepts**\n### **A. Neural Network Basics**\n- **Layers**: Input → Hidden → Output.\n- **Neurons**: Apply weights, bias, and activation (e.g., ReLU, Sigmoid).\n- **Forward Pass**: Compute predictions from input to output.\n- **Loss Function**: Measures prediction error (e.g., Mean Squared Error, Cross-Entropy).\n\n### **B. Backpropagation Intuition**\n- **Goal**: Adjust weights to minimize loss.\n- **Method**: Propagate error **backward** from output to input, computing gradients for each weight.\n\n---\n\n## **2. Mathematical Foundations**\n### **A. Chain Rule**\nFor a composite function \\( f(g(x)) \\):\n\\[\n\\frac{df}{dx} = \\frac{df}{dg} \\cdot \\frac{dg}{dx}\n\\]\n\n### **B. Gradient Descent Update Rule**\n\\[\nw_{new} = w_{old} - \\eta \\cdot \\frac{\\partial L}{\\partial w}\n\\]\n- \\( \\eta \\): Learning rate.\n- \\( \\frac{\\partial L}{\\partial w} \\): Gradient of loss \\( L \\) w.r.t weight \\( w \\).\n\n---\n\n## **3. Step-by-Step Backpropagation**\nConsider a simple 2-layer NN:\n1. **Input Layer** → **Hidden Layer** (activation: Sigmoid \\( \\sigma \\)).\n2. **Hidden Layer** → **Output Layer** (activation: Linear for regression).\n\n### **Step 1: Forward Pass**\n- **Input to Hidden**:\n  \\[\n  z_h = w_1 x + b_1, \\quad a_h = \\sigma(z_h)\n  \\]\n- **Hidden to Output**:\n  \\[\n  z_o = w_2 a_h + b_2, \\quad \\hat{y} = z_o \\quad (\\text{Linear})\n  \\]\n- **Loss** (MSE):\n  \\[\n  L = \\frac{1}{2}(y - \\hat{y})^2\n  \\]\n\n### **Step 2: Backward Pass (Gradient Calculation)**\n#### **1. Compute \\( \\frac{\\partial L}{\\partial w_2} \\) (Output Layer)**\n\\[\n\\frac{\\partial L}{\\partial w_2} = \\frac{\\partial L}{\\partial \\hat{y}} \\cdot \\frac{\\partial \\hat{y}}{\\partial z_o} \\cdot \\frac{\\partial z_o}{\\partial w_2}\n\\]\n\\[\n\\frac{\\partial L}{\\partial \\hat{y}} = - (y - \\hat{y}), \\quad \\frac{\\partial \\hat{y}}{\\partial z_o} = 1, \\quad \\frac{\\partial z_o}{\\partial w_2} = a_h\n\\]\n\\[\n\\boxed{\\frac{\\partial L}{\\partial w_2} = - (y - \\hat{y}) \\cdot a_h}\n\\]\n\n#### **2. Compute \\( \\frac{\\partial L}{\\partial w_1} \\) (Hidden Layer)**\n\\[\n\\frac{\\partial L}{\\partial w_1} = \\frac{\\partial L}{\\partial \\hat{y}} \\cdot \\frac{\\partial \\hat{y}}{\\partial z_o} \\cdot \\frac{\\partial z_o}{\\partial a_h} \\cdot \\frac{\\partial a_h}{\\partial z_h} \\cdot \\frac{\\partial z_h}{\\partial w_1}\n\\]\n\\[\n\\frac{\\partial z_o}{\\partial a_h} = w_2, \\quad \\frac{\\partial a_h}{\\partial z_h} = \\sigma(z_h)(1 - \\sigma(z_h)), \\quad \\frac{\\partial z_h}{\\partial w_1} = x\n\\]\n\\[\n\\boxed{\\frac{\\partial L}{\\partial w_1} = - (y - \\hat{y}) \\cdot w_2 \\cdot \\sigma'(z_h) \\cdot x}\n\\]\n\n#### **3. Update Biases (Similar Logic)**\n\\[\n\\frac{\\partial L}{\\partial b_2} = - (y - \\hat{y}), \\quad \\frac{\\partial L}{\\partial b_1} = - (y - \\hat{y}) \\cdot w_2 \\cdot \\sigma'(z_h)\n\\]\n\n---\n\n## **4. Generalization to Deep Networks**\nFor a network with \\( L \\) layers:\n1. **Forward Pass**: Compute activations \\( a^{(l)} \\) for all layers.\n2. **Backward Pass**:\n   - Initialize **error term** at output:\n     \\[\n     \\delta^{(L)} = \\nabla_{\\hat{y}} L \\odot f'(z^{(L)})\n     \\]\n   - Propagate backward:\n     \\[\n     \\delta^{(l)} = (w^{(l+1)})^T \\delta^{(l+1)} \\odot f'(z^{(l)})\n     \\]\n   - Compute gradients:\n     \\[\n     \\frac{\\partial L}{\\partial w^{(l)}} = \\delta^{(l)} (a^{(l-1)})^T, \\quad \\frac{\\partial L}{\\partial b^{(l)}} = \\delta^{(l)}\n     \\]\n\n---\n\n## **5. Practical Considerations**\n### **A. Activation Derivatives**\n| **Activation** | **Derivative \\( f'(z) \\)**           |\n|----------------|--------------------------------------|\n| Sigmoid        | \\( \\sigma(z)(1 - \\sigma(z)) \\)       |\n| ReLU           | \\( 1 \\text{ if } z > 0 \\text{ else } 0 \\) |\n| Tanh           | \\( 1 - \\tanh^2(z) \\)                 |\n\n### **B. Common Loss Functions**\n| **Loss**       | **Derivative \\( \\frac{\\partial L}{\\partial \\hat{y}} \\)** |\n|----------------|--------------------------------------------------------|\n| MSE            | \\( \\hat{y} - y \\)                                      |\n| Cross-Entropy  | \\( \\frac{\\hat{y} - y}{\\hat{y}(1 - \\hat{y})} \\)        |\n\n### **C. Numerical Stability**\n- **Vanishing Gradients**: Use ReLU/Leaky ReLU, skip connections (ResNet).\n- **Exploding Gradients**: Gradient clipping, weight initialization (Xavier/He).\n\n---\n\n## **6. Pseudocode for Backpropagation**\n```python\ndef backprop(X, y, weights, biases):\n    # Forward pass\n    z1 = X @ weights['w1'] + biases['b1']\n    a1 = sigmoid(z1)\n    z2 = a1 @ weights['w2'] + biases['b2']\n    y_pred = z2\n    \n    # Loss gradient (MSE)\n    dL_dy = y_pred - y\n    \n    # Backward pass\n    dL_dw2 = a1.T @ dL_dy\n    dL_db2 = np.sum(dL_dy, axis=0)\n    \n    dL_da1 = dL_dy @ weights['w2'].T\n    dL_dz1 = dL_da1 * sigmoid_derivative(z1)\n    dL_dw1 = X.T @ dL_dz1\n    dL_db1 = np.sum(dL_dz1, axis=0)\n    \n    return {'w1': dL_dw1, 'b1': dL_db1, 'w2': dL_dw2, 'b2': dL_db2}\n```\n\n---\n\n## **7. Visual Explanation**\n```\nInput (x) → [w1, b1] → Hidden Layer (σ) → [w2, b2] → Output (ŷ)\n          ↑ Backward pass (gradients) ↑\n```\n- **Red arrows**: Error propagation from output → input.\n- **Blue arrows**: Weight updates using gradients.\n\n---\n\n## **Key Takeaways**\n1. Backpropagation computes gradients **efficiently** using the chain rule.\n2. **Forward Pass**: Compute predictions and loss.\n3. **Backward Pass**: Propagate errors and update weights.\n4. **Critical for Deep Learning**: Enables training of complex architectures (CNNs, RNNs).\n"
  },
  {
    "url": "University/Data_Mining/Module_3/Classification.html",
    "content": "---\nid: Classification\naliases: []\ntags: []\ntitle: Classification\n---\n\n## **1. Classification: Basic Concepts**\n**Classification** is a supervised learning technique where a model predicts categorical class labels based on input features.\n\n### **Key Terms**\n- **Classifier**: Algorithm that maps input data to a category.\n- **Training Data**: Labeled dataset used to train the model.\n- **Testing Data**: Unseen data used to evaluate model performance.\n- **Features (Attributes)**: Input variables used for prediction.\n- **Class Label**: Output category to be predicted.\n\n### **Evaluation Metrics**\n- **Accuracy**: (TP + TN) / Total predictions  \n- **Precision**: TP / (TP + FP) *(How many selected items are relevant?)*  \n- **Recall (Sensitivity)**: TP / (TP + FN) *(How many relevant items are selected?)*  \n- **F1-Score**: Harmonic mean of Precision & Recall  \n- **Confusion Matrix**: Tabulates TP, TN, FP, FN.\n\n---\n\n## **2. Decision Tree Induction**\nA **decision tree** is a flowchart-like structure where:\n- **Internal nodes** = Feature tests  \n- **Branches** = Outcomes of tests  \n- **Leaf nodes** = Class labels  \n\n### **Tree Construction (ID3, C4.5, CART)**\n1. **Select the best attribute** to split data (using a **splitting criterion**).\n2. **Partition data** into subsets based on attribute values.\n3. **Repeat recursively** until:\n   - All samples belong to one class, or  \n   - No remaining features, or  \n   - Tree reaches max depth.\n\n### **Splitting Criteria**\n- **Information Gain (ID3)**  \n  \\( IG(D, A) = H(D) - H(D|A) \\)  \n  (Maximize gain; biased towards high-cardinality features.)  \n- **Gain Ratio (C4.5)**  \n  \\( GR(D, A) = \\frac{IG(D, A)}{SplitInfo(A)} \\)  \n  (Normalizes IG to reduce bias.)  \n- **Gini Index (CART)**  \n  \\( Gini(D) = 1 - \\sum (p_i)^2 \\)  \n  (Measures impurity; prefers larger partitions.)\n\n### **Advantages & Disadvantages**\n| **Pros**                     | **Cons**                          |\n|------------------------------|-----------------------------------|\n| Easy to interpret            | Prone to overfitting             |\n| Handles non-linear data      | Unstable (small changes → new tree) |\n| No need for feature scaling  | Biased if classes are imbalanced |\n\n---\n\n## **3. Bayesian Classification**\nBayesian methods use probability to predict class membership.\n\n### **Naïve Bayes Classifier**\n- Assumes **features are independent** given the class (naïve assumption).  \n- Uses **Bayes’ Theorem**:  \n  \\( P(Y|X) = \\frac{P(X|Y) \\cdot P(Y)}{P(X)} \\)  \n  - \\( P(Y|X) \\): Posterior probability (class given features).  \n  - \\( P(X|Y) \\): Likelihood (feature distribution per class).  \n  - \\( P(Y) \\): Prior probability of class.  \n\n#### **Types of Naïve Bayes**\n1. **Gaussian NB**: Assumes continuous features follow a normal distribution.  \n2. **Multinomial NB**: For discrete counts (e.g., text classification).  \n3. **Bernoulli NB**: Binary features (e.g., word presence/absence).  \n\n#### **Pros & Cons**\n| **Pros**                     | **Cons**                          |\n|------------------------------|-----------------------------------|\n| Fast & scalable              | Naïve assumption (feature independence) |\n| Works well with high dimensions | Struggles if dependencies exist |\n\n---\n\n## **4. Bayesian Belief Networks (BBNs)**\n- Also called **Bayesian Networks** or **Probabilistic Graphical Models**.  \n- Represents dependencies between variables via a **Directed Acyclic Graph (DAG)**.  \n\n### **Key Components**\n1. **Nodes**: Random variables (features or class).  \n2. **Edges**: Conditional dependencies.  \n3. **Conditional Probability Tables (CPTs)**: Quantify relationships.  \n\n### **Example**\n- **Medical Diagnosis**:  \n  - Nodes: `Smoking`, `Cancer`, `Cough`  \n  - Edges: `Smoking → Cancer → Cough`  \n  - CPT: \\( P(Cough | Cancer) \\), \\( P(Cancer | Smoking) \\).  \n\n### **Inference in BBNs**\n- Compute posterior probabilities given evidence (e.g., \\( P(Cancer | Cough = True) \\)).  \n- Algorithms: **Variable Elimination, Markov Chain Monte Carlo (MCMC)**.  \n\n### **Advantages & Disadvantages**\n| **Pros**                     | **Cons**                          |\n|------------------------------|-----------------------------------|\n| Handles dependencies         | Complex to construct             |\n| Interpretable structure      | Computationally expensive for large networks |\n| Incorporates prior knowledge | Requires probability estimations |\n\n---\n\n## **Summary Table**\n| **Method**               | **Key Idea**                              | **When to Use**                  |\n|--------------------------|------------------------------------------|-----------------------------------|\n| Decision Trees           | Split data via feature tests             | Need interpretability, non-linear data |\n| Naïve Bayes              | Probabilistic, independence assumption  | Text classification, high dimensions |\n| Bayesian Networks        | Models dependencies via DAG              | Domain knowledge available, dependencies matter |\n\n"
  },
  {
    "url": "University/Data_Mining/Module_3/Genetic_Algorithm.html",
    "content": "---\nid: Genetic_Algorithm\naliases: []\ntags: []\ntitle: Genetic Algorithm\n---\n\n## **1. Genetic Algorithm**\nA **GA** is a metaheuristic search method that mimics Darwinian evolution:\n- **Population**: Set of candidate solutions (chromosomes).\n- **Fitness Function**: Evaluates solution quality.\n- **Selection**: Favors high-fitness individuals.\n- **Crossover & Mutation**: Generates new solutions.\n\n---\n\n## **2. Key Components of Genetic Algorithms**\n| **Component**       | **Description**                                                                 |\n|----------------------|-------------------------------------------------------------------------------|\n| **Chromosome**       | Encoded solution (binary, real-valued, permutation).                         |\n| **Population**       | Group of chromosomes (e.g., 50–100 candidates).                              |\n| **Fitness Function** | Measures solution quality (e.g., accuracy, RMSE).                            |\n| **Selection**        | Chooses parents for reproduction (e.g., roulette wheel, tournament).         |\n| **Crossover**        | Combines parent genes to produce offspring (e.g., single-point, uniform).    |\n| **Mutation**         | Introduces random changes to maintain diversity (e.g., bit flip, Gaussian).  |\n| **Termination**      | Stops when convergence is reached (e.g., max generations, no improvement).   |\n\n---\n\n## **3. How Genetic Algorithms Work in Data Mining**\n### **Step-by-Step Workflow**\n1. **Initialization**  \n   - Generate a random population of solutions (e.g., random feature subsets).\n\n2. **Fitness Evaluation**  \n   - Compute fitness (e.g., model accuracy using selected features).\n\n3. **Selection**  \n   - Retain top-performing chromosomes (e.g., rank-based selection).\n\n4. **Crossover**  \n   - Combine parents to create offspring (e.g., swap feature subsets).\n\n5. **Mutation**  \n   - Randomly alter genes (e.g., add/drop a feature).\n\n6. **Termination**  \n   - Repeat until convergence (e.g., 100 generations).\n\n---\n\n## **4. Applications in Data Mining**\n### **A. Feature Selection**\n- **Problem**: High-dimensional data reduces model efficiency.  \n- **GA Approach**:  \n  - **Chromosome**: Binary string (1 = feature selected, 0 = excluded).  \n  - **Fitness**: Classification accuracy (e.g., SVM with selected features).  \n- **Example**:  \n  ```python\n  # Chromosome: [1, 0, 1, 1] → Features 1, 3, 4 selected.\n  fitness = accuracy_score(y_test, model.fit(X_train[:, chromosome], y_train).predict(X_test[:, chromosome]))\n  ```\n\n### **B. Clustering**\n- **Problem**: Optimal cluster number/assignment is NP-hard.  \n- **GA Approach**:  \n  - **Chromosome**: Encodes cluster centroids (e.g., [μ₁, μ₂, μ₃]).  \n  - **Fitness**: Inverse of within-cluster variance.  \n- **Example**:  \n  ```python\n  def fitness(chromosome):\n      kmeans = KMeans(n_clusters=3, init=chromosome.reshape(3, 2))\n      return -kmeans.inertia_  # Minimize variance\n  ```\n\n### **C. Classification Rule Discovery**\n- **Problem**: Extract interpretable \"IF-THEN\" rules.  \n- **GA Approach**:  \n  - **Chromosome**: Encodes rule conditions (e.g., `IF Age>30 AND Income<50k THEN Churn=Yes`).  \n  - **Fitness**: Rule coverage + accuracy.  \n\n### **D. Hyperparameter Tuning**\n- **Problem**: Grid search is computationally expensive.  \n- **GA Approach**:  \n  - **Chromosome**: Encodes hyperparameters (e.g., [learning_rate=0.01, depth=5]).  \n  - **Fitness**: Cross-validation score.  \n\n---\n\n## **5. Advantages of Genetic Algorithms**\n| **Advantage**                | **Why It Matters**                                                                 |\n|-------------------------------|-----------------------------------------------------------------------------------|\n| **Global Optimization**       | Avoids local optima (vs. gradient descent).                                       |\n| **Handles Non-Differentiable Problems** | Works where calculus-based methods fail (e.g., feature selection).              |\n| **Parallelizable**            | Evaluates multiple solutions simultaneously.                                      |\n| **Interpretability**          | Generates human-readable rules (e.g., in classification).                        |\n\n---\n\n## **6. Challenges & Solutions**\n| **Challenge**                | **Solution**                                      |\n|------------------------------|---------------------------------------------------|\n| **High Computational Cost**  | Use elitism (preserve top solutions), limit generations. |\n| **Premature Convergence**    | Increase mutation rate, use niche techniques.     |\n| **Parameter Tuning**         | Adaptive GAs (e.g., self-adjusting mutation rates). |\n\n---\n\n## **7. Example: Feature Selection with GA**\n### **Python Implementation (using DEAP)**\n```python\nfrom deap import base, creator, tools, algorithms\nimport numpy as np\n\n# 1. Define fitness and chromosome structure\ncreator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\ncreator.create(\"Individual\", list, fitness=creator.FitnessMax)\n\ntoolbox = base.Toolbox()\ntoolbox.register(\"attr_bool\", np.random.randint, 0, 2)  # Binary encoding\ntoolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, n=10)  # 10 features\ntoolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n\n# 2. Fitness function (e.g., SVM accuracy)\ndef eval_feature_subset(individual):\n    selected_features = [i for i, val in enumerate(individual) if val == 1]\n    if not selected_features:\n        return 0.0,\n    X_subset = X[:, selected_features]\n    return (cross_val_score(SVC(), X_subset, y, cv=5).mean(),)  # Mean CV accuracy\n\ntoolbox.register(\"evaluate\", eval_feature_subset)\ntoolbox.register(\"mate\", tools.cxTwoPoint)\ntoolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.1)\ntoolbox.register(\"select\", tools.selTournament, tournsize=3)\n\n# 3. Evolve the population\npopulation = toolbox.population(n=50)\nalgorithms.eaSimple(population, toolbox, cxpb=0.5, mutpb=0.2, ngen=10, verbose=True)\n\n# 4. Extract best solution\nbest_individual = tools.selBest(population, k=1)[0]\nprint(\"Selected Features:\", [i for i, val in enumerate(best_individual) if val == 1])\n```\n\n---\n\n## **8. Key Takeaways**\n1. **GAs are versatile** for optimization in data mining (feature selection, clustering, etc.).  \n2. **Evolutionary operators** (crossover, mutation) balance exploration and exploitation.  \n3. **Combine with ML models** (e.g., SVM, K-means) for enhanced performance.  \n4. **Use libraries** like DEAP, TPOT, or scikit-learn’s `GeneticAlgorithmCV`.  \n"
  },
  {
    "url": "University/Data_Mining/Module_3/Improving_Classifier_Accuracy.html",
    "content": "---\nid: Improving_Classifier_Accuracy\naliases: []\ntags: []\ntitle: Improving Classifier Accuracy\n---\n\n## **1. Data Preprocessing**\n### **A. Handle Missing Data**\n- **Drop rows/columns** if missing values are excessive.\n- **Impute** using:\n  - Mean/median (numerical data).\n  - Mode (categorical data).\n  - Predictive models (e.g., k-NN imputation).\n\n### **B. Feature Engineering**\n- **Create new features** (e.g., ratios, interactions, polynomial terms).\n- **Bin continuous variables** (e.g., age groups).\n- **Use domain knowledge** (e.g., extracting day/month from dates).\n\n### **C. Feature Scaling**\n- **Standardization** (Z-score):  \n  \\( X_{\\text{scaled}} = \\frac{X - \\mu}{\\sigma} \\)  \n  (For SVM, k-NN, neural networks.)\n- **Normalization (Min-Max)**:  \n  \\( X_{\\text{scaled}} = \\frac{X - X_{\\min}}{X_{\\max} - X_{\\min}} \\)  \n  (For algorithms like k-NN, gradient descent.)\n\n### **D. Encoding Categorical Variables**\n- **One-Hot Encoding** (for nominal data).\n- **Label Encoding** (for ordinal data).\n\n### **E. Outlier Detection & Removal**\n- **Z-score** (if Gaussian-distributed).\n- **IQR method**:  \n  Remove points outside \\( Q1 - 1.5 \\times IQR \\) and \\( Q3 + 1.5 \\times IQR \\).\n\n---\n\n## **2. Algorithm Selection**\nChoose the right model based on data characteristics:\n\n| **Scenario**               | **Recommended Algorithms**          |\n|----------------------------|-------------------------------------|\n| Small dataset              | SVM, Naïve Bayes, Decision Trees   |\n| Large dataset             | Random Forest, XGBoost, Neural Nets |\n| High-dimensional data     | Regularized models (Lasso, Ridge)   |\n| Imbalanced classes        | SMOTE, Class weights, F1-score opt. |\n| Non-linear relationships  | Kernel SVM, Random Forest, XGBoost  |\n\n---\n\n## **3. Hyperparameter Tuning**\nOptimize model parameters using:\n### **A. Grid Search**\n- Exhaustively tests all combinations.\n- Example for **Random Forest**:\n  ```python\n  params = {\n      'n_estimators': [50, 100, 200],\n      'max_depth': [5, 10, None],\n      'min_samples_split': [2, 5, 10]\n  }\n  ```\n### **B. Random Search**\n- Faster than grid search; samples randomly.\n### **C. Bayesian Optimization**\n- Uses probabilistic models to find optimal params.\n\n---\n\n## **4. Handle Class Imbalance**\n### **A. Resampling**\n- **Oversampling**: SMOTE (Synthetic Minority Oversampling).\n- **Undersampling**: Random removal of majority class.\n### **B. Class Weighting**\n- Assign higher weights to minority classes.\n  ```python\n  # In scikit-learn\n  model = RandomForestClassifier(class_weight='balanced')\n  ```\n### **C. Use Better Metrics**\n- **F1-score**, **Precision-Recall AUC** instead of accuracy.\n\n---\n\n## **5. Ensemble Methods**\nCombine multiple models to boost performance:\n### **A. Bagging (Bootstrap Aggregating)**\n- **Random Forest**: Reduces variance by averaging multiple decision trees.\n### **B. Boosting**\n- **XGBoost/LightGBM**: Sequentially corrects errors from prior models.\n### **C. Stacking**\n- Uses predictions of base models as input to a meta-model.\n\n---\n\n## **6. Advanced Techniques**\n### **A. Feature Selection**\n- **Filter Methods**: Correlation, Chi-square.\n- **Wrapper Methods**: Recursive Feature Elimination (RFE).\n- **Embedded Methods**: Lasso regression, feature importance from trees.\n### **B. Dimensionality Reduction**\n- **PCA**: For linear relationships.\n- **t-SNE/UMAP**: For visualization/non-linear data.\n### **C. Cross-Validation**\n- **Stratified k-Fold**: Preserves class distribution.\n- **Leave-One-Out (LOO)**: For very small datasets.\n\n---\n\n## **7. Debugging Low Accuracy**\n| **Issue**                | **Solution**                          |\n|--------------------------|---------------------------------------|\n| High bias (underfitting) | Add more features, use complex models |\n| High variance (overfitting) | Regularization, more training data   |\n| Poor feature quality     | Feature engineering, selection        |\n| Data leakage             | Ensure no test data leaks into train  |\n\n---\n\n## **8. Example Workflow**\n1. **Preprocess data** (clean, scale, encode).\n2. **Train baseline model** (e.g., logistic regression).\n3. **Tune hyperparameters** (GridSearchCV).\n4. **Apply ensemble methods** (XGBoost).\n5. **Evaluate** using cross-validation and metrics like F1-score.\n6. **Deploy best model**.\n\n---\n\n## **Key Takeaways**\n- **Data quality > Model complexity**.\n- **Always cross-validate** to avoid overfitting.\n- **Ensemble methods** (XGBoost, Random Forest) often outperform single models.\n- **Focus on the right metric** (e.g., F1 for imbalanced data).\n"
  },
  {
    "url": "University/Data_Mining/Module_3/Lazy_Learners_Rule_based_Classification_Model_Evaluation_Selection.html",
    "content": "---\nid: Lazy_Learners_Rule_based_Classification_Model_Evaluation_Selection\naliases: []\ntags: []\ntitle: Lazy Learners Rule based Classification Model Evaluation Selection\n---\n\n# **1. Lazy Learners (Instance-Based Learning)**\nLazy learners **do not build an explicit model** during training. Instead, they **store the training data** and defer processing until prediction time.\n\n### **Key Characteristics**\n- **No training phase**: Simply memorizes data (non-parametric).\n- **Fast training, slow prediction**: Must compute distances/weights for each new query.\n- **Adapts to new data**: No need to retrain; just add new instances.\n\n---\n\n### **A. k-Nearest Neighbors (k-NN)**\n#### **How It Works**\n1. **Store** all training examples.\n2. For a new instance:\n   - Compute **distance** (e.g., Euclidean, Manhattan) to all stored examples.\n   - Select the **k closest neighbors**.\n   - Assign the **majority class** (classification) or **average value** (regression).\n\n#### **Distance Metrics**\n| Metric          | Formula (for vectors \\(x, y\\))                     | Use Case                     |\n|-----------------|----------------------------------------------------|-----------------------------|\n| **Euclidean**   | \\(\\sqrt{\\sum_{i=1}^n (x_i - y_i)^2}\\)             | Continuous features         |\n| **Manhattan**   | \\(\\sum_{i=1}^n |x_i - y_i|\\)                    | Robust to outliers          |\n| **Minkowski**   | \\((\\sum_{i=1}^n |x_i - y_i|^p)^{1/p}\\)          | Generalizes Euclidean (p=2) |\n| **Cosine**      | \\(1 - \\frac{x \\cdot y}{\\|x\\| \\|y\\|}\\)             | Text/data with sparsity     |\n\n#### **Choosing k**\n- **Small k (e.g., 1)** → High variance (overfitting, noisy boundaries).  \n- **Large k** → High bias (underfitting, smoother boundaries).  \n- **Rule of thumb**: \\(k = \\sqrt{n}\\) (where \\(n\\) = training samples).\n\n#### **Pros & Cons**\n| **Advantages**                          | **Disadvantages**                          |\n|-----------------------------------------|--------------------------------------------|\n| Simple to implement                     | Slow prediction (O(n) per query)           |\n| No assumptions about data distribution  | Sensitive to irrelevant features           |\n| Naturally handles multi-class problems  | Requires feature scaling                   |\n\n---\n\n### **B. Case-Based Reasoning (CBR)**\n- **Concept**: Solve new problems by retrieving **similar past cases** (e.g., medical diagnosis, legal reasoning).  \n- **Steps**:\n  1. **Retrieve** similar cases from memory.\n  2. **Reuse** solutions from past cases.\n  3. **Revise** solutions if needed.\n  4. **Retain** new solutions for future use.\n\n#### **Example: Medical Diagnosis**\n- **New case**: Patient with {fever, cough}.  \n- **Retrieve**: Past cases with similar symptoms.  \n- **Reuse**: Diagnose as \"flu\" if most matches suggest it.  \n\n#### **Pros & Cons**\n| **Advantages**                          | **Disadvantages**                          |\n|-----------------------------------------|--------------------------------------------|\n| Interpretable (human-like reasoning)    | Requires a large case database             |\n| Adapts to new knowledge incrementally  | Computationally expensive for retrieval   |\n\n---\n\n# **2. Rule-Based Classification**\nRule-based classifiers use **\"if-then\" rules** to assign classes. Rules are derived from data or expert knowledge.\n\n### **Types of Rules**\n1. **Decision Lists**: Ordered rules (first match wins).  \n2. **Decision Sets**: Unordered rules (may require conflict resolution).  \n\n### **Rule Extraction Methods**\n#### **A. Direct Methods (Learn Rules from Data)**\n- **RIPPER (Repeated Incremental Pruning to Produce Error Reduction)**:\n  - Greedily adds rules to cover positive examples.\n  - Prunes rules to avoid overfitting.\n- **CN2 (Inductive Rule Learning)**:\n  - Uses beam search to find high-coverage rules.\n\n#### **B. Indirect Methods (Convert Models to Rules)**\n- **From Decision Trees**: Each path from root to leaf → a rule.\n  - Example:  \n    `IF (Age < 30) AND (Income = High) THEN Buy = Yes`.\n\n#### **Rule Quality Measures**\n- **Coverage**: % of instances the rule applies to.  \n- **Accuracy**: % of correctly classified instances covered by the rule.  \n- **Laplace Estimate**: Adjusts for small sample sizes.  \n\n#### **Pros & Cons**\n| **Advantages**                          | **Disadvantages**                          |\n|-----------------------------------------|--------------------------------------------|\n| Highly interpretable                    | May overfit with noisy data                |\n| Handles categorical data well           | Rule conflicts may require resolution     |\n\n---\n\n# **3. Model Evaluation and Selection**\nEvaluating classifiers ensures they generalize well to unseen data.\n\n### **A. Evaluation Metrics**\n#### **For Classification**\n| Metric          | Formula                          | Interpretation                          |\n|-----------------|----------------------------------|----------------------------------------|\n| **Accuracy**    | \\(\\frac{TP + TN}{TP + TN + FP + FN}\\) | Overall correctness                   |\n| **Precision**   | \\(\\frac{TP}{TP + FP}\\)           | How many selected are relevant?       |\n| **Recall**      | \\(\\frac{TP}{TP + FN}\\)           | How many relevant are selected?       |\n| **F1-Score**    | \\(2 \\times \\frac{Precision \\times Recall}{Precision + Recall}\\) | Harmonic mean of P & R |\n\n#### **For Imbalanced Data**\n- **ROC Curve**: Plots TPR (Recall) vs. FPR (\\( \\frac{FP}{TN + FP} \\)).  \n- **AUC (Area Under Curve)**: Higher AUC = better model.  \n\n#### **For Regression**\n- **MSE (Mean Squared Error)**: \\(\\frac{1}{n} \\sum (y_i - \\hat{y}_i)^2\\).  \n- **R² (R-Squared)**: Proportion of variance explained by the model.  \n\n### **B. Cross-Validation**\n- **k-Fold CV**: Splits data into k folds; each fold serves as test set once.  \n- **Stratified k-Fold**: Preserves class distribution in splits.  \n\n### **C. Model Selection**\n1. **Bias-Variance Tradeoff**:  \n   - **High bias** (underfitting) → Simplify model.  \n   - **High variance** (overfitting) → Regularize or get more data.  \n2. **Hyperparameter Tuning**:  \n   - **Grid Search**: Exhaustive search over parameter combinations.  \n   - **Random Search**: Randomly samples parameter space.  \n\n---\n\n# **Summary Table**\n| **Concept**               | **Key Idea**                              | **When to Use**                  |\n|---------------------------|------------------------------------------|----------------------------------|\n| **k-NN**                  | Instance-based, distance-weighted voting | Small datasets, interpretability |\n| **Rule-Based**            | \"If-then\" rules from data/expertise      | Need transparent decision logic  |\n| **Model Evaluation**      | Metrics (Accuracy, F1, AUC), CV          | Ensure generalization            |\n| **Model Selection**       | Hyperparameter tuning, bias-variance     | Optimize performance             |\n"
  },
  {
    "url": "University/Data_Mining/Module_3/Regression.html",
    "content": "---\nid: Regression\naliases: []\ntags: []\ntitle: Regression\n---\n\n# **Prediction Techniques: Linear & Non-Linear Regression in Data Mining**\n\nRegression is a **fundamental predictive modeling technique** used in data mining to forecast continuous outcomes. Below is a structured breakdown of **linear and non-linear regression methods**, their applications, and implementation strategies.\n\n---\n\n## **1. Linear Regression**\n### **A. Simple Linear Regression**\n- **Model**: Predicts a dependent variable (\\( y \\)) using one independent variable (\\( x \\)).\n- **Equation**:\n  \\[\n  y = \\beta_0 + \\beta_1 x + \\epsilon\n  \\]\n  - \\( \\beta_0 \\): Intercept  \n  - \\( \\beta_1 \\): Slope  \n  - \\( \\epsilon \\): Error term  \n\n- **Assumptions**:\n  1. Linear relationship between \\( x \\) and \\( y \\).\n  2. Homoscedasticity (constant variance of residuals).\n  3. Independence of errors (no autocorrelation).\n\n### **B. Multiple Linear Regression**\n- **Model**: Uses **multiple predictors** (\\( x_1, x_2, \\dots, x_n \\)).\n- **Equation**:\n  \\[\n  y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_n x_n + \\epsilon\n  \\]\n\n### **C. Evaluation Metrics**\n| **Metric**       | **Formula**                          | **Interpretation**                     |\n|------------------|--------------------------------------|----------------------------------------|\n| **R² (R-Squared)** | \\( 1 - \\frac{SS_{res}}{SS_{tot}} \\) | % variance explained (0 to 1)         |\n| **Adjusted R²**  | Adjusts R² for # predictors          | Penalizes overfitting                  |\n| **RMSE**         | \\( \\sqrt{\\frac{1}{n} \\sum (y_i - \\hat{y}_i)^2} \\) | Lower = better          |\n| **MAE**          | \\( \\frac{1}{n} \\sum |y_i - \\hat{y}_i| \\)    | Robust to outliers       |\n\n### **D. Example: Python Implementation**\n```python\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score, mean_squared_error\n\n# Sample data\nX = [[1], [2], [3]]  # Feature\ny = [2, 4, 6]        # Target\n\n# Train model\nmodel = LinearRegression()\nmodel.fit(X, y)\n\n# Predict and evaluate\ny_pred = model.predict(X)\nprint(f\"R²: {r2_score(y, y_pred):.2f}, RMSE: {mean_squared_error(y, y_pred, squared=False):.2f}\")\n```\n\n---\n\n## **2. Non-Linear Regression**\nUsed when relationships between variables are **not linear**.\n\n### **A. Polynomial Regression**\n- **Model**: Fits a polynomial equation (e.g., quadratic, cubic).\n- **Equation**:\n  \\[\n  y = \\beta_0 + \\beta_1 x + \\beta_2 x^2 + \\dots + \\beta_n x^n + \\epsilon\n  \\]\n- **Example**:\n  ```python\n  from sklearn.preprocessing import PolynomialFeatures\n\n  # Transform features to polynomial\n  poly = PolynomialFeatures(degree=2)\n  X_poly = poly.fit_transform(X)\n\n  # Fit linear regression on polynomial features\n  model.fit(X_poly, y)\n  ```\n\n### **B. Generalized Additive Models (GAMs)**\n- **Model**: Combines smooth functions of predictors.\n- **Equation**:\n  \\[\n  y = \\beta_0 + f_1(x_1) + f_2(x_2) + \\dots + f_n(x_n) + \\epsilon\n  \\]\n- **Library**: `pygam` (Python).\n\n### **C. Decision Trees & Random Forests**\n- **Non-parametric** methods for complex relationships.\n- **Example**:\n  ```python\n  from sklearn.ensemble import RandomForestRegressor\n  model = RandomForestRegressor(n_estimators=100)\n  model.fit(X, y)\n  ```\n\n### **D. Support Vector Regression (SVR)**\n- Uses **kernel trick** for non-linear predictions.\n- **Key Parameter**: \\( \\epsilon \\)-insensitive tube.\n- **Example**:\n  ```python\n  from sklearn.svm import SVR\n  model = SVR(kernel='rbf', C=1.0, epsilon=0.1)\n  model.fit(X, y)\n  ```\n\n---\n\n## **3. Choosing Between Linear & Non-Linear Regression**\n| **Scenario**                | **Recommended Technique**          |\n|-----------------------------|------------------------------------|\n| Linear relationship         | Linear Regression                  |\n| Curved trends               | Polynomial Regression              |\n| High-dimensional interactions| Random Forest / XGBoost            |\n| Small dataset with clear pattern | SVR / GAMs                   |\n\n---\n\n## **4. Practical Applications**\n### **A. Sales Forecasting**\n- **Linear Regression**: Predict sales based on ad spend.\n- **Non-Linear**: Seasonal trends (Polynomial/SVR).\n\n### **B. Housing Price Prediction**\n- **Multiple Regression**: Square footage, location.\n- **Random Forest**: Captures non-linear feature interactions.\n\n### **C. Medical Research**\n- **GAMs**: Model non-linear effects of drug dosage.\n\n---\n\n## **5. Key Takeaways**\n1. **Linear Regression**: Simple, interpretable, but limited to linear trends.\n2. **Polynomial Regression**: Captures curves but risks overfitting.\n3. **Tree-Based Methods (Random Forest, XGBoost)**: Handle complex interactions.\n4. **SVR/GAMs**: Flexible for non-linearities but computationally heavier.\n\n### **Python Tip**\nUse `scikit-learn` for most regression tasks:\n```python\n# For advanced non-linear models\nfrom xgboost import XGBRegressor\nfrom sklearn.neural_network import MLPRegressor\n```\n"
  },
  {
    "url": "University/Data_Mining/Module_3/Support_Vector_Machine.html",
    "content": "---\nid: Support_Vector_Machine\naliases: []\ntags: []\ntitle: Support Vector Machine\n---\n\n# **Support Vector Machines**\n\nSupport Vector Machines (SVMs) are **powerful supervised learning models** used for classification and regression tasks in data mining. They are particularly effective in **high-dimensional spaces** and for problems with **clear margin separation**.\n\n---\n\n## **1. Core Concepts of SVM**\n\n### **A. What is an SVM?**\nAn SVM is a **discriminative classifier** that finds the **optimal hyperplane** separating data points of different classes with the **maximum margin**.\n\n### **B. Key Terminology**\n- **Hyperplane**: Decision boundary (e.g., a line in 2D, plane in 3D).\n- **Support Vectors**: Data points closest to the hyperplane (critical for margin).\n- **Margin**: Distance between the hyperplane and the nearest data points.\n- **Kernel Trick**: Maps data into higher dimensions to handle non-linear separation.\n\n---\n\n## **2. How SVM Works**\n\n### **A. Linear SVM (Hard Margin)**\n- **Goal**: Find a hyperplane that **perfectly separates** classes.\n- **Mathematical Formulation**:\n  \\[\n  w \\cdot x + b = 0\n  \\]\n  where:\n  - \\( w \\) = weight vector.\n  - \\( b \\) = bias term.\n- **Optimization Objective**:\n  \\[\n  \\text{Minimize } \\frac{1}{2} \\|w\\|^2 \\quad \\text{subject to } y_i (w \\cdot x_i + b) \\geq 1\n  \\]\n\n### **B. Soft Margin SVM (Handling Overlapping Classes)**\n- **Problem**: Data may not be perfectly separable.\n- **Solution**: Introduce **slack variables** \\( \\xi_i \\) to allow misclassification.\n- **Optimization**:\n  \\[\n  \\text{Minimize } \\frac{1}{2} \\|w\\|^2 + C \\sum \\xi_i\n  \\]\n  - \\( C \\): Penalty parameter (larger \\( C \\) → stricter margin).\n\n### **C. Non-Linear SVM (Kernel Trick)**\n- **Problem**: Data may not be linearly separable.\n- **Solution**: Use **kernel functions** to map data into higher dimensions.\n- **Common Kernels**:\n  | **Kernel**       | **Formula**                          | **Use Case**                     |\n  |------------------|--------------------------------------|----------------------------------|\n  | Linear           | \\( K(x_i, x_j) = x_i \\cdot x_j \\)   | Linearly separable data          |\n  | Polynomial       | \\( (x_i \\cdot x_j + c)^d \\)         | Moderate non-linearity           |\n  | RBF (Gaussian)   | \\( e^{-\\gamma \\|x_i - x_j\\|^2} \\)   | Highly non-linear data           |\n  | Sigmoid          | \\( \\tanh(\\alpha x_i \\cdot x_j + c) \\) | Neural network-like models      |\n\n---\n\n## **3. Applications in Data Mining**\n\n### **A. Text Classification**\n- **Example**: Spam detection.\n- **Why SVM?** Handles high-dimensional text data well.\n\n### **B. Image Recognition**\n- **Example**: Handwritten digit classification (MNIST).\n- **Why SVM?** Effective with feature extraction (e.g., HOG, SIFT).\n\n### **C. Bioinformatics**\n- **Example**: Cancer classification from gene expression data.\n- **Why SVM?** Works well with small sample sizes and high dimensions.\n\n### **D. Anomaly Detection**\n- **Example**: Fraud detection.\n- **Why SVM?** One-class SVM can model normal behavior.\n\n---\n\n## **4. Advantages & Disadvantages**\n\n| **Advantages**                          | **Disadvantages**                         |\n|-----------------------------------------|-------------------------------------------|\n| Effective in high-dimensional spaces    | Computationally expensive for large datasets |\n| Robust to overfitting (with good \\( C \\)) | Requires careful kernel selection        |\n| Works well with small datasets          | Black-box model (hard to interpret)       |\n\n---\n\n## **5. SVM vs. Other Classifiers**\n\n| **Classifier** | **When to Use**                          | **Comparison with SVM**                  |\n|---------------|------------------------------------------|------------------------------------------|\n| **Logistic Regression** | Simple linear problems              | SVM better for clear margin separation   |\n| **Decision Trees** | Interpretability needed            | SVM better for high-dimensional data     |\n| **k-NN**       | Lazy learning, small datasets       | SVM more efficient for large feature sets |\n\n---\n\n## **6. Practical Example: SVM in Python**\n\n```python\nfrom sklearn import svm\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\n\n# Load data\niris = load_iris()\nX, y = iris.data, iris.target\n\n# Split data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n\n# Train SVM\nmodel = svm.SVC(kernel='rbf', C=1.0, gamma='scale')\nmodel.fit(X_train, y_train)\n\n# Evaluate\naccuracy = model.score(X_test, y_test)\nprint(f\"Accuracy: {accuracy:.2f}\")\n```\n\n---\n\n## **7. Parameter Tuning in SVM**\n\n### **A. Key Parameters**\n- **\\( C \\)**: Controls trade-off between margin and misclassification.\n  - Low \\( C \\) → Wider margin, more errors.\n  - High \\( C \\) → Narrow margin, fewer errors.\n- **\\( \\gamma \\) (RBF kernel)**: Controls influence of individual points.\n  - Low \\( \\gamma \\) → Far influence (smoother boundaries).\n  - High \\( \\gamma \\) → Near influence (complex boundaries).\n\n### **B. Tuning with Grid Search**\n```python\nfrom sklearn.model_selection import GridSearchCV\n\nparams = {\n    'C': [0.1, 1, 10],\n    'gamma': [0.1, 1, 'scale']\n}\ngrid = GridSearchCV(svm.SVC(kernel='rbf'), params, cv=5)\ngrid.fit(X_train, y_train)\nprint(f\"Best params: {grid.best_params_}\")\n```\n\n---\n\n## **8. Key Takeaways**\n1. **SVM maximizes margin** for robust classification.\n2. **Kernel trick** enables non-linear decision boundaries.\n3. **Critical parameters**: \\( C \\), kernel type, \\( \\gamma \\).\n4. **Best for**: High-dimensional data, small-to-medium datasets.\n"
  },
  {
    "url": "University/Data_Mining/Module_4/Mining_Data_Types.html",
    "content": "---\nid: Mining_Data_Types\naliases: []\ntags: []\ntitle: Mining Data Types\n---\n\n# **Mining Complex Data Types: Techniques and Applications**\n\nComplex data types present unique challenges and opportunities in data mining. Below is a structured guide to mining these advanced data formats, including methodologies, algorithms, and real-world applications.\n\n---\n\n## **1. Time Series Data**\n**Definition**: Data points indexed in time order (e.g., stock prices, sensor readings).\n\n### **Key Techniques**\n| **Method**               | **Description**                                                                 | **Algorithms**                          |\n|--------------------------|-------------------------------------------------------------------------------|----------------------------------------|\n| **Segmentation**         | Divides series into meaningful intervals                                      | SWAB, Sliding Window                   |\n| **Similarity Search**    | Finds similar patterns (e.g., ECG comparisons)                                | DTW (Dynamic Time Warping), SAX        |\n| **Forecasting**          | Predicts future values                                                       | ARIMA, LSTM, Prophet                   |\n| **Anomaly Detection**    | Identifies unusual patterns                                                  | Isolation Forest, STL Decomposition    |\n\n**Example**:  \n```python\nfrom statsmodels.tsa.arima.model import ARIMA\nmodel = ARIMA(stock_prices, order=(1,1,1)).fit()\nforecast = model.forecast(steps=10)\n```\n\n---\n\n## **2. Spatial Data**\n**Definition**: Data with geographic components (e.g., maps, GPS trajectories).\n\n### **Key Techniques**\n| **Method**               | **Description**                                                                 | **Algorithms**                          |\n|--------------------------|-------------------------------------------------------------------------------|----------------------------------------|\n| **Clustering**           | Groups nearby points (e.g., crime hotspots)                                   | DBSCAN, ST-DBSCAN                      |\n| **Spatial Autocorrelation** | Measures dependency (e.g., house prices proximity effects)                 | Moran’s I, Geary’s C                   |\n| **Route Optimization**   | Finds shortest paths (e.g., logistics)                                        | A* Algorithm, Dijkstra’s               |\n\n**Example**:  \n```python\nfrom sklearn.cluster import DBSCAN\ncoords = [[lat1, lon1], [lat2, lon2], ...]\nclusters = DBSCAN(eps=0.5, min_samples=5).fit(coords)\n```\n\n---\n\n## **3. Text Data**\n**Definition**: Unstructured language data (e.g., tweets, reviews).\n\n### **Key Techniques**\n| **Method**               | **Description**                                                                 | **Algorithms**                          |\n|--------------------------|-------------------------------------------------------------------------------|----------------------------------------|\n| **Topic Modeling**       | Extracts themes (e.g., news categorization)                                   | LDA, NMF                               |\n| **Sentiment Analysis**   | Classifies emotion (e.g., product reviews)                                    | BERT, VADER                            |\n| **Named Entity Recognition** | Identifies people/places (e.g., résumé parsing)                          | spaCy, CRF                             |\n\n**Example**:  \n```python\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import LatentDirichletAllocation\n\nvectorizer = TfidfVectorizer()\nX = vectorizer.fit_transform(documents)\nlda = LatentDirichletAllocation(n_components=5).fit(X)\n```\n\n---\n\n## **4. Graph/Network Data**\n**Definition**: Data with entities and relationships (e.g., social networks, fraud rings).\n\n### **Key Techniques**\n| **Method**               | **Description**                                                                 | **Algorithms**                          |\n|--------------------------|-------------------------------------------------------------------------------|----------------------------------------|\n| **Community Detection**  | Finds tightly-knit groups (e.g., friend circles)                              | Louvain, Girvan-Newman                 |\n| **Link Prediction**      | Predicts future connections (e.g., friend suggestions)                        | Adamic-Adar, Node2Vec                  |\n| **Centrality Analysis**  | Identifies influential nodes (e.g., key opinion leaders)                     | PageRank, Betweenness Centrality       |\n\n**Example**:  \n```python\nimport networkx as nx\nG = nx.karate_club_graph()\ncommunities = nx.algorithms.community.louvain_communities(G)\n```\n\n---\n\n## **5. Image/Video Data**\n**Definition**: Pixel-based data (e.g., medical scans, surveillance footage).\n\n### **Key Techniques**\n| **Method**               | **Description**                                                                 | **Algorithms**                          |\n|--------------------------|-------------------------------------------------------------------------------|----------------------------------------|\n| **Object Detection**     | Locates and classifies objects (e.g., pedestrian tracking)                    | YOLO, Faster R-CNN                     |\n| **Segmentation**         | Divides images into regions (e.g., tumor detection)                           | U-Net, Mask R-CNN                      |\n| **Feature Extraction**   | Reduces dimensionality (e.g., facial recognition)                             | SIFT, CNN (ResNet)                     |\n\n**Example**:  \n```python\nfrom tensorflow.keras.applications import ResNet50\nmodel = ResNet50(weights='imagenet', include_top=False)\nfeatures = model.predict(image_array)\n```\n\n---\n\n## **6. Multi-Relational Data**\n**Definition**: Data spread across linked tables (e.g., relational databases).\n\n### **Key Techniques**\n| **Method**               | **Description**                                                                 | **Algorithms**                          |\n|--------------------------|-------------------------------------------------------------------------------|----------------------------------------|\n| **Inductive Logic Programming** | Learns rules from relations (e.g., \"IF parent(X,Y) THEN ancestor(X,Y)\")   | FOIL, Progol                           |\n| **Graph Embeddings**     | Represents entities as vectors (e.g., knowledge graphs)                       | TransE, ComplEx                        |\n\n---\n\n## **7. Key Challenges & Solutions**\n| **Challenge**            | **Solution**                                                                 |\n|--------------------------|-----------------------------------------------------------------------------|\n| **High Dimensionality**  | Dimensionality reduction (PCA, t-SNE)                                      |\n| **Noise & Missing Data** | Robust algorithms (Random Forests, GAN imputation)                         |\n| **Scalability**          | Distributed computing (Spark ML, Dask)                                     |\n| **Interpretability**     | SHAP values, LIME for model explanations                                   |\n\n---\n\n## **8. Tools for Complex Data Mining**\n| **Data Type**    | **Recommended Libraries**                                                  |\n|------------------|---------------------------------------------------------------------------|\n| Time Series      | `statsmodels`, `prophet`, `tslearn`                                       |\n| Spatial          | `geopandas`, `folium`, `pysal`                                           |\n| Text             | `nltk`, `spaCy`, `gensim`                                                |\n| Graph            | `networkx`, `igraph`, `PyTorch Geometric`                                |\n| Image/Video      | `OpenCV`, `TensorFlow/Keras`, `PyTorch`                                  |\n\n---\n\n## **9. Real-World Applications**\n- **Healthcare**: Mining EEG time series for seizure prediction.\n- **Retail**: Spatial clustering of store locations for optimal placement.\n- **Finance**: Graph analysis for fraud detection in transaction networks.\n- **Social Media**: Topic modeling on tweets to track trends.\n\n---\n\n### **Key Takeaways**\n1. **Match algorithms to data types**:  \n   - Time series → ARIMA/LSTM  \n   - Graphs → PageRank/Node2Vec  \n2. **Preprocessing is critical**:  \n   - Text: Tokenization, stemming  \n   - Images: Normalization, augmentation  \n3. **Hybrid approaches often win**:  \n   - Combine CNN (images) + LSTM (temporal) for video analysis.  \n"
  },
  {
    "url": "University/Data_Mining/Module_4/Mining_Time_Series_Data.html",
    "content": "---\nid: Mining_Time_Series_Data\naliases: []\ntags: []\ntitle: Mining Time Series Data\n---\n\n# **Mining Time-Series Data: Periodicity Analysis & Similarity Search**\n\nTime-series data mining involves extracting meaningful patterns from temporal data. Two critical techniques are **Periodicity Analysis** (identifying recurring patterns) and **Similarity Search** (finding matching subsequences). Below is a detailed breakdown of methods, algorithms, and applications.\n\n---\n\n## **1. Periodicity Analysis**\n**Goal**: Detect repeating patterns (e.g., daily sales spikes, weekly ECG cycles).\n\n### **A. Key Concepts**\n- **Period**: Time interval after which a pattern repeats (e.g., 24 hours for daily trends).\n- **Seasonality**: Regular periodic fluctuations (e.g., holiday sales surges).\n- **Cyclic Patterns**: Non-fixed periods (e.g., economic cycles).\n\n### **B. Methods for Periodicity Detection**\n| **Method**               | **Description**                                                                 | **Use Case**                          |\n|--------------------------|-------------------------------------------------------------------------------|---------------------------------------|\n| **Fourier Transform**    | Converts time-series to frequency domain to identify dominant cycles.         | ECG signal analysis                   |\n| **Autocorrelation**      | Measures self-similarity at different time lags.                              | Traffic flow analysis                 |\n| **Lomb-Scargle Periodogram** | Detects periods in unevenly sampled data.                                 | Astronomy light curves                |\n| **Wavelet Analysis**     | Captures localized periodicity in non-stationary data.                       | Vibration sensor data                 |\n\n### **C. Example: Autocorrelation in Python**\n```python\nimport pandas as pd\nfrom statsmodels.graphics.tsaplots import plot_acf\n\n# Load time-series data\ndata = pd.read_csv('sales.csv', parse_dates=['date'], index_col='date')\n\n# Plot autocorrelation to detect periodicity\nplot_acf(data['sales'], lags=50)  # Peaks at lag=7 → weekly pattern\n```\n\n---\n\n## **2. Similarity Search in Time-Series**\n**Goal**: Find similar subsequences within or across time-series (e.g., matching ECG anomalies).\n\n### **A. Key Challenges**\n- **Time Warping**: Sequences may vary in speed (e.g., walking vs. running).\n- **Noise**: Sensor artifacts or missing data.\n- **Scale**: Large datasets require efficient indexing.\n\n### **B. Similarity Measures**\n| **Measure**              | **Description**                                                                 | **Pros & Cons**                       |\n|--------------------------|-------------------------------------------------------------------------------|---------------------------------------|\n| **Euclidean Distance**   | Compares point-to-point distances.                                            | Fast but inflexible to warping.       |\n| **DTW (Dynamic Time Warping)** | Aligns sequences non-linearly.                                      | Handles warping but slower.           |\n| **Shape-Based (SAX)**    | Symbolic Aggregate Approximation reduces dimensionality.                      | Scalable but loses granularity.       |\n| **Pearson Correlation**  | Measures linear dependence.                                                   | Ignores magnitude, focuses on shape. |\n\n### **C. Algorithms for Similarity Search**\n| **Algorithm**            | **Description**                                                                 | **Library/Tool**                      |\n|--------------------------|-------------------------------------------------------------------------------|---------------------------------------|\n| **k-NN with DTW**        | Finds k most similar sequences using DTW.                                     | `tslearn`, `dtaidistance`             |\n| **FastDTW**              | Optimized DTW with reduced complexity.                                        | `fastdtw`                             |\n| **UCR Suite**            | State-of-the-art exact similarity search.                                     | [UCR Suite](https://www.cs.ucr.edu/~eamonn/UCRsuite.html) |\n| **TS-Clust**             | Clustering-based similarity search.                                           | `pyts`                                |\n\n### **D. Example: DTW in Python**\n```python\nfrom dtaidistance import dtw\nimport numpy as np\n\n# Two time-series sequences\nseries1 = np.array([1, 3, 5, 6, 8])\nseries2 = np.array([2, 4, 6, 7, 9])\n\n# Compute DTW distance\ndistance = dtw.distance(series1, series2)\nprint(f\"DTW Distance: {distance:.2f}\")\n```\n\n---\n\n## **3. Applications**\n### **A. Periodicity Analysis**\n- **Retail**: Detect weekly/monthly sales cycles.\n- **Healthcare**: Identify circadian rhythms in vital signs.\n- **Energy**: Forecast electricity demand peaks.\n\n### **B. Similarity Search**\n- **Finance**: Find stock price patterns resembling past crashes.\n- **IoT**: Match sensor fault signatures.\n- **Biometrics**: Identify gait patterns for security.\n\n---\n\n## **4. Tools & Libraries**\n| **Task**                | **Tool/Library**                              | **Key Feature**                       |\n|-------------------------|----------------------------------------------|---------------------------------------|\n| Periodicity Detection   | `statsmodels`, `astropy`                     | Lomb-Scargle, autocorrelation        |\n| Similarity Search       | `tslearn`, `dtaidistance`, `UCR Suite`      | DTW, FastDTW                         |\n| Visualization           | `matplotlib`, `plotly`                      | Interactive time-series plots        |\n\n---\n\n## **5. Key Takeaways**\n1. **Periodicity Analysis**:\n   - Use Fourier transforms for stationary data, wavelets for non-stationary.\n   - Autocorrelation helps identify fixed intervals (e.g., seasonality).\n\n2. **Similarity Search**:\n   - **DTW** is gold standard for warped sequences but computationally heavy.\n   - **SAX** balances speed and accuracy for large datasets.\n\n3. **Domain-Specific Tuning**:\n   - Normalize data for magnitude-invariant comparisons.\n   - Use indexing (e.g., UCR Suite) for scalability.\n\n```python\n# Pro Tip: Speed up DTW with lower-bounding (LB_Keogh)\nfrom dtaidistance.dtw_ndim import lb_keogh\nlb = lb_keogh(series1, series2, radius=3)\n```\n\nMastering these techniques unlocks actionable insights from temporal data! 🚀\n"
  },
  {
    "url": "University/OOP/Module_1.html",
    "content": "hi bro how "
  },
  {
    "url": "University/Economics/Module_2.html",
    "content": "---\nid: Module_2\naliases: []\ntags: []\ntitle: Module_2\n---\n\n### Time Value Money\nThe time value of money (TVM) is the idea that money available at the present time is worth more than the same amount in the future due to its potential earning capacity\n\n#### Why Time Value of Money Exists- Reasons\n- Risk and uncertainity\n- Inflation\n- Consumption\n- Investment\n\n#### Application\n- Investment decisions\n- Capital Budgeting decisions\n- Applied in present and future value calculation\n- Bond Evaluation\n- Stock Evaluation\n- Accept/Reject decisions for Project Management\n- Financial Analysis of Firms\n\n### Capital Budgeting\n- Capital budgeting, and investment appraisal, is the planning process used to determine whether an organization's long term investments. \n- It is the process of allocating resources for major capital, or investment, expenditures\n- It is process of deciding whether to invest or not to invest in a particular asset, the benefit of which will be available over a period of time.\n- Capital budgeting is a process of evaluating investments and huge expenses in order to obtain the best returns on investment\n\n#### Types of Projects or Long term Investment Decision\n- New projects\n- Expansion projects\n- Diversification Projects\n- Replacement and Modernisation Projects\n- Research and Development Projects\n\n#### Significance of Capital Budgeting\n- Long term Decision\n- Irreversible Decision\n- Huge Investments\n- Growth\n- Selecting profitable projects\n- Capital expenditure control\n- Finding the right sources for funds\n\n#### Types of Capital Budgeting Decision\n- Accept-Reject Investment Decisions - accept or reject the project\n- Mutually Exclusive Investments Decisions - projects that compete with each other\n- Capital Rationing Investment Decisions - projects fight for funding due to limited funds\n\n#### Process of Capital Budgeting\n- Searching of Investment Opportunities\n- Evaluation or Analysis\n- Selection of Project\n- Financing the Project\n- Execution or Implementation\n- Review of the Project\n\n#### Methods of Capital Budgeting or Evaluation Criteria\n- Traditional Methods or Non Discounted Cash flow\n    - Payback Period - initial investment / annual cash flow\n    - Accounting rate or return method\n- Discounted Cash Flow Method or Modern Method\n    - Net Present Value Method\n    - Profitability Index Method\n    - Internal Rate of Return Method\n\n#### Merits of Payback period\n- Easy and Simple Method\n- Liquidity is emphasized\n- Useful in Case of Uncertainty.\n\n#### Limitation of Payback period\n- Ignores the returns generated after the payback period\n- Ignores the Time Value of Money\n- It overlook cost of capital or interest factor\n- It Ignore the risk of future cash flows\n\n### Investment Evaluation Criteria\n- Estimation of cash flows\n- Estimation of the required rate of return\n- Application of a decision rule for making the choice\n\n### Discounted Cash Flow Techniques\n- Considered to be the best method to evaluate the investment The cash inflows and outflows are calculated proposals\n- The cash inflows and outflows are calculated\n- These cash inflows and outflows are then discounted at an appropriate discount rate\n- The difference between the discounted cash inflow and discounted cash outflow is calculated\n\n### Net Present Value (NPV)\n- In NPV technique the profitability of investment proposal is measured through the difference between the cash inflows generated out of the cash outflows or the investments made in the project.\n- Net Present Value = PVCI (inflow)– PVCO (outflow)\n- Decision Criteria\n    - If the net present value is greater than zero, the proposal has to be accepted.\n    - If the net present value is less than zero, the proposal has to be rejected.\n\n#### Profitability Index or Benefit- Cost ratio\nProfitability Index measures the present value of returns derived from per rupee invested. It shows the relationship between the benefits and cost of the project and therefore it is called as Benefit-cost ratio\n PI = present value of cash flow / present value of cash outflow\n PI = (NPV + initial investment) / initial investment\n\n#### Merits of NPV\n- Consider time value of money.\n- Consider all cash flows over the entire project life\n- It helps to make a comparative assessment of different projects\n\n#### Limitation of NPV\n- The application or usage of this method requires the knowledge of rate of cost of capital. If cost of capital is unknown, this method cannot be used.\n- Determining an appropriate discount rate is difficult in this method.\n- This method does not indicate the rate of return which is expected to be earned.\n- This method may fail to give satisfactory answers when the projects are requiring different level of amount of investment and with different economic life of the project.\n\n#### Merits of PI\n- It consider time value of money.\n- It considers all cash inflows\n- It is recommended for use particularly when there is shortage of funds, because it correctly ranks the proposals.\n- It makes right decision in the case of different amount of cash outflow of different project.\n\n#### Limitations of PI\n- May lead to incorrect decisions in comparisons of mutually exclusive investments.\n- Cost of capital is required to calculate PI.\n\n### Accounting rate of return\nThe **Accounting Rate of Return (ARR)** is a financial metric used to evaluate the profitability of an investment or project. It measures the expected annual return as a percentage of the initial investment or average investment cost, based on accounting profits (net income) rather than cash flows.\n\n### **Formula**\n\\[\nARR = \\frac{\\text{Average Annual Accounting Profit}}{\\text{Initial Investment (or Average Investment)}} \\times 100\n\\]\n- **Average Annual Accounting Profit**: Total profit over the project's life divided by the number of years.\n- **Initial Investment**: The total cost of the investment.\n- **Average Investment**: (Initial Investment + Salvage Value) / 2, if used instead of initial investment.\n\n#### **Merits of ARR**\n1. **Simplicity**:\n2. **Focus on Profitability**:\n3. **Useful for Comparisons**:\n4. **Incorporates Entire Project Life**:\n5. **Familiar to Managers**:\n\n#### **Demerits of ARR**\n1. **Ignores Time Value of Money**:\n2. **Based on Accounting Profits, Not Cash Flows**:\n3. **Inconsistent Definitions**:\n4. **Ignores Risk and Uncertainty**:\n5. **No Clear Acceptance Criterion**:\n6. **May Encourage Short-Term Focus**:\n\nThe image lists three **Modern Methods of Discounted Cash Flow (DCF)** used for investment appraisal: Net Present Value (NPV), Internal Rate of Return (IRR), and Profitability Index (PI). Below is an explanation of each method, along with their merits and demerits in points.\n\n### **Net Present Value (NPV) Method**\n**Explanation**: NPV calculates the present value of a project’s cash inflows minus the present value of cash outflows, discounted at a specific rate (usually the cost of capital). A positive NPV indicates the project adds value.\n\n#### **Merits**:\n- **Accounts for Time Value of Money**: Discounts future cash flows to reflect their present value.\n- **Focuses on Absolute Value**: Measures the actual value added by the project in monetary terms.\n- **Considers All Cash Flows**: Incorporates cash flows over the entire project life.\n- **Clear Decision Rule**: Accept if NPV > 0; reject if NPV < 0.\n- **Risk Adjustment**: Discount rate can be adjusted to account for project risk.\n\n#### **Demerits**:\n- **Requires Discount Rate**: Needs an accurate cost of capital, which can be hard to estimate.\n- **Complexity**: Involves detailed cash flow projections and discounting, which can be time-consuming.\n- **Ignores Scale**: Does not consider the relative size of the investment (e.g., a smaller project may have a lower NPV but higher return rate).\n- **Assumes Reinvestment at Discount Rate**: Assumes cash flows are reinvested at the discount rate, which may not be realistic.\n\n### **Internal Rate of Return (IRR) Method**\n**Explanation**: IRR is the discount rate that makes the NPV of a project zero. It represents the project’s expected rate of return. If IRR exceeds the cost of capital, the project is accepted.\n\n#### **Merits**:\n- **Time Value of Money**: Like NPV, it accounts for the time value of cash flows.\n- **Percentage-Based**: Provides a rate of return, making it easy to compare with the cost of capital or other projects.\n- **No Need for Discount Rate Upfront**: Calculates the break-even rate internally.\n- **Considers All Cash Flows**: Includes cash flows over the project’s entire life.\n\n#### **Demerits**:\n- **Multiple IRRs**: Can produce multiple IRRs for projects with unconventional cash flows (e.g., alternating inflows and outflows).\n- **Assumes Reinvestment at IRR**: Assumes cash flows are reinvested at the IRR, which may be unrealistically high.\n- **Conflicts with NPV**: May rank projects differently from NPV, especially for mutually exclusive projects.\n- **Complex Calculation**: Requires trial-and-error or software to compute, as it’s not a direct formula.\n\n\n### **Profitability Index (PI) Method**\n**Explanation**: PI (also called the benefit-cost ratio) is the ratio of the present value of cash inflows to the initial investment. A PI greater than 1 indicates the project is profitable.\n\n**Formula**:\n\\[\nPI = \\frac{\\text{Present Value of Cash Inflows}}{\\text{Initial Investment}}\n\\]\n\n#### **Merits**:\n- **Time Value of Money**: Discounts cash flows to their present value.\n- **Relative Measure**: Useful for comparing projects of different sizes, as it measures return per unit of investment.\n- **Complements NPV**: A PI > 1 aligns with a positive NPV, reinforcing decision-making.\n- **Useful for Capital Rationing**: Helps prioritize projects when funds are limited.\n\n#### **Demerits**:\n- **Requires Discount Rate**: Like NPV, it depends on an accurate cost of capital.\n- **Ignores Absolute Value**: A high PI doesn’t show the total value added (e.g., a small project may have a high PI but low overall benefit).\n- **Less Intuitive**: Not as widely understood as NPV or IRR for decision-making.\n- **May Conflict with NPV**: For mutually exclusive projects, PI may rank projects differently from NPV.\n"
  },
  {
    "url": "University/Economics/Module_3.html",
    "content": "---\nid: Module_3\naliases: []\ntags: []\n---\n\n## Demand\n- Demand is desire.\n- Demand is economics means both the willingness as well as the ability to purchase a commodity.\n\n## Law of demand\n- The law of demand states that the quantity demanded of a good or service decreases as it price increases and conversely, the quantity demand increases when the price decreases\n\n![[Pasted image 20250307022044.png]]\n\n### Assumptions\n- Income of people remain unchanged\n- Taste, preference and habits of consumer unchanged.\n- Prices of related goods i.e. substitute and complementary goods remain unchanged.\n- There is no expectation of future change in price of commodity-- The commodity in question is not consumed for its prestige value.\n"
  },
  {
    "url": "University/Economics/Module_4.html",
    "content": "---\nid: Module_4\naliases: []\ntags: []\ntitle: Module_4\n---\n\n### **Meaning of Production**\nProduction refers to the process of creating goods or services by combining various inputs to satisfy human wants. It involves transforming raw materials, labor, and other resources into finished products or services that have economic value.\n\n#### **Factors of Production**\nFactors of production are the resources used in the production process. They are traditionally classified into four categories:\n\n1. **Land**:\n   - Natural resources used in production (e.g., minerals, water, forests, land for farming).\n   - Reward: Rent.\n   \n2. **Labor**:\n   - Human effort, both physical and mental, used in production (e.g., workers, managers).\n   - Reward: Wages or salaries.\n\n3. **Capital**:\n   - Man-made resources used in production (e.g., machinery, tools, buildings).\n   - Reward: Interest.\n\n4. **Entrepreneurship (or Organization)**:\n   - The ability to organize the other factors, take risks, and innovate (e.g., a business owner).\n   - Reward: Profit.\n\n### **Law of Variable Proportions**\nThe **Law of Variable Proportions** (also called the Law of Diminishing Returns) describes how output changes when one input is increased while other inputs are held constant in the short run.\n\n#### **Explanation**:\n- As more units of a variable input (e.g., labor) are added to a fixed input (e.g., land), total output initially increases at an increasing rate, then at a decreasing rate, and eventually decreases.\n- It applies in the short run, where at least one input is fixed.\n\n#### **Stages**:\n1. **Increasing Returns**: Output rises at an increasing rate as the variable input is added (e.g., more workers on a fixed plot of land improve efficiency initially).\n2. **Diminishing Returns**: Output continues to rise but at a decreasing rate (e.g., too many workers on the same land lead to overcrowding).\n3. **Negative Returns**: Output decreases as adding more of the variable input becomes counterproductive (e.g., too many workers hinder each other).\n\n#### **Assumptions**:\n- One input is variable, others are fixed.\n- Technology remains constant.\n- Inputs are not perfectly substitutable.\n\n### **Returns to Scale**\n**Returns to Scale** describe how output changes when all inputs are increased proportionally in the long run, where all inputs are variable.\n\n#### **Types**:\n1. **Increasing Returns to Scale (IRS)**:\n   - Output increases by a greater proportion than the increase in inputs.\n   - Example: Doubling all inputs (labor, capital) leads to more than double the output.\n   - Cause: Economies of scale (e.g., specialization, better technology).\n\n2. **Constant Returns to Scale (CRS)**:\n   - Output increases in the same proportion as the increase in inputs.\n   - Example: Doubling all inputs doubles the output.\n   - Cause: Proportional scaling without significant efficiency gains or losses.\n\n3. **Decreasing Returns to Scale (DRS)**:\n   - Output increases by a smaller proportion than the increase in inputs.\n   - Example: Doubling all inputs leads to less than double the output.\n   - Cause: Diseconomies of scale (e.g., coordination issues, management inefficiencies).\n\n#### **Key Difference from Law of Variable Proportions**:\n- **Law of Variable Proportions**: Applies in the short run with one variable input.\n- **Returns to Scale**: Applies in the long run with all inputs variable.\n\n### **Economies and Diseconomies of Scale**\n**Economies of scale** refer to the cost advantages a firm experiences as it increases its scale of production, leading to a decrease in average cost per unit. **Diseconomies of scale** occur when a firm grows too large, causing the average cost per unit to rise. These can be classified as **internal** (within the firm) or **external** (outside the firm, affecting the industry).\n\n### **Internal Economies of Scale**\nThese are cost savings that arise from the firm’s own growth and operations.\n\n- **Technical Economies**:\n  - Larger firms can use advanced machinery or technology, reducing per-unit costs (e.g., automated production lines).\n- **Managerial Economies**:\n  - Specialized management teams improve efficiency (e.g., dedicated HR or marketing departments).\n- **Financial Economies**:\n  - Larger firms get better access to capital at lower interest rates due to their creditworthiness.\n- **Marketing Economies**:\n  - Bulk purchasing of raw materials or advertising reduces costs per unit.\n- **Risk-Bearing Economies**:\n  - Diversification of products or markets reduces the impact of market fluctuations.\n- **Network Economies**:\n  - Expanding customer base (e.g., more users on a platform) increases value and reduces costs per user.\n\n### **Internal Diseconomies of Scale**\nThese are inefficiencies that arise within the firm as it grows too large.\n\n- **Managerial Diseconomies**:\n  - Overly complex hierarchies lead to communication breakdowns and slower decision-making.\n- **Technical Diseconomies**:\n  - Overuse of fixed resources (e.g., machinery) causes breakdowns or inefficiencies.\n- **Labor Diseconomies**:\n  - Large workforces may lead to demotivation, reduced productivity, or coordination issues.\n- **Bureaucratic Diseconomies**:\n  - Excessive red tape and rigid procedures slow operations and increase costs.\n- **Overexpansion**:\n  - Expanding beyond optimal capacity leads to inefficiencies (e.g., overstocking or underutilized resources).\n\n### **External Economies of Scale**\nThese are cost advantages that benefit all firms in an industry due to the industry’s growth or location.\n\n- **Access to Skilled Labor**:\n  - Industry hubs attract specialized workers (e.g., tech talent in Silicon Valley).\n- **Infrastructure Development**:\n  - Growth of the industry leads to better transport, utilities, or services (e.g., ports near manufacturing hubs).\n- **Knowledge Sharing**:\n  - Firms benefit from shared research, innovation, or technology within the industry.\n- **Supplier Networks**:\n  - A larger industry attracts more suppliers, reducing input costs through competition or bulk discounts.\n- **Government Support**:\n  - Industry growth may lead to subsidies, tax breaks, or favorable policies.\n\n### **External Diseconomies of Scale**\nThese are cost disadvantages faced by all firms in an industry due to external factors as the industry grows.\n\n- **Resource Scarcity**:\n  - Overdemand for inputs (e.g., raw materials, skilled labor) drives up costs.\n- **Infrastructure Strain**:\n  - Overcrowding or overuse of shared infrastructure (e.g., traffic congestion, strained utilities).\n- **Environmental Costs**:\n  - Industry growth may lead to pollution or regulatory penalties, increasing costs.\n- **Wage Inflation**:\n  - Competition for skilled labor in a large industry pushes wages higher.\n- **Market Saturation**:\n  - Too many firms in the industry lead to intense competition, reducing prices and profits.\n\n### **Concepts of Cost of Production**\nThe **cost of production** refers to the total expenses incurred by a firm to produce goods or services. It includes all costs associated with acquiring inputs (like raw materials, labor, and capital) and transforming them into finished products. These costs are crucial for pricing decisions, profitability analysis, and production planning.\n\n\n### **Different Types of Costs**\n\n#### **1. Based on Nature**\n- **Explicit Costs**:\n  - Direct, out-of-pocket payments for inputs (e.g., wages, rent, raw materials).\n  - Example: Paying $5,000 for machinery.\n- **Implicit Costs**:\n  - Opportunity costs of using the firm’s own resources, not involving direct payment (e.g., the forgone salary of an owner working in their own business).\n  - Example: A shop owner not earning $2,000 elsewhere by managing their own store.\n\n#### **2. Based on Time Period (Short Run vs. Long Run)**\n- **Fixed Costs (FC)**:\n  - Costs that do not vary with output in the short run (e.g., rent, salaries of permanent staff, depreciation).\n  - Example: $1,000 monthly rent, regardless of production level.\n- **Variable Costs (VC)**:\n  - Costs that change with the level of output (e.g., raw materials, wages of temporary workers, electricity).\n  - Example: $500 for raw materials to produce 100 units.\n\n#### **3. Based on Total, Average, and Marginal Costs**\n- **Total Cost (TC)**:\n  - Sum of fixed and variable costs (TC = FC + VC).\n  - Example: If FC = $1,000 and VC = $500, then TC = $1,500.\n- **Average Cost (AC)**:\n  - Cost per unit of output (AC = TC / Quantity).\n  - Example: If TC = $1,500 for 100 units, AC = $15/unit.\n  - Subtypes:\n    - **Average Fixed Cost (AFC)**: AFC = FC / Quantity.\n    - **Average Variable Cost (AVC)**: AVC = VC / Quantity.\n- **Marginal Cost (MC)**:\n  - Additional cost of producing one more unit (MC = ΔTC / ΔQuantity).\n  - Example: If TC rises from $1,500 to $1,520 when output increases from 100 to 101 units, MC = $20.\n\n#### **4. Based on Accounting vs. Economic Perspective**\n- **Accounting Costs**:\n  - Only explicit costs recorded in financial statements (e.g., wages, rent).\n- **Economic Costs**:\n  - Includes both explicit and implicit costs (e.g., accounting costs + opportunity costs).\n  - Example: Accounting cost of production = $10,000; implicit cost (owner’s forgone salary) = $2,000; economic cost = $12,000.\n\n#### **5. Based on Decision-Making**\n- **Sunk Costs**:\n  - Costs already incurred and cannot be recovered (e.g., cost of a non-refundable license).\n  - Example: $5,000 spent on a failed marketing campaign.\n- **Opportunity Costs**:\n  - The cost of the next best alternative forgone (e.g., using a factory to produce Product A instead of Product B).\n  - Example: Choosing to produce cars over trucks, losing potential truck profits.\n- **Incremental Costs**:\n  - Additional costs from a specific decision (e.g., cost of adding a new product line).\n  - Example: $3,000 extra for producing a new type of widget.\n- **Avoidable Costs**:\n  - Costs that can be eliminated by stopping an activity (e.g., raw material costs if production stops).\n- **Unavoidable Costs**:\n  - Costs that persist regardless of the decision (e.g., rent, even if production stops).\n\n#### **6. Based on Behavior with Output**\n- **Direct Costs**:\n  - Costs directly tied to a specific product or activity (e.g., raw materials for a product).\n  - Example: $200 in wood for making a table.\n- **Indirect Costs (Overheads)**:\n  - Costs not directly tied to a specific product but shared across activities (e.g., factory rent, utilities).\n  - Example: $500 electricity bill for the entire factory.\n\n#### **7. Based on Controllability**\n- **Controllable Costs**:\n  - Costs a manager can influence (e.g., advertising budget).\n- **Uncontrollable Costs**:\n  - Costs beyond a manager’s control (e.g., corporate taxes, rent set by a lease).\n\n---\n\n### **Explanation of Accounting Cost, Sunk Cost, Marginal Cost, and Opportunity Cost**\n\n#### **1. Accounting Cost**\n- **Definition**: Accounting costs are the explicit, out-of-pocket expenses recorded in a firm’s financial statements. They include direct payments for resources used in production.\n- **Example**: Paying $10,000 for raw materials, $2,000 for wages, or $1,000 for rent.\n- **Key Point**: Focuses only on actual monetary transactions, ignoring implicit costs like opportunity costs.\n\n#### **2. Sunk Cost**\n- **Definition**: Sunk costs are expenses that have already been incurred and cannot be recovered, regardless of future decisions.\n- **Example**: $5,000 spent on a non-refundable market research study that yielded no useful results.\n- **Key Point**: Should not influence future decisions, as they are irretrievable (e.g., \"throwing good money after bad\").\n\n#### **3. Marginal Cost (MC)**\n- **Definition**: Marginal cost is the additional cost incurred by producing one more unit of output. It’s calculated as the change in total cost divided by the change in quantity (MC = ΔTC / ΔQuantity).\n- **Example**: If the total cost rises from $1,500 to $1,520 when output increases from 100 to 101 units, MC = $20.\n- **Key Point**: Helps firms decide whether producing an additional unit is profitable (compare MC with marginal revenue).\n\n#### **4. Opportunity Cost**\n- **Definition**: Opportunity cost is the value of the next best alternative forgone when a decision is made to use resources in a particular way.\n- **Example**: If a factory is used to produce cars instead of trucks, the opportunity cost is the profit that could have been earned from producing trucks.\n- **Key Point**: Represents the implicit cost of a decision, often not recorded in financial statements but critical for economic decision-making.\n\n---\n\n### **Break-Even Analysis**\n**Break-even analysis** determines the point at which total revenue equals total costs, meaning no profit or loss is made. It helps businesses understand the minimum output or sales needed to cover costs.\n\n#### **Key Concepts**:\n- **Fixed Costs (FC)**: Costs that don’t change with output (e.g., rent, salaries).\n- **Variable Costs (VC)**: Costs that vary with output (e.g., raw materials).\n- **Total Cost (TC)**: FC + VC.\n- **Selling Price per Unit (SP)**: Revenue per unit sold.\n- **Break-Even Point (BEP)**: The output level where Total Revenue = Total Cost.\n\n#### **Formula**:\n- **BEP (in units)** = Fixed Costs / (Selling Price per Unit - Variable Cost per Unit)\n- **Contribution Margin per Unit** = SP - VC.\n- **BEP (in sales value)** = BEP (units) × Selling Price per Unit.\n\n#### **Example**:\n- Fixed Costs = $10,000, Variable Cost per Unit = $5, Selling Price per Unit = $10.\n- Contribution Margin = $10 - $5 = $5.\n- BEP (units) = $10,000 / $5 = 2,000 units.\n- BEP (sales value) = 2,000 × $10 = $20,000.\n\n#### **Uses**:\n- Helps determine the minimum sales needed to avoid losses.\n- Assists in pricing, cost control, and production planning.\n\n---\n\n### **Make or Buy Decision (Case Study)**\n\n#### **Case Study: XYZ Manufacturing Company**\nXYZ Manufacturing produces a component for its product. It’s deciding whether to **make** the component in-house or **buy** it from an external supplier.\n\n#### **Data**:\n- **Annual Demand**: 10,000 units.\n- **Cost to Make (per unit)**:\n  - Direct Materials: $4.\n  - Direct Labor: $3.\n  - Variable Overhead: $2.\n  - Fixed Overhead: $20,000 (total, specific to this component).\n  - Total Cost to Make per Unit = $4 + $3 + $2 + ($20,000/10,000) = $11.\n  - Total Cost to Make = $11 × 10,000 = $110,000.\n- **Cost to Buy (per unit)**: $10 (from a supplier, no additional fixed costs).\n  - Total Cost to Buy = $10 × 10,000 = $100,000.\n- **Other Factors**:\n  - Making in-house ensures better quality control.\n  - Buying frees up capacity for other production but risks supplier dependency.\n\n#### **Analysis**:\n- **Cost Comparison**:\n  - Make: $110,000.\n  - Buy: $100,000.\n  - Savings from Buying = $110,000 - $100,000 = $10,000.\n- **Qualitative Factors**:\n  - **Make**: Retains control over quality, avoids supplier risks, but ties up resources.\n  - **Buy**: Frees capacity, reduces costs, but risks quality issues and dependency on the supplier.\n\n#### **Decision**:\n- **Buy** the component, as it saves $10,000 annually, assuming quality and supply risks are manageable. XYZ can use the freed capacity for other profitable activities.\n- **Recommendation**: Negotiate with the supplier for quality assurance and maintain a backup plan to mitigate risks.\n\n#### **Key Factors in Make or Buy Decisions**:\n- Cost comparison (make vs. buy).\n- Quality control and reliability of suppliers.\n- Capacity utilization and opportunity costs.\n- Strategic factors (e.g., maintaining core competencies in-house).\n\n---\n\n### **Relevance of Depreciation Towards Industry**\n\n#### **What is Depreciation?**\nDepreciation is the allocation of the cost of a tangible fixed asset (e.g., machinery, equipment) over its useful life. It reflects the asset’s wear and tear, obsolescence, or reduction in value over time.\n\n#### **Relevance to Industry**:\n1. **Cost Allocation**:\n   - Depreciation spreads the cost of expensive assets over multiple years, matching expenses with the revenue they generate (matching principle in accounting).\n   - Example: A $100,000 machine with a 10-year life depreciates at $10,000/year, ensuring accurate cost reporting.\n\n2. **Profitability Measurement**:\n   - By accounting for depreciation, industries can accurately calculate net profit, as it reduces taxable income.\n   - Example: If revenue is $50,000 and depreciation is $10,000, taxable income decreases, lowering tax liability.\n\n3. **Budgeting and Planning**:\n   - Helps industries plan for asset replacement by estimating the annual cost of asset usage.\n   - Example: Knowing a machine depreciates $10,000/year helps budget for its replacement after 10 years.\n\n4. **Pricing Decisions**:\n   - Depreciation is included in production costs, influencing product pricing to ensure cost recovery.\n   - Example: A firm adds depreciation to its cost structure to set a price that covers all expenses.\n\n5. **Financial Reporting**:\n   - Reflects the true value of assets on the balance sheet, improving transparency for investors and stakeholders.\n   - Example: A machine bought for $100,000 with $40,000 accumulated depreciation is shown at $60,000 net book value.\n\n6. **Tax Benefits**:\n   - Depreciation is a non-cash expense that reduces taxable income, providing tax savings.\n   - Example: $10,000 depreciation lowers taxable income, saving taxes at the firm’s tax rate (e.g., 30% tax rate saves $3,000).\n\n7. **Investment Decisions**:\n   - Industries use depreciation to assess the cost of maintaining assets, influencing decisions on new investments or asset disposal.\n   - Example: High depreciation costs may signal the need to replace outdated machinery.\n\n8. **Impact on Cash Flow**:\n   - While depreciation doesn’t involve cash outflow, the tax shield it provides improves cash flow.\n   - Example: A $10,000 depreciation expense saves $3,000 in taxes (at 30%), increasing available cash.\n\n#### **Limitations**:\n- Depreciation is an estimate, not an actual cash expense, and may not reflect the asset’s true market value.\n- Different methods (e.g., straight-line, declining balance) can affect reported profits, complicating comparisons across firms.\n"
  },
  {
    "url": "University/Economics/Module_5.html",
    "content": "---\nid: Module_5\naliases: []\ntags: []\n---\n\n### **Meaning of Market**\nA **market** is a place (physical or virtual) where buyers and sellers interact to exchange goods, services, or resources at a mutually agreed price. It facilitates the determination of prices through the forces of demand and supply.\n\n---\n\n### **Types of Market Structures**\n\n#### **1. Perfect Competition**\n- **Definition**: A market with many buyers and sellers trading identical products, where no single participant can influence the price.\n- **Features**:\n  - Large number of buyers and sellers.\n  - Identical (homogeneous) products (e.g., wheat, rice).\n  - Perfect knowledge of market conditions.\n  - Free entry and exit of firms.\n  - Price takers: Firms accept the market price.\n- **Example**: Agricultural markets (e.g., a vegetable market where many farmers sell identical tomatoes).\n- **Outcome**: Price equals marginal cost (P = MC), leading to allocative efficiency.\n\n#### **2. Monopoly**\n- **Definition**: A market with a single seller controlling the entire supply of a unique product with no close substitutes.\n- **Features**:\n  - Single seller, many buyers.\n  - Unique product with no substitutes.\n  - High barriers to entry (e.g., patents, legal restrictions).\n  - Price maker: The firm sets the price.\n- **Example**: A utility company like a sole electricity provider in a region (e.g., a government-owned power company).\n- **Outcome**: Higher prices, lower output compared to perfect competition; potential for inefficiency and consumer exploitation.\n\n#### **3. Monopolistic Competition**\n- **Definition**: A market with many sellers offering differentiated products that are close substitutes, allowing some control over pricing.\n- **Features**:\n  - Many buyers and sellers.\n  - Differentiated products (e.g., through branding, quality, design).\n  - Some control over price due to product differentiation.\n  - Low barriers to entry and exit.\n- **Example**: Fast food restaurants (e.g., McDonald’s, Burger King) offering slightly different burgers.\n- **Outcome**: Firms compete on non-price factors (e.g., advertising, quality); inefficiency due to excess capacity (firms don’t produce at minimum average cost).\n\n#### **4. Oligopoly**\n- **Definition**: A market dominated by a few large firms, where each firm’s actions (e.g., pricing, output) impact the others.\n- **Features**:\n  - Few dominant firms, many buyers.\n  - Products may be homogeneous (e.g., steel) or differentiated (e.g., smartphones).\n  - High barriers to entry (e.g., capital requirements, economies of scale).\n  - Interdependence: Firms consider rivals’ reactions (e.g., price wars).\n- **Example**: Smartphone market (e.g., Apple, Samsung, Google dominate).\n- **Outcome**: Can lead to collusion (e.g., cartels like OPEC) or competition; prices may be higher than in perfect competition but lower than in a monopoly.\n\n### **Supply and Law of Supply**\n\n#### **Supply**\n**Supply** refers to the quantity of a good or service that producers are willing and able to offer for sale at various prices over a given period, assuming other factors remain constant (ceteris paribus).\n\n#### **Law of Supply**\nThe **Law of Supply** states that, all else being equal, as the price of a good increases, the quantity supplied increases, and as the price decreases, the quantity supplied decreases. This results in a positive relationship between price and quantity supplied.\n\n- **Reason**: Higher prices incentivize producers to supply more due to increased profitability, while lower prices discourage production.\n- **Supply Curve**: Upward sloping (positive slope) on a graph with price on the y-axis and quantity on the x-axis.\n- **Example**: If the price of apples rises from $1 to $2 per pound, farmers supply 1,000 pounds instead of 500 pounds.\n\n#### **Factors Affecting Supply (Non-Price Factors)**:\n- **Production Costs**: Lower costs (e.g., cheaper raw materials) increase supply.\n- **Technology**: Improved technology increases supply by making production more efficient.\n- **Government Policies**: Taxes decrease supply; subsidies increase supply.\n- **Prices of Related Goods**: If the price of a substitute in production (e.g., corn vs. wheat) rises, supply of the original good may decrease.\n- **Expectations**: If producers expect higher future prices, they may reduce current supply.\n- **Number of Suppliers**: More suppliers increase total market supply.\n\n---\n\n### **Role of Demand and Supply in Price Determination**\n\n#### **Demand**\n**Demand** refers to the quantity of a good or service that consumers are willing and able to buy at various prices, ceteris paribus. The **Law of Demand** states that as price decreases, quantity demanded increases (inverse relationship), resulting in a downward-sloping demand curve.\n\n#### **Interaction of Demand and Supply**\nPrice determination occurs at the **equilibrium** where the quantity demanded equals the quantity supplied. This interaction is the foundation of market economics.\n\n1. **Equilibrium Price and Quantity**:\n   - The point where the demand and supply curves intersect.\n   - At this price, there’s no surplus (excess supply) or shortage (excess demand).\n   - **Example**: If the demand for apples is 800 pounds at $1.50 per pound, and supply is also 800 pounds at $1.50, the equilibrium price is $1.50, and the equilibrium quantity is 800 pounds.\n\n2. **Surplus (Excess Supply)**:\n   - If the price is above equilibrium, quantity supplied exceeds quantity demanded.\n   - Producers lower prices to clear the surplus.\n   - **Example**: At $2 per pound, supply is 1,000 pounds, but demand is only 600 pounds. The surplus of 400 pounds pushes the price down toward equilibrium.\n\n3. **Shortage (Excess Demand)**:\n   - If the price is below equilibrium, quantity demanded exceeds quantity supplied.\n   - Consumers bid the price up to eliminate the shortage.\n   - **Example**: At $1 per pound, demand is 1,000 pounds, but supply is only 500 pounds. The shortage of 500 pounds drives the price up toward equilibrium.\n\n4. **Shifts in Demand and Supply**:\n   - **Demand Shifts**:\n     - Increase in demand (e.g., due to higher consumer income) shifts the demand curve right, raising equilibrium price and quantity.\n     - Decrease in demand (e.g., due to a substitute becoming cheaper) shifts the demand curve left, lowering equilibrium price and quantity.\n   - **Supply Shifts**:\n     - Increase in supply (e.g., due to better technology) shifts the supply curve right, lowering equilibrium price but increasing quantity.\n     - Decrease in supply (e.g., due to higher production costs) shifts the supply curve left, raising equilibrium price but decreasing quantity.\n\n#### **Example of Price Determination**:\n- **Initial Equilibrium**: Demand and supply for coffee intersect at $3 per pound, with 500 pounds sold.\n- **Demand Increases** (e.g., due to a health trend favoring coffee): Demand curve shifts right. New equilibrium: $4 per pound, 600 pounds.\n- **Supply Decreases** (e.g., due to a drought affecting coffee beans): Supply curve shifts left. New equilibrium: $5 per pound, 400 pounds.\n"
  },
  {
    "url": "University/OOP/Module_1/Basic_Concepts.html",
    "content": "---\nid: Basic Concepts\naliases: []\ntags: []\ntitle: Basic Concepts\n---\n\n## Basic Concepts\nThe four key principles of OOP in Java are:\n\n### Encapsulation\nIt is the process of bundling data and methods that operate on the data into single unit (classes) and restricting direct access to some of the object's details.\n#### Key features\n- Prevent direct access to private data members.\n- Access Modifiers:\n    - `private` -> Accessible only within same class.\n    - `protected` -> Accessible within same package and subclasses\n    - `public` -> Accessible from anywhere.\n    - `default` (no modifier) -> Accessible within the same package\n\n```text\nModifier    Class   Package Subclass    World\npublic        Y        Y       Y         Y \nprotected     Y        Y       Y         N\nno modifier   Y        Y       N         N\nprivate       Y        N       N         N\n```\n\n```java\nclass BankAccount {\n    private double balance; // Private variable\n\n    // Constructor\n    public BankAccount(double balance) {\n        this.balance = balance;\n    }\n\n    // Public methods to access private data\n    public void deposit(double amount) {\n        balance += amount;\n    }\n\n    public void withdraw(double amount) {\n        if (amount <= balance) {\n            balance -= amount;\n        } else {\n            System.out.println(\"Insufficient funds\");\n        }\n    }\n\n    public double getBalance() {\n        return balance;\n    }\n}\n\npublic class Main {\n    public static void main(String[] args) {\n        BankAccount account = new BankAccount(1000);\n        account.deposit(500);\n        System.out.println(\"Balance: \" + account.getBalance()); // Output: 1500\n    }\n}\n```\n\n- `balance` is `private`, meaning it cannot be accessed directly.\n- The `getBalance()`, `deposit()`, and `withdraw()` methods provide controlled access.\n\n### Abstraction\nAbstraction is the process of hiding complex implementation details and exposing only necessary functionality.\n#### Key Features \n- Achieved using abstract classes and interfaces.\n- Abstract classes can have both abstract and non-abstract methods.\n- Interfaces only contain method declarations (Java 8+ allows default methods).\n\n```java\nabstract class Vehicle {\n    abstract void start(); // Abstract method (no body)\n\n    public void stop() {\n        System.out.println(\"Vehicle stopped\");\n    }\n}\n\nclass Car extends Vehicle {\n    @Override\n    void start() {\n        System.out.println(\"Car is starting\");\n    }\n}\n\npublic class Main {\n    public static void main(String[] args) {\n        Vehicle myCar = new Car();\n        myCar.start(); // Output: Car is starting\n        myCar.stop();  // Output: Vehicle stopped\n    }\n}\n```\n- `Vehicle` is an abstract class, meaning it cannot be instantiated.\n- `start()` is an abstract method, so it must be implemented by any subclass (`Car` in this case).\n- `stop()` is a concrete method (implemented in `Vehicle`) that can be used by all subclasses.\n\n### Inheritance\nInheritance is the mechanism in which one class (child/subclass) acquires the properties of another class(parent/superclass).\n#### Key features\n- Enable code reusability\n- The `extends` keyword is used to inherit a class.\n- The `super` keyword is used to access parent class members.\n\n```java\n// Parent Class\nclass Animal {\n    String name;\n\n    public void eat() {\n        System.out.println(name + \" is eating\");\n    }\n}\n\n// Child Class\nclass Dog extends Animal {\n    public void bark() {\n        System.out.println(name + \" is barking\");\n    }\n}\n\npublic class Main {\n    public static void main(String[] args) {\n        Dog myDog = new Dog();\n        myDog.name = \"Buddy\";\n        myDog.eat();  // Output: Buddy is eating\n        myDog.bark(); // Output: Buddy is barking\n    }\n}\n```\n- `Dog` class inherits properties and methods from the Animal class.\n- `myDog` can access both `eat()` (from Animal) and `bark()` (from Dog).\n\n#### Types of Inheritance in Java\n##### Single Inheritance\n- A subclass inherits from a single superclass.\n- The subclass gets access to public and protected members of the superclass.\n- Used to avoid code duplication and promote reusability.\n\n```java\n// Superclass\nclass Animal {\n    void eat() {\n        System.out.println(\"This animal eats food.\");\n    }\n}\n\n// Subclass\nclass Dog extends Animal {\n    void bark() {\n        System.out.println(\"The dog barks.\");\n    }\n}\n\n// Main Class\npublic class SingleInheritance {\n    public static void main(String[] args) {\n        Dog dog = new Dog();\n        dog.eat();  // Inherited method\n        dog.bark(); // Own method\n    }\n}\n\noutput: \nThis animal eats food.\nThe dog barks.\n```\n\n##### Multilevel inheritance\n- A class inherits from another class, which itself inherits from another class.\n- It creates a chain of inheritance.\n- The last derived class gets access to all properties of the previous classes.\n\n```java\n// Grandparent class\nclass Animal {\n    void eat() {\n        System.out.println(\"This animal eats food.\");\n    }\n}\n\n// Parent class\nclass Mammal extends Animal {\n    void walk() {\n        System.out.println(\"Mammals can walk.\");\n    }\n}\n\n// Child class\nclass Dog extends Mammal {\n    void bark() {\n        System.out.println(\"Dogs bark.\");\n    }\n}\n\n// Main class\npublic class MultilevelInheritance {\n    public static void main(String[] args) {\n        Dog dog = new Dog();\n        dog.eat();  // Inherited from Animal\n        dog.walk(); // Inherited from Mammal\n        dog.bark(); // Own method\n    }\n}\n\noutput: \nThis animal eats food.\nMammals can walk.\nDogs bark.\n```\n\n##### Hierarchical inheritance\n- One parent class is inherited by multiple child classes.\n- It creates a tree-like structure.\n\n```java\n// Superclass\nclass Animal {\n    void eat() {\n        System.out.println(\"This animal eats food.\");\n    }\n}\n\n// Subclass 1\nclass Dog extends Animal {\n    void bark() {\n        System.out.println(\"The dog barks.\");\n    }\n}\n\n// Subclass 2\nclass Cat extends Animal {\n    void meow() {\n        System.out.println(\"The cat meows.\");\n    }\n}\n\n// Main class\npublic class HierarchicalInheritance {\n    public static void main(String[] args) {\n        Dog dog = new Dog();\n        dog.eat();  // Inherited method\n        dog.bark(); // Own method\n\n        Cat cat = new Cat();\n        cat.eat();  // Inherited method\n        cat.meow(); // Own method\n    }\n}\n\noutput: \nThis animal eats food.\nThe dog barks.\nThis animal eats food.\nThe cat meows.\n```\n\n##### Multiple inheritance\n- Java does not support multiple inheritance of classes (a class inheriting from multiple classes) to avoid the \"diamond problem\" (ambiguity when two parent classes have methods with the same name). However, multiple inheritance is achieved using interfaces.\n- Multiple inheritance refers to the ability of a class to inherit properties and behaviors (methods and fields) from more than one superclass.\n\n```java\ninterface CanFly {\n    void fly();\n}\n\ninterface CanSwim {\n    void swim();\n}\n\nclass Duck implements CanFly, CanSwim {\n    public void fly() {\n        System.out.println(\"The duck flies.\");\n    }\n    public void swim() {\n        System.out.println(\"The duck swims.\");\n    }\n}\n\npublic class Main {\n    public static void main(String[] args) {\n        Duck duck = new Duck();\n        duck.fly();  // From CanFly\n        duck.swim(); // From CanSwim\n    }\n}\n\noutput:\nThe duck flies.\nThe duck swims.\n```\n\n##### Hybrid inheritance\n- Hybrid inheritance is a combination of two or more types of inheritance (e.g., hierarchical and multilevel). In Java, this is achieved using a mix of class inheritance and interface implementation, as direct multiple class inheritance is not allowed.\n\n```java\nclass Animal {\n    void eat() {\n        System.out.println(\"This animal eats food.\");\n    }\n}\n\ninterface CanRun {\n    void run();\n}\n\nclass Dog extends Animal implements CanRun {\n    void bark() {\n        System.out.println(\"The dog barks.\");\n    }\n    public void run() {\n        System.out.println(\"The dog runs.\");\n    }\n}\n\nclass Puppy extends Dog {\n    void play() {\n        System.out.println(\"The puppy plays.\");\n    }\n}\n\npublic class Main {\n    public static void main(String[] args) {\n        Puppy puppy = new Puppy();\n        puppy.eat();  // From Animal\n        puppy.bark(); // From Dog\n        puppy.run();  // From CanRun\n        puppy.play(); // From Puppy\n    }\n}\n\noutput: \nThis animal eats food.\nThe dog barks.\nThe dog runs.\nThe puppy plays.\n```\n\n### Polymorphism\nPolymorphism is the property by which an object can take many forms, meaning a method or function behaves differently based on the object calling it.\n\n#### Compile time polymorphism - Method overloading\n- Occurs when multiple methods have the same name but different parameters.\n- The method to be called is determined at compile time.\n- Can be achieved by changing:\n    - Number of parameters\n    - Data type of parameters\n    - Order of parameters\n\n```java\nclass MathOperations {\n    // Method with one integer parameter\n    int add(int a, int b) {\n        return a + b;\n    }\n\n    // Method with three integer parameters\n    int add(int a, int b, int c) {\n        return a + b + c;\n    }\n\n    // Method with two double parameters\n    double add(double a, double b) {\n        return a + b;\n    }\n}\n\npublic class CompileTimePolymorphism {\n    public static void main(String[] args) {\n        MathOperations obj = new MathOperations();\n        System.out.println(\"Sum (int, int): \" + obj.add(5, 10)); \n        System.out.println(\"Sum (int, int, int): \" + obj.add(5, 10, 15)); \n        System.out.println(\"Sum (double, double): \" + obj.add(5.5, 2.5));\n    }\n}\n\noutput: \nSum (int, int): 15\nSum (int, int, int): 30\nSum (double, double): 8.0\n```\n\n##### Runtime Polymorphism - Method Overriding\n- Occurs when a subclass provides a specific implementation of a method that is already defined in the parent class.\n- The method to be executed is determined at runtime.\n- Requires inheritance and method overriding.\n\n**Rules:** - \n- Method name and parameters must be identical in the parent and child classes.\n- The return type must be the same or a subtype (covariant return type).\n- The access modifier of the overriding method cannot be more restrictive than the overridden method.\n- Only instance methods can be overridden (not static methods).\n- The `@Override` annotation is recommended to ensure correctness.\n\n```java\n// Parent class\nclass Animal {\n    void sound() {\n        System.out.println(\"Animals make different sounds.\");\n    }\n}\n\n// Child class overriding the method\nclass Dog extends Animal {\n    @Override\n    void sound() {\n        System.out.println(\"Dogs bark.\");\n    }\n}\n\n// Child class overriding the method\nclass Cat extends Animal {\n    @Override\n    void sound() {\n        System.out.println(\"Cats meow.\");\n    }\n}\n\n// Main class\npublic class RuntimePolymorphism {\n    public static void main(String[] args) {\n        Animal myAnimal;   // Reference variable of Animal\n\n        myAnimal = new Dog();\n        myAnimal.sound();  // Calls Dog's overridden method\n\n        myAnimal = new Cat();\n        myAnimal.sound();  // Calls Cat's overridden method\n    }\n}\n\noutput: \nDogs bark.\nCats meow.\n```\n\nPolymorphism can be achieved using interfaces too.\n```java\n// Interface\ninterface Animal {\n    void makeSound();\n}\n\n// Dog class implementing the interface\nclass Dog implements Animal {\n    public void makeSound() {\n        System.out.println(\"Dog barks.\");\n    }\n}\n\n// Cat class implementing the interface\nclass Cat implements Animal {\n    public void makeSound() {\n        System.out.println(\"Cat meows.\");\n    }\n}\n\n// Main class\npublic class InterfacePolymorphism {\n    public static void main(String[] args) {\n        Animal animal;\n\n        animal = new Dog();\n        animal.makeSound();  // Calls Dog's implementation\n\n        animal = new Cat();\n        animal.makeSound();  // Calls Cat's implementation\n    }\n}\n\noutput: \nDog barks.\nCat meows.\n```\n\n"
  },
  {
    "url": "University/OOP/Module_3/Exceptions.html",
    "content": "---\nid: Exceptions\naliases: []\ntags: []\ntitle: Exceptions\n---\n\n### 1. **Exception**\n\nAn **exception** in Java is an event that disrupts the normal flow of a program during execution, typically due to an error or unexpected condition (e.g., dividing by zero, accessing a null object, or reading a nonexistent file).\n\n- **Key Points**:\n  - Exceptions are objects derived from the `java.lang.Throwable` class.\n  - `Throwable` has two subclasses:\n    - **`Error`**: Represents serious problems that a program usually cannot recover from (e.g., `OutOfMemoryError`, `StackOverflowError`). Errors are typically not caught.\n    - **`Exception`**: Represents recoverable conditions that a program can handle (e.g., `IOException`, `NullPointerException`).\n  - Exceptions are thrown by the Java runtime or explicitly by code and can be caught and handled.\n\n- **Why Handle Exceptions?**:\n  - Prevents program crashes.\n  - Allows graceful error recovery.\n  - Provides meaningful error messages to users.\n  - Ensures resources (e.g., files, database connections) are properly closed.\n\n---\n\n### 2. **Handling of Exception**\n\nException handling in Java is the process of responding to exceptions to prevent program termination and manage errors gracefully. Java uses a structured mechanism involving `try`, `catch`, `finally`, `throw`, and `throws`.\n\n- **Core Mechanism**:\n  - **Try-catch**: Used to catch and handle exceptions.\n  - **Finally**: Ensures code (e.g., resource cleanup) executes regardless of whether an exception occurs.\n  - **Throw**: Explicitly throws an exception.\n  - **Throws**: Declares that a method may throw exceptions.\n\n- **Benefits**:\n  - Separates error-handling code from normal code.\n  - Improves code robustness and maintainability.\n  - Supports debugging with stack traces.\n\n---\n\n### 3. **Using try-catch**\n\nThe `try-catch` block is used to enclose code that might throw an exception and handle it if it occurs.\n\n- **Syntax**:\n  ```java\n  try {\n      // Code that might throw an exception\n  } catch (ExceptionType variable) {\n      // Handle the exception\n  }\n  ```\n\n- **How It Works**:\n  - Code in the `try` block is executed.\n  - If an exception is thrown, the JVM looks for a matching `catch` block.\n  - If caught, the `catch` block executes, and the program continues.\n  - If not caught, the exception propagates up the call stack, potentially terminating the program.\n\n- **Example**:\n  ```java\n  package com.example.myapp;\n  public class Test {\n      public static void main(String[] args) {\n          try {\n              int result = 10 / 0; // Throws ArithmeticException\n          } catch (ArithmeticException e) {\n              System.out.println(\"Error: Division by zero\");\n              System.out.println(\"Message: \" + e.getMessage());\n          }\n          System.out.println(\"Program continues\");\n      }\n  }\n  ```\n  **Output**:\n  ```\n  Error: Division by zero\n  Message: / by zero\n  Program continues\n  ```\n\n- **Key Points**:\n  - The `catch` block must specify the exact exception type or a superclass (e.g., `Exception` catches all exceptions).\n  - Use `e.getMessage()` or `e.printStackTrace()` to get details about the exception.\n  - Multiple `catch` blocks can be used for different exception types (see below).\n\n---\n\n### 4. **Catching Multiple Exceptions**\n\nA single `try` block can have multiple `catch` blocks to handle different types of exceptions, or you can use a multi-catch block (Java 7+) to catch multiple exceptions in one `catch`.\n\n- **Multiple Catch Blocks**:\n  ```java\n  try {\n      // Code that might throw exceptions\n      int[] arr = new int[5];\n      arr[10] = 100; // Throws ArrayIndexOutOfBoundsException\n      int result = 10 / 0; // Throws ArithmeticException\n  } catch (ArithmeticException e) {\n      System.out.println(\"Arithmetic error: \" + e.getMessage());\n  } catch (ArrayIndexOutOfBoundsException e) {\n      System.out.println(\"Array error: \" + e.getMessage());\n  } catch (Exception e) {\n      System.out.println(\"General error: \" + e.getMessage());\n  }\n  ```\n\n- **Rules**:\n  - Order matters: Catch more specific exceptions before general ones (e.g., `ArithmeticException` before `Exception`).\n  - If a `catch` block for a superclass (e.g., `Exception`) is placed first, it will catch all exceptions, making subsequent `catch` blocks unreachable (compiler error).\n\n- **Multi-Catch Block (Java 7+)**:\n  - Use a single `catch` block to handle multiple exception types.\n  - Syntax: `catch (ExceptionType1 | ExceptionType2 variable)`.\n  - Example:\n    ```java\n    try {\n        String str = null;\n        System.out.println(str.length()); // Throws NullPointerException\n        int result = 10 / 0; // Throws ArithmeticException\n    } catch (NullPointerException | ArithmeticException e) {\n        System.out.println(\"Error: \" + e.getMessage());\n    }\n    ```\n\n- **Key Points**:\n  - Multi-catch is concise but requires exceptions to be unrelated (not in the same inheritance hierarchy).\n  - The variable in a multi-catch block is implicitly `final` and cannot be reassigned.\n\n---\n\n### 5. **Using finally Clause**\n\nThe `finally` block contains code that executes **always**, whether an exception is thrown or not, typically used for resource cleanup (e.g., closing files or database connections).\n\n- **Syntax**:\n  ```java\n  try {\n      // Code that might throw an exception\n  } catch (ExceptionType e) {\n      // Handle the exception\n  } finally {\n      // Code that always executes\n  }\n  ```\n\n- **Example**:\n  ```java\n  package com.example.myapp;\n  import java.io.*;\n  public class Test {\n      public static void main(String[] args) {\n          FileReader file = null;\n          try {\n              file = new FileReader(\"file.txt\");\n              // Read file\n          } catch (FileNotFoundException e) {\n              System.out.println(\"File not found: \" + e.getMessage());\n          } finally {\n              if (file != null) {\n                  try {\n                      file.close();\n                  } catch (IOException e) {\n                      System.out.println(\"Error closing file\");\n                  }\n              }\n              System.out.println(\"Finally block executed\");\n          }\n      }\n  }\n  ```\n\n- **Key Points**:\n  - The `finally` block executes even if:\n    - No exception is thrown.\n    - An exception is thrown and caught.\n    - An exception is thrown and not caught (before the program terminates).\n    - A `return`, `break`, or `continue` statement is executed in `try` or `catch`.\n  - **Exception**: `finally` does not execute if the JVM exits (e.g., `System.exit(0)`).\n  - `finally` is optional; a `try` block can have `catch` or `finally`, or both.\n  - Use for cleanup to avoid resource leaks.\n\n- **Try-with-Resources (Java 7+)**:\n  - Simplifies resource management by automatically closing resources that implement `AutoCloseable`.\n  - Example:\n    ```java\n    try (FileReader file = new FileReader(\"file.txt\")) {\n        // Use file\n    } catch (FileNotFoundException e) {\n        System.out.println(\"File not found\");\n    }\n    // No need for finally; file is closed automatically\n    ```\n\n---\n\n### 6. **Types of Exceptions**\n\nJava exceptions are classified into two main categories: **Checked Exceptions** and **Unchecked Exceptions**.\n\n- **Checked Exceptions**:\n  - Checked at **compile-time**.\n  - Must be declared in a method’s `throws` clause or handled in a `try-catch` block.\n  - Derived from `Exception` but not `RuntimeException`.\n  - Examples:\n    - `IOException` (file operations).\n    - `SQLException` (database operations).\n    - `ClassNotFoundException`.\n  - Example:\n    ```java\n    import java.io.*;\n    public class Test {\n        public static void readFile() throws IOException {\n            FileReader file = new FileReader(\"file.txt\");\n        }\n    }\n    ```\n\n- **Unchecked Exceptions**:\n  - Checked at **runtime**.\n  - Do not need to be declared or caught (though they can be).\n  - Derived from `RuntimeException` (a subclass of `Exception`).\n  - Examples:\n    - `NullPointerException` (accessing null object).\n    - `ArithmeticException` (division by zero).\n    - `ArrayIndexOutOfBoundsException`.\n    - `IllegalArgumentException`.\n  - Example:\n    ```java\n    public class Test {\n        public static void main(String[] args) {\n            String str = null;\n            System.out.println(str.length()); // Throws NullPointerException\n        }\n    }\n    ```\n\n- **Errors** (Not Exceptions):\n  - Represent serious, unrecoverable problems (e.g., `OutOfMemoryError`, `VirtualMachineError`).\n  - Derived from `Error`, not `Exception`.\n  - Not typically caught or handled.\n\n- **Hierarchy**:\n  ```\n  Throwable\n  ├── Error (e.g., OutOfMemoryError, StackOverflowError)\n  └── Exception\n      ├── RuntimeException (Unchecked, e.g., NullPointerException, ArithmeticException)\n      └── Other Exceptions (Checked, e.g., IOException, SQLException)\n  ```\n\n- **Key Points**:\n  - Checked exceptions enforce error handling at compile-time.\n  - Unchecked exceptions are programmer errors and can be avoided with proper coding.\n  - Use checked exceptions for recoverable conditions, unchecked for programming errors.\n\n---\n\n### 7. **Throwing Exceptions**\n\nYou can explicitly **throw** an exception using the `throw` keyword to signal an error condition. A method can declare that it throws exceptions using the `throws` keyword.\n\n- **Throw Keyword**:\n  - Syntax: `throw new ExceptionType(\"message\");`\n  - Example:\n    ```java\n    public class Test {\n        public static void checkAge(int age) {\n            if (age < 18) {\n                throw new IllegalArgumentException(\"Age must be 18 or older\");\n            }\n            System.out.println(\"Age is valid\");\n        }\n        public static void main(String[] args) {\n            try {\n                checkAge(16);\n            } catch (IllegalArgumentException e) {\n                System.out.println(\"Error: \" + e.getMessage());\n            }\n        }\n    }\n    ```\n    **Output**:\n    ```\n    Error: Age must be 18 or older\n    ```\n\n- **Throws Keyword**:\n  - Used in a method signature to declare that it may throw one or more checked exceptions.\n  - Syntax: `returnType methodName() throws ExceptionType1, ExceptionType2`\n  - Example:\n    ```java\n    import java.io.*;\n    public class Test {\n        public static void readFile() throws IOException {\n            FileReader file = new FileReader(\"file.txt\");\n        }\n        public static void main(String[] args) {\n            try {\n                readFile();\n            } catch (IOException e) {\n                System.out.println(\"Error: \" + e.getMessage());\n            }\n        }\n    }\n    ```\n\n- **Key Points**:\n  - Only `Throwable` objects (`Error` or `Exception`) can be thrown.\n  - `throws` is required for checked exceptions but optional for unchecked exceptions.\n  - Use meaningful exception messages to aid debugging.\n\n---\n\n### 8. **Writing Exception Subclasses**\n\nYou can create **custom exceptions** by extending `Exception` (for checked exceptions) or `RuntimeException` (for unchecked exceptions). Custom exceptions allow you to define application-specific error conditions.\n\n- **Syntax**:\n  ```java\n  class CustomException extends Exception {\n      public CustomException() {\n          super();\n      }\n      public CustomException(String message) {\n          super(message);\n      }\n      public CustomException(String message, Throwable cause) {\n          super(message, cause);\n      }\n  }\n  ```\n\n- **Example**:\n  ```java\n  package com.example.myapp;\n  // Custom checked exception\n  class InvalidBalanceException extends Exception {\n      public InvalidBalanceException(String message) {\n          super(message);\n      }\n  }\n  // Class using the custom exception\n  class BankAccount {\n      private double balance;\n      public void withdraw(double amount) throws InvalidBalanceException {\n          if (amount > balance) {\n              throw new InvalidBalanceException(\"Insufficient balance: \" + balance);\n          }\n          balance -= amount;\n          System.out.println(\"Withdrawal successful. New balance: \" + balance);\n      }\n      public void deposit(double amount) {\n          balance += amount;\n      }\n  }\n  // Test class\n  public class Test {\n      public static void main(String[] args) {\n          BankAccount account = new BankAccount();\n          account.deposit(100.0);\n          try {\n              account.withdraw(150.0);\n          } catch (InvalidBalanceException e) {\n              System.out.println(\"Error: \" + e.getMessage());\n          }\n      }\n  }\n  ```\n  **Output**:\n  ```\n  Error: Insufficient balance: 100.0\n  ```\n\n- **Key Points**:\n  - Extend `Exception` for checked exceptions, `RuntimeException` for unchecked.\n  - Provide constructors to pass error messages or causes.\n  - Use custom exceptions to make error handling specific to your application.\n  - Store custom exceptions in appropriate packages (e.g., `com.example.myapp.exceptions`).\n\n- **Best Practices**:\n  - Use meaningful names (e.g., `InvalidBalanceException` instead of `MyException`).\n  - Include detailed messages for debugging.\n  - Consider adding fields or methods to the custom exception for additional context (e.g., error codes).\n\n---\n\n###  **Practice Program**:\n   ```java\n   package com.example.myapp;\n   import java.io.*;\n   class InsufficientFundsException extends Exception {\n       public InsufficientFundsException(String message) {\n           super(message);\n       }\n   }\n   class Account {\n       private double balance;\n       public Account(double balance) {\n           this.balance = balance;\n       }\n       public void withdraw(double amount) throws InsufficientFundsException {\n           if (amount > balance) {\n               throw new InsufficientFundsException(\"Balance too low: \" + balance);\n           }\n           balance -= amount;\n       }\n   }\n   public class Test {\n       public static void main(String[] args) {\n           Account account = new Account(50.0);\n           try (BufferedReader reader = new BufferedReader(new FileReader(\"data.txt\"))) {\n               account.withdraw(100.0);\n           } catch (InsufficientFundsException | FileNotFoundException e) {\n               System.out.println(\"Error: \" + e.getMessage());\n           } catch (IOException e) {\n               System.out.println(\"IO Error: \" + e.getMessage());\n           } finally {\n               System.out.println(\"Cleanup complete\");\n           }\n       }\n   }\n   ```\n\n   **Compile and Run**:\n   ```bash\n   javac com/example/myapp/*.java\n   java -cp . com.example.myapp.Test\n   ```\n"
  },
  {
    "url": "University/OOP/Module_3/Packages.html",
    "content": "---\nid: Packages\naliases: []\ntags: []\ntitle: Packages\n---\n\n### 1. **Defining a Package**\n\nA **package** in Java is a mechanism to organize related classes, interfaces, and other types into a single namespace. It helps avoid naming conflicts, provides modularity, and improves code maintainability.\n\n- **Purpose**:\n  - Group related classes and interfaces.\n  - Prevent naming collisions (e.g., two classes with the same name in different packages).\n  - Provide access control (e.g., restricting access to package members).\n  - Facilitate code reuse and organization.\n\n- **How to Define a Package**:\n  - Use the `package` keyword at the top of a Java source file.\n  - Syntax: `package packageName;`\n  - Example:\n    ```java\n    package com.example.myapp;\n    public class MyClass {\n        public void display() {\n            System.out.println(\"Hello from MyClass!\");\n        }\n    }\n    ```\n  - The above code declares that `MyClass` belongs to the `com.example.myapp` package.\n\n- **Directory Structure**:\n  - The package name must correspond to the directory structure where the source file is stored.\n  - For example, `com.example.myapp.MyClass` should be in the directory `com/example/myapp/`.\n  - Compiled `.class` files must also follow this structure.\n\n- **Default Package**:\n  - If no `package` statement is specified, the class belongs to the **default package** (no namespace).\n  - Example:\n    ```java\n    // No package statement\n    public class Test {\n        // Class in default package\n    }\n    ```\n  - Using the default package is discouraged for large projects due to lack of organization.\n\n- **Rules**:\n  - The `package` statement must be the first non-comment line in the source file.\n  - Only one `package` statement is allowed per file.\n  - All classes in the same source file belong to the declared package.\n\n---\n\n### 2. **CLASSPATH**\n\nThe **CLASSPATH** is an environment variable or a parameter that tells the Java Virtual Machine (JVM) and Java compiler where to look for user-defined classes and packages.\n\n- **Purpose**:\n  - Specifies the location of `.class` files and other resources (e.g., JAR files).\n  - Helps the JVM locate classes during compilation and runtime.\n\n- **How CLASSPATH Works**:\n  - The JVM searches for classes in the directories or JAR files listed in the CLASSPATH.\n  - The search includes:\n    - The standard Java library (automatically included).\n    - Directories or JAR files specified in the CLASSPATH.\n    - The current directory (if included, often denoted by a dot `.`).\n\n- **Setting CLASSPATH**:\n  - **Environment Variable**:\n    - Set the CLASSPATH variable on your system.\n    - Example (Unix/Linux):\n      ```bash\n      export CLASSPATH=/path/to/classes:/path/to/lib.jar\n      ```\n    - Example (Windows):\n      ```cmd\n      set CLASSPATH=C:\\path\\to\\classes;C:\\path\\to\\lib.jar\n      ```\n  - **Command-Line Option**:\n    - Use the `-cp` or `-classpath` option when running `javac` or `java`.\n    - Example:\n      ```bash\n      javac -cp /path/to/classes MyClass.java\n      java -cp /path/to/classes com.example.myapp.MyClass\n      ```\n\n- **Default CLASSPATH**:\n  - If not set, the default CLASSPATH is the current directory (`.`).\n  - Example: If you run `java MyClass`, the JVM looks for `MyClass.class` in the current directory.\n\n- **Common Issues**:\n  - **ClassNotFoundException**: Occurs if the JVM cannot find the class in the CLASSPATH.\n  - **NoClassDefFoundError**: Occurs if a class was available during compilation but not at runtime.\n  - Solution: Ensure the correct path to the `.class` file or JAR is included in the CLASSPATH.\n\n- **Example**:\n  - Directory structure:\n    ```\n    /home/user/myapp/com/example/myapp/MyClass.class\n    ```\n  - Set CLASSPATH:\n    ```bash\n    export CLASSPATH=/home/user/myapp\n    ```\n  - Run:\n    ```bash\n    java com.example.myapp.MyClass\n    ```\n\n---\n\n### 3. **Package Naming**\n\nPackage naming follows a **convention** to ensure uniqueness and clarity. It helps avoid naming conflicts and makes code easier to understand.\n\n- **Naming Convention**:\n  - Use a **reverse domain name** to ensure uniqueness, as domain names are globally unique.\n  - Example: If your organization’s domain is `example.com`, the package name might be `com.example`.\n  - Structure: `topLevelDomain.organizationName.projectName.subModule`.\n  - Examples:\n    - `com.google.utils`\n    - `org.apache.commons`\n    - `com.example.myapp.model`\n\n- **Rules**:\n  - Use lowercase letters for package names (convention, not enforced).\n  - Avoid using reserved keywords (e.g., `class`, `public`).\n  - Separate levels with dots (`.`), e.g., `com.example.myapp`.\n  - Each level corresponds to a directory in the file system.\n\n- **Examples**:\n  - Valid: `com.example.myapp`, `edu.university.cs101`\n  - Invalid: `com.example.my-app` (hyphens not allowed), `Com.Example` (uppercase discouraged).\n\n- **Why Follow Conventions?**:\n  - Prevents naming conflicts with other developers’ packages.\n  - Makes it easier to locate and understand the purpose of a package.\n  - Aligns with industry standards, improving code readability.\n\n- **Standard Packages**:\n  - Java provides built-in packages, e.g.:\n    - `java.lang` (automatically imported, contains `String`, `System`, etc.).\n    - `java.util` (contains `ArrayList`, `HashMap`, etc.).\n    - `java.io` (for input/output operations).\n\n---\n\n### 4. **Accessibility of Packages**\n\nAccessibility in packages refers to how classes, methods, and fields within a package can be accessed by other classes, either within the same package or from outside it. Java uses **access modifiers** to control accessibility.\n\n- **Access Modifiers**:\n  - **`public`**: The member (class, method, field) is accessible from everywhere.\n  - **`protected`**: The member is accessible within the same package and also in subclasses (even in different packages).\n  - **`default`** (also called package-private): If no modifier is specified, the member is accessible only within the same package.\n  - **`private`**: The member is accessible only within the same class.\n\n- **Package Accessibility Rules**:\n  - **Classes**:\n    - A `public` class is accessible from any package.\n    - A `default` (no modifier) class is accessible only within the same package.\n    - Example:\n      ```java\n      package com.example.myapp;\n      public class PublicClass {\n          // Accessible everywhere\n      }\n      class DefaultClass {\n          // Accessible only in com.example.myapp\n      }\n      ```\n  - **Members (Fields, Methods, Constructors)**:\n    - `public`: Accessible from any class.\n    - `protected`: Accessible within the same package and in subclasses.\n    - `default`: Accessible only within the same package.\n    - `private`: Accessible only within the same class.\n    - Example:\n      ```java\n      package com.example.myapp;\n      public class MyClass {\n          public int publicField = 1;\n          protected int protectedField = 2;\n          int defaultField = 3; // package-private\n          private int privateField = 4;\n      }\n      ```\n\n- **Accessing Across Packages**:\n  - To access a class or member in another package, you must:\n    1. Import the package/class (see **Using Package Members** below).\n    2. Ensure the class/member is `public` or `protected` (if accessed via inheritance).\n  - Example:\n    ```java\n    package com.example.other;\n    import com.example.myapp.MyClass;\n    public class Test {\n        public void testAccess() {\n            MyClass obj = new MyClass();\n            System.out.println(obj.publicField); // OK\n            // System.out.println(obj.defaultField); // Error: not visible\n        }\n    }\n    ```\n\n- **Package-Private Advantage**:\n  - Using `default` access restricts visibility to the package, which is useful for internal implementation details.\n  - Example: Utility classes or helper classes used only within a package.\n\n---\n\n### 5. **Using Package Members**\n\nTo use classes, interfaces, or other members from a package, you need to **import** them or refer to them using their **fully qualified name**. Here’s how it works:\n\n- **Fully Qualified Name**:\n  - Refers to the complete package path plus the class name.\n  - Example: `com.example.myapp.MyClass`.\n  - Usage:\n    ```java\n    public class Test {\n        public static void main(String[] args) {\n            com.example.myapp.MyClass obj = new com.example.myapp.MyClass();\n            obj.display();\n        }\n    }\n    ```\n  - Drawback: Fully qualified names are verbose and make code harder to read.\n\n- **Importing Packages/Classes**:\n  - Use the `import` keyword to avoid writing fully qualified names.\n  - Syntax:\n    ```java\n    import packageName.subPackage.ClassName; // Import specific class\n    import packageName.subPackage.*; // Import all classes in package\n    ```\n  - Example:\n    ```java\n    import com.example.myapp.MyClass;\n    public class Test {\n        public static void main(String[] args) {\n            MyClass obj = new MyClass();\n            obj.display();\n        }\n    }\n    ```\n\n- **Types of Imports**:\n  - **Single-Type Import**:\n    - Imports a specific class or interface.\n    - Example: `import java.util.ArrayList;`\n  - **On-Demand Import** (Importing Entire Package):\n    - Imports all classes in a package (but not subpackages).\n    - Example: `import java.util.*;`\n    - Note: This does not import subpackages like `java.util.concurrent`.\n  - **Static Import**:\n    - Imports static members (fields, methods) of a class.\n    - Example:\n      ```java\n      import static java.lang.Math.PI;\n      import static java.lang.Math.sqrt;\n      public class Test {\n          public static void main(String[] args) {\n              System.out.println(PI); // No need for Math.PI\n              System.out.println(sqrt(16)); // No need for Math.sqrt\n          }\n      }\n      ```\n\n- **Automatic Imports**:\n  - The `java.lang` package is automatically imported in every Java program.\n  - Example: You can use `String`, `System`, or `Math` without importing.\n\n- **Resolving Naming Conflicts**:\n  - If two imported packages contain classes with the same name, use the fully qualified name or import only one class.\n  - Example:\n    ```java\n    import java.util.Date;\n    import java.sql.Date; // Conflict: two Date classes\n    ```\n    Solution:\n    ```java\n    java.util.Date utilDate = new java.util.Date();\n    java.sql.Date sqlDate = new java.sql.Date();\n    ```\n\n- **Rules for Imports**:\n  - Imports must appear after the `package` statement and before class declarations.\n  - Importing a package does not import its subpackages.\n  - Unused imports do not affect performance but should be removed for clarity (modern IDEs do this automatically).\n\n- **Accessing Package Members**:\n  - Ensure the member is accessible based on its access modifier (`public`, `protected`, `default`, `private`).\n  - Example:\n    ```java\n    package com.example.other;\n    import com.example.myapp.MyClass;\n    public class Test {\n        public static void main(String[] args) {\n            MyClass obj = new MyClass();\n            System.out.println(obj.publicField); // OK\n            // System.out.println(obj.privateField); // Error: not accessible\n        }\n    }\n    ```\n\n---\n\n### Summary for Exam Preparation\n\n- **Defining Package**:\n  - Use `package` keyword to group classes.\n  - Matches directory structure.\n  - Default package if no `package` statement.\n\n- **CLASSPATH**:\n  - Tells JVM where to find `.class` files.\n  - Set via environment variable or `-cp` option.\n  - Default is current directory (`.`).\n\n- **Package Naming**:\n  - Use reverse domain name (e.g., `com.example.myapp`).\n  - Lowercase, no hyphens, follow conventions.\n\n- **Accessibility of Packages**:\n  - Controlled by `public`, `protected`, `default`, `private`.\n  - `default` restricts to same package.\n  - `public` allows access from any package.\n\n- **Using Package Members**:\n  - Import with `import` or use fully qualified names.\n  - Single-type, on-demand, and static imports.\n  - Resolve conflicts with fully qualified names.\n\n---\n\n### Example Program for Practice\n\n**File 1: `com/example/myapp/MyClass.java`**\n```java\npackage com.example.myapp;\npublic class MyClass {\n    public int publicField = 1;\n    protected int protectedField = 2;\n    int defaultField = 3;\n    private int privateField = 4;\n    public void display() {\n        System.out.println(\"Public: \" + publicField);\n        System.out.println(\"Protected: \" + protectedField);\n        System.out.println(\"Default: \" + defaultField);\n        System.out.println(\"Private: \" + privateField);\n    }\n}\n```\n\n**File 2: `com/example/other/Test.java`**\n```java\npackage com.example.other;\nimport com.example.myapp.MyClass;\npublic class Test {\n    public static void main(String[] args) {\n        MyClass obj = new MyClass();\n        obj.display();\n        System.out.println(\"Accessing public field: \" + obj.publicField);\n        // System.out.println(obj.defaultField); // Error: not visible\n    }\n}\n```\n\n**Compile and Run**:\n```bash\n# Compile\njavac com/example/myapp/MyClass.java\njavac com/example/other/Test.java\n# Run\njava -cp . com.example.other.Test\n```\n"
  },
  {
    "url": "University/OOP/Module_3/Threads.html",
    "content": "---\nid: Threads\naliases: []\ntags: []\ntitle: Threads\n---\n\n### 1. **Introduction to Multithreading**\n\n**Multithreading** is the ability of a program to execute multiple threads concurrently, allowing tasks to run in parallel within the same process. A **thread** is a lightweight unit of execution, and multithreading improves performance, responsiveness, and resource utilization.\n\n- **Key Concepts**:\n  - A **process** is an executing program with its own memory space.\n  - A **thread** is a subset of a process, sharing the same memory and resources.\n  - Multithreading enables tasks like UI updates, background processing, and parallel computations.\n\n- **Advantages**:\n  - Improved performance on multi-core processors.\n  - Better resource sharing (threads share memory).\n  - Enhanced responsiveness (e.g., GUI remains active while processing).\n  - Simplified modeling of concurrent tasks.\n\n- **Challenges**:\n  - **Race conditions**: When multiple threads access shared resources unpredictably.\n  - **Deadlocks**: When threads wait indefinitely for each other.\n  - **Thread safety**: Ensuring shared data is accessed correctly.\n\n- **Java’s Role**:\n  - Java provides built-in support for multithreading via the `java.lang.Thread` class and `java.lang.Runnable` interface.\n  - The Java Virtual Machine (JVM) manages thread scheduling and execution.\n\n---\n\n### 2. **The Main Thread**\n\nThe **main thread** is the primary thread of execution in a Java program, automatically created by the JVM when the program starts.\n\n- **Key Points**:\n  - Entry point: The `main` method (`public static void main(String[] args)`).\n  - Responsible for executing the program’s initial code.\n  - Can create and manage other threads.\n  - Program terminates when the main thread (and all non-daemon threads) finishes.\n\n- **Accessing the Main Thread**:\n  - Use `Thread.currentThread()` to get the current thread (main thread in the `main` method).\n  - Example:\n    ```java\n    package com.example.myapp;\n    public class MainThreadDemo {\n        public static void main(String[] args) {\n            Thread mainThread = Thread.currentThread();\n            System.out.println(\"Main thread: \" + mainThread.getName());\n            System.out.println(\"Priority: \" + mainThread.getPriority());\n        }\n    }\n    ```\n    **Output**:\n    ```\n    Main thread: main\n    Priority: 5\n    ```\n\n- **Key Methods**:\n  - `getName()`: Returns the thread’s name (default: “main”).\n  - `setName(String name)`: Sets a custom name.\n  - `getPriority()`: Returns the thread’s priority.\n  - `isAlive()`: Checks if the thread is running.\n\n- **Relevance**:\n  - The main thread is the starting point for creating other threads.\n  - Exceptions in the main thread (if unhandled) terminate the program.\n\n---\n\n### 3. **Java Thread Model**\n\nJava’s thread model defines how threads are created, managed, and executed. It is built around the `Thread` class and `Runnable` interface, with support for thread lifecycle, scheduling, and synchronization.\n\n- **Creating Threads**:\n  1. **Extend `Thread` Class**:\n     - Override the `run()` method.\n     - Example:\n       ```java\n       package com.example.myapp;\n       public class MyThread extends Thread {\n           public void run() {\n               System.out.println(\"Thread running: \" + getName());\n           }\n           public static void main(String[] args) {\n               MyThread t1 = new MyThread();\n               t1.start(); // Starts the thread\n           }\n       }\n       ```\n  2. **Implement `Runnable` Interface** (Preferred):\n     - Implement the `run()` method.\n     - Pass the `Runnable` object to a `Thread` constructor.\n     - Example:\n       ```java\n       package com.example.myapp;\n       public class MyRunnable implements Runnable {\n           public void run() {\n               System.out.println(\"Runnable running: \" + Thread.currentThread().getName());\n           }\n           public static void main(String[] args) {\n               MyRunnable r = new MyRunnable();\n               Thread t1 = new Thread(r, \"RunnableThread\");\n               t1.start();\n           }\n       }\n       ```\n     - **Why Preferred?**: Allows the class to extend another class and promotes better design (separation of task and thread).\n\n- **Thread Lifecycle**:\n  - **New**: Thread created but not started (`new Thread()`).\n  - **Runnable**: Thread is ready to run after `start()` is called (may be running or waiting for CPU).\n  - **Blocked/Waiting**: Thread is waiting for a monitor lock (e.g., in `synchronized` block) or explicitly waiting (`wait()`, `sleep()`).\n  - **Timed Waiting**: Thread is waiting for a specified time (`sleep(millis)`, `wait(millis)`).\n  - **Terminated**: Thread has completed execution or stopped (`run()` finishes or exception occurs).\n\n- **Key Methods**:\n  - `start()`: Begins thread execution; calls `run()`.\n  - `run()`: Contains the thread’s task (override in `Thread` or implement in `Runnable`).\n  - `sleep(long millis)`: Pauses the thread for the specified time.\n  - `join()`: Makes the calling thread wait for this thread to finish.\n  - `interrupt()`: Interrupts the thread (e.g., to stop a sleeping thread).\n\n- **Thread States**:\n  - Use `Thread.getState()` to check the state (e.g., `NEW`, `RUNNABLE`, `TERMINATED`).\n\n- **Example with Lifecycle**:\n  ```java\n  package com.example.myapp;\n  public class ThreadDemo implements Runnable {\n      public void run() {\n          try {\n              System.out.println(\"Thread sleeping\");\n              Thread.sleep(1000);\n              System.out.println(\"Thread awake\");\n          } catch (InterruptedException e) {\n              System.out.println(\"Thread interrupted\");\n          }\n      }\n      public static void main(String[] args) throws InterruptedException {\n          Thread t1 = new Thread(new ThreadDemo());\n          System.out.println(\"State: \" + t1.getState()); // NEW\n          t1.start();\n          System.out.println(\"State: \" + t1.getState()); // RUNNABLE\n          t1.join();\n          System.out.println(\"State: \" + t1.getState()); // TERMINATED\n      }\n  }\n  ```\n\n- **Java’s Thread Model Features**:\n  - **Preemptive Scheduling**: JVM assigns CPU time to threads based on priority and scheduling.\n  - **Platform Independence**: Java threads are managed by the JVM, not the OS directly.\n  - **Daemon Threads**: Background threads (e.g., garbage collector) that terminate when all non-daemon threads finish. Set with `setDaemon(true)` before `start()`.\n\n---\n\n### 4. **Thread Priorities**\n\n**Thread priorities** determine the relative importance of threads, influencing the order in which the JVM schedules them for execution.\n\n- **Key Points**:\n  - Priorities range from `Thread.MIN_PRIORITY` (1) to `Thread.MAX_PRIORITY` (10), with `Thread.NORM_PRIORITY` (5) as the default.\n  - Higher-priority threads are scheduled before lower-priority ones, but this is **not guaranteed** (depends on the OS and JVM).\n  - Use sparingly, as over-reliance on priorities can lead to platform-dependent behavior.\n\n- **Methods**:\n  - `setPriority(int priority)`: Sets the thread’s priority.\n  - `getPriority()`: Returns the thread’s priority.\n\n- **Example**:\n  ```java\n  package com.example.myapp;\n  public class PriorityDemo {\n      public static void main(String[] args) {\n          Thread t1 = new Thread(() -> System.out.println(\"Low priority thread\"));\n          Thread t2 = new Thread(() -> System.out.println(\"High priority thread\"));\n          t1.setPriority(Thread.MIN_PRIORITY); // 1\n          t2.setPriority(Thread.MAX_PRIORITY); // 10\n          t1.start();\n          t2.start();\n      }\n  }\n  ```\n  - **Output**: Order is not guaranteed, but `t2` is likely to run first due to higher priority.\n\n- **Best Practices**:\n  - Avoid heavy reliance on priorities; use synchronization for critical tasks.\n  - Test threading behavior across platforms, as scheduling varies.\n\n---\n\n### 5. **Synchronization in Java**\n\n**Synchronization** ensures that only one thread can access a shared resource at a time, preventing race conditions and ensuring thread safety.\n\n- **Why Needed?**:\n  - Multiple threads accessing shared data (e.g., a counter) can lead to inconsistent results.\n  - Example (Race Condition):\n    ```java\n    package com.example.myapp;\n    public class Counter {\n        private int count = 0;\n        public void increment() {\n            count++; // Not thread-safe\n        }\n        public int getCount() {\n            return count;\n        }\n        public static void main(String[] args) throws InterruptedException {\n            Counter counter = new Counter();\n            Runnable task = () -> {\n                for (int i = 0; i < 1000; i++) {\n                    counter.increment();\n                }\n            };\n            Thread t1 = new Thread(task);\n            Thread t2 = new Thread(task);\n            t1.start();\n            t2.start();\n            t1.join();\n            t2.join();\n            System.out.println(\"Count: \" + counter.getCount()); // May not be 2000\n        }\n    }\n    ```\n\n- **Synchronization Mechanisms**:\n  1. **Synchronized Method**:\n     - Add the `synchronized` keyword to a method to lock the object’s monitor.\n     - Example:\n       ```java\n       public synchronized void increment() {\n           count++;\n       }\n       ```\n  2. **Synchronized Block**:\n     - Lock a specific object or block of code.\n     - Example:\n       ```java\n       public void increment() {\n           synchronized(this) {\n               count++;\n           }\n       }\n       ```\n  3. **Static Synchronization**:\n     - Use `synchronized` on static methods or blocks to lock the class’s monitor.\n     - Example:\n       ```java\n       public static synchronized void staticMethod() {\n           // Thread-safe\n       }\n       ```\n\n- **Thread-Safe Counter Example**:\n  ```java\n  package com.example.myapp;\n  public class Counter {\n      private int count = 0;\n      public synchronized void increment() {\n          count++;\n      }\n      public int getCount() {\n          return count;\n      }\n      public static void main(String[] args) throws InterruptedException {\n          Counter counter = new Counter();\n          Runnable task = () -> {\n              for (int i = 0; i < 1000; i++) {\n                  counter.increment();\n              }\n          };\n          Thread t1 = new Thread(task);\n          Thread t2 = new Thread(task);\n          t1.start();\n          t2.start();\n          t1.join();\n          t2.join();\n          System.out.println(\"Count: \" + counter.getCount()); // Always 2000\n      }\n  }\n  ```\n\n- **Key Points**:\n  - Synchronization uses a **monitor** (lock) to ensure mutual exclusion.\n  - Only one thread can hold the monitor at a time.\n  - Over-synchronization can reduce performance (use minimal synchronized blocks).\n  - Use `synchronized` blocks for fine-grained control.\n\n- **Connection to Exception Handling**:\n  - Synchronization may involve exceptions (e.g., `InterruptedException` in `wait()`).\n  - Example: Handle `InterruptedException` in synchronized code (see Interthread Communication).\n\n---\n\n### 6. **Interthread Communication**\n\n**Interthread communication** allows threads to coordinate by signaling each other, typically using `wait()`, `notify()`, and `notifyAll()`. This is more efficient than polling (e.g., checking a flag repeatedly).\n\n- **Key Methods** (Defined in `Object` class):\n  - `wait()`: Causes the current thread to wait (release the monitor) until another thread calls `notify()` or `notifyAll()` on the same object.\n  - `notify()`: Wakes up one waiting thread.\n  - `notifyAll()`: Wakes up all waiting threads.\n  - These methods must be called within a `synchronized` block or method.\n\n- **Example (Producer-Consumer Problem)**:\n  ```java\n  package com.example.myapp;\n  import java.util.LinkedList;\n  import java.util.Queue;\n  public class ProducerConsumer {\n      private Queue<Integer> queue = new LinkedList<>();\n      private final int LIMIT = 10;\n      public synchronized void produce(int item) throws InterruptedException {\n          while (queue.size() == LIMIT) {\n              wait(); // Wait if queue is full\n          }\n          queue.add(item);\n          System.out.println(\"Produced: \" + item);\n          notify(); // Notify consumer\n      }\n      public synchronized int consume() throws InterruptedException {\n          while (queue.isEmpty()) {\n              wait(); // Wait if queue is empty\n          }\n          int item = queue.remove();\n          System.out.println(\"Consumed: \" + item);\n          notify(); // Notify producer\n          return item;\n      }\n      public static void main(String[] args) {\n          ProducerConsumer pc = new ProducerConsumer();\n          Thread producer = new Thread(() -> {\n              try {\n                  for (int i = 1; i <= 5; i++) {\n                      pc.produce(i);\n                      Thread.sleep(100);\n                  }\n              } catch (InterruptedException e) {\n                  e.printStackTrace();\n              }\n          });\n          Thread consumer = new Thread(() -> {\n              try {\n                  for (int i = 1; i <= 5; i++) {\n                      pc.consume();\n                      Thread.sleep(200);\n                  }\n              } catch (InterruptedException e) {\n                  e.printStackTrace();\n              }\n          });\n          producer.start();\n          consumer.start();\n      }\n  }\n  ```\n  **Output** (Example):\n  ```\n  Produced: 1\n  Consumed: 1\n  Produced: 2\n  Consumed: 2\n  Produced: 3\n  ...\n  ```\n\n- **Key Points**:\n  - `wait()`, `notify()`, and `notifyAll()` require the thread to own the object’s monitor (i.e., be in a `synchronized` block).\n  - Use `while` loops (not `if`) to check conditions after `wait()` to handle spurious wakeups.\n  - `InterruptedException` must be handled when using `wait()` or `sleep()`.\n  - `notifyAll()` is safer than `notify()` when multiple threads are waiting.\n\n- **Alternatives**:\n  - Java’s `java.util.concurrent` package provides high-level constructs like `BlockingQueue`, `ExecutorService`, and `Lock` for better thread coordination.\n  - Example: Use `ArrayBlockingQueue` instead of manual `wait()/notify()`.\n\n---\n\n### **Practice Program**:\n   ```java\n   package com.example.myapp;\n   public class ThreadTest {\n       private static int sharedCounter = 0;\n       public static synchronized void increment() {\n           sharedCounter++;\n       }\n       public static void main(String[] args) throws InterruptedException {\n           Runnable task = () -> {\n               for (int i = 0; i < 1000; i++) {\n                   increment();\n               }\n           };\n           Thread t1 = new Thread(task, \"Thread1\");\n           Thread t2 = new Thread(task, \"Thread2\");\n           t1.setPriority(Thread.MAX_PRIORITY);\n           t2.setPriority(Thread.MIN_PRIORITY);\n           t1.start();\n           t2.start();\n           t1.join();\n           t2.join();\n           System.out.println(\"Final counter: \" + sharedCounter); // 2000\n       }\n   }\n   ```\n\n   **Compile and Run**:\n   ```bash\n   javac com/example/myapp/ThreadTest.java\n   java -cp . com.example.myapp.ThreadTest\n   ```\n"
  },
  {
    "url": "University/OOP/Module_4/IO.html",
    "content": "---\nid: IO\naliases: []\ntags: []\ntitle: IO\n---\n\n### 1. **I/O Basics**\n\n**Input/Output (I/O)** in Java refers to the process of reading data from a source (input) and writing data to a destination (output). Java provides a robust I/O framework to handle various data sources and destinations, such as files, console, network sockets, and memory.\n\n- **Key Concepts**:\n  - I/O operations are performed using **streams**, which are sequences of data.\n  - Java I/O is built around the `java.io` package, with additional support in `java.nio` (New I/O) for advanced operations.\n  - I/O operations often involve **exceptions** (e.g., `IOException`), requiring proper handling.\n\n- **Types of I/O**:\n  - **Byte-oriented I/O**: Handles raw binary data (e.g., images, files) using byte streams.\n  - **Character-oriented I/O**: Handles text data (e.g., Unicode characters) using character streams.\n  - **Buffered I/O**: Uses buffers to reduce direct access to underlying resources, improving performance.\n  - **Non-buffered I/O**: Direct access to resources, less efficient for frequent operations.\n\n- **Why Important?**:\n  - Enables interaction with external systems (files, network, console).\n  - Supports data persistence and communication.\n  - Critical for real-world applications (e.g., reading configuration files, logging).\n\n---\n\n### 2. **Streams and Stream Classes**\n\n**Streams** are abstractions for reading from or writing to a data source/destination. Java provides two main types of streams: **byte streams** and **character streams**, each with specific classes in the `java.io` package.\n\n- **Byte Streams**:\n  - Handle raw binary data (8-bit bytes).\n  - Base classes:\n    - `InputStream`: Abstract class for reading bytes.\n    - `OutputStream`: Abstract class for writing bytes.\n  - Common subclasses:\n    - `FileInputStream`, `FileOutputStream`: For file I/O.\n    - `BufferedInputStream`, `BufferedOutputStream`: For buffered I/O.\n    - `DataInputStream`, `DataOutputStream`: For reading/writing primitive data types.\n    - `ObjectInputStream`, `ObjectOutputStream`: For object serialization.\n\n- **Character Streams**:\n  - Handle Unicode characters (16-bit).\n  - Base classes:\n    - `Reader`: Abstract class for reading characters.\n    - `Writer`: Abstract class for writing characters.\n  - Common subclasses:\n    - `FileReader`, `FileWriter`: For file I/O.\n    - `BufferedReader`, `BufferedWriter`: For buffered I/O.\n    - `InputStreamReader`, `OutputStreamWriter`: Bridge between byte and character streams.\n\n- **Key Features**:\n  - **Chaining**: Streams can be wrapped (e.g., `BufferedReader` wraps `FileReader` for efficiency).\n  - **Closing**: Streams must be closed to release resources (use `close()` or try-with-resources).\n  - **Exceptions**: Most I/O operations throw `IOException` (checked exception).\n\n- **Example (Byte Stream)**:\n  ```java\n  package com.example.myapp;\n  import java.io.*;\n  public class ByteStreamDemo {\n      public static void main(String[] args) {\n          try (FileInputStream fis = new FileInputStream(\"input.txt\");\n               FileOutputStream fos = new FileOutputStream(\"output.txt\")) {\n              int byteData;\n              while ((byteData = fis.read()) != -1) { // Read byte\n                  fos.write(byteData); // Write byte\n              }\n          } catch (IOException e) {\n              System.out.println(\"Error: \" + e.getMessage());\n          }\n      }\n  }\n  ```\n\n- **Example (Character Stream)**:\n  ```java\n  package com.example.myapp;\n  import java.io.*;\n  public class CharStreamDemo {\n      public static void main(String[] args) {\n          try (BufferedReader reader = new BufferedReader(new FileReader(\"input.txt\"));\n               BufferedWriter writer = new BufferedWriter(new FileWriter(\"output.txt\"))) {\n              String line;\n              while ((line = reader.readLine()) != null) {\n                  writer.write(line);\n                  writer.newLine();\n              }\n          } catch (IOException e) {\n              System.out.println(\"Error: \" + e.getMessage());\n          }\n      }\n  }\n  ```\n\n- **Key Points**:\n  - Use byte streams for binary data, character streams for text.\n  - Buffering (e.g., `BufferedReader`) improves performance.\n  - Try-with-resources (Java 7+) ensures streams are closed automatically.\n\n---\n\n### 3. **The Predefined Streams**\n\nJava provides three **predefined streams** in the `java.lang.System` class for console I/O, automatically available in every program.\n\n- **System.in**:\n  - Type: `InputStream`.\n  - Purpose: Reads input from the console (standard input, typically the keyboard).\n  - Example: Use with `Scanner` or `BufferedReader`.\n\n- **System.out**:\n  - Type: `PrintStream`.\n  - Purpose: Writes output to the console (standard output).\n  - Example: `System.out.println(\"Hello\")`.\n\n- **System.err**:\n  - Type: `PrintStream`.\n  - Purpose: Writes error messages to the console (standard error).\n  - Example: `System.err.println(\"Error occurred\")`.\n\n- **Example**:\n  ```java\n  package com.example.myapp;\n  import java.io.*;\n  public class PredefinedStreamDemo {\n      public static void main(String[] args) {\n          BufferedReader reader = new BufferedReader(new InputStreamReader(System.in));\n          try {\n              System.out.println(\"Enter your name: \");\n              String name = reader.readLine();\n              System.out.println(\"Hello, \" + name);\n              System.err.println(\"This is an error message\");\n          } catch (IOException e) {\n              System.err.println(\"Error reading input: \" + e.getMessage());\n          }\n      }\n  }\n  ```\n\n- **Key Points**:\n  - `System.in` is typically wrapped with `BufferedReader` or `Scanner` for easier input.\n  - `System.out` and `System.err` are `PrintStream` objects, supporting methods like `println()` and `printf()`.\n  - These streams are automatically open and do not need closing.\n\n---\n\n### 4. **Reading from and Writing to Console**\n\nConsole I/O involves reading user input from the keyboard (`System.in`) and writing output to the console (`System.out`, `System.err`).\n\n- **Reading from Console**:\n  - Use `Scanner` (simpler) or `BufferedReader` (more control).\n  - Example with `Scanner`:\n    ```java\n    package com.example.myapp;\n    import java.util.Scanner;\n    public class ConsoleReadDemo {\n        public static void main(String[] args) {\n            Scanner scanner = new Scanner(System.in);\n            System.out.println(\"Enter an integer: \");\n            try {\n                int number = scanner.nextInt();\n                System.out.println(\"You entered: \" + number);\n            } catch (Exception e) {\n                System.err.println(\"Invalid input: \" + e.getMessage());\n            } finally {\n                scanner.close();\n            }\n        }\n    }\n    ```\n  - Example with `BufferedReader`:\n    ```java\n    package com.example.myapp;\n    import java.io.*;\n    public class ConsoleReadBufferedDemo {\n        public static void main(String[] args) {\n            try (BufferedReader reader = new BufferedReader(new InputStreamReader(System.in))) {\n                System.out.println(\"Enter text: \");\n                String text = reader.readLine();\n                System.out.println(\"You entered: \" + text);\n            } catch (IOException e) {\n                System.err.println(\"Error: \" + e.getMessage());\n            }\n        }\n    }\n    ```\n\n- **Writing to Console**:\n  - Use `System.out.println()`, `System.out.printf()`, or `System.out.print()`.\n  - Example:\n    ```java\n    System.out.println(\"Simple message\");\n    System.out.printf(\"Formatted: %d, %s%n\", 42, \"test\");\n    System.err.println(\"Error message\");\n    ```\n\n- **Key Points**:\n  - `Scanner` is easier for parsing numbers, strings, etc.\n  - `BufferedReader` is better for reading raw text or large inputs.\n  - Always handle `IOException` for `BufferedReader` and validate `Scanner` input.\n  - Use try-with-resources to close `Scanner` or `BufferedReader`.\n\n---\n\n### 5. **Reading and Writing Files**\n\nFile I/O involves reading from and writing to files using byte or character streams. Java provides classes like `FileInputStream`, `FileOutputStream`, `FileReader`, and `FileWriter`, often wrapped with buffered streams for efficiency.\n\n- **Reading a File**:\n  - Use `FileReader` with `BufferedReader` for text files.\n  - Use `FileInputStream` with `BufferedInputStream` for binary files.\n  - Example (Text File):\n    ```java\n    package com.example.myapp;\n    import java.io.*;\n    public class FileReadDemo {\n        public static void main(String[] args) {\n            try (BufferedReader reader = new BufferedReader(new FileReader(\"input.txt\"))) {\n                String line;\n                while ((line = reader.readLine()) != null) {\n                    System.out.println(line);\n                }\n            } catch (IOException e) {\n                System.err.println(\"Error reading file: \" + e.getMessage());\n            }\n        }\n    }\n    ```\n\n- **Writing to a File**:\n  - Use `FileWriter` with `BufferedWriter` for text files.\n  - Use `FileOutputStream` with `BufferedOutputStream` for binary files.\n  - Example (Text File):\n    ```java\n    package com.example.myapp;\n    import java.io.*;\n    public class FileWriteDemo {\n        public static void main(String[] args) {\n            try (BufferedWriter writer = new BufferedWriter(new FileWriter(\"output.txt\"))) {\n                writer.write(\"Hello, Java!\");\n                writer.newLine();\n                writer.write(\"This is a test.\");\n            } catch (IOException e) {\n                System.err.println(\"Error writing file: \" + e.getMessage());\n            }\n        }\n    }\n    ```\n\n- **Key Points**:\n  - Use try-with-resources to ensure streams are closed.\n  - Handle `IOException` (e.g., `FileNotFoundException` for missing files).\n  - Use `newLine()` for platform-independent line breaks in character streams.\n  - For appending to a file, use `FileWriter(file, true)` (append mode).\n\n- **File Class**:\n  - The `java.io.File` class represents file/directory paths.\n  - Methods: `exists()`, `isFile()`, `isDirectory()`, `createNewFile()`, `delete()`.\n  - Example:\n    ```java\n    File file = new File(\"data.txt\");\n    if (file.exists()) {\n        System.out.println(\"File size: \" + file.length());\n    }\n    ```\n\n---\n\n### 6. **The Transient and Volatile Modifiers**\n\nThe `transient` and `volatile` modifiers are related to I/O in the context of serialization and multithreading, respectively.\n\n- **Transient Modifier**:\n  - Used in **serialization** to mark fields that should **not** be serialized (saved) when an object is written to a stream.\n  - Serialization: Converting an object to a byte stream (e.g., using `ObjectOutputStream`).\n  - Example:\n    ```java\n    package com.example.myapp;\n    import java.io.*;\n    public class TransientDemo implements Serializable {\n        private String name;\n        private transient String password; // Not serialized\n        public TransientDemo(String name, String password) {\n            this.name = name;\n            this.password = password;\n        }\n        public static void main(String[] args) {\n            TransientDemo obj = new TransientDemo(\"Alice\", \"secret\");\n            // Serialize\n            try (ObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream(\"data.ser\"))) {\n                oos.writeObject(obj);\n            } catch (IOException e) {\n                System.err.println(\"Error: \" + e.getMessage());\n            }\n            // Deserialize\n            try (ObjectInputStream ois = new ObjectInputStream(new FileInputStream(\"data.ser\"))) {\n                TransientDemo deserialized = (TransientDemo) ois.readObject();\n                System.out.println(\"Name: \" + deserialized.name); // Alice\n                System.out.println(\"Password: \" + deserialized.password); // null\n            } catch (IOException | ClassNotFoundException e) {\n                System.err.println(\"Error: \" + e.getMessage());\n            }\n        }\n    }\n    ```\n\n- **Volatile Modifier**:\n  - Used in **multithreading** to ensure a variable’s value is always read from and written to **main memory**, preventing thread-local caching.\n  - Ensures **visibility** of changes across threads but does not guarantee atomicity.\n  - Example:\n    ```java\n    package com.example.myapp;\n    public class VolatileDemo {\n        private volatile boolean running = true;\n        public void stop() {\n            running = false;\n        }\n        public void run() {\n            while (running) {\n                System.out.println(\"Running...\");\n                try {\n                    Thread.sleep(500);\n                } catch (InterruptedException e) {\n                    System.err.println(\"Interrupted\");\n                }\n            }\n            System.out.println(\"Stopped\");\n        }\n        public static void main(String[] args) throws InterruptedException {\n            VolatileDemo demo = new VolatileDemo();\n            Thread t1 = new Thread(demo::run);\n            t1.start();\n            Thread.sleep(2000);\n            demo.stop();\n        }\n    }\n    ```\n\n- **Key Points**:\n  - `transient`: Prevents sensitive data (e.g., passwords) from being serialized.\n  - `volatile`: Ensures thread visibility for variables in multithreaded environments.\n  - Use `transient` in I/O (serialization), `volatile` in multithreading (with I/O implications for shared resources).\n\n---\n\n### 7. **Using Instance of Native Methods**\n\n**Native methods** are Java methods implemented in a non-Java language (e.g., C or C++) using the Java Native Interface (JNI). They are used for performance-critical tasks or to access platform-specific features not available in Java.\n\n- **Key Points**:\n  - Declared with the `native` keyword and no implementation in Java.\n  - Implemented in a native library (e.g., `.dll` on Windows, `.so` on Linux).\n  - Loaded using `System.loadLibrary()`.\n\n- **Syntax**:\n  ```java\n  public native void nativeMethod();\n  ```\n\n- **Example**:\n  ```java\n  package com.example.myapp;\n  public class NativeDemo {\n      public native void printHello();\n      static {\n          System.loadLibrary(\"NativeLib\"); // Load native library\n      }\n      public static void main(String[] args) {\n          NativeDemo demo = new NativeDemo();\n          demo.printHello(); // Calls native method\n      }\n  }\n  ```\n  - **C Implementation** (e.g., `NativeLib.c`):\n    ```c\n    #include <jni.h>\n    #include <stdio.h>\n    JNIEXPORT void JNICALL Java_com_example_myapp_NativeDemo_printHello(JNIEnv *env, jobject obj) {\n        printf(\"Hello from C!\\n\");\n    }\n    ```\n  - Compile and link the C code into a shared library (platform-specific).\n\n- **Steps to Use Native Methods**:\n  1. Declare the `native` method in Java.\n  2. Generate a header file using `javah` (or `javac -h` in Java 9+).\n  3. Implement the method in C/C++.\n  4. Compile the C/C++ code into a shared library.\n  5. Load the library with `System.loadLibrary()`.\n  6. Call the native method.\n\n- **Key Points**:\n  - Native methods are rare in standard I/O but used in libraries like `java.io` for low-level file operations.\n  - Risks: Platform dependence, memory leaks, and debugging complexity.\n  - Requires `CLASSPATH` to include native libraries.\n\n- **Connection to I/O**:\n  - Native methods are used in `java.io` classes (e.g., `FileInputStream`) for OS-level file access.\n  - Example: `FileInputStream.read()` may call native code for direct disk access.\n\n---\n\n### **Practice Program**:\n   ```java\n   package com.example.myapp;\n   import java.io.*;\n   import java.util.Scanner;\n   public class IODemo implements Serializable {\n       private String data;\n       private transient int temp;\n       public IODemo(String data, int temp) {\n           this.data = data;\n           this.temp = temp;\n       }\n       public static void main(String[] args) {\n           // Console I/O\n           Scanner scanner = new Scanner(System.in);\n           System.out.println(\"Enter text: \");\n           String input = scanner.nextLine();\n           System.out.println(\"You entered: \" + input);\n           scanner.close();\n           // File I/O\n           try (BufferedWriter writer = new BufferedWriter(new FileWriter(\"output.txt\"))) {\n               writer.write(input);\n           } catch (IOException e) {\n               System.err.println(\"Error writing file: \" + e.getMessage());\n           }\n           // Serialization\n           IODemo obj = new IODemo(\"Test\", 42);\n           try (ObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream(\"data.ser\"))) {\n               oos.writeObject(obj);\n           } catch (IOException e) {\n               System.err.println(\"Error serializing: \" + e.getMessage());\n           }\n       }\n   }\n   ```\n\n   **Compile and Run**:\n   ```bash\n   javac com/example/myapp/IODemo.java\n   java -cp . com.example.myapp.IODemo\n   ```\n"
  },
  {
    "url": "University/OOP/Module_4/Strings.html",
    "content": "---\nid: Strings\naliases: []\ntags: []\ntitle: Strings\n---\n\n### 1. **Fundamentals of Characters and Strings**\n\nCharacters and strings are essential for text processing in Java. They represent textual data and are widely used in I/O, user interfaces, and data manipulation.\n\n- **Characters**:\n  - Represented by the `char` primitive type or the `Character` wrapper class.\n  - Java uses **Unicode** (16-bit, UTF-16) to support international characters.\n  - Example: `'A'`, `'\\u0041'` (Unicode for 'A'), `'\\n'` (newline).\n  - `Character` class provides utility methods (e.g., `isDigit()`, `toUpperCase()`).\n  - Example:\n    ```java\n    char ch = 'A';\n    System.out.println(Character.isLetter(ch)); // true\n    System.out.println(Character.toLowerCase(ch)); // a\n    ```\n\n- **Strings**:\n  - Represented by the `String` class (immutable) or mutable classes like `StringBuffer` and `StringBuilder`.\n  - A `String` is a sequence of characters (e.g., `\"Hello\"`).\n  - Stored in the **String pool** (a special area in heap memory) for memory efficiency.\n  - Example:\n    ```java\n    String str = \"Hello\";\n    System.out.println(str.length()); // 5\n    ```\n\n- **Key Points**:\n  - `char` is a 16-bit Unicode character; `String` is a sequence of `char` values.\n  - Strings are **immutable** (cannot be modified after creation), ensuring thread-safety and memory efficiency.\n  - Use `Character` for character-specific operations, `String` for text manipulation.\n\n---\n\n### 2. **The String Class**\n\nThe `String` class, in the `java.lang` package, is used to create and manipulate immutable strings. It is one of the most commonly used classes in Java.\n\n- **Key Characteristics**:\n  - **Immutable**: Once created, a `String` object’s content cannot change (modifications create new `String` objects).\n  - Stored in the **String pool** for reuse (e.g., `\"Hello\"` is shared across variables).\n  - Automatically imported (no need for `import java.lang.String`).\n  - Supports various methods for manipulation, searching, and comparison.\n\n- **Creating Strings**:\n  - **Literal**: `String str = \"Hello\";` (uses String pool).\n  - **Constructor**: `String str = new String(\"Hello\");` (creates a new object in heap, not recommended).\n  - Example:\n    ```java\n    String s1 = \"Hello\"; // String pool\n    String s2 = \"Hello\"; // Reuses same object\n    String s3 = new String(\"Hello\"); // New object in heap\n    System.out.println(s1 == s2); // true (same pool reference)\n    System.out.println(s1 == s3); // false (different objects)\n    System.out.println(s1.equals(s3)); // true (same content)\n    ```\n\n- **Common Methods** (See **String Operations** for detailed usage):\n  - `length()`: Returns the number of characters.\n  - `charAt(int index)`: Returns the character at the specified index.\n  - `substring(int begin, int end)`: Extracts a portion of the string.\n  - `equals(Object obj)`: Compares content for equality.\n  - `compareTo(String other)`: Compares lexicographically.\n  - `toUpperCase()`, `toLowerCase()`: Converts case.\n  - `trim()`: Removes leading/trailing whitespace.\n  - `indexOf(String str)`: Finds the index of a substring.\n  - `replace(char old, char new)`: Replaces characters.\n\n- **Key Points**:\n  - Use `equals()` for content comparison, not `==` (which compares references).\n  - String literals are interned (stored in the String pool) for efficiency.\n  - Avoid excessive `String` concatenation in loops (use `StringBuilder` instead).\n\n---\n\n### 3. **String Operations**\n\nThe `String` class provides a rich set of methods for manipulating and processing strings. These operations are critical for text processing tasks.\n\n- **Common String Operations**:\n  ```java\n  package com.example.myapp;\n  public class StringOperationsDemo {\n      public static void main(String[] args) {\n          String str = \"  Hello, Java!  \";\n          // Length\n          System.out.println(\"Length: \" + str.length()); // 15\n          // Character access\n          System.out.println(\"Char at 2: \" + str.charAt(2)); // H\n          // Substring\n          System.out.println(\"Substring: \" + str.substring(2, 7)); // Hello\n          // Case conversion\n          System.out.println(\"Upper: \" + str.toUpperCase()); //   HELLO, JAVA!  \n          System.out.println(\"Lower: \" + str.toLowerCase()); //   hello, java!  \n          // Trim\n          System.out.println(\"Trim: \" + str.trim()); // Hello, Java!\n          // Replace\n          System.out.println(\"Replace: \" + str.replace(\"Java\", \"World\")); //   Hello, World!  \n          // Index of\n          System.out.println(\"Index of 'Java': \" + str.indexOf(\"Java\")); // 9\n          // Contains\n          System.out.println(\"Contains 'Hello': \" + str.contains(\"Hello\")); // true\n          // Comparison\n          String s1 = \"apple\";\n          String s2 = \"banana\";\n          System.out.println(\"Compare: \" + s1.compareTo(s2)); // Negative (apple < banana)\n          // Equality\n          System.out.println(\"Equals: \" + s1.equals(\"apple\")); // true\n          // Split\n          String csv = \"a,b,c\";\n          String[] parts = csv.split(\",\");\n          System.out.println(\"Split: \" + java.util.Arrays.toString(parts)); // [a, b, c]\n          // Concat\n          System.out.println(\"Concat: \" + s1.concat(\" pie\")); // apple pie\n      }\n  }\n  ```\n\n- **Key Operations**:\n  - **Accessing Characters**: `charAt()`, `toCharArray()` (converts to `char[]`).\n  - **Substrings**: `substring()` extracts portions (0-based indexing).\n  - **Searching**: `indexOf()`, `lastIndexOf()`, `contains()`.\n  - **Modification**: `replace()`, `replaceAll()` (regex), `trim()`.\n  - **Case Conversion**: `toUpperCase()`, `toLowerCase()`.\n  - **Comparison**: `equals()`, `equalsIgnoreCase()`, `compareTo()`, `compareToIgnoreCase()`.\n  - **Splitting/Joining**: `split()` (splits into array), `String.join()` (Java 8+).\n  - **Concatenation**: `concat()` or `+` operator (creates new `String`).\n\n- **Key Points**:\n  - Most operations return a **new** `String` due to immutability.\n  - Methods like `indexOf()` return `-1` if the substring is not found.\n  - Handle `StringIndexOutOfBoundsException` for invalid indices (e.g., `charAt(-1)`).\n  - Use `String.format()` or `printf()` for formatted strings.\n\n---\n\n### 4. **Data Conversion using valueOf() Methods**\n\nThe `String` class provides `valueOf()` methods to convert various data types (primitives, objects) into `String` representations. These are static methods used for data conversion.\n\n- **Syntax**:\n  ```java\n  String.valueOf(dataType value)\n  ```\n\n- **Supported Types**:\n  - Primitives: `int`, `long`, `float`, `double`, `boolean`, `char`.\n  - Objects: Any object (calls `toString()`).\n  - Arrays: `char[]`.\n\n- **Examples**:\n  ```java\n  package com.example.myapp;\n  public class ValueOfDemo {\n      public static void main(String[] args) {\n          // Primitives\n          int num = 42;\n          String str1 = String.valueOf(num); // \"42\"\n          double d = 3.14;\n          String str2 = String.valueOf(d); // \"3.14\"\n          boolean b = true;\n          String str3 = String.valueOf(b); // \"true\"\n          char ch = 'A';\n          String str4 = String.valueOf(ch); // \"A\"\n          // Array\n          char[] arr = {'H', 'i'};\n          String str5 = String.valueOf(arr); // \"Hi\"\n          // Object\n          Object obj = new Integer(100);\n          String str6 = String.valueOf(obj); // \"100\"\n          // Output\n          System.out.println(str1 + \", \" + str2 + \", \" + str3 + \", \" + str4 + \", \" + str5 + \", \" + str6);\n      }\n  }\n  ```\n  **Output**:\n  ```\n  42, 3.14, true, A, Hi, 100\n  ```\n\n- **Key Points**:\n  - `valueOf()` is overloaded for different types.\n  - For objects, `valueOf()` calls `toString()`; override `toString()` in custom classes for meaningful output.\n  - Alternative: Use `String.valueOf()` instead of concatenation with `\"\" + value` for clarity.\n  - `null` input returns the string `\"null\"`.\n\n- **Parsing Strings to Primitives** (Reverse Conversion):\n  - Use wrapper class methods: `Integer.parseInt()`, `Double.parseDouble()`, etc.\n  - Example:\n    ```java\n    String str = \"123\";\n    int num = Integer.parseInt(str); // 123\n    double d = Double.parseDouble(\"3.14\"); // 3.14\n    ```\n  - Handle `NumberFormatException` for invalid inputs.\n\n---\n\n### 5. **StringBuffer Class and Methods**\n\nThe `StringBuffer` class, in the `java.lang` package, provides a **mutable** alternative to `String` for efficient string manipulation, especially in scenarios involving frequent modifications (e.g., loops). It is **thread-safe** (synchronized), unlike `StringBuilder` (non-thread-safe, faster).\n\n- **Key Characteristics**:\n  - **Mutable**: Can modify contents without creating new objects.\n  - **Thread-safe**: Synchronized methods ensure safe use in multithreaded environments.\n  - Default capacity: 16 characters (expands automatically).\n\n- **Creating StringBuffer**:\n  ```java\n  StringBuffer sb1 = new StringBuffer(); // Empty, capacity 16\n  StringBuffer sb2 = new StringBuffer(\"Hello\"); // Initialized with \"Hello\"\n  StringBuffer sb3 = new StringBuffer(50); // Capacity 50\n  ```\n\n- **Common Methods**:\n  - **append(type value)**: Adds data (primitives, strings, objects) to the end.\n  - **insert(int offset, type value)**: Inserts data at the specified index.\n  - **delete(int start, int end)**: Removes characters from `start` to `end-1`.\n  - **replace(int start, int end, String str)**: Replaces characters with `str`.\n  - **reverse()**: Reverses the characters.\n  - **setCharAt(int index, char ch)**: Sets the character at `index`.\n  - **length()**: Returns the number of characters.\n  - **capacity()**: Returns the current capacity.\n  - **ensureCapacity(int minCapacity)**: Ensures at least the specified capacity.\n  - **toString()**: Converts to `String`.\n\n- **Example**:\n  ```java\n  package com.example.myapp;\n  public class StringBufferDemo {\n      public static void main(String[] args) {\n          StringBuffer sb = new StringBuffer(\"Hello\");\n          // Append\n          sb.append(\" Java\"); // Hello Java\n          System.out.println(\"Append: \" + sb);\n          // Insert\n          sb.insert(5, \",\"); // Hello, Java\n          System.out.println(\"Insert: \" + sb);\n          // Delete\n          sb.delete(0, 6); // Java\n          System.out.println(\"Delete: \" + sb);\n          // Replace\n          sb.replace(0, 4, \"World\"); // World\n          System.out.println(\"Replace: \" + sb);\n          // Reverse\n          sb.reverse(); // dlroW\n          System.out.println(\"Reverse: \" + sb);\n          // Capacity and length\n          System.out.println(\"Length: \" + sb.length()); // 5\n          System.out.println(\"Capacity: \" + sb.capacity()); // 21 (16 + \"Hello\".length())\n          // Convert to String\n          String result = sb.toString();\n          System.out.println(\"To String: \" + result);\n      }\n  }\n  ```\n  **Output**:\n  ```\n  Append: Hello Java\n  Insert: Hello, Java\n  Delete: Java\n  Replace: World\n  Reverse: dlroW\n  Length: 5\n  Capacity: 21\n  To String: dlroW\n  ```\n\n- **StringBuffer vs. StringBuilder**:\n  - `StringBuffer`: Thread-safe (synchronized), slower, used in multithreaded environments.\n  - `StringBuilder`: Not thread-safe, faster, used in single-threaded environments.\n  - Example (Use `StringBuilder` for better performance):\n    ```java\n    StringBuilder sb = new StringBuilder(\"Hello\");\n    sb.append(\" World\"); // Hello World\n    ```\n\n- **Key Points**:\n  - Use `StringBuffer` for thread-safe string manipulation.\n  - Use `StringBuilder` for single-threaded performance.\n  - Methods return the `StringBuffer` object (chaining possible, e.g., `sb.append(\"x\").append(\"y\")`).\n  - Handle `StringIndexOutOfBoundsException` for invalid indices.\n\n---\n\n### Connecting to Previous Topics\n\n- **Packages**:\n  - `String`, `StringBuffer`, and `Character` are in `java.lang` (automatically imported).\n  - Custom string utilities can be organized in packages (e.g., `com.example.myapp.utils`).\n  - Ensure classes using I/O or threading with strings are in the `CLASSPATH`.\n\n- **Interfaces**:\n  - `String` implements `CharSequence` (also implemented by `StringBuffer`, `StringBuilder`).\n  - Example: `CharSequence cs = \"Hello\";` or `CharSequence cs = new StringBuffer(\"Hello\");`.\n  - `Serializable` and `Comparable` are implemented by `String` and `StringBuffer`.\n\n- **Exception Handling**:\n  - String operations like `charAt()` or `substring()` throw `StringIndexOutOfBoundsException` (unchecked).\n  - Parsing with `Integer.parseInt()` throws `NumberFormatException`.\n  - Example:\n    ```java\n    try {\n        String str = \"abc\";\n        System.out.println(str.charAt(5)); // Throws StringIndexOutOfBoundsException\n    } catch (StringIndexOutOfBoundsException e) {\n        System.err.println(\"Invalid index: \" + e.getMessage());\n    }\n    ```\n\n- **Multithreading**:\n  - `String` is immutable and thread-safe by design.\n  - `StringBuffer` is synchronized, suitable for multithreaded environments.\n  - Example:\n    ```java\n    StringBuffer sb = new StringBuffer();\n    Runnable task = () -> sb.append(Thread.currentThread().getName() + \" \");\n    Thread t1 = new Thread(task);\n    Thread t2 = new Thread(task);\n    t1.start();\n    t2.start();\n    ```\n\n- **I/O**:\n  - Strings are used extensively in I/O (e.g., reading/writing files, console I/O).\n  - Example (Reading file into `String`):\n    ```java\n    try (BufferedReader reader = new BufferedReader(new FileReader(\"input.txt\"))) {\n        StringBuilder sb = new StringBuilder();\n        String line;\n        while ((line = reader.readLine()) != null) {\n            sb.append(line).append(\"\\n\");\n        }\n        String content = sb.toString();\n    } catch (IOException e) {\n        System.err.println(\"Error: \" + e.getMessage());\n    }\n    ```\n  - `transient` fields in serialized objects may include `String` or `StringBuffer`.\n\n---\n\n### **Practice Program**:\n   ```java\n   package com.example.myapp;\n   import java.io.*;\n   public class StringDemo {\n       public static void main(String[] args) {\n           // String operations\n           String str = \"  Hello, Java!  \";\n           System.out.println(\"Trim: \" + str.trim());\n           System.out.println(\"Substring: \" + str.substring(2, 7));\n           System.out.println(\"Replace: \" + str.replace(\"Java\", \"World\"));\n           // valueOf\n           int num = 42;\n           String strNum = String.valueOf(num);\n           System.out.println(\"valueOf: \" + strNum);\n           try {\n               int parsed = Integer.parseInt(strNum);\n               System.out.println(\"Parsed: \" + parsed);\n           } catch (NumberFormatException e) {\n               System.err.println(\"Invalid number: \" + e.getMessage());\n           }\n           // StringBuffer\n           StringBuffer sb = new StringBuffer(\"Java\");\n           sb.append(\" is fun!\");\n           sb.reverse();\n           System.out.println(\"StringBuffer: \" + sb);\n           // File I/O with String\n           try (BufferedWriter writer = new BufferedWriter(new FileWriter(\"output.txt\"))) {\n               writer.write(str);\n           } catch (IOException e) {\n               System.err.println(\"Error: \" + e.getMessage());\n           }\n       }\n   }\n   ```\n\n   **Compile and Run**:\n   ```bash\n   javac com/example/myapp/StringDemo.java\n   java -cp . com.example.myapp.StringDemo\n   ```\n"
  },
  {
    "url": "University/OOP/Module_4/Swing.html",
    "content": "---\nid: Swing\naliases: []\ntags: []\ntitle: Swing\n---\n\n### 1. **Swing Components**\n\n**Swing** is a Java library for creating platform-independent GUIs, part of the Java Foundation Classes (JFC) in the `javax.swing` package. Swing components are lightweight (drawn by Java, not native OS) and highly customizable.\n\n- **Key Characteristics**:\n  - Built on top of AWT (Abstract Window Toolkit) but more flexible and feature-rich.\n  - Components are in `javax.swing` (e.g., `JFrame`, `JButton`, `JLabel`).\n  - Platform-independent, with customizable look and feel.\n  - Supports MVC (Model-View-Controller) architecture for separating data and UI.\n\n- **Common Swing Components**:\n  - **Containers**:\n    - `JFrame`: Top-level window with a title bar and borders.\n    - `JPanel`: General-purpose container for grouping components.\n    - `JDialog`: Pop-up dialog for user interaction.\n  - **Basic Controls**:\n    - `JButton`: Clickable button.\n    - `JLabel`: Displays text or images.\n    - `JTextField`: Single-line text input.\n    - `JTextArea`: Multi-line text input.\n    - `JCheckBox`, `JRadioButton`: Selection options.\n    - `JComboBox`: Dropdown list.\n  - **Complex Components**:\n    - `JTable`: Displays tabular data.\n    - `JTree`: Displays hierarchical data.\n    - `JList`: Displays a list of items.\n  - **Menus**:\n    - `JMenuBar`, `JMenu`, `JMenuItem`: For menu systems.\n\n- **Example**:\n  ```java\n  package com.example.myapp;\n  import javax.swing.*;\n  public class SwingDemo {\n      public static void main(String[] args) {\n          JFrame frame = new JFrame(\"Swing Demo\");\n          frame.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);\n          frame.setSize(300, 200);\n          // Add components\n          JLabel label = new JLabel(\"Hello, Swing!\");\n          JButton button = new JButton(\"Click Me\");\n          JTextField textField = new JTextField(10);\n          JPanel panel = new JPanel();\n          panel.add(label);\n          panel.add(textField);\n          panel.add(button);\n          frame.add(panel);\n          frame.setVisible(true);\n      }\n  }\n  ```\n\n- **Key Points**:\n  - Always set `JFrame.setDefaultCloseOperation()` (e.g., `EXIT_ON_CLOSE`).\n  - Use `setVisible(true)` to display the frame.\n  - Components must be added to a container (e.g., `JPanel` or `JFrame`’s content pane).\n  - Swing components throw unchecked exceptions (e.g., `NullPointerException`) if misconfigured.\n\n---\n\n### 2. **Laying Out Components in a Container**\n\n**Layout managers** control the positioning and sizing of components within a container (e.g., `JPanel`, `JFrame`). Swing provides several layout managers to organize components flexibly.\n\n- **Common Layout Managers**:\n  - **`FlowLayout`**:\n    - Arranges components in a row, wrapping to the next line if needed.\n    - Default for `JPanel`.\n    - Example:\n      ```java\n      panel.setLayout(new FlowLayout());\n      panel.add(new JButton(\"Button 1\"));\n      panel.add(new JButton(\"Button 2\"));\n      ```\n  - **`BorderLayout`**:\n    - Divides the container into five regions: `NORTH`, `SOUTH`, `EAST`, `WEST`, `CENTER`.\n    - Default for `JFrame`’s content pane.\n    - Example:\n      ```java\n      frame.setLayout(new BorderLayout());\n      frame.add(new JButton(\"North\"), BorderLayout.NORTH);\n      frame.add(new JButton(\"Center\"), BorderLayout.CENTER);\n      ```\n  - **`GridLayout`**:\n    - Arranges components in a grid (equal-sized cells).\n    - Example:\n      ```java\n      panel.setLayout(new GridLayout(2, 2));\n      panel.add(new JButton(\"1\"));\n      panel.add(new JButton(\"2\"));\n      panel.add(new JButton(\"3\"));\n      panel.add(new JButton(\"4\"));\n      ```\n  - **`BoxLayout`**:\n    - Arranges components in a single row or column.\n    - Example:\n      ```java\n      panel.setLayout(new BoxLayout(panel, BoxLayout.Y_AXIS));\n      panel.add(new JButton(\"Top\"));\n      panel.add(new JButton(\"Bottom\"));\n      ```\n  - **`GridBagLayout`**:\n    - Highly flexible, grid-based layout with customizable constraints.\n    - Example:\n      ```java\n      panel.setLayout(new GridBagLayout());\n      GridBagConstraints gbc = new GridBagConstraints();\n      gbc.gridx = 0;\n      gbc.gridy = 0;\n      panel.add(new JButton(\"Button\"), gbc);\n      ```\n\n- **Example (Combining Layouts)**:\n  ```java\n  package com.example.myapp;\n  import javax.swing.*;\n  import java.awt.*;\n  public class LayoutDemo {\n      public static void main(String[] args) {\n          JFrame frame = new JFrame(\"Layout Demo\");\n          frame.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);\n          frame.setSize(400, 300);\n          // BorderLayout for frame\n          frame.setLayout(new BorderLayout());\n          // Panel with FlowLayout\n          JPanel topPanel = new JPanel(new FlowLayout());\n          topPanel.add(new JLabel(\"Top\"));\n          topPanel.add(new JTextField(10));\n          frame.add(topPanel, BorderLayout.NORTH);\n          // Panel with GridLayout\n          JPanel centerPanel = new JPanel(new GridLayout(2, 2));\n          centerPanel.add(new JButton(\"1\"));\n          centerPanel.add(new JButton(\"2\"));\n          centerPanel.add(new JButton(\"3\"));\n          centerPanel.add(new JButton(\"4\"));\n          frame.add(centerPanel, BorderLayout.CENTER);\n          frame.setVisible(true);\n      }\n  }\n  ```\n\n- **Key Points**:\n  - Set the layout manager using `setLayout()`.\n  - Use `null` layout for absolute positioning (not recommended, as it’s not responsive).\n  - Combine layouts by nesting panels with different layout managers.\n  - Layout managers handle resizing and alignment automatically.\n\n---\n\n### 3. **Panels**\n\n**Panels** (`JPanel`) are lightweight containers used to group and organize components within a larger container (e.g., `JFrame`). They are versatile and support any layout manager.\n\n- **Key Characteristics**:\n  - Default layout: `FlowLayout`.\n  - Can contain other components (e.g., buttons, labels) or nested panels.\n  - Used to modularize UI design (e.g., separate sections of a form).\n\n- **Example**:\n  ```java\n  package com.example.myapp;\n  import javax.swing.*;\n  import java.awt.*;\n  public class PanelDemo {\n      public static void main(String[] args) {\n          JFrame frame = new JFrame(\"Panel Demo\");\n          frame.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);\n          frame.setSize(300, 200);\n          // Main panel with BorderLayout\n          JPanel mainPanel = new JPanel(new BorderLayout());\n          // Sub-panel 1 (FlowLayout)\n          JPanel topPanel = new JPanel(new FlowLayout());\n          topPanel.add(new JLabel(\"Name:\"));\n          topPanel.add(new JTextField(10));\n          mainPanel.add(topPanel, BorderLayout.NORTH);\n          // Sub-panel 2 (GridLayout)\n          JPanel buttonPanel = new JPanel(new GridLayout(1, 2));\n          buttonPanel.add(new JButton(\"OK\"));\n          buttonPanel.add(new JButton(\"Cancel\"));\n          mainPanel.add(buttonPanel, BorderLayout.SOUTH);\n          frame.add(mainPanel);\n          frame.setVisible(true);\n      }\n  }\n  ```\n\n- **Key Points**:\n  - Use panels to break down complex UIs into manageable sections.\n  - Each panel can have its own layout manager.\n  - Add panels to `JFrame`’s content pane (`frame.add(panel)`).\n  - Panels are transparent by default; set background with `setBackground(Color)`.\n\n---\n\n### 4. **Look & Feel**\n\n**Look and Feel** (L&F) defines the visual appearance and behavior of Swing components (e.g., colors, fonts, borders). Swing supports pluggable look and feel, allowing you to change the UI style.\n\n- **Default Look and Feel**:\n  - Cross-platform (Java’s “Metal” look, or “Nimbus” in newer versions).\n  - Platform-specific (e.g., Windows, macOS) via `UIManager.setLookAndFeel()`.\n\n- **Changing Look and Feel**:\n  - Use `UIManager.setLookAndFeel(String className)` or predefined look and feel classes.\n  - Common options:\n    - `com.sun.java.swing.plaf.nimbus.NimbusLookAndFeel` (modern, cross-platform).\n    - `UIManager.getSystemLookAndFeelClassName()` (native OS look).\n  - Example:\n    ```java\n    package com.example.myapp;\n    import javax.swing.*;\n    import java.awt.*;\n    public class LookAndFeelDemo {\n        public static void main(String[] args) {\n            try {\n                // Set Nimbus Look and Feel\n                UIManager.setLookAndFeel(\"javax.swing.plaf.nimbus.NimbusLookAndFeel\");\n            } catch (Exception e) {\n                System.err.println(\"Error setting look and feel: \" + e.getMessage());\n            }\n            JFrame frame = new JFrame(\"Look and Feel Demo\");\n            frame.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);\n            frame.setSize(300, 200);\n            JPanel panel = new JPanel();\n            panel.add(new JButton(\"Click Me\"));\n            panel.add(new JLabel(\"Nimbus Look\"));\n            frame.add(panel);\n            frame.setVisible(true);\n        }\n    }\n    ```\n\n- **Key Points**:\n  - Set look and feel before creating components for consistency.\n  - Handle exceptions (`UnsupportedLookAndFeelException`, etc.).\n  - Use `UIManager.getInstalledLookAndFeels()` to list available L&Fs.\n  - Nimbus is recommended for modern applications.\n\n---\n\n### 5. **Event Listeners**\n\n**Event listeners** handle user interactions (e.g., button clicks, key presses, mouse movements) in Swing. Swing uses the **event-driven programming** model, where events trigger listener methods.\n\n- **Key Concepts**:\n  - **Event**: An object (e.g., `ActionEvent`, `MouseEvent`) representing a user action.\n  - **Listener**: An interface (e.g., `ActionListener`, `MouseListener`) defining methods to handle events.\n  - **Source**: The component generating the event (e.g., `JButton`).\n  - Register listeners using `addXXXListener()` methods (e.g., `addActionListener()`).\n\n- **Common Listeners**:\n  - `ActionListener`: Handles actions (e.g., button clicks, menu selections).\n    - Method: `actionPerformed(ActionEvent e)`.\n  - `MouseListener`: Handles mouse events (e.g., clicks, enters/exits).\n    - Methods: `mouseClicked()`, `mousePressed()`, etc.\n  - `KeyListener`: Handles keyboard events.\n    - Methods: `keyPressed()`, `keyReleased()`, `keyTyped()`.\n  - `WindowListener`: Handles window events (e.g., closing, opening).\n    - Methods: `windowClosing()`, `windowOpened()`, etc.\n\n- **Example (ActionListener)**:\n  ```java\n  package com.example.myapp;\n  import javax.swing.*;\n  import java.awt.event.*;\n  public class EventListenerDemo {\n      public static void main(String[] args) {\n          JFrame frame = new JFrame(\"Event Demo\");\n          frame.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);\n          frame.setSize(300, 200);\n          JPanel panel = new JPanel();\n          JButton button = new JButton(\"Click Me\");\n          JTextField textField = new JTextField(10);\n          // Add ActionListener\n          button.addActionListener(new ActionListener() {\n              @Override\n              public void actionPerformed(ActionEvent e) {\n                  textField.setText(\"Button Clicked!\");\n              }\n          });\n          panel.add(button);\n          panel.add(textField);\n          frame.add(panel);\n          frame.setVisible(true);\n      }\n  }\n  ```\n\n- **Lambda Expression (Java 8+)**:\n  ```java\n  button.addActionListener(e -> textField.setText(\"Button Clicked!\"));\n  ```\n\n- **Key Points**:\n  - Listeners are interfaces; implement them using classes, anonymous classes, or lambdas.\n  - Multiple listeners can be added to a component.\n  - Use `getSource()` or `getActionCommand()` in `ActionEvent` to identify the source.\n  - Handle exceptions (e.g., `IllegalArgumentException`) for invalid listener configurations.\n\n---\n\n### 6. **Concurrency in Swing**\n\nSwing is **not thread-safe**, meaning most Swing components must be accessed from the **Event Dispatch Thread (EDT)**, a single thread responsible for handling GUI events and updates. Concurrency in Swing ensures responsive UIs during long-running tasks.\n\n- **Key Concepts**:\n  - **Event Dispatch Thread (EDT)**:\n    - Handles all GUI events (e.g., button clicks, repaints).\n    - All Swing component creation and updates must occur on the EDT.\n  - **SwingUtilities.invokeLater()**:\n    - Schedules code to run on the EDT.\n    - Example:\n      ```java\n      SwingUtilities.invokeLater(() -> {\n          JFrame frame = new JFrame(\"Demo\");\n          frame.setVisible(true);\n      });\n      ```\n  - **SwingUtilities.invokeAndWait()**:\n    - Runs code on the EDT and waits for completion (used rarely).\n  - **Worker Threads**:\n    - Perform long-running tasks (e.g., file I/O, network calls) off the EDT to avoid freezing the UI.\n    - Use `SwingWorker` for background tasks with UI updates.\n\n- **SwingWorker**:\n  - A utility class (`javax.swing.SwingWorker`) for running tasks in a background thread and updating the UI on the EDT.\n  - Methods:\n    - `doInBackground()`: Runs the task in a worker thread.\n    - `done()`: Executes on the EDT after the task completes.\n    - `publish()/process()`: Sends intermediate results to the EDT.\n\n- **Example (SwingWorker)**:\n  ```java\n  package com.example.myapp;\n  import javax.swing.*;\n  import java.awt.*;\n  import java.util.List;\n  public class ConcurrencyDemo {\n      public static void main(String[] args) {\n          SwingUtilities.invokeLater(() -> {\n              JFrame frame = new JFrame(\"Concurrency Demo\");\n              frame.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);\n              frame.setSize(300, 200);\n              JLabel label = new JLabel(\"Waiting...\");\n              JButton button = new JButton(\"Start Task\");\n              JPanel panel = new JPanel();\n              panel.add(button);\n              panel.add(label);\n              frame.add(panel);\n              // ActionListener with SwingWorker\n              button.addActionListener(e -> {\n                  SwingWorker<String, String> worker = new SwingWorker<>() {\n                      @Override\n                      protected String doInBackground() throws Exception {\n                          // Simulate long-running task\n                          for (int i = 1; i <= 5; i++) {\n                              Thread.sleep(1000);\n                              publish(\"Processing \" + i + \"...\");\n                          }\n                          return \"Task Completed!\";\n                      }\n                      @Override\n                      protected void process(List<String> chunks) {\n                          // Update UI on EDT\n                          label.setText(chunks.get(chunks.size() - 1));\n                      }\n                      @Override\n                      protected void done() {\n                          try {\n                              label.setText(get()); // Final result\n                          } catch (Exception ex) {\n                              label.setText(\"Error: \" + ex.getMessage());\n                          }\n                      }\n                  };\n                  worker.execute();\n              });\n              frame.setVisible(true);\n          });\n      }\n  }\n  ```\n\n- **Key Points**:\n  - Always create and modify Swing components on the EDT (`invokeLater()`).\n  - Use `SwingWorker` for background tasks to keep the UI responsive.\n  - Avoid long-running tasks on the EDT to prevent freezing.\n  - Handle exceptions (e.g., `InterruptedException`, `ExecutionException`) in `SwingWorker`.\n\n---\n\n### Connecting to Previous Topics\n\n- **Packages**:\n  - Swing classes are in `javax.swing` and `java.awt`.\n  - Custom Swing applications should be organized in packages (e.g., `com.example.myapp.gui`).\n  - Ensure `CLASSPATH` includes Swing libraries (standard in Java).\n\n- **Interfaces**:\n  - Event listeners (e.g., `ActionListener`, `MouseListener`) are interfaces.\n  - Example: `public class MyListener implements ActionListener`.\n  - Swing components implement interfaces like `Serializable` and `Accessible`.\n\n- **Exception Handling**:\n  - Swing operations may throw unchecked exceptions (e.g., `NullPointerException`, `IllegalArgumentException`).\n  - `SwingWorker` tasks may throw `InterruptedException` or `ExecutionException`.\n  - Example:\n    ```java\n    try {\n        Thread.sleep(1000); // In SwingWorker\n    } catch (InterruptedException e) {\n        System.err.println(\"Task interrupted\");\n    }\n    ```\n\n- **Multithreading**:\n  - Swing relies on the EDT, a single-threaded model.\n  - Use `SwingWorker` or `invokeLater()` for thread-safe GUI updates.\n  - `volatile` or synchronized methods may be used in Swing applications for shared data.\n\n- **I/O**:\n  - Swing applications often read/write files (e.g., saving user preferences).\n  - Example: Use `JFileChooser` for file selection.\n    ```java\n    JFileChooser chooser = new JFileChooser();\n    if (chooser.showOpenDialog(frame) == JFileChooser.APPROVE_OPTION) {\n        File file = chooser.getSelectedFile();\n        // Read file\n    }\n    ```\n\n- **Strings and Characters**:\n  - Swing components use `String` for text (e.g., `JLabel.setText(\"Hello\")`).\n  - Use `StringBuilder` for dynamic text updates in `SwingWorker`.\n  - Example:\n    ```java\n    StringBuilder sb = new StringBuilder();\n    sb.append(\"Result: \").append(count);\n    label.setText(sb.toString());\n    ```\n\n---\n### **Practice Program**:\n   ```java\n   package com.example.myapp;\n   import javax.swing.*;\n   import java.awt.*;\n   import java.awt.event.*;\n   public class SwingApp {\n       public static void main(String[] args) {\n           SwingUtilities.invokeLater(() -> {\n               JFrame frame = new JFrame(\"Swing App\");\n               frame.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);\n               frame.setSize(400, 300);\n               // Panel with BorderLayout\n               JPanel panel = new JPanel(new BorderLayout());\n               // Top: Input\n               JPanel topPanel = new JPanel(new FlowLayout());\n               JTextField textField = new JTextField(10);\n               topPanel.add(new JLabel(\"Enter text:\"));\n               topPanel.add(textField);\n               panel.add(topPanel, BorderLayout.NORTH);\n               // Center: Output\n               JLabel outputLabel = new JLabel(\"Output: \");\n               panel.add(outputLabel, BorderLayout.CENTER);\n               // Bottom: Button\n               JButton button = new JButton(\"Submit\");\n               button.addActionListener(e -> {\n                   SwingWorker<Void, String> worker = new SwingWorker<>() {\n                       @Override\n                       protected Void doInBackground() throws Exception {\n                           publish(\"Processing: \" + textField.getText());\n                           Thread.sleep(1000);\n                           return null;\n                       }\n                       @Override\n                       protected void process(java.util.List<String> chunks) {\n                           outputLabel.setText(chunks.get(chunks.size() - 1));\n                       }\n                   };\n                   worker.execute();\n               });\n               panel.add(button, BorderLayout.SOUTH);\n               frame.add(panel);\n               try {\n                   UIManager.setLookAndFeel(\"javax.swing.plaf.nimbus.NimbusLookAndFeel\");\n               } catch (Exception ex) {\n                   System.err.println(\"Look and feel error: \" + ex.getMessage());\n               }\n               frame.setVisible(true);\n           });\n       }\n   }\n   ```\n\n   **Compile and Run**:\n   ```bash\n   javac com/example/myapp/SwingApp.java\n   java -cp . com.example.myapp.SwingApp\n   ```\n"
  },
  {
    "url": "index.html",
    "content": "---\nid: index\naliases: []\ntags: []\n---\n\nHi and welcome to my part of the internet \n\nI'm <u>**quantinium**</u>, just another university student having fun programming in <u>**neovim**</u> and learning new stuff in this field everyday. \n\n**Open to new roles**.\n\n### Projects\n- [**Lomes**](https://github.com/quantinium03/lomes) - A self-hosting media server  \n- [**grimoire**](https://github.com/quantinium03/grimoire) - A static site generator  \n- [**Webalyze**](https://github.com/quantinium03/webalyze) - Analyze and summarize any site on the web  \n- [**lated**](https://github.com/quantinium03/lated) - Online LaTeX editor and PDF converter  \n- [**Asami**](https://github.com/quantinium03/asami) - Asciify any image  \n\n\n### Contact\n- [X](https://x.com/quantinium_dev)\n- [github](https://github.com/quantinium03)\n- email - quantinium.dev@gmail.com\n- discord - quantinium.dev\n\n### Stats\n"
  }
]